[{"title":"秋招的终局之战：意向书、offer 选择与三方","path":"/post/秋招指南/salary-negotiation/","content":"关于校招，我发现目前网上可参考的资料一般都是面试注意事项和面试经验，关于面试通过之后要怎么做的经验特别少。比方说面完 hr 面我该干嘛？谈薪的时候是怎么谈的？收到意向书是不是就可以什么都不管了？有这么多 offer 我该怎么选？我要拒绝 offer 最好什么时候说？怎么说？有没有模板？等等。 对于大多数人来说，我们都是第一次拿到 offer，甚至是第一次参加面试，对于这些相关的流程一窍不通。但是用人单位呢，他们大多已经举办了多届招聘，对于应届生的心态了如指掌，关键时刻打电话给你这么一催，你就容易上头，本来还在犹豫的 offer 也不等了。这就造成同学们前期不知道进行到哪一步了，下一步要做什么该做什么，整天检查邮箱生怕到手的 offer 因为没完成某个步骤而丢掉了，后期在面对多个 offer 的时候不知道该用什么标准来选择，被 hr 忽悠了去，错失了 argue 的机会或者跳到坑里去。 所以我写这篇文章的目的很简单，就是整理一下互联网秋招后期，主要是拿到 offer 之后的攻略，为大家的 offer 锦上添花。 HR 面结束后的全流程这里只列举秋招面完hr面之后的流程，从投递到面试的过程不考虑在这篇文章之内，并且不同公司和不同学校的要求可能有所不同。 hr 面结束 做测评（百度华为等才会有）：测评主要是测试你的性格和一些行测题目，认真做就行，只要不是非常离谱都会过的，测评很少有卡人的。收到测评一般来说就意味着你面试通过了。 hr 打电话问你愿不愿意去实习（百度、快手等）：如果加了 hr 微信可能会在微信上问。比较缺人的组就会有这样子问，实习一般都不是必须，不过能去实习的话用人单位会比较喜欢，对于你上手工作也比较快，有的公司会将这一段实习时间算在晋升考核时间里，也就是晋升会更快。 hr 打电话发口头 offer（也就是 oc）：口头 offer 就是你通过了所有面试，这个口头 offer 约束力没那么强，也不会透露你的薪资，但是有 hr 会问你期望薪资是多少（比如 shopee），这个时候建议做好准备，给 hr 报一个年薪下限。我的经验是去找小伙伴，找到同样投这个公司的小伙伴的 QQ 群或者微信群，大家信息互通一下（不是说让你交流薪资啊！高压线），看看大家对于期望薪资是怎么报的，参考一下，然后也可以互相交流一下。 找这些群的渠道有：在牛客网上这个公司的话题里面找帖子，或者发帖求组团；问身边已经加入群组的人拉你进去。 第二个是看看 offershow，看往年相同职位的薪资，然后参考今年的整体情况报一下，给 hr 报的时候不能报具体数字，也不要报上限，建议就报一个下限，比如说我希望公司能给我不低于 30 万的年薪。但这个薪资不是最终的，这个时候除非是特别不想去的公司，一般建议都接下口头 offfer（或者说养鱼）。 座谈会（只有 TP-LINK 有）：座谈会就是发一封邮件约定某个时间参与一个线上会议，同一批次很多个候选人一起参加，主要是 hr 宣讲公司情况，福利待遇，和接下来的流程。座谈会上不会透露薪资情况，因为通常这个时候当年的薪酬方案还没做出来（薪酬方案每年都要重新做，因为市场薪酬价格一直在变）。就是了解一下公司的，只需要听就行，不听也行。 云证信息（只有腾讯有）。会发一封邮件让你验证身份，就是扫码通过微信小程序做一下人脸识别，不需要准备其他手续材料。 邮件意向书：一般邮件意向书会在 oc 之后，你接受 oc 之后才有。注意，意向书也不能和 offer 划等号，这个意向书只是说我们公司承诺给你这个 offer，并且意向书上通常不会有薪资情况。有的公司会要求回复意向书，因为这个意向书可以视作两方协议，关于两方协议，相关工作里面有介绍，没有法律约束力，可以随意毁两方，并且通常是没有违约金的。注意看意向书邮件的末尾是否说了需要回复，或者点击链接确认，以及有效期，否则没有及时回复或确认可能会错失 offer！通常来说，收到意向书就 99% 稳了，一般很少有毁意向书的。这个时候除非特别不想去或者说明确说明两方违约要交违约金，一般建议接下意向书（或者说养鱼）。 谈薪：也就是俗称的“开奖”，通常形式是 hr 打电话过来跟你聊你的薪资情况。有几点需要注意的： 第一，hr 会问你手头都有什么 offer，薪资分别是多少，这个时候如果有其他的，就报一下，hr 可能会让你发意向书邮件截图或者带薪 offer 的薪资截图，如果你的其他 offer 确实很好，hr 会考虑给你重新确定薪酬方案（因为薪酬方案是已经确定的，要改的话要重新定），但一般不会因为你只有他一家 offer 立马 pua 压价（薪酬方案一般做出来了就不会临时改动）。 第二，有很多公司虽然说是谈薪，其实只是通知你一下你的薪酬方案是多少，不要以为 hr 会像面试一样花半个小时跟你讨论你的薪资该怎么分配。他把台词读完了之后会问你对 offer 有什么问题吗，要接 offer 吗，这时候如果你有更好的 offer 要 argue，就要在这个时候提出你的要求，比如不能比某某公司的薪酬低，总包不能低于多少多少等等，记住不要说确定的数字比如我要总包 42W，一定要说一个范围或者下限。如果你觉得这个 offer 不 ok，直接说很抱歉我不能接受这个薪酬或者我已经有更好的 offer 了。 第三，谈薪时间是不会提前约定的，谈薪电话通常会毫无征兆的打过来，如果漏接了也没关系，hr 会过几个小时再打一次，如果一直打不通，会给你发邮件的（亲测 TP-LINK 在多次打不通我的电话之后给我发了一封邮件约谈薪时间），如果你有加等开奖群，你会发现群里会一个接一个的有人开奖，如果开奖的跟你是同一个部门的，那你就要做好接电话的准备了。并且一个谈薪电话通常很短，没有 argue 环节的话通常不超过 5 分钟，hr 语速拉满，仿佛台词烫嘴，这个时候如果听不清，最好的方法是开启通话录音。并且如果公司 hr 收到拒 offer 反馈太多了还会二次谈薪（比如 2020 年秋招的百度、shopee 等等，第一次谈薪后又涨了一波，给所有人又打电话谈了一次薪），甚至你都已经接了还会再谈薪一次。如果有些公司催你接 offer 而另一些公司还没有到谈薪的地步，那你要拖一下，另外用这个已经谈薪的 offer 去催那个没谈薪的，一般你跟 hr 说一下有效期，对方会很快给你谈薪的。 签三方：这是最重要的一步！三方的形式有网签三方和纸质三方，根据发起方不同有学校发起和公司发起，这个要看学校，对，这是学校定的而不是公司规定的。比如广东的高校采用的就是网签三方的形式，且无需公司发起，通过小程序“广东大学生就业创业”来完成。 带薪 offer（大部分银行没有带薪 offer）：很多公司是在收到三方之后才会发放带薪 offer。带薪 offer 这个就是最终的 offer 啦，这个带薪 offer 会详细写明你的职位，福利和薪资，offer 上面数据可能会和三方不同或者跟 hr 跟你讲的不同，比方说签字费总包房补啥的，数字都需要好好看一下。这个带薪 offer 一般都是不需要确认的，但是为了稳妥起见，建议通读 offer 邮件全文。 填入职信息（比如腾讯）和申请实习：有的公司在带薪 offer 里面会提供入职信息填写的链接，这个时候就要填你的入职信息了，通常需要准备工牌照、英文名、毕业时间、入职时间等等。有些信息确实太早没法确定，可以问一下师兄师姐往年情况或者 hr 这种不确定的情况怎么处理。 选择 offer 考虑因素 更多参考链接：分享 offer 选择 这个东西非常主观的其实，因人而异，因为每个人考虑问题的时候最关心的点不同，比如有的人面向薪资编程，有的人家里不缺钱就想找个稳定的工作融入社会，有的人想跟 npy 待的近些，有的人非大厂不去，等等。我在这里结合自身心路历程和相关资料总结列举一下可能需要考虑的因素，具体每个因素怎么看待要看同学们了。其实适合自己的自己喜欢就行，没有必要掂量来掂量去的，比别人好也不见得是永远都好，以下各条因素之间并无排序，并不表示某一个比较重要，看个人偏好。 薪资（offershow）：一般来说这个具体看自己得到的薪酬跟同年同岗位应届生相比是什么水平（这个可以在 offershow 小程序里面看得到），跟往年同岗位相比什么水平，以及跟自己同实验室或者水平相当的同学相比什么水平，如果相差的比较大，先考虑能不能 argue，不能 argue 基本可以确定是公司开给你的劝退价，别去了。还要看薪资的构成，总包具体包括哪些？分几年给？加班费另外算还是算在了月薪里面？是不是把房补餐补也算在里面了？年终有多大的比例能拿满？通常来说薪资&#x3D;base+签字费+股票（+房补+餐补+加班费+人才补贴），base 就是基本工资，通常是 M×N 的形式，以 32×16 为例，这个 base 的意思就是每个月月薪 32000，16 是一年发 16 个月，因为一年只有 12 个月，那么也就是说年终奖金是 16-12&#x3D;4 个月的月薪，也就是 128000 元的年终。签字费也在很多公司里面有，意思就是你在劳动合同上签字我就给你这笔钱，一次性的。 base 地：base 地就是你将在哪个城市工作。base 地我们要考虑什么呢，通常来说同学们都会选择离家比较近的，或者当地有人才补贴的，落户比较方便的，房价比较低的，跟好朋友或者 npy 比较近的，这个 base 是不是总部，这个城市互联网产业发展好不好，机会多不多，气候怎么样。通常来说在总部比较好一些，年会什么的在总部举办的活动要大一些，总部的设施要完善一些，leader 一般都在总部。如果你打算在哪里工作哪里买房定居，那么户口和房价应该好好考虑一下，当然如果打算干两年回老家就不用了。 公司规模：看公司的平台大不大，对于应届生来说，第一份工作最好选平台比较大的，大公司流程比较规范，以后跳槽的时候简历上有一条比较加分的工作经历。并且大公司一般来说不会出现不良行为。在牛客文章「分享 offer 选择」中就有比较小公司之间的 offer 该怎么选和大公司之间的 offer 该怎么选的建议，在这里就不多说了，我觉得这篇文章总结的就很好。 是不是核心业务：每个大公司都有自己主打的业务，或者公司的营收主要靠某项业务支撑，那么最好了解一下自己的 team 是不是这项业务的。如果自己的业务是核心业务的话，能得到公司的重视，做的事情都不是小儿科，能够得到极大的锻炼机会，并且核心业务通常赚钱多，相应的绩效和年终也会很多。不过最近技术中台的职位也是比较受欢迎的，这种职位一般都是为各个业务提供接口，做业务的通常就是 ToC 的，技术中台则通常是 ToB 的，并且一般 ToB 的没有 ToC 的赚钱多，但是也没有 ToC 这么累。 公司文化（脉脉）：看个人对公司文化的喜好吧，可以问问身边一些已经在公司入职的学长学姐们，毕竟坊间的一些传闻多是添油加醋的，分分钟让你感觉像火坑，但是实际上感觉如何还是看个人的。具体就是你要去的那个组好不好了，可以让已经在公司工作的人内部打听一下，也可以到脉脉上看看（btw 脉脉上的东西建议不要过于迷信） 薪资组成结构年包：base (基本工资 + 绩效 + 年终奖) + 期权&#x2F;股票 + 签字费 ⚠️ 互联网没有绩效，华为有绩效 薪资结构：薪资通常由基本工资 + 绩效工资构成。有些公司会将绩效工资设的较高，这虽然可能赚的更多，但也意味着更大的不确定性，往往比较卷。 五险一金：尤其关注社保和公积金的缴纳基数与比例。多数私企不会按全额月薪缴纳，但缴纳基数和比例越高对个人越有利。 年终奖：了解年终奖的评估标准，如是否固定发放、基于个人或公司绩效等，并询问普通员工的一般绩效水平。年终奖通常以 15 薪、16 薪等形式体现，表现突出者可获得更高奖金。 补贴：确认是否有餐补、交通补助、季节性补贴、住房补贴及生日福利等额外补贴，这些都是收入的一部分。 福利：健身房（建议考察其设施规模）、食堂、茶水间零食饮料、夜宵以及员工折扣等福利也挺重要的。 其他福利：留意是否有签字费、安家费或政府人才补贴等一次性或阶段性奖励。比如杭州就有人才补贴，相当于变相提高了收入。 如何谈薪？ 参考链接： 如何谈薪 HR 常见压价话术 + 谈薪公式 2025 届秋招谈薪急救指南 如何跟 hr 聊薪资，argue 薪资的技巧全在这里 谈薪时间及基本常识 谈薪时间（HR 面后还需要确定是否给你发放 offer，发放 offer 后一段时间才会统一约谈薪资） 互联网企业大致在 10 月底 &#x2F; 11 月初高峰统一谈薪，逼签三方 如果是体制内 &#x2F; 国企，一般是直接面试完现场谈薪，而且这个薪资基本无法谈（argue） ⚠️ 互联网没有绩效（月薪 &#x3D; base），华为才有绩效（月薪 &#x3D; base + 绩效） 期望薪资：顾名思义就是你自己期望在这份工作中得到的薪资，通常有两种说法，不同公司 hr 方式不一样 一种是月薪，比如 30k 还有一种就是总包，比如年薪 50w 签字费：签字费就是签订了三方入职之后，公司会直接发到你账户一笔费用，这也是近些年公司们对人才争夺的一种方式。 白菜价（校招中最基础的 offer）、sp (special offer)、ssp (super special offer) … 谈薪谈的是什么？ 薪资中的固定部分：基本月薪如何发放？有没有拆分？如果有，不算绩效、补贴、提成的话，写在合同里的基本月薪是多少？ 薪资中的浮动部分：绩效奖金、提成的发放标准是什么？计算逻辑是怎样的？公司有百分之几的人能够拿到全额奖金？有没有机会拿到超额奖金？ 几险几金？缴纳基数是多少？缴纳比例是多少？有没有额外的商业保险？ 其他福利待遇：有没有餐补、房补、交通补、出差补、医疗补、生日福利、节日福利等等？ 公司的考勤制度是怎样的？每天工作几个小时？是不是双休？有没有全勤奖金？请假扣不扣钱？有没有带薪休假？年假不休的话能否折算成奖金发放？ 有无签字费？签字费怎么发放？合约期是多少？发生违约该怎么办？ 谈薪避坑 非常不建议说“自己找工作主要是积累经验，更看重机会，薪资不是那么重要”。这点非常致命，这很明显给了 HR 后续压你薪资的借口，属于是自己给自己画饼了 不要直接给出你的心理预期薪资，可以先反问对方“请问公司给咱们这个岗位的预算是多少”或“咱们的薪资结构大概是怎样一个构成呢” 月 base 多少？发多少个月？ 多少个月是年终奖？ 年终奖的计算逻辑是怎样的？ 有没有绩效津贴？ 薪酬的支付周期和具体到账时间？ 不要用城市生活成本高、压力大之类的话术要求更高工资，因为公司给你更高薪资取决于你的能力而非生活成本 不要直接说出自己期望薪资的底线，往往会造成薪资低于这个数。可以先不说具体数字，先和 HR 沟通公司的薪资结构，福利待遇等，最后稍加思考后，适当抬高你的期望薪资 谈薪必问合集 薪资结构一定要了解清楚 固薪发几个月？几月发？ 年终奖范围？几月发？ 月薪包含绩效吗？ 社保公积金缴纳比例？ 工资以外的福利？ 公司加班是发加班费还是调休呢？ 谈薪模板 ✅ 万能报价语句：准确报数字 + 缓和气氛 + 综合考虑 🔥 参考薪资公式：目标薪资 + 15% 报价 HR 一定会压价，所以需要还价 ✅ 万能还价语句：理解 + 阐述优势 + 加入意愿 + 再次报价 + 请求协助 比如说你的底线薪资是 20K，市场平均薪资是 25K，你的目标薪资是 27K，就直接说： 1️⃣ 我的期望薪资是月薪 31K，我之前做了一些市场调查，还有我在这个岗位师兄师姐进行了解和反馈，这个薪资我觉得是一个市场的平均值； 2️⃣ 回归到胜任能力上，同时在前面几轮的面试中，我相信面试官你们也是充分了解了我的能力；而这个岗位所需要的 XX、XX 能力，在我过往的经历中是可以体现的，因此这个岗位我是完全能够胜任的； 3️⃣ 另外我手上也有其它公司的面试机会 &#x2F; offer，但在此前面试中我也感受到贵公司的企业氛围&#x2F;福利&#x2F;文化是我比较喜欢的，所以在同等情况前提下我更愿意来贵公司； 4️⃣ 同时因为我从学校出来要考虑到租房、出行等费用，综合考虑下我觉得这个薪资是比较合理的。 5️⃣ 希望 HR 您能帮我争取一下！ 如何 argue 寒暄环节：客套一下，感谢公司发 offer，快速切入正题； 核心模板：先表达你来该公司的强烈意愿，然后表示你拿了什么什么厂的什么价位的 offer，白菜就别说了，如果 sp 可以说，然后表示如果能在这个价位基础之上加多少钱就更合适了，自己未来还是想来这边发展的，希望这边可以帮忙申请一下。 最后等待结果，并再次感谢对方给与这次机会。 一般来说，如果第一次没有 argue 下来，又特别想试试，可以二次 argue，但不建议事过三。 当然以上的方式有点强硬，对于没有高薪 offer 的同学也想得到稍微比较高的薪资的 offer，态度可以换一种。 沟通的时候依旧去表达一下自己的期望薪资，也许期望薪资会在 hr 给你开出具体薪资之后才说，并且这两者之间有一定的出入，那么可以尝试性的沟通一下，我这边对薪资也有了一定的了解，结合我个人能力来评估，希望能够你在开出的薪资上面提升一些，跟我的预期更符合一些，同时我也有一些其他的 offer 的在手上，他们有些开了薪资，有些会在之后谈薪资，但是如果贵公司能够达到我的期望值，我会立马下定决心去这里。 当然特别需要注意自己的语气和行为方式，所谓知己知彼方能百战不殆，之前也出现过 argue offer 将 offer 弄没了的，也有些公司如果需要 argue sp offer 需要进行加面，不成功也许 offer 就没了，去年身边有同学就在加面中挂了，血的教训所以对于那些你比较想去的公司，需要合理的去评估自己的实力。现在大家都会有一种心态，就是比较。在没拿到公司的 offer 之前，特别想通过面试，拿到 offer，拿到 offer 之后，发现身边的同学薪资都比较高，心理多少会出现不平衡的状态，然后可能就会导致在和 hr 谈薪资的过程中会犯错误，没有合理的去评估实力就进行 argue，如果只是 argue 失败，保持一开始的薪资还好，如果被收回 offer 就追悔莫及。 另外，脱离公司、岗位、部门比较薪资本身就是一种错误的行为，例如近两年火热的算法岗，一部分公司区别对待，算法和开发工资有点差别，有些公司就是无差别对待。 另外要注意 offer 提供的地点。举个例子，小米在北京和武汉开出的薪资就是不一致的，可千万别看见 offershow 北京的工资去和公司谈武汉的薪资，因为一线城市和二线城市消费水平本身就有一定的差距，二线城市对于许多人来说，离家近，所以也一定程度上牺牲了薪资。 总结： argue 薪资有可能需要出示证明，所以没有备用 offer 原则上不建议编造 通过 offershow 提前知道公司开出的 offer 薪资大致的区间，同时也给自己制定一个期望薪资 需要有同级别公司的 offer（白菜、sp、ssp）才能去 argue 大公司的 offer。例如百度的签字费去年是针对拿到字节、阿里、腾讯的人可以 argue 有些公司 sp、白菜是在面试的时候就已经确定了的，这个是根据面试表现来给，argue 的话更多的是要签字费 阿里（杭州）第一年对于应届生有 10w 补贴，所以在拿阿里 offer 去和别的公司 argue，自己也可以算上 对于不那么想去的公司，argue 可以强硬一点，对于特别想去的公司，如果薪资还满意的话，符合自己的实力，不建议盲目的上去 argue 部分公司可以在谈完薪资之后继续谈，如果不成，大不了不去 如果想留多个 offer 进行比较，还是那句话，argue 要注意分寸，不要把原来的 offer 给 argue 没了 有些公司薪资是可以谈的（比如美团），有些公司的薪资对于大部分的人来说谈不了（比如字节），所以了解清楚你要去谈薪资的公司是否可以谈 argue 有风险、合理评估实力再决定 毁约或拒绝 offer 话术什么时候放弃 offer，一般来说有两个阶段（意向书阶段 or 谈薪阶段）： 一个是公司发下来意向书的时候，在意向书的末尾都需要点击链接确认或者放弃意向书，这个时候点击放弃，或者等待意向书有效期过自动放弃，又或者要求回复该意向书邮件，这时候回复邮件里就表明放弃就可以了。不过这样的话无论你是点击放弃还是过了有效期自动放弃，hr 都会打一个电话过来向你了解情况，防止你忘了或者误操作之类的。这个时候一般都会问你为啥放弃这个 offer 呢，你就说你的理由就可以了，不过需要注意的是这个时候一般还没有谈薪，你不知道你将要放弃的公司会开给你多少钱，或者你的 dream offer 会开给你多少钱。 第二个阶段就是 hr 打电话来谈薪的时候，谈完薪资，就基本上一切都确定了，你再考虑是不是要放弃，这个时候可以直接在电话里头跟 hr 说你要拒绝。当然还有一种委婉的方式是在 hr 给你的考虑期限内，给 hr 发一封邮件拒绝。 如果拒绝的很早，也是可以的，但是一般不建议在口头 offer 或者意向书之后就拒绝，因为你还没有薪资信息给你参考，这个时候就拒绝的话难免有考虑不周的可能。 开头感谢： 对方的机会、认可和时间付出 表明态度： 说明无法接受 offer，态度诚恳且明确 简述原因： 原因简洁，避免负面评价（如职业规划调整、家庭原因等） 表达歉意： 对浪费的时间与资源表示歉意 表达期望： 祝福对方，并表达未来合作的可能性 电话&#x2F;微信&#x2F;短信如果是打电话或者发微信，发短信的话，你可以说: “很感谢你们给我的宝贵机会，我已经有更好的 offer 了，所以暂时不考虑其他 offer，希望将来有机会再合作，非常抱歉给贵公司的招聘工作带来不便，祝你们招聘顺利！”。 或者： “非常感谢你们对我的认可，但是我现在已经拿到了更合适我的 offer，综合考虑之后，我认为这个 offer 跟我的职业规划并不是十分匹配（适用于不喜欢这个岗位，这个 base 的情况）&#x2F;我认为贵公司的薪资不符合我的预期（适用于薪资太低的情况），因此我决定放弃这个 offer，很抱歉给贵公司的招聘工作带来的不便，祝你们招聘顺利！希望将来有机会再合作！” 或者： “面试官您好，了解完贵团队的相关业务之后，我觉得我还是不太适合这个方面的开发工作，所以我打算放弃这个机会，感谢贵公司给我的宝贵机会（这个是我在面完某公司二面之后，面试官觉得这个职位跟我的背景不是很符合，加微信让我考虑考虑，之后我给面试官发的微信消息）” 或者： “面试官您好，我已经慎重考虑过了，综合 XX 的价值观和 base 薪资等因素，我觉得目前来说 XX 公司不是很适合我。非常感谢 XX 公司对我的认可，希望以后有机会再合作。”（这是我面试时加了 XX 公司面试官的微信，谈完薪后在微信上把决定告诉面试官，由面试官传达 hr 的） 或者： “面试官您好，很抱歉这么晚来打扰您。我很认真的思考过了，因为我目前已经拿到了十分合适我的 offer 啦，因此并不打算考虑其他机会，也不想浪费面试官们宝贵的时间。XXXX 我有一点了解，您的部门有很光明的前景和潜力，但是我个人觉得并不是很适合这个方向，所以还是不打算继续接下来的流程啦。”（这是我已经拿到 Y 公司的意向书后，XX 公司的面试官加我微信邀请我面试，我给面试官发的拒绝消息，仅供不打算继续面试流程的同学们参考） 邮件而如果你是发邮件拒绝的话，可以这么说： 尊敬的 TT 公司 hr 您好！我是 YYYY 年校园招聘提前批中获得贵公司 offer 的候选人 XXX。非常感谢 TT 公司给我的 offer，由于本人获得了另外更适合我的 offer，根据自己的职业期望与规划，思考良久，认为目前 TT 公司不是十分符合自己的专业方向与职业规划，故决定放弃贵公司的录用邀请。祝愿贵公司能找到更加适合这个职位的人选，我很抱歉给贵公司的工作带来的不便，若今后有机会也非常希望能再次合作。 三方与毁三方流程三方实际就是毕业生就业协议。其实是全国普通高等学校就业协议书，哪三方呢，有毕业生，用人单位和学校。能够解决应届毕业生的一些福利待遇等，具体根据双方谈的条件来定，正常来讲会有五险一金，有的公司涉及档案，户籍等等，等到正式入职之后这个三方就自动终止了，说白了对我们就没有用了。 毁三方的流程：如果不是因为特别的原因一般不要毁三方，因为一个是时间会拖的很长，一个是需要违约金，因为我也没有毁过三方，所以这里引用牛客帖子「offer、三方、两方、毁约，这些你需要知道的事」中关于毁三方的详细流程： 与原单位协商，向原单位接收违约，按照三方协议规定，交纳违约金（有些单位不收违约金），从原单位开出退函。 从新单位获取接收函。 拿着原单位退函和新单位接收函到就业指导中心领新三方（有时也不需要接收函）。 拿新三方与新单位签约。 这个过程中，关键在于第一步：如何与原单位协商，拿到退函。具体的情况，不同单位不一样，有的单位可能会拖很久。所以，如果新单位的签约时间很紧，而原单位又不会很快给你开退函的话，那结果很可能是你两家单位都签不了。","tags":["秋招"],"categories":["秋招指南"]},{"title":"技术面反问环节与 HR 面常见套路与反问","path":"/post/秋招指南/reverse-interview/","content":"本文主要罗列一下技术面&#x2F;主管面的反问环节参考问题，以及 HR 面的常见问题和反问参考。 首先，作为求职者而言，要清楚面试是一个双向选择的过程，刚刚被面试官一通提问过后，权力的棒子就交回你手中了。所以在这个环节，要基于你自身实际的需求，充分挖掘这家公司你在意的点。如果什么也不问，等于你就错失了一次通过内部渠道熟悉公司的好机会，还可能会跳进一些不知道的坑。对于招聘方而言，清晰、有条理的提问不仅会提高你在面试人员心中的好感度，也能让面试方觉得你对他们感兴趣、是真的想来他们公司，而不是把公司当做自己池子里的鱼。 下面我将按照不同轮次的面试去分类，分别介绍一下反问环节的技巧。注意面试之前要还是要通过各种信息途径对公司去有一个基本的了解，所谓知己知彼者，百战不殆。 预期使用方式 检查一下哪些问题你感兴趣 检查一下哪些是你可以自己在网上找到答案 找不到的话就向面试官提问 绝对不要想把这个列表里的每个问题都问一遍（尊重面试官的时间） ⚠️ 注意：无论哪一轮的面试，一定要做到不卑不亢，不能怯场，特别是 HR 面。 HR 面一定要做到：自信！自信！还是 tmd 自信！ HR 不懂技术，这时候可以狠狠地吹。 聊天时言语中可以带有真诚的语气，但回答的内容不要过于老实。 正所谓真诚是必杀技，但是只有真诚那是杀必。 个人推荐的问题 🙋技术面 &#x2F; 主管面 组内的业务与技术栈？ 可以再详细介绍一下这个岗位的具体职责吗？ 组内的 Code Review 是怎么做的？ 公司&#x2F;部门对于实习生&#x2F;校招生有没有技术栈上的要求？计算机基础、项目经历和编程能力怎么考量？ 您能介绍一下你们部门在整个业务环节中扮演的角色吗？（用于试探是不是边缘部门） 工作节奏是怎样的呢&#x2F;是否加班？（这个问题我觉得问一线员工比问 HR 靠谱） 你们部门的工作是预研还是解决现有需求？ 对接人&#x2F;乙方&#x2F;客户主要是谁？ 生产环境发生事故了怎么办？ 新员工入职的培训流程&#x2F;培养机制？ 团队总共有多少人？ 部门未来会逐渐拓展新的业务吗？ HR 面 按以下 3 个模块顺序问，因为薪资在后续还会再提及，如果 hr 没问预期薪资，则不需要&#x2F;不该（在 hr 面）主动咨询具体给到的薪资范围，但是一定要问问薪资结构的组成、福利等。 个人发展 培养机制？晋升渠道？涨薪途径？ 每年几月份调薪？调薪幅度是？ 试用期多久？转正要求是什么？试用期薪资打折吗？ 岗位稳定性如何、是否会裁员？ 休假 工作节奏如何？午休多久？双休吗？ 年假有多久？带薪休假时间有多久？ 病假和事假是分开的还是一起算？ 加班是调休还是双倍薪资呢？ 薪资福利 薪资结构是怎样的？ 年终奖情况与绩效评定？ 有五险一金或者其他退休养老金等福利吗？ 公积金按多少比例缴纳？ 公司是否有食堂，是否提供餐补&#x2F;房补&#x2F;交通补贴？ 技术&#x2F;主管面【反问环节】该轮面试的特点是面试方对具体的工作业务流程都很熟悉，所以可以问以下内容： 工作内容：主要针对技术面，包括不限于岗位职责、具体工作形式等，可结合自己对部门的了解去问，越详细越好，最好能接着面试官的话题去问，他们会认为你对这份工作有着深入的理解，也方便你判断自己对岗位是否感兴趣、契合度高不高。常见提问形式： 可以再详细介绍一下这个岗位的具体职责吗？ 我们部门的工作是预研还是解决现有需求？ 对接人&#x2F;乙方&#x2F;客户主要是谁？ 工作时间如何&#x2F;是否加班？（这个问题我觉得问一线员工比问 HR 靠谱） 公司层面：主要针对主管面，相比于基层员工，主管对于业务和整个公司战略的层面有更深入的理解。常见提问形式： 您能介绍一下我们部门在整个业务环节中扮演的角色吗？（用于试探是不是边缘部门） 公司&#x2F;部门的氛围如何？工作节奏怎么样？ 新员工入职的培训流程&#x2F;培养机制？ 团队总共有多少人？ 会逐渐拓展新的业务吗？ 行业未来前景如何？ 其它也可以接着技术面觉得没问充分的点继续深入，下列是所有反问合集，仅供参考。 职责 On-call （电话值班）的计划或者规定是什么？值班或者遇到问题加班时候有加班费吗？ 我的日常工作是什么？ 有给我设定的特定目标吗？ 团队里面初级和高级工程师的比例是多少？（有计划改变吗） 入职培训 (onboarding) 会是什么样的？ 每个开发者有多大的自由来做出决定？ 在你看来，这个工作做到什么程度算成功？ 你期望我在最初的一个月 &#x2F; 三个月能够完成什么？ 试用期结束的时候，你会怎么样衡量我的绩效？ 自己单独的开发活动和按部就班工作的比例大概是怎样的？ 一个典型的一天或者一周的工作是怎样安排的？ 对我的申请你有什么疑虑么？ 在这份工作上，我将会和谁紧密合作？ 我的直接上级他们的上级都是什么样的管理风格？（事无巨细还是着眼宏观） 我在这个岗位上应该如何发展？会有哪些机会？ 每天预期 &#x2F; 核心工作时间是多少小时？ 我入职的岗位是新增还是接替之前离职的同事？（是否有技术债需要还）？ 入职之后在哪个项目组，项目是新成立还是已有的？ 技术 公司常用的技术栈是什么？ 你们怎么使用源码控制系统？ 你们怎么测试代码？ 你们怎么追踪 bug？ 你们怎样监控项目？ 你们怎么集成和部署代码改动？是使用持续集成和持续部署吗 (CI&#x2F;CD)？ 你们的基础设施搭建在版本管理系统里吗？或者是代码化的吗？ 从计划到完成一项任务的工作流是什么样的？ 你们如何准备故障恢复？ 有标准的开发环境吗？是强制的吗？ 你们需要花费多长时间来给产品搭建一个本地测试环境？（分钟 &#x2F; 小时 &#x2F; 天） 你们需要花费多长时间来响应代码或者依赖中的安全问题？ 所有的开发者都可以使用他们电脑的本地管理员权限吗？ 介绍一下你们的技术原则或者展望。 你们的代码有开发文档吗？有没有单独的供消费者阅读的文档？ 你们有更高层次的文档吗？比如说 ER 图，数据库范式 你们使用静态代码分析吗？ 你们如何管理内部和外部的数字资产？ 你们如何管理依赖？ 公司是否有技术分享交流活动？有的话，多久一次呢？ 你们的数据库是怎么进行版本控制的？ 业务需求有没有文档记录？是如何记录的？ 你们是如何面对和解决技术债的？是否有专门的时间或者预算用于重构？ 你们如何进行单元测试呢，是否都有单元测试的习惯？ 团队 工作是怎么组织的？ 团队内 &#x2F; 团队间的交流通常是怎样的？ 你们使用什么工具来做项目组织？你的实际体会是什么？ 如果遇到不同的意见怎样处理？ 谁来设定优先级 &#x2F; 计划？ 如果团队没能赶上预期发布日期怎么办？ 每周都会开什么类型的会议？ 会有定期的和上级的一对一谈话吗？ 产品 &#x2F; 服务的规划是什么样的？（n 周一发布 &#x2F; 持续部署 &#x2F; 多个发布流 &#x2F; …） 生产环境发生事故了怎么办？是否有不批评人而分析问题的文化？ 有没有一些团队正在经历还尚待解决的挑战？ 你们如何跟踪进度？ 预期和目标是如何设定的？谁来设定？ Code Review 如何实施？ 给我介绍下团队里一个典型的 sprint 你们如何平衡技术和商业目标？ 你们如何共享知识？ 团队有多大？ 公司技术团队的架构和人员组成？ 团队内开发、产品、运营哪一方是需求的主要提出方？哪一方更强势？ 问未来的同事 开发者倾向于从哪里学习？ 你对在这里工作最满意的地方是？ 最不满意的呢？ 如果可以的话，你想改变哪里？ 团队最老的成员在这里多久了？ 在小团队中，有没有出现成员性格互相冲突的情况？最后是如何解决的？ 公司 公司为什么在招人？（产品发展 &#x2F; 新产品 &#x2F; 波动…） 有没有会议 &#x2F; 旅行预算？使用的规定是什么？ 晋升流程是怎样的？要求 &#x2F; 预期是怎样沟通的？ 绩效评估流程是怎样的？ 技术和管理两条职业路径是分开的吗？ 对于多元化招聘的现状或者观点是什么？ 有公司级别的学习资源吗？比如电子书订阅或者在线课程？ 有获取证书的预算吗？ 公司的成熟度如何？（早期寻找方向 &#x2F; 有内容的工作 &#x2F; 维护中 &#x2F; …） 我可以为开源项目做贡献吗？是否需要审批？ 你认为公司未来五年或者十年会发展成什么样子？ 公司的大多数员工是如何看待整洁代码的？ 你上次注意到有人成长是什么时候？他们在哪方面成长了？ 在这里成功的定义是什么？如何衡量成功？ 有体育活动或者团建么？ 有内部的黑客马拉松活动吗？ 公司支持开源项目吗？ 有竞业限制或者保密协议需要签吗？ 你们认为公司文化中的空白是什么？ 能够跟我说一公司处于不良情况，以及如何处理的故事吗？ 您在这工作了多久了？您觉得体验如何？ 大家为什么会喜欢这里？ 公司的调薪制度是如何的？ 公司有没有申请调岗的制度？ 公司对于员工的心理健康和福祉有什么具体措施？ 你对在这里工作最满意的地方是？你为什么留在这家公司？ 社会问题 你们关于多元化招聘什么看法？ 你们的公司文化如何？你认为有什么空白么？ 这里的工作生活平衡地怎么样？ 公司对气候变化有什么态度吗？ 冲突 不同的意见如何处理？ 如果被退回了会怎样？（“这个在预计的时间内做不完”） 当团队有压力并且在超负荷工作的时候怎么处理？ 如果有人注意到了在流程或者技术等其他方面又改进的地方，怎么办？ 当管理层的预期和工程师的绩效之间有差距的时候如何处理？ 能给我讲一个公司深处有毒环境以及如何处理的故事吗？ 如果在公司内你的同事因侵犯他人而被调查，请问你会如何处理？ 假设我自己很不幸是在公司内的受害者，在公司内部有没有争取合法权益的渠道？ 商业 你们现在盈利吗？ 如果没有的话，还需要多久？ 如果有的话，年度营业额是大概有多少？（我现在的公司年度营业额是 5 亿） 公司的资金来源是什么？谁影响或者制定高层计划或方向？ 你们如何挣钱？ 什么阻止了你们挣更多的钱？ 公司未来一年的增长计划怎样？五年呢？ 你们认为什么是你们的竞争优势？ 你们的竞争优势是什么？ 公司未来的商业规划是怎样的？有上市的计划吗？ 都在做副业吗？ 远程工作 远程工作和办公室工作的比例是多少？ 公司提供硬件吗？更新计划如何？ 使用自己的硬件办公可以吗？现在有政策吗？ 额外的附件和家具可以通过公司购买吗？这方面是否有预算？ 有共享办公或者上网的预算吗？ 多久需要去一次办公室？ 公司的会议室是否一直是视频会议就绪的？ 办公室布局 办公室的布局如何？（开放的 &#x2F; 小隔间 &#x2F; 独立办公室） 有没有支持 &#x2F; 市场 &#x2F; 或者其他需要大量打电话的团队在我的团队旁边办公？ 终极问题 该职位为何会空缺？ 公司如何保证人才不流失？ 这份工作 &#x2F; 团队 &#x2F; 公司最好和最坏的方面是？ 你最开始为什么选择了这家公司？ 你为什么留在这家公司？ HR 面【常见问题】 HR 面之前一定要背调公司以及相关部门，对公司有一个大概的了解。 还有个大伙常见的疑问：公司 HR 面会刷人吗？ 首先很多大厂的 HR 权限很大，拥有一票否决权，真的会刷人 小厂的 HR 来说权限不大，一般不太会刷人 一般来说，只要 HR 面你表现得像个正常人&#x2F;人一样，然后自信一点，对公司价值观认可点，问题都不大，很多时候你挂了不一定是 HR 面挂了，可能是 HR 面之后的排序挂了 1. 你为什么选择我们公司？ 想和优秀的人（前几轮面试官）做有挑战的事（业务与未来发展契合） 🔥 回答这个问题的前提：提前了解了公司的主营业务、核心产品、行业地位、文化价值观（如官网、新闻稿、社交媒体），仔细阅读 JD，提炼岗位关键词，针对性准备案例。 高分逻辑：体现对企业的深度了解 + 个人职业规划的契合（有理有据即可，体现你对公司的向往和理解） 【示例】我注意到贵司近年来在大模型领域的技术投入（如 xxx 项目），这与我的专业背景和长期关注的行业方向高度匹配。同时，我也想和优秀的人做有挑战的事，通过前几轮面试，我感受到了贵公司技术有深度，氛围好，让我坚信在这里能快速成长。 2. 职业规划&#x2F;你对未来有什么规划？ 不要假大空，说做几年然后升架构师… 我的未来规划是，我觉得人应该两条腿走路，一条腿是技术，一条腿是业务。技术是为业务服务的，你脱离了业务，技术就没有意义了；脱离了技术，业务就没法实现了。 业务层面：我了解咱们公司，（举个例子）咱们部门是搞本地生活的，本地生活涉及到了人的衣食住行，至关重要，有一天可能短视频&#x2F;游戏&#x2F;xxx 业务都没了，但是人的衣食住行一定是存在的，所以我觉得公司的业务是很有价值的，我希望未来在公司中深挖业务，能够提升自己对整个行业的理解，我之前实习&#x2F;工作的时候，有个 xxx 需求没解决&#x2F;报错了，但是半个月都没人发现，为什么，因为当时我们做的是伪需求，我们解决的问题不是痛点问题，我希望我的技术能够为业务赋能，去挖掘用户痛点，解决用户的痛点问题，以此创造价值。 技术层面：我希望深入了解公司的技术，陪着公司一起成长，…（了解公司的技术的话可以吹一波） 希望我后面无论是在技术方面还是在业务方面，都能做到在公司独当一面。 这样回答，既有技术又有业务，还有你对公司行业的思考，中间甚至吹了一波公司，比那些假大空的回答好多了。 3. 你怎么看待加班 &#x2F; 996，是否接受加班？ 不卑不亢，尽显男儿本色 [doge] 我可以接受加班，尤其是在紧急需求下，工作分内之事我肯定义不容辞，但是这一定是要建立在高效的工作之上，而不是为了加班而加班，所以我会提高自己的工作效率，避免不必要的加班。 因人而异地追问：想问下贵公司一般都是什么原因导致加班呢？其他小伙伴加班频率怎样？加班有没有调休制度呢？方便我提前做准备。 4. 你有什么优点&#x2F;特点？ 如果 HR 问你有什么特点&#x2F;优点，请记住一定要说出一个词“靠谱”。 为什么要一面、二面、HR面，往宽泛了说就是，往往学历越高的人都是越有能力的，面试表现得越好就越有能力，越有能力的人越能干成事儿，能干成事的人他就靠谱，就能放心的把事情交给你。 参考词汇：靠谱、目标感强、有规划、主动性强、不拖沓、有责任心 可根据以上几个词举实际场景佐证。 5. 你有什么缺点？ 选择与岗位无关且可改善的点，避免暴露致命短板。 ⚠️ 别和优点矛盾 下列举几个例子 1️⃣ 我有时候会对细节过于苛求，希望把事情做得尽善尽美，这可能导致在项目初期花费较多时间进行打磨。但我已经意识到，在追求质量的同时也需要兼顾效率，完成比完美来得重要。后来我会在项目开始前设定清晰的时间节点和优先级标准，确保在关键细节上投入主要精力，同时不影响整体的进度。这个方法让我既能保证工作输出质量，又能按时完成任务。 2️⃣ 我过去在大型会议或面对不熟悉的群体做 presentation 时容易紧张，不过我们实验室每周会固定开组会分享论文，我都会主动在组会上争取更多的分享机会来锻炼自己，挑战自己的软肋，因为我清楚这对于职业发展很重要。导师也会带我们出去各种大型会议参加活动和做 presentation，现在我已经能更自信、有条理地表达自己的观点了，虽然还存在不足，但是已经有所进步了。 3️⃣ 在读研的期间，我对很多新任务都充满热情，所以有时会不自觉地承接过多任务，导致自己的核心项目受到影响。后来我学会了更高效地进行优先级管理，并且定期和我的导师对齐工作重点，确保我的时间精力都投入在最重要的事情上。这不仅提高了我的个人效率，也保证了主线和所有支线的平稳推进。 4️⃣ 我的缺点是缺乏自信，… 5️⃣ 我是个急性子，有时候没有特别想清楚就开始干了，可能会导致过程中和团队同事有一些往复的讨论和确认，耽误时间，造成团队同事的困惑。 6. 目前手上有没有其他 offer？ 无论什么面试，一定要扬长避短，当 HR 询问你是否手头有其他 offer 时，回答这个问题需要既展示你的市场竞争力，也要表现出对当前面试公司的高度兴趣。 你有其他公司的 offer 说明你能力强、价值高、比较抢手，但同时也说明了你没那么稳定，你有可能去其他公司。候选人的稳定性是非常重要的，你有其他 offer，价值上去了，稳定性就下来了。 ⚠️ 如果没有 offer，HR 面可以说有 offer，但是谈薪阶段不能编造 offer，有些需要提供证明才能 argue。 个人战略： 对于「小厂」就说没有 offer 或者提及几个体量差不多的公司； 对于大厂则必须说有 offer，用于 argue 和体现自己价值。 ✅ 有 offer 的话术： 1️⃣ 现在 xxx 公司给我发了 offer，但是我觉得你们公司很不错，业务前景很好，（此处省略一段，这里可以吹一波公司的业务），但是他那边已经发了 offer，如果说你们这边能够尽快发 offer 的话，我收到 offer 之后我就把那边拒了。 2️⃣ 目前我确实收到了几个公司的 offer。这些公司虽然各有千秋，但我发现它们与我的职业发展规划并不完全吻合。相比之下，贵公司的职位更符合我的长远职业目标。我对贵公司的发展潜能非常感兴趣，因此我非常期待能有机会加入您的团队。 3️⃣ 是的，我已经拿到了两个 offer，这些公司与贵公司在行业定位上有不少相似之处。然而，通过今天的了解，无论是从公司的发展前景、职业成长空间，还是面试过程中体验到的公司氛围来看，贵公司都给我留下了更为深刻的印象。我会在您做出决定之后，认真考虑是否接受其他 offer。 核心是表达出我有后手有退路，但只要你们给，一定是选你们。而且别搞得太生硬，整些什么仰慕公司文化之类的就太假太尬了（除非一些企业文化印象深刻 &#x2F; 广为流传，比如鹅厂），尽量给一些软理由（信服力比较强）： xx 公司路程远，贵公司的路程比较方便； 我男&#x2F;女朋友要去你们那里发展&#x2F;拿了那边公司的 offer，我不想异地恋； 我有个 xx 亲戚在你们那 xx 城市，可以给我点帮助，这样我不用租房； 看中 xx 城市户口，希望给未来自己孩子 xx 条件。 ⚠️ 但是如果两家公司差距过大，就不要提了，比如你在面一个小公司，你告诉 HR 说你拿到了字节的 offer，但是我更想去你们这个小公司，别说 HR 不信了，你自己都不相信这是你说的。 ✅ 没 offer 的话术： 1️⃣ 我近期才开始积极寻找工作机会，之前参与过两家公司的面试，并且已经进入最后阶段。尽管还未收到正式 offer，但我对贵公司的职位特别感兴趣。我认为贵公司的岗位职责和未来的发展潜力与我的职业规划高度契合。因此，我非常希望有机会加入贵公司的团队。 2️⃣ 我最近才开始面试，对于求职过程持谨慎态度，并没有广泛投递简历，而是选择性地申请了几家我特别感兴趣的公司。目前有两家公司正在进行中，但尚未接到具体 offer。我对贵公司所在行业的前景感到非常乐观，并认为这是一个能够促进我职业发展的绝佳机会。因此，我非常倾向于加入贵公司。 7. 你的期望薪资是多少？ ⚠️ 并非每一场 HR 面都会问你期望薪资，一般在 10~11 月谈薪。 参考视频：2025 届秋招谈薪急救指南 不要直接给出你的心理预期薪资，可以先反问对方“请问公司给咱们这个岗位的预算是多少”或“咱们的薪资结构大概是怎样一个构成呢” 月 base 多少？发多少个月（几薪）？ 月薪有没有包含绩效？ 多少个月是年终奖？ 年终奖的计算逻辑是怎样的？ 薪酬的支付周期和具体到账时间？ 非常不建议说“自己找工作主要是积累经验，更看重机会，薪资不是那么重要”，这点非常致命，这很明显给了 HR 后续压你薪资的借口，属于是自己给自己画饼了 HR 直接问候选人期望薪资是多少，一般有「月薪」或者「总包」两种说法，可以先咨询下 hr 问的是月薪还是年包，建议说年包 参考往年和今年的整体情况报一下，给 hr 报的时候不能报具体数字，也不要报上限，建议就报一个下限，比如说我希望公司能给我不低于 50 万的年薪，但这个薪资不是最终的 至于该公司往年市场薪资如何，可以根据「OfferShow」提供的数据，让你对各公司各岗位（各 bg 下）的市场价位有一个大致的了解 ✅ 回答模板（以月薪为例） 比如说你的底线薪资是 23k，市场平均薪资是 25k，你的目标薪资是 27k，就直接说我的期望薪资是 29k。原因如下： 1️⃣ 我之前做了一些市场调查，还有我在这个岗位师兄师姐进行了解和反馈，这个薪资我觉得是一个市场的平均值； 2️⃣ 回归到胜任能力上，同时在前面几轮的面试中，我相信面试官你们也是充分了解了我的能力；而这个岗位所需要的 XX、XX 能力，在我过往的经历中是可以体现的，因此这个岗位我是完全能够胜任的； 3️⃣ 另外我手上也有其它公司的面试机会，但在此前面试中我也感受到贵公司的企业氛围&#x2F;福利&#x2F;文化是我比较喜欢的，所以在同等情况前提下我更愿意来贵公司； 4️⃣ 同时因为我从学校出来要考虑到租房、出行等费用，综合考虑下我觉得这个薪资是比较合理的。 5️⃣ 希望 HR 您能帮我争取一下！ 具体谈薪时间（并非 HR 面，而是接收 offer 后（一段时间 &#x2F; 立刻）到谈薪环节） 互联网企业大致在 10 月底 &#x2F; 11 月初高峰统一谈薪，逼签三方 如果是体制内 &#x2F; 国企，一般是直接面试完现场谈薪，而且这个薪资基本无法谈（argue） … 8. 你有没有女&#x2F;男朋友？家庭情况如何？主要是确定你的稳定性，你到底会不会来，知道 HR 的目的后，你就可以根据自己的情况灵活作答。 9. 敬请期待… HR 面【反问环节】该轮面试的重要性不用我多说了吧，求职者最关注的薪资待遇等关键信息都会在这轮中体现。 薪资待遇 工资及工资构成？ 五险一金基数分别是多少？ 年终奖情况与绩效评定？ 年假？ 食宿&#x2F;房补餐补？ 落户政策？ 工作方面 工作时间？工作地点？通勤是否方便？办公环境如何？ 加班 and 出差情况？ 试用期多久？转正要求是什么？试用期工资&#x2F;年终奖情况？ 个人发展方面 培养机制？晋升渠道？涨薪途径？ 往年公司营收如何？ 岗位稳定性如何、是否会裁员？ 🧑🏻‍💻 鉴于裁员是咱应届生都比较关注的一点，直接问会不会裁员可能得到一个模棱两可的答复，可以像这样问： 在网上看到一些关于贵司裁员的消息，请问这些消息是否属实？如果属实，方便告知一下是什么原因吗？毕竟我更希望和贵司成为长期的合作伙伴（这样 HR 就能感受到你的真诚，会给予更多对你有用的信息） 🧑🏻‍💻 另外，对于手头有多个 offer 的大佬，面的这家 HR 对你也很感兴趣的情况下，出于怕你是海投的考虑一般会问为什么没有选择之前的 offer？可以这么回答，得体又能给自己加分： 我觉得找工作是人生的一件大事，所以会深思熟虑，如果随便就签约一个不满足自己期望的公司导致后面又走违约流程，这样对公司对自己都是极其不负责任的。遇到合适的机会再签约，也是对招聘方的尊重。如果您觉得我满足您这边的招聘要求，麻烦您给我一些考虑的时间。 下列是所有反问合集，仅供参考。 待遇 如果有奖金计划的话，奖金如何分配？ 如果有奖金计划的话，过去的几年里通常会发百分之多少的奖金？ 有五险一金或者其他退休养老金等福利吗？ 五险一金中，补充公积金一般交多少比例？我可以自己选择这一比例吗？ 有什么医疗保险吗？如果有的话何时开始？ 有额外商业保险吗？例如人寿保险和额外的养老&#x2F;医疗保险？ 商业保险可以给家人办理吗？成年人&#x2F;未成年人？ 更换工作地点，公司付费吗？ 是否可以申请更换工作地点？ 是否愿意协助海外应聘者申请工作签证？ 休假 带薪休假时间有多久？ 病假和事假是分开的还是一起算？ 我可以提前使用假期时间吗？也就是说应休假期是负的？ 假期的更新策略是什么样的？也就是说未休的假期能否滚入下一周期？ 照顾小孩的政策如何？ 无薪休假政策是什么样的？ 学术性休假政策是怎么样的？ 孕产假政策具体是怎样的？ 福利 公司提供 Mac 开发吗？ 使用自带电脑有补贴吗？ 公积金多少比例缴纳？ 公司是否有食堂，是否有餐饮福利补贴？ 是否提供租房补贴？ 是否提供话费补贴？ 是否有交通补贴？ 人才培养 升职加薪条件是否量化？ 每年给团队安排多少费用用于学习培训？ 每年组织多少次关于技术能力提升的讲座&#x2F;论坛？","tags":["面经","大厂"],"categories":["秋招指南"]},{"title":"✍️ 八股文 @ 智力题","path":"/post/秋招指南/2025-brainteaser/","content":"其实互联网招聘中，有一类型考察是考察你的临场反应速度，比如脑筋急转弯这种智力题或者情景题，比如很知名的腾讯赛马问题。 1. 三人三鬼过桥有三个人跟三个鬼要过河，河上没桥只有条小船，然后船一次只能渡一个人和一个鬼，或者两个鬼或者两个人，无论在哪边岸上，只有是人比鬼少的情况下（如两鬼一人，三鬼两人，三鬼一人）人会被鬼吃，然而船又一定需要人或鬼操作才能航行（要有人或鬼划船），问如何安全的把三人三鬼渡过河对岸? 参考回答 先两鬼过去。在一鬼回来。对面有一鬼。这边有三人两鬼。 再两鬼过去。在一鬼回来。对面有两鬼。这边有三人一鬼。 再两人过去。一人一鬼回来。对面一人一鬼。这边两人两鬼。 最后两人过去。一鬼回来。对面三人。这边三鬼。 剩下的就三个鬼二个过去一个回来在接另外个就OK了。 2. 赛马找最快的马匹（Tencent）一般有这么几种问法： 25 匹马 5 条跑道找最快的 3 匹马，需要跑几次？参考回答：7 次 64 匹马 8 条跑道找最快的 4 匹马，需要跑几次？参考回答：11 次 25 匹马 5 条跑道找最快的 5 匹马，需要跑几次？参考回答：最少 8 次，最多 9 次 建议画图表来看，将问题简单化一点，将大问题化成小问题即可，同时 B 站有个讲解视频还不错。 Q1：25 匹马 5 条跑道找最快的 3 匹马，需要跑几次？将 25 匹马分成 ABCDE 共 5 组，假设每组的排名就是 A1&gt;A2&gt;A3&gt;A4&gt;A5,用边相连，这里比赛 5 次 第 6 次，每组的第一名进行比赛，可以找出最快的马，这里假设 A1&gt;B1&gt;C1&gt;D1&gt;E1 D1，E1 肯定进不了前 3，直接排除掉 第 7 次，B1 C1 A2 B2 A3 比赛，可以找出第二，第三名 所以最少比赛需要 7 次 Q2：64 匹马 8 条跑道找最快的 4 匹马，需要跑几次？第一步：全部马分为 8 组，每组 8 匹，每组各跑一次，然后淘汰掉每组的后四名，如下图（需要比赛 8 场） 第二步：取每组第一名进行一次比赛，然后淘汰最后四名所在组的所有马，如下图（需要比赛 1 场） 这个时候总冠军已经诞生，它就是 A1（它不需要比赛了）。 而其他可能跑得最快的三匹马只可能是下图中的黄域了（A2，A3，A4，B1，B2，B3，C1，C2，D1，共 9 匹马） 第三步：只要从上面的 9 匹马中找出跑得最快的三匹马就可以了，但是现在只要 8 个跑道，那就随机选出 8 匹马进行一次比赛吧（需要比赛一场） 第四步：上面比赛完，选出了前三名，但是 9 匹马中还有一匹马没跑呢，它可能是一个潜力股啊，那就和前三名比一比吧，这四匹马比一场，选出前三名。最后加上总冠军，跑得最快的四匹马诞生了！ 最后，一共需要比赛的场次：8 + 1 + 1 + 1 &#x3D; 11 场 Q3：25 匹马 5 条跑道找最快的 5 匹马，需要跑几次？通过前 6 场决出第一名的方式不变，第 7 场才是关键，能否同时决出第 2、3 名次的马。 在上面的方法中，第 7 场比赛 [A2、B1、C1、D1、E1] 是为了决定第 2 名的马。但是在第 6 场比赛中我们已经得到 (B1&gt;C1&gt;D1&gt;E1)，试问？有 B1 在的比赛，C1、D1、E1 还有可能争夺第 2 名吗？ 当然不可能，也就是说第 2 名只能在 A2、B1 中出现。实际上只需要 2 条跑道就可以决出第 2 名，剩下 C1、D1、E1 的 3 条跑道都只能用来凑热闹的吗？ 能够优化的关键出来了，我们是否能够通过剩下的 3 个跑道来决出第 3 名呢？当然可以，我们来进一步分析第 3 名的情况？ 如果 A2&gt;B1 (即第 2 名为 A2)，那么根据第 6 场比赛中的 (B1&gt;C1&gt;D1&gt;E1)。 可以断定第 3 名只能在 A3 和 B1 中产生。 如果 B1&gt;A2 (即第 2 名为 B1)，那么可以断定的第 3 名只能在 A2, B2, C1 中产生。 好了，结论也出来了，只要我们把 [A2、B1、A3、B2、C1] 作为第 7 场比赛的马，那么这场比赛的第 2，3 名一定是整个 25 匹马中的第 2，3 名。 我们在这里列举出第 7 场的 2，3 名次的所有可能情况： ① 第 2 名&#x3D;A2，第 3 名&#x3D;A3 ② 第 2 名&#x3D;A2，第 3 名&#x3D;B1 ③ 第 2 名&#x3D;B1，第 3 名&#x3D;A2 ④ 第 2 名&#x3D;B1，第 3 名&#x3D;B2 ⑤ 第 2 名&#x3D;B1，第 3 名&#x3D;C1 第 8 场比赛很复杂，我们要根据第 7 场的所有可能的比赛情况进行分析。 ① 第 2 名&#x3D;A2，第 3 名&#x3D;A3。那么此种情况下第 4 名只能在 A4 和 B1 中产生。 如果第 4 名&#x3D;A4，那么第 5 名只能在 A5、B1 中产生。 如果第 4 名&#x3D;B1，那么第 5 名只能在 A4、B2、C1 中产生。 不管结果如何，此种情况下，第 4、5 名都可以在第 8 场比赛中决出。其中比赛马匹为 [A4、A5、B1、B2、C1]。 ② 第 2 名&#x3D;A2，第 3 名&#x3D;B1。那么此种情况下第 4 名只能在 A3、B2、C1 中产生。 如果第 4 名&#x3D;A3，那么第 5 名只能在 A4、B2、C1 中产生。 如果第 4 名&#x3D;B2，那么第 5 名只能在 A3、B3、C1 中产生。 如果第 4 名&#x3D;C1，那么第 5 名只能在 A3、B2、C2、D1 中产生。 那么，第 4、5 名需要在马匹 [A3、B2、B3、C1、A4、C2、D1] 七匹马中产生，则必须比赛两场才行，也就是到第 9 场角逐出全部的前 5 名。 ③ 第 2 名&#x3D;B1，第 3 名&#x3D;A2。那么此种情况下第 4 名只能在 A3、B2、C1 中产生。 情况和 ② 一样，必须角逐第 9 场 ④ 第 2 名&#x3D;B1，第 3 名&#x3D;B2。 那么此种情况下第 4 名只能在 A2、B3、C1 中产生。 如果第 4 名&#x3D;A2，那么第 5 名只能在 A3、B3、C1 中产生。 如果第 4 名&#x3D;B3，那么第 5 名只能在 A2、B4、C1 中产生。 如果第 4 名&#x3D;C1，那么第 5 名只能在 A2、B3、C2、D1 中产生。 那么，第 4、5 名需要在马匹 [A2、B3、B4、C1、A3、C2、D1] 七匹马中产 生，则必须比赛两场才行，也就是到第 9 场角逐出全部的前 5 名。 ⑤ 第 2 名&#x3D;B1，第 3 名&#x3D;C1。那么此种情况下第 4 名只能在 A2、B2、C2、D1 中产生。 如果第 4 名&#x3D;A2，那么第 5 名只能在 A3、B2、C2、D1 中产生。 如果第 4 名&#x3D;B2，那么第 5 名只能在 A2、B3、C2、D1 中产生。 如果第 4 名&#x3D;C2，那么第 5 名只能在 A2、B2、C3、D1 中产生。 如果第 4 名&#x3D;D1，那么第 5 名只能在 A2、B2、C2、D2、E2 中产生。 那么，第 4、5 名需要在马匹 [A2、B2、C2、D1、A3、B3、C3、D2、E1] 九匹马中产 生，因此也必须比赛两场，也就是到第 9 长决出胜负。 总结：最好情况可以在第 8 场角逐出前 5 名，最差也可以在第 9 场搞定。 3. 给定随机函数，生成别的随机数（Tencent） 基本都是小生成大： 小生成大：给定生成 1 到 7 的随机数 Rand7()，如何得到生成 1 到 10 的随机数函数 Rand10()？ 大生成小：给定生成 1 到 7 的随机数 Rand7()，如何得到生成 1 到 5 的随机数函数 Rand5()？ 1️⃣ 如果是大生成小的就比较容易，比如 Rand7() 生成 Rand5()，直接取前 5 个值即可。 2️⃣ 如果是小生成大的，我们可以先构造一个大于 7 的随机数生成函数。记住以下式子：$$RandNN&#x3D;(RandN()-1)*N+RandN()$$以上式子是「等概率」生成 $1$ 到 $N^2$ 之间的随机数，等概率很重要。 式子以看作是在数轴上撒豆子： $N$ 是跨度&#x2F;步长，是 RandN() 生成的数的范围长度 RandN() - 1 的目的是生成 $0$ 到 $N-1$ 的数，是跳数 后面 + RandN() 的目的是填满中间的空隙 比如 Rand49 = (Rand7() - 1) * 7 + Rand7() 可以等概率生成 1～49 之间的随机数，然后大生成小的话只需要取 1～40 (4 * 10) 之间的数字。代码如下： LeetCode 原题：470. 用 Rand7() 实现 Rand10() 1234567891011121314// The rand7() API is already defined for you.// int rand7();// @return a random integer in the range 1 to 7class Solution &#123;public: int rand10() &#123; while (true) &#123; int v = (rand7() - 1) * 7 + rand7(); // equal prob [1 ~ 49] if (v &gt;= 1 &amp;&amp; v &lt;= 40) return v % 10 + 1; &#125; &#125;&#125;; 4. 砝码称轻重，找出最轻的其实这都是一类题，这里列举几个经典的： Q1：有一个天平，九个砝码，其中一个砝码比另八个要轻一些，问至少要用天平称几次才能将轻的那个找出来？ A1：至少 2 次。第一次，一边 3 个，哪边轻就在哪边，一样重就是剩余的 3 个； 第二次，一边 1 个，哪边轻就是哪个，一样重就是剩余的那个；至少称 2 次． Q2：十组砝码每组十个，每个砝码都是 10g 重，但是现在其中有一组砝码每个都只有 9g 重，现有一个能显示克数的秤，最少称几次能找到轻的那组？ A2：至少 1 次。将砝码分组 1~10，第一组拿一个，第二组拿两个以此类推。。第十组拿十个放到秤上称出克数 x，则 y &#x3D; 550 - x，第 y 组就是轻的那组。 5. 利用空瓶换饮料，最多喝几瓶Q：1000 瓶饮料，3 个空瓶子能够换 1 瓶饮料，问最多能喝几瓶？ 思路 1 拿走 3 瓶，换回 1 瓶，相当于减少 2 瓶。 但是最后剩下 4 瓶的时候例外，这时只能换 1 瓶！ 所以我们计算 1000 减 2 能减多少次，直到剩下 4（1000-4&#x3D;996，996&#x2F;2&#x3D;498），所以 1000 减 2 能减 498 次直到剩下 4 瓶，最后剩下的 4 瓶还可以换一瓶。 所以总共是 1000+498+1&#x3D;1499 瓶。 思路 2 —— 动态规划 3 个瓶子时将发生一次交换，因此前 3 个视为特殊情况 之后每增加 2 个瓶子又可以再换 1 瓶 即 dp[i] = dp[i - 2] + 2 + 1：增加 2 瓶饮料可以再换 1 瓶饮料 12345678910int dp(int n) &#123; vector&lt;int&gt; f(n + 1); f[0] = 0; f[1] = 1; f[2] = 2; for(int i = 3; i &lt;= n; i++) &#123; f[i] = f[i - 2] + 2 + 1; &#125; return f[n];&#125; 6. 毒药毒白鼠，找出哪个瓶子中是毒药有 1000 个一模一样的瓶子，其中有 999 瓶是普通的水，有 1 瓶是毒药。任何喝下毒药的生命都会在一星期之后死亡。现在你只有 10 只小白鼠和 1 个星期的时间，如何检验出哪个瓶子有毒药？ 参考答案 涉及位运算思想，首先一共有 1000 瓶，2 的 10 次方是 1024，刚好大于 1000，也就是说，1000 瓶药品可以使用 10 位二进制数就可以表示。从第一个开始： 第 1 瓶： 00 0000 0001 第 2 瓶： 00 0000 0010 第 3 瓶： 00 0000 0011 … 第 999 瓶： 11 1111 0010 第 1000 瓶： 11 1111 0011 需要十只老鼠，如果按顺序编号，ABCDEFGHIJ 分别代表从低位到高位每一个位。 每只老鼠对应一个二进制位，如果该位上的数字为 1，则给老鼠喝瓶里的药。 观察，若死亡的老鼠编号为：ACFGJ，一共死去五只老鼠，则对应的编号为 10 0110 0101，则有毒的药品为该编号的药品，转为十进制数为：613 号。 类似问题还有：8 瓶酒一瓶有毒，用小老鼠测试。每次测试结果 8 小时后才会得出，而你只有 8 个小时的时间。最少需要（ ）老鼠测试？A、2B、3C、4D、6 答案：$8 &#x3D; 2^3$，所以选 B 7. 利用烧绳子计算时间现有若干不均匀的绳子，烧完这根绳子需要一个小时，问如何准确计时 15 分钟，30 分钟，45 分钟，75 分钟 … 15 分钟：对折之后两头烧（如果不能对折，那就参考 45 分钟的解法） 30 分钟：两头烧 45 分钟：准备两根绳子，一根两头烧，一根一头烧，同时进行，两头烧完过了 30 分钟，立即将另一根的另一头点燃，等烧完又过了 15 分钟，加起来 45 分钟 75 分钟：30 + 45 … 8. 在 24 小时内时针、分针、秒针可以重合几次 ⚠️ 前提是模拟最真实的时钟走法（2 次），而非只会停留在整数（22 次） ❌ 错误答案：24 小时中时针走 2 圈，而分针走 24 圈，时针和分针重合 24-2&#x3D;22 次，而只要时针和分针重合，秒针一定有机会重合，所以总共重合 22 次。 ✅ 正确答案：在 24 小时内（不包含 24 点），也就只有两次重合，分别为 0 点和 12 点。 时针和分针重合的时候，秒针根本就不在重合的地方，而是在其他地方，以下是数学推导： 9. 100 个囚犯猜帽子颜色一百个囚犯站成一纵列，每人头上随机带上黑色或白色的帽子，每个人都不知道自己帽子的颜色，但是能看见自己前面所有人帽子的颜色． 然后从最后一个囚犯开始，每人只能用同一种声调和音量说一个字：”黑”或”白”， 如果说中了自己帽子的颜色，就存活，说错了就拉出去斩了，说的参考回答所有囚犯都能听见。是否说对，其他囚犯不知道。在这之前，所有囚犯可以聚在一起商量策略，问如果囚犯都足够聪明而且反应足够快，100 个人最大存活人数是多少？ 如果增加限制条件，每个囚犯只能看见前面一个人帽子颜色：那么方法 (3) 就失效了，只能用方法 (2)，即存活 50 人。 (1) 所有人凭运气乱猜 [50]最坏情况下所有人都猜错，平均有 50 人猜对。 (2) 一半人凭运气 [75]很显然，坐在最后面的囚犯是不可能保证自己猜对的，他猜黑猜白都只有一半的几率猜对，似乎没什么区别；但囚犯可以事先约定好一种暗号，即最后一个囚犯猜黑表示什么意思，猜白表示什么意思。比如，最后一个囚犯可以猜测和他前面的囚犯的帽子一样的颜色，这就相当于用他的猜测告诉了他前面那个囚犯该猜什么，于是坐倒数第二的囚犯可以保证被释放；此时，坐在倒数第三个位置上的囚犯面对与刚才坐最后的囚犯相同的处境，他同样可以用他的猜测提示出他前面那个人的帽子颜色。 相当于 50 人（偶数索引位置）给前一个报点，保证活 50 个（奇数索引位置），这样可以保证至少 50 个人猜对，平均情况则有 75 个人猜对。但这不是最佳的策略。 (3) 最佳策略 [99]最佳策略可以保证，除了坐在最后面的囚犯以外，其余 99 个囚犯都能猜对。 最后的囚犯他完全可以透露出与全局相关的一些信息，因此以后所有的人都可以用这条信息： 比如，他可以数一数他前面 99 个人一共有多少顶白帽子，并约定他猜“黑”表示他前面共有偶数顶白帽，他猜“白”表示他前面共有奇数顶白帽。 坐倒数第二的那个人也数一数他前面 98 个人的白帽子个数：如果他数出来的个数与先前透露出的个数一奇一偶，则他自己肯定戴的是白帽子；如果他数出来的和先前透露的结果奇偶性相同，则他自己戴的肯定是黑帽子。 这样，坐倒数第二的保证可以猜对了。那接下来咋办呢？不要忘了，其他囚犯能听到刚才那人猜的是什么，并且知道他的猜测保证是对的。这相当于每个人： 不仅能看到坐他前面的所有人的帽子颜色 还知道他背后那些人的帽子颜色 结合最初的那个奇偶性信息 接下来的每一个人都可以猜出自己脑袋上的帽子颜色。这样下去，至少 99 个囚犯可以保证被释放。这种策略显然是最佳的，不可能再有什么策略能保证所有人都被释放，因为至少坐最后的那个人不可能保证自己猜对。 总结：等价于最后一个囚犯报全局信息，往前每一个囚犯根据全局信息、自己数得到的信息、背后那些囚犯的信息，这三条信息可以保证自己一定猜对。 10. 小猴子搬香蕉一个小猴子边上有 100 根香蕉，它要走过 50 米才能到家，每次它最多搬 50 根香蕉，多了就被压死了，它每走 1 米就要吃掉一根，请问它最多能把多少根香蕉搬到家里？ 提示：他可以把香蕉放下往返的走，但是必须保证它每走一米都能有香蕉吃。也可以走到 n 米时，放下一些香蕉，拿着 n 根香蕉走回去重新搬 50 根。 参考回答：这种试题通常有一个迷惑点，让人看不懂题目的意图。此题迷惑点在于 走一米吃一根香蕉，一共走 50 米，那不是把 50 根香蕉吃完了吗？ 如果要回去搬另外 50 根香蕉，则往回走的时候也要吃香蕉，这样每走一米需要吃掉三根香蕉，走 50 米岂不是需要 150 根香蕉？ 其实不然，本题关键点在于：猴子搬箱子的过程其实分为两个阶段： 第一阶段：来回搬，当香蕉数目大于 50 根时，猴子每搬一米需要吃掉三根香蕉。 第二阶段：香蕉数 &lt;&#x3D; 50，直接搬回去。每走一米吃掉 1 根。 我们分析第一阶段：假如把 100 根香蕉分为两箱。一箱 50 根。 第一步，把 A 箱搬一米，吃一根。 第二步，往回走一米，吃一根。 第三步，把 B 箱搬一米，吃一根。 这样，把所有香蕉搬走一米需要吃掉三根香蕉。 这样走到第几米的时候，香蕉数刚好小于 50 呢？ $100-(n*3)&lt;50\\ &amp;&amp;\\ 100-((n-1)*3)&gt;50$，n 取整数只能是 17。 走到 16 米的时候，吃掉 48 根香蕉，剩 52 根香蕉。 16 这步很有意思，它可以直接搬 50 往前走：50 - (50 -16) &#x3D; 16 根 也可以再来回搬一次（即 17 这种），结果都是一样的。 到 17 米的时候，猴子还有 49 根香蕉。这时猴子就轻松啦，直接背着 49 根走就行，把剩下的 50 - 17 &#x3D; 33 米走完，还剩 49 - 33 &#x3D; 16 根香蕉。 11. 高楼扔鸡蛋（经典）有 2 个鸡蛋，从 100 层楼上往下扔，以此来测试鸡蛋的硬度。比如鸡蛋在第 9 层没有摔碎，在第 10 层摔碎了，那么鸡蛋不会摔碎的临界点就是 9 层。 问：如何用最少的尝试次数，测试出鸡蛋不会摔碎的临界点？ 首先要说明的是这道题你要是一上来就说出正确参考回答，那说明你的智商不是超过 160 就是你做过这题。 所以建议你循序渐进的回答，一上来就说最优解可能结果不会让面试官满意。 (1) 暴力法按楼层顺序逐层扔，但是在最坏情况下，这个方法需要扔 100 次。 (2) 二分法类似于二分查找的方法，这个方法在最坏情况下，需要尝试 50 次。 (3) 均匀法如何让第一枚鸡蛋和第二枚鸡蛋的尝试次数尽可能均衡呢？ 只需对 100 做一个平方根运算，$\\sqrt{100}&#x3D;10$。 因此，尝试每 10 层扔一次： 第一次从第 10 层扔 第二次从第 20 层扔 … 第九次从第 90 层扔 第十次从第 100 层扔 这样最好的情况是第 10 层碎掉，尝试次数为 1 + 9 &#x3D; 10 次； 最坏的情况是在第 100 层碎掉，尝试次数为 10 + 9 &#x3D; 19 次。 优化点 可以从 15 层开始扔，接下来是 25、35、…、95，这样最坏情况是在第 95 层碎掉，尝试次数为 9 + 9 &#x3D; 18 次。 (4) 最优解法我们需要一种策略，使得无论临界楼层在哪，最坏情况下的尝试次数都相同。这意味着我们需要平衡每次扔鸡蛋后可能的后续尝试次数。 最优解法是反向思考的经典：如果最优解法在最坏情况下需要扔 X 次，那第一次在第几层扔最好呢？ 参考回答是：从 X 层扔。 反向证明： 假设最优的尝试次数的 x 次，为什么第一次扔就要选择第 x 层呢？ 假设第一次扔在第 x+1 层：如果第一个鸡蛋碎了，那么第二个鸡蛋只能从第 1 层开始一层一层扔，一直扔到第 x 层。这样一来，我们总共尝试了 x+1 次，和假设尝试 x 次相悖。由此可见，第一次扔的楼层必须小于 x+1 层。 假设第一次扔在第 x-1 层：如果第一个鸡蛋碎了，那么第二个鸡蛋只能从第 1 层开始一层一层扔，一直扔到第 x-2 层。这样一来，我们总共尝试了 x-2+1 &#x3D; x-1 次，虽然没有超出假设次数，但似乎有些过于保守。 假设第一次扔在第 x 层：如果第一个鸡蛋碎了，那么第二个鸡蛋只能从第 1 层开始一层一层扔，一直扔到第 x-1 层。这样一来，我们总共尝试了 x-1+1 &#x3D; x 次，刚刚好没有超出假设次数。 因此，要想尽量楼层跨度大一些，又要保证不超过假设的尝试次数 x，那么第一次扔鸡蛋的最优选择就是第 x 层。 如何求 x ？ 设最优策略下，第一次在第 x 层扔鸡蛋： 如果碎了，用第二个鸡蛋从第 1 层到第 x-1 层逐层测试，最多需要 x 次（第一次 + (x-1)次）。 如果没碎，下一步从第 x + (x-1)层扔（因为已经用了一次尝试，所以下一步减少一层来保持次数平衡）。 如果这次碎了，用第二个鸡蛋从第 x+1 层到第 x + (x-1) - 1 层逐层测试，最多需要 2 + (x-2) &#x3D; x 次。 如果没碎，下一步从第 x + (x-1) + (x-2)层扔，依此类推。 这样，我们需要找到一个 x，使得 $x + (x-1) + (x-2) + … + 1 ≥ 100$。即，$x(x + 1)&#x2F;2 ≥ 100$。 解这个不等式：$x² + x - 200 ≥ 0$ 使用求根公式：$x &#x3D; \\frac{-1 ± \\sqrt{1 + 800}}{2} &#x3D; \\frac{-1 ± \\sqrt{801}}{2} ≈ \\frac{-1 ± 28.3}{2}$ 正根约为 13.65，所以 x 至少为 $14$。 因此，最优解在最坏情况的尝试次数是 14 次，第一次扔鸡蛋的楼层也是 14 层。 最后，让我们把第一个鸡蛋没碎的情况下，所尝试的楼层数完整列举出来：14，27， 39， 50， 60， 69， 77， 84， 90， 95， 99， 100。 12. N 只蚂蚁走树枝，问总距离或者总时间问题：放 N 只蚂蚁在一条长度为 M 树枝上，蚂蚁与蚂蚁之间碰到就各自往反方向走，问所有蚂蚁离开树枝的总时间是多少？ 这个问题看起来复杂，但有一个非常巧妙的等价转换 —— 蚂蚁相遇掉头的等效性： 当两只蚂蚁相遇并掉头时，可以认为它们互相穿过而不改变方向。 这是因为： 从蚂蚁个体的角度看，掉头后继续走的方向和直接穿过是一样的。 从整体角度看，蚂蚁的位置和离开树枝的时间不会改变。 所以可以忽略碰到往反方向走这个条件。 所以答案就很简单了，就是离开树枝时间最长的那只蚂蚁所需的时间：$$T&#x3D;max(max(x_i),max(M-x_i))$$ 13. N 个强盗分配 M 个金币，求方案使得自己分配最多 海盗分金博弈 🏴‍☠️ 5 个海盗抢到了 100 枚金币，每一颗都一样的大小和价值。 他们决定这么分： 抽签决定自己的号码（1，2，3，4，5） 首先，由 1 号提出分配方案，然后大家 5 人进行表决，当半数以上的人同意时（不包括半数，这是重点），按照他的提案进行分配，否则将被扔入大海喂鲨鱼。 如果 1 号死后，再由 2 号提出分配方案，然后大家 4 人进行表决，当且仅当半超过半数的人同意时，按照他的提案进行分配，否则将被扔入大海喂鲨鱼。 依次类推…… 假设每一位海盗都足够聪明，并且利益至上，能多分一枚金币绝不少分，那么 1 号海盗该怎么分金币才能使自己分到最多的金币呢？ 思路 从后向前推，如果 1 至 3 号强盗都喂了鲨鱼，只剩 4 号和 5 号的话，5 号一定投反对票让 4 号喂鲨鱼，以独吞全部金币。所以，4 号惟有支持 3 号才能保命。 3 号知道这一点，就会提出“100，0，0”的分配方案，对 4 号、5 号一毛不拔而将全部金币归为已有，因为他知道 4 号一无所获但还是会投赞成票，再加上自己一票，他的方案即可通过。 不过，2 号推知 3 号的方案，就会提出“98，0，1，1”的方案，即放弃 3 号，而给予 4 号和 5 号各一枚金币。由于该方案对于 4 号和 5 号来说比在 3 号分配时更为有利，他们将支持他而不希望他出局而由 3 号来分配。这样，2 号将拿走 98 枚金币。 同样，2 号的方案也会被 1 号所洞悉，1 号并将提出（97，0，1，2，0）或（97，0，1，0，2）的方案，即放弃 2 号，而给 3 号一枚金币，同时给 4 号（或 5 号）2 枚金币。由于 1 号的这一方案对于 3 号和 4 号（或 5 号）来说，相比 2 号分配时更优，他们将投 1 号的赞成票，再加上 1 号自己的票，1 号的方案可获通过，97 枚金币可轻松落入囊中。这无疑是 1 号能够获取最大收益的方案了！ ✅ 参考回答是：1 号强盗分给 3 号 1 枚金币，分给 4 号或 5 号强盗 2 枚，自己独得 97 枚。分配方案可写成（97，0，1，2，0）或（97，0，1，0，2）。 此题还有变种：就是只需要一半人同意即可，不需要一半人以上同意方案就可以通过，在其他条件不变的情况下，1 号该怎么分配才能获得最多的金币？ 参考回答：类似的推理过程 4 号：4 号提出的方案的时候肯定是最终方案，因为不管 5 号同意不同意都能通过，所以 4 号 5 号不必担心自己被投入大海。那此时 5 号获得的金币为 0，4 号获得的金币为 100。 5 号：因为 4 号提方案的时候 ，自己获取的金币为 0 。所以只要 4 号之前的人分配给自己的金币大于 0 就同意该方案。 4 号：如果 3 号提的方案一定能获得通过（原因：3 号给 5 号的金币大于 0， 5 号就同意 因此就能通过），那自己获得的金币就为 0，所以只要 2 号让自己获得的金币大于 0 就会同意。 3 号：因为到了自己提方案的时候可以给 5 号一金币，自己的方案就能通过，但考虑到 2 号提方案的时候给 4 号一个金币，2 号的方案就会通过，那自己获得的金币就为 0。所以只要 1 号让自己获得的金币大于 0 就会同意。 2 号：因为到了自己提方案的时候只要给 4 号一金币，就能获得通过，根本就不用顾及 3 号 5 号同意不同意，所以不管 1 号怎么提都不会同意。 1 号：2 号肯定不会同意。但只要给 3 号一块金币，5 号一块金币（因为 5 号如果不同意，那么 4 号分配的时候，他什么都拿不到）就能获得通过。 所以参考回答是 98，0，1，0，1。 类似的问题也可用类似的推理即可。 14. 火枪手决斗，谁活下来等概率大彼此痛恨的甲、乙、丙三个枪手准备决斗。 甲枪法最好，十发八中； 乙枪法次之，十发六中； 丙枪法最差，十发四中。 如果三人同时开枪，并且每人每轮只发一枪；那么枪战后，谁活下来的机会大一些？ 一般人认为甲的枪法好，活下来的可能性大一些。但合乎推理的结论是，枪法最糟糕的丙活下来的几率最大。那么我们先来分析一下各个枪手的策略。 如同田忌赛马一般，枪手甲一定要对枪手乙先。因为乙对甲的威胁要比丙对甲的威胁更大，甲应该首先干掉乙，这是甲的最佳策略。同样的道理，枪手乙的最佳策略是第一枪瞄准甲。乙一旦将甲干掉，乙和丙进行对决，乙胜算的概率自然大很多。枪手丙的最佳策略也是先对甲。乙的枪法毕竟比甲差一些，丙先把甲干掉再与乙进行对决，丙的存活概率还是要高一些。 我们根据分析来计算一下三个枪手在上述情况下的存活几率： 第一轮：甲射乙，乙射甲，丙射甲。 甲的活率为24%（40% X 60%） 乙的活率为20%（100% - 80%) 丙的活率为100%（无人射丙） 由于丙 100％ 存活率，因此根据上轮甲乙存活的情况来计算三人第二轮的存活几率： 情况 1：甲活乙死（24% X 80% &#x3D; 19.2%） 甲射丙，丙射甲：甲的活率为 60%，丙的活率为 20% 情况 2：乙活甲死（20% X 76% &#x3D; 15.2%） 乙射丙，丙射乙：乙的活率为 60%，丙的活率为 40% 情况 3：甲乙同活（24% X 20% &#x3D; 4.8%） 重复第一轮 情况 4：甲乙同死（76% X 80% &#x3D; 60.8%） 枪战结束 据此来计算三人活率： 甲的活率为 (19.2% X 60%) + (4.8% X 24%) &#x3D; 12.672% 乙的活率为 (15.2% X 60%) + (4.8% X 20%) &#x3D; 10.08% 丙的活率为 (19.2% X 20%) + (15.2% X 40%) + (4.8% X 100%) + (60.8% X 100%) &#x3D; 75.52% 通过对两轮枪战的详细概率计算，我们发现枪法最差的丙存活的几率最大，枪法较好的甲和乙的存活几率却远低于丙的存活几率。 15. 先手必胜问题100 本书，每次能够拿 1～5 本，怎么拿能保证最后一次是你拿？ 寻找每个回合固定的拿取模式，最后一次是我拿，那么上个回合最少剩下 $6(5_{max} + 1_{min})$ 本。那么只要保持每个回合结束后都剩下 6 的倍数，并且在这个回合中我拿的和对方拿的加起来为 6（这样这个回合结束后剩下的还是 6 的倍数），就必胜。 关键是第一次我必须先手拿（100 % 6 &#x3D; 4）本（这不算在第一回合里面），剩下 96 本对方先手，只需我每次都维持当前回合共取 6 本即可，经过 16 回合即可获胜。 16. 掰巧克力问题或者参加辩论赛 掰巧克力问题 Q：我们有一块由 N×M 个小方块组成的巧克力。每次操作，可以选择一块当前的巧克力，然后沿着一行或一列将其掰开（即水平或垂直切割）。最少需要多少次操作，才能将所有巧克力掰成 1×1 的小块？ A：模拟题，即 $N - 1 + N * (M - 1) &#x3D; (M*N - 1) 次$ 辩论赛问题 Q：1000 个人参加辩论赛，1V1，输了就退出，需要安排多少场比赛？ A：999 场。 每场比赛有 2 人对决，1 人胜出，1 人被淘汰。因此，每场比赛都会淘汰 1 人。 最终要淘汰 999 人。因此，需要 999 场比赛，因为每场比赛淘汰 1 人。","tags":["面经","智力题","八股文"],"categories":["秋招指南"]},{"title":"✍️ 八股文 @ 面试手撕","path":"/post/秋招指南/2025-interview-hand-tear/","content":"415. 大数相加 腾讯 WXG 一面 ✅ LeetCode: 415. 字符串相加 给定两个字符串形式的非负整数 num1 和 num2 ，计算它们的和并同样以字符串形式返回。 你不能使用任何內建的用于处理大整数的库（比如 BigInteger）， 也不能直接将输入的字符串转换为整数形式。 示例 1： 12输入：num1 = &quot;11&quot;, num2 = &quot;123&quot;输出：&quot;134&quot; 示例 2： 12输入：num1 = &quot;456&quot;, num2 = &quot;77&quot;输出：&quot;533&quot; 1️⃣ 解法一：对位数较短的数字进行了补零操作（预处理）：self-AC 1234567891011121314151617181920212223242526272829303132class Solution &#123;public: string addStrings(string num1, string num2) &#123; int m = num1.length(), n = num2.length(); int len = abs(m - n); string zero(len, &#x27;0&#x27;); if (m &lt; n) num1 = zero + num1; else if (m &gt; n) num2 = zero + num2; int mx = max(m, n); int remain = 0; string ans; // cout &lt;&lt; num1 &lt;&lt; &quot;, &quot; &lt;&lt; num2 &lt;&lt; endl; for (int i = mx - 1; i &gt;= 0 || remain; i--) &#123; if (i &lt; 0 &amp;&amp; remain) &#123; ans.push_back(&#x27;1&#x27;); break; &#125; char ch = num1[i] + (num2[i] - &#x27;0&#x27;) + remain; if (ch &gt; &#x27;9&#x27;) &#123; ch = ch - 10; remain = 1; &#125; else &#123; remain = 0; &#125; ans.push_back(ch); &#125; reverse(ans.begin(), ans.end()); return ans; &#125;&#125;; 2️⃣ 解法二：去除预处理的过程，直接模拟 123456789101112131415161718class Solution &#123;public: string addStrings(string num1, string num2) &#123; int i = num1.length() - 1, j = num2.length() - 1, add = 0; string ans = &quot;&quot;; while (i &gt;= 0 || j &gt;= 0 || add) &#123; int x = i &gt;= 0 ? num1[i] - &#x27;0&#x27; : 0; int y = j &gt;= 0 ? num2[j] - &#x27;0&#x27; : 0; int result = x + y + add; ans.push_back(&#x27;0&#x27; + result % 10); add = result / 10; i--; j--; &#125; reverse(ans.begin(), ans.end()); return ans; &#125;&#125;; 43. 大数相乘 小鹏汽车智驾一面 ✅ LeetCode: 43. 字符串相乘 给定两个以字符串形式表示的非负整数 num1 和 num2，返回 num1 和 num2 的乘积，它们的乘积也表示为字符串形式。 **注意：**不能使用任何内置的 BigInteger 库或直接将输入转换为整数。 示例 1: 12输入: num1 = &quot;2&quot;, num2 = &quot;3&quot;输出: &quot;6&quot; 示例 2: 12输入: num1 = &quot;123&quot;, num2 = &quot;456&quot;输出: &quot;56088&quot; 1️⃣ 解法一思路（竖式相加）：建立在「大数相加」的基础上，因为多个数之间需要累加（这段代码自己 AC 的，容易理解） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Solution &#123;public: // 大数相加 string addStrings(string num1, string num2) &#123; int i = num1.length() - 1, j = num2.length() - 1, add = 0; string ans = &quot;&quot;; while (i &gt;= 0 || j &gt;= 0 || add) &#123; int x = i &gt;= 0 ? num1[i] - &#x27;0&#x27; : 0; int y = j &gt;= 0 ? num2[j] - &#x27;0&#x27; : 0; int result = x + y + add; add = result / 10; ans.push_back(&#x27;0&#x27; + result % 10); i--; j--; &#125; reverse(ans.begin(), ans.end()); return ans; &#125; // 大数相乘 string multiply(string num1, string num2) &#123; if (num1 == &quot;0&quot; || num2 == &quot;0&quot;) return &quot;0&quot;; int multiply = 0; int m = num1.length(), n = num2.length(); string ans = &quot;0&quot;; for (int i = m - 1; i &gt;= 0; i--) &#123; int x = num1[i] - &#x27;0&#x27;; string num; int add = 0; for (int j = n - 1; j &gt;= 0 || add; j--) &#123; if (x == 0) &#123; num = &quot;0&quot;; break; &#125; if (j &lt; 0) &#123; num.push_back(&#x27;0&#x27; + add); break; &#125; int y = num2[j] - &#x27;0&#x27;; int result = x * y + add; add = result / 10; num.push_back(&#x27;0&#x27; + result % 10); &#125; reverse(num.begin(), num.end()); if (num != &quot;0&quot;) ans = addStrings(ans, num + string(multiply, &#x27;0&#x27;)); multiply++; &#125; return ans; &#125;&#125;; 2️⃣ 解法二：直接做乘法，长度分别为 m 和 n 的数字相乘，值长度不超过 m + n，vector&lt;int&gt; ansArr(m + n) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** E x a m p l e * * 9 9 9 * × 6 7 8 * ---------------------- * 72 72 72 * 63 63 63 * 54 54 54 * ---------------------- * 54 117 189 135 72 * ---------------------- * 54 117 189 142 2 * ----------------------- * 54 117 203 2 2 * ----------------------- * 54 137 3 2 2 * ----------------------- * 67 7 3 2 2 * ----------------------- * 6 7 7 3 2 2 */class Solution &#123;public: string multiply(string num1, string num2) &#123; if (num1 == &quot;0&quot; || num2 == &quot;0&quot;) &#123; return &quot;0&quot;; &#125; int m = num1.length(), n = num2.length(); vector&lt;int&gt; ansArr(m + n); for (int i = m - 1; i &gt;= 0; i--) &#123; int x = num1[i] - &#x27;0&#x27;; for (int j = n - 1; j &gt;= 0; j--) &#123; int y = num2[j] - &#x27;0&#x27;; ansArr[i + j + 1] += x * y; &#125; &#125; for (int i = m + n - 1; i &gt; 0; i--) &#123; ansArr[i - 1] += ansArr[i] / 10; ansArr[i] %= 10; &#125; int idx = ansArr[0] == 0 ? 1 : 0; string ans; while (idx &lt; m + n) &#123; ans.push_back(&#x27;0&#x27; + ansArr[idx]); idx++; &#125; return ans; &#125;&#125;; 239. 滑动窗口最大值 腾讯 WXG 一面 ✅ LeetCode: 239. 滑动窗口最大值 给你一个整数数组 nums，有一个大小为 k 的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的 k 个数字。滑动窗口每次只向右移动一位。 返回 滑动窗口中的最大值 。 示例 1： 1234567891011输入：nums = [1,3,-1,-3,5,3,6,7], k = 3输出：[3,3,5,5,6,7]解释：滑动窗口的位置 最大值--------------- -----[1 3 -1] -3 5 3 6 7 3 1 [3 -1 -3] 5 3 6 7 3 1 3 [-1 -3 5] 3 6 7 5 1 3 -1 [-3 5 3] 6 7 5 1 3 -1 -3 [5 3 6] 7 6 1 3 -1 -3 5 [3 6 7] 7 1️⃣ 优先队列 priority_queue（记录最大值） + 哈希表（记录删除元素）：self-AC 123456789101112131415161718192021class Solution &#123;public: vector&lt;int&gt; maxSlidingWindow(vector&lt;int&gt;&amp; nums, int k) &#123; priority_queue&lt;int, vector&lt;int&gt;, less&lt;int&gt;&gt; pq; int n = nums.size(); unordered_map&lt;int, int&gt; cnt; for (int i = 0; i &lt; k; i++) pq.push(nums[i]); vector&lt;int&gt; ans&#123;pq.top()&#125;; for (int i = k; i &lt; n; i++) &#123; cnt[nums[i - k]]++; pq.push(nums[i]); while (pq.size() &gt; k &amp;&amp; cnt[pq.top()] &gt; 0) &#123; cnt[pq.top()]--; pq.pop(); &#125; ans.push_back(pq.top()); &#125; return ans; &#125;&#125;; 2️⃣ 优先队列 priority_queue&lt;pair&lt;int, int&gt;&gt;，通过记录索引值判断 pq.top() 元素是否在定长窗口内 123456789101112131415161718class Solution &#123;public: vector&lt;int&gt; maxSlidingWindow(vector&lt;int&gt;&amp; nums, int k) &#123; priority_queue&lt;pair&lt;int, int&gt;&gt; pq; for (int i = 0; i &lt; k; i++) &#123; pq.emplace(nums[i], i); &#125; vector&lt;int&gt; ans&#123;pq.top().first&#125;; for (int i = k; i &lt; nums.size(); i++) &#123; pq.emplace(nums[i], i); while (pq.top().second &lt; i - k + 1) &#123; pq.pop(); &#125; ans.push_back(pq.top().first); &#125; return ans; &#125;&#125;; 206. 反转链表 腾讯 WXG 一面 ✅ LeetCode: 206. 反转链表 相关例题 —— 92. 反转链表 II：反转部分区间，找到区间 leftNode 与 rightNode，以及 leftNode 左节点 pre 与 rightNode 右节点 nxt，独立区间（断开连接）后反转再接回。 给你单链表的头节点 head ，请你反转链表，并返回反转后的链表。 示例 1： 12输入：head = [1,2,3,4,5]输出：[5,4,3,2,1] 1️⃣ 解法一：递归 12345678910111213141516171819202122// 手写链表（LeetCode 已经定义，题目若需要则自己定义）struct ListNode &#123; int val; ListNode* next; ListNode() : val(0), next(nullptr) &#123;&#125; ListNode(int x) : val(x), next(nullptr) &#123;&#125; ListNode(int x, ListNode* next) : val(x), next(next) &#123;&#125;;&#125;;class Solution &#123;public: // 递归 ListNode* reverseList(ListNode* head) &#123; if (!head || !head-&gt;next) &#123; return head; &#125; ListNode* new_head = reverseList(head-&gt;next); head-&gt;next-&gt;next = head; head-&gt;next = nullptr; return new_head; &#125;&#125;; 2️⃣ 解法二：三指针迭代（pre = nullptr, cur = head, nxt = cur-&gt;next） 123456789101112131415161718192021222324/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; ListNode* pre = nullptr; ListNode* cur = head; while (cur) &#123; ListNode* nxt = cur-&gt;next; cur-&gt;next = pre; pre = cur; cur = nxt; &#125; return pre; &#125;&#125;; 146. LRU 缓存 腾讯 WXG 一面｜腾讯 CSIG 一面｜腾讯 PCG 一面 据说是所有面试中出现概率的 No.1 ✅ LeetCode: 146. LRU 缓存、面试题 16.25. LRU 缓存 请你设计并实现一个满足 LRU (最近最少使用) 缓存 约束的数据结构。 实现 LRUCache 类： LRUCache(int capacity) 以 正整数 作为容量 capacity 初始化 LRU 缓存 int get(int key) 如果关键字 key 存在于缓存中，则返回关键字的值，否则返回 -1 。 void put(int key, int value) 如果关键字 key 已经存在，则变更其数据值 value ；如果不存在，则向缓存中插入该组 key-value 。如果插入操作导致关键字数量超过 capacity ，则应该 逐出 最久未使用的关键字。 函数 get 和 put 必须以 O(1) 的平均时间复杂度运行。 示例： 1234567891011121314151617输入[&quot;LRUCache&quot;, &quot;put&quot;, &quot;put&quot;, &quot;get&quot;, &quot;put&quot;, &quot;get&quot;, &quot;put&quot;, &quot;get&quot;, &quot;get&quot;, &quot;get&quot;][[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]输出[null, null, null, 1, null, -1, null, -1, 3, 4]解释LRUCache lRUCache = new LRUCache(2);lRUCache.put(1, 1); // 缓存是 &#123;1=1&#125;lRUCache.put(2, 2); // 缓存是 &#123;1=1, 2=2&#125;lRUCache.get(1); // 返回 1lRUCache.put(3, 3); // 该操作会使得关键字 2 作废，缓存是 &#123;1=1, 3=3&#125;lRUCache.get(2); // 返回 -1 (未找到)lRUCache.put(4, 4); // 该操作会使得关键字 1 作废，缓存是 &#123;4=4, 3=3&#125;lRUCache.get(1); // 返回 -1 (未找到)lRUCache.get(3); // 返回 3lRUCache.get(4); // 返回 4 LRUCache：循环双向链表 + 哈希表 循环：方便获取末尾节点进行 LRU 逐出&#x2F;删除 双向链表 哈希表：快速找到 key 对应的节点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// LRUCache = 循环双向链表 + 哈希表class Node &#123;public: int key; int value; Node* prev; Node* next; Node(int k = 0, int v = 0) : key(k), value(v) &#123;&#125;&#125;;class LRUCache &#123;private: int capacity; Node* dummy; unordered_map&lt;int, Node*&gt; key_to_node; // 删除一个节点 void remove(Node* x) &#123; x-&gt;prev-&gt;next = x-&gt;next; x-&gt;next-&gt;prev = x-&gt;prev; &#125; // 在链表头添加一个节点 void push_front(Node* x) &#123; x-&gt;prev = dummy; x-&gt;next = dummy-&gt;next; x-&gt;prev-&gt;next = x; x-&gt;next-&gt;prev = x; &#125; // 获取 key 对应的节点, 同时把该节点移到链表头部 Node* get_node(int key) &#123; auto it = key_to_node.find(key); if (it == key_to_node.end()) &#123; return nullptr; &#125; Node* node = it-&gt;second; remove(node); push_front(node); return node; &#125;public: LRUCache(int capacity) : capacity(capacity), dummy(new Node()) &#123; // 循环双向链表: 方便取末尾值进行删除 dummy-&gt;prev = dummy; dummy-&gt;next = dummy; &#125; int get(int key) &#123; Node* node = get_node(key); return node ? node-&gt;value : -1; &#125; void put(int key, int value) &#123; Node* node = get_node(key); if (node) &#123; node-&gt;value = value; return; &#125; node = new Node(key, value); key_to_node[key] = node; push_front(node); if (key_to_node.size() &gt; capacity) &#123; Node* back_node = dummy-&gt;prev; key_to_node.erase(back_node-&gt;key); remove(back_node); delete back_node; &#125; &#125;&#125;;/** * Your LRUCache object will be instantiated and called as such: * LRUCache* obj = new LRUCache(capacity); * int param_1 = obj-&gt;get(key); * obj-&gt;put(key,value); */ 460. LFU 缓存 华为机考 ✅ LeetCode: 460. LFU 缓存 相关例题：146. LRU 缓存 请你为 最不经常使用（LFU）缓存算法设计并实现数据结构。 实现 LFUCache 类： LFUCache(int capacity) - 用数据结构的容量 capacity 初始化对象 int get(int key) - 如果键 key 存在于缓存中，则获取键的值，否则返回 -1 。 void put(int key, int value) - 如果键 key 已存在，则变更其值；如果键不存在，请插入键值对。当缓存达到其容量 capacity 时，则应该在插入新项之前，移除最不经常使用的项。在此问题中，当存在平局（即两个或更多个键具有相同使用频率）时，应该去除 最久未使用 的键。 为了确定最不常使用的键，可以为缓存中的每个键维护一个 使用计数器 。使用计数最小的键是最久未使用的键。 当一个键首次插入到缓存中时，它的使用计数器被设置为 1 (由于 put 操作)。对缓存中的键执行 get 或 put 操作，使用计数器的值将会递增。 函数 get 和 put 必须以 O(1) 的平均时间复杂度运行。 示例： 1234567891011121314151617181920212223242526输入：[&quot;LFUCache&quot;, &quot;put&quot;, &quot;put&quot;, &quot;get&quot;, &quot;put&quot;, &quot;get&quot;, &quot;get&quot;, &quot;put&quot;, &quot;get&quot;, &quot;get&quot;, &quot;get&quot;][[2], [1, 1], [2, 2], [1], [3, 3], [2], [3], [4, 4], [1], [3], [4]]输出：[null, null, null, 1, null, -1, 3, null, -1, 3, 4]解释：// cnt(x) = 键 x 的使用计数// cache=[] 将显示最后一次使用的顺序（最左边的元素是最近的）LFUCache lfu = new LFUCache(2);lfu.put(1, 1); // cache=[1,_], cnt(1)=1lfu.put(2, 2); // cache=[2,1], cnt(2)=1, cnt(1)=1lfu.get(1); // 返回 1 // cache=[1,2], cnt(2)=1, cnt(1)=2lfu.put(3, 3); // 去除键 2 ，因为 cnt(2)=1 ，使用计数最小 // cache=[3,1], cnt(3)=1, cnt(1)=2lfu.get(2); // 返回 -1（未找到）lfu.get(3); // 返回 3 // cache=[3,1], cnt(3)=2, cnt(1)=2lfu.put(4, 4); // 去除键 1 ，1 和 3 的 cnt 相同，但 1 最久未使用 // cache=[4,3], cnt(4)=1, cnt(3)=2lfu.get(1); // 返回 -1（未找到）lfu.get(3); // 返回 3 // cache=[3,4], cnt(4)=1, cnt(3)=3lfu.get(4); // 返回 4 // cache=[3,4], cnt(4)=2, cnt(3)=3 LFU 缓存 &#x3D; 循环双向链表 + key_to_node 哈希表 + freq_to_dummy 哈希表 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101class Node &#123;public: int key; int value; int freq = 1; // default Node* prev; Node* next; Node(int k = 0, int v = 0) : key(k), value(v) &#123;&#125;&#125;;class LFUCache &#123;private: int min_freq; int capacity; unordered_map&lt;int, Node*&gt; key_to_node; unordered_map&lt;int, Node*&gt; freq_to_dummy; // 每个 freq 代表一个链表的头节点 // 创新一个新的双向链表 Node* new_list() &#123; Node* dummy = new Node(); // 哨兵节点 dummy-&gt;prev = dummy; dummy-&gt;next = dummy; return dummy; &#125; void remove(Node* node) &#123; node-&gt;prev-&gt;next = node-&gt;next; node-&gt;next-&gt;prev = node-&gt;prev; &#125; void push_front(int freq, Node* node) &#123; auto it = freq_to_dummy.find(freq); if (it == freq_to_dummy.end()) &#123; // pair&lt;iterator, bool&gt; emplace() it = freq_to_dummy.emplace(freq, new_list()).first; &#125; Node* dummy = it-&gt;second; node-&gt;prev = dummy; node-&gt;next = dummy-&gt;next; node-&gt;prev-&gt;next = node; node-&gt;next-&gt;prev = node; &#125; Node* get_node(int key) &#123; auto it = key_to_node.find(key); if (it == key_to_node.end()) &#123; return nullptr; &#125; Node* node = it-&gt;second; remove(node); Node* dummy = freq_to_dummy[node-&gt;freq]; if (dummy-&gt;prev == dummy) &#123; // 如果该 freq 对应的链表移除 node 后为空时 freq_to_dummy.erase(node-&gt;freq); delete dummy; if (min_freq == node-&gt;freq) &#123; // node-&gt;freq 为最小记数 min_freq++; &#125; &#125; push_front(++node-&gt;freq, node); return node; &#125;public: LFUCache(int capacity) : capacity(capacity) &#123;&#125; int get(int key) &#123; Node* node = get_node(key); return node ? node-&gt;value : -1; &#125; void put(int key, int value) &#123; Node* node = get_node(key); if (node) &#123; node-&gt;value = value; return; &#125; if (key_to_node.size() == capacity) &#123; Node* dummy = freq_to_dummy[min_freq]; Node* last_node = dummy-&gt;prev; key_to_node.erase(last_node-&gt;key); remove(last_node); delete last_node; if (dummy-&gt;prev == dummy) &#123; freq_to_dummy.erase(min_freq); delete dummy; &#125; &#125; node = new Node(key, value); key_to_node[key] = node; push_front(1, node); min_freq = 1; &#125;&#125;;/** * Your LFUCache object will be instantiated and called as such: * LFUCache* obj = new LFUCache(capacity); * int param_1 = obj-&gt;get(key); * obj-&gt;put(key,value); */ 560. 和为 k 的子数组 Momenta 一面 ✅ LeetCode: 560. 和为 K 的子数组 给你一个整数数组 nums 和一个整数 k ，请你统计并返回该数组中和为 k 的子数组的个数 。 子数组是数组中元素的连续非空序列。 示例 1： 12输入：nums = [1,1,1], k = 2输出：2 示例 2： 12输入：nums = [1,2,3], k = 3输出：2 1️⃣ 前缀和 + 哈希表 12345678910111213141516class Solution &#123;public: int subarraySum(vector&lt;int&gt;&amp; nums, int k) &#123; int n = nums.size(); vector&lt;int&gt; preSum(n + 1); for(int i = 1; i &lt;= n; i++) preSum[i] = nums[i - 1] + preSum[i - 1]; int ans = 0; unordered_map&lt;int, int&gt; cnt; for(int num : preSum) &#123; ans += cnt.contains(num - k) ? cnt[num - k] : 0; cnt[num]++; &#125; return ans; &#125;&#125;; 93. 复原 IP 地址 腾讯 PCG 一面 ✅ LeetCode: 93. 复原 IP 地址 有效 IP 地址 正好由四个整数（每个整数位于 0 到 255 之间组成，且不能含有前导 0），整数之间用 &#39;.&#39; 分隔。 例如：&quot;0.1.2.201&quot; 和 &quot;192.168.1.1&quot; 是 有效 IP 地址，但是 &quot;0.011.255.245&quot;、&quot;192.168.1.312&quot; 和 &quot;192.168@1.1&quot; 是 无效 IP 地址。 给定一个只包含数字的字符串 s ，用以表示一个 IP 地址，返回所有可能的有效 IP 地址，这些地址可以通过在 s 中插入 &#39;.&#39; 来形成。你 不能 重新排序或删除 s 中的任何数字。你可以按 任何 顺序返回答案。 示例 1： 12输入：s = &quot;25525511135&quot;输出：[&quot;255.255.11.135&quot;,&quot;255.255.111.35&quot;] 示例 2： 12输入：s = &quot;0000&quot;输出：[&quot;0.0.0.0&quot;] 1️⃣ 解法一：四层循环迭代，简单易懂暴力 12345678910111213141516171819202122232425262728293031class Solution &#123;public: vector&lt;string&gt; restoreIpAddresses(string s) &#123; int n = s.length(); vector&lt;string&gt; ans; for (int a = 1; a &lt;= 3; a++) &#123; for (int b = 1; b &lt;= 3; b++) &#123; for (int c = 1; c &lt;= 3; c++) &#123; for (int d = 1; d &lt;= 3; d++) &#123; if (a + b + c + d == n) &#123; int numA = stoi(s.substr(0, a)); int numB = stoi(s.substr(a, b)); int numC = stoi(s.substr(a + b, c)); int numD = stoi(s.substr(a + b + c, d)); if (numA &lt;= 255 &amp;&amp; numB &lt;= 255 &amp;&amp; numC &lt;= 255 &amp;&amp; numD &lt;= 255) &#123; string ip = to_string(numA) + &quot;.&quot; + to_string(numB) + &quot;.&quot; + to_string(numC) + &quot;.&quot; + to_string(numD); if (ip.length() == n + 3) &#123; ans.push_back(ip); &#125; &#125; &#125; &#125; &#125; &#125; &#125; return ans; &#125;&#125;; 2️⃣ 回溯法｜递归 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273// 代码1class Solution &#123;public: vector&lt;string&gt; ans; string ip; void backtracking(string s, int i, int segment) &#123; if (i == s.length() &amp;&amp; segment == 4) &#123; ip = ip.substr(0, ip.length() - 1); ans.push_back(ip); return; &#125; if (segment &gt; 4) &#123; return; &#125; for (int j = 1; j &lt;= 3 &amp;&amp; i + j - 1 &lt; s.length(); j++) &#123; if (j &gt; 1 &amp;&amp; s[i] == &#x27;0&#x27;) &#123; return; &#125; string subIP = s.substr(i, j); int numIP = stoi(subIP); if (numIP &gt; 255) break; int len = ip.length(); ip = ip + subIP + &#x27;.&#x27;; backtracking(s, i + j, segment + 1); ip = ip.substr(0, len); &#125; &#125; vector&lt;string&gt; restoreIpAddresses(string s) &#123; int n = s.length(); if (n &lt; 4) &#123; return &#123;&#125;; &#125; backtracking(s, 0, 0); return ans; &#125;&#125;;// 代码2class Solution &#123;public: vector&lt;string&gt; ans; vector&lt;string&gt; path; vector&lt;string&gt; restoreIpAddresses(string s) &#123; int n = s.length(); if (n &lt; 4 || n &gt; 12) &#123; return &#123;&#125;; &#125; function&lt;void(int)&gt; dfs = [&amp;](int i) &#123; if (i == n &amp;&amp; path.size() == 4) &#123; string ip = path[0] + &quot;.&quot; + path[1] + &quot;.&quot; + path[2] + &quot;.&quot; + path[3]; ans.push_back(ip); return; &#125; for (int j = 1; j &lt;= 3 &amp;&amp; i + j - 1 &lt; n; j++) &#123; string sub = s.substr(i, j); if ((j &gt; 1 &amp;&amp; s[i] == &#x27;0&#x27;) || stoi(sub) &gt; 255) break; path.push_back(sub); dfs(i + j); path.pop_back(); &#125; &#125;; dfs(0); return ans; &#125;&#125;; 25. K 个一组反转链表 腾讯 WXG 一面 ✅ LeetCode: 25. K 个一组翻转链表 相关例题 1：24. 两两交换链表中的节点 迭代｜四指针 递归｜三指针 相关例题 2：206. 反转链表 相关例题 3：92. 反转链表 II 给你链表的头节点 head ，每 k 个节点一组进行翻转，请你返回修改后的链表。 k 是一个正整数，它的值小于或等于链表的长度。如果节点总数不是 k 的整数倍，那么请将最后剩余的节点保持原有顺序。 你不能只是单纯的改变节点内部的值，而是需要实际进行节点交换。 示例 1： 12输入：head = [1,2,3,4,5], k = 2输出：[2,1,4,3,5] 1️⃣ 解法一：利用「206. 反转链表」+「92. 反转链表 II」完成 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: // 206. 反转链表 ListNode* reverseList(ListNode* head) &#123; ListNode* pre = nullptr; ListNode* cur = head; while (cur) &#123; ListNode* nxt = cur-&gt;next; cur-&gt;next = pre; pre = cur; cur = nxt; &#125; return pre; &#125; // 92. 反转链表 II ListNode* reverseBetween(ListNode* head, int left, int right) &#123; ListNode dummy(0, head); ListNode* pre = &amp;dummy; for (int i = 0; i &lt; left - 1; i++) &#123; pre = pre-&gt;next; &#125; ListNode* leftNode = pre-&gt;next; ListNode* rightNode = leftNode; for (int i = left; i &lt; right; i++) &#123; rightNode = rightNode-&gt;next; &#125; ListNode* nxt = rightNode-&gt;next; rightNode-&gt;next = nullptr; reverseList(leftNode); pre-&gt;next = rightNode; leftNode-&gt;next = nxt; return dummy.next; &#125; ListNode* reverseKGroup(ListNode* head, int k) &#123; int n = 0; ListNode* cur = head; while (cur) &#123; n++; cur = cur-&gt;next; &#125; if (n &lt; k) &#123; return head; &#125; ListNode* new_head = head; int times = n / k; for (int i = 0; times--; i += k) &#123; ListNode* node = reverseBetween(new_head, i + 1, i + k); if (i == 0) &#123; new_head = node; &#125; &#125; return new_head; &#125;&#125;; 2️⃣ 解法二｜0x3f：从反转链表直接到「K 个一组翻转链表」 反转过程同「反转链表」代码，从 while (cur) 变成 for (int i = 0; i &lt; k; i++)；其次每处理 k 个一组后，节点之间需要切换（🌟）。 1234567891011121314151617181920212223242526272829class Solution &#123;public: ListNode* reverseKGroup(ListNode* head, int k) &#123; // 统计节点个数 int n = 0; for (ListNode* cur = head; cur; cur = cur-&gt;next) &#123; n++; &#125; ListNode dummy(0, head); ListNode* p0 = &amp;dummy; ListNode* pre = nullptr; ListNode* cur = head; // k 个一组处理 for (; n &gt;= k; n -= k) &#123; // 同 [206. 反转链表] for (int i = 0; i &lt; k; i++) &#123; ListNode* nxt = cur-&gt;next; cur-&gt;next = pre; pre = cur; cur = nxt; &#125; ListNode* nxt = p0-&gt;next; p0-&gt;next-&gt;next = cur; p0-&gt;next = pre; p0 = nxt; &#125; return dummy.next; &#125;&#125;; 234. 回文链表✅ LeetCode: 234. 回文链表 相关例题： 876. 链表的中间结点 206. 反转链表 给你一个单链表的头节点 head ，请你判断该链表是否为回文链表。如果是，返回 true ；否则，返回 false 。 示例 1： 12输入：head = [1,2,2,1]输出：true 先找到中间节点（类 876 题使用快慢指针），然后反转后半段的链表（206 题反转链表），之后逐个比较即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: // 876. 链表的中间结点 ListNode* middleNode(ListNode* head) &#123; ListNode *slow = head, *fast = head; while (fast &amp;&amp; fast-&gt;next) &#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; &#125; return slow; &#125; // 206. 反转链表｜迭代 ListNode* reverseList(ListNode* head) &#123; ListNode* pre = nullptr; ListNode* cur = head; while (cur) &#123; ListNode* nxt = cur-&gt;next; cur-&gt;next = pre; pre = cur; cur = nxt; &#125; return pre; &#125; // 206. 反转链表｜递归 ListNode* recursion_reverseList(ListNode* head) &#123; if (!head || !head-&gt;next) &#123; return head; &#125; ListNode* new_head = recursion_reverseList(head-&gt;next); head-&gt;next-&gt;next = head; head-&gt;next = nullptr; return new_head; &#125; bool isPalindrome(ListNode* head) &#123; // 中间节点 (偶数则为后一个节点) ListNode* middle = middleNode(head); ListNode* node = reverseList(middle); while (node) &#123; if (head-&gt;val != node-&gt;val) &#123; return false; &#125; head = head-&gt;next; node = node-&gt;next; &#125; return true; &#125;&#125;; 23. 合并 K 个升序链表 快手搜广推一面 ✅ LeetCode: 23. 合并 K 个升序链表 给你一个链表数组，每个链表都已经按升序排列。 请你将所有链表合并到一个升序链表中，返回合并后的链表。 示例 1： 12345678910输入：lists = [[1,4,5],[1,3,4],[2,6]]输出：[1,1,2,3,4,4,5,6]解释：链表数组如下：[ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6]将它们合并到一个有序链表中得到。1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6 1️⃣ 最小堆 12345678910111213141516171819202122232425262728293031323334353637/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; auto cmp = [](const ListNode* a, const ListNode* b) &#123; return a-&gt;val &gt; b-&gt;val; &#125;; // decltype 推断表达式类型 priority_queue&lt;ListNode*, vector&lt;ListNode*&gt;, decltype(cmp)&gt; pq; for (auto head : lists) &#123; if (head) &#123; pq.push(head); &#125; &#125; ListNode dummy&#123;&#125;; auto cur = &amp;dummy; while (!pq.empty()) &#123; ListNode* nxt = pq.top(); pq.pop(); cur-&gt;next = nxt; cur = cur-&gt;next; if (nxt-&gt;next) &#123; pq.push(nxt-&gt;next); &#125; &#125; return dummy.next; &#125;&#125;; 2️⃣ 分治法 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeTwoLists(ListNode* list1, ListNode* list2) &#123; ListNode dummy&#123;&#125;; ListNode* cur = &amp;dummy; while (list1 &amp;&amp; list2) &#123; if (list1-&gt;val &lt; list2-&gt;val) &#123; cur-&gt;next = list1; list1 = list1-&gt;next; &#125; else &#123; cur-&gt;next = list2; list2 = list2-&gt;next; &#125; cur = cur-&gt;next; &#125; cur-&gt;next = list1 ? list1 : list2; return dummy.next; &#125; ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists, int l, int r) &#123; if (l == r) return lists[l]; if (l &gt; r) return nullptr; int m = (l + r) &gt;&gt; 1; auto left = mergeKLists(lists, l, m); auto right = mergeKLists(lists, m + 1, r); return mergeTwoLists(left, right); &#125; ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; return mergeKLists(lists, 0, lists.size() - 1); &#125;&#125;; 445. 两数相加 II 腾讯 CDG 一面 ✅ LeetCode: 445. 两数相加 II 前置题目： 2. 两数相加 206. 反转链表 给你两个 非空 链表来代表两个非负整数。数字最高位位于链表开始位置。它们的每个节点只存储一位数字。将这两数相加会返回一个新的链表。 你可以假设除了数字 0 之外，这两个数字都不会以零开头。 示例1： 12输入：l1 = [7,2,4,3], l2 = [5,6,4]输出：[7,8,0,7] 反转链表 + 两数相加 &#x3D; 秒杀 123456789101112131415161718192021222324252627282930313233class Solution &#123; ListNode* reverseList(ListNode* head) &#123; if (head == nullptr || head-&gt;next == nullptr) &#123; return head; &#125; auto new_head = reverseList(head-&gt;next); head-&gt;next-&gt;next = head; // 把下一个节点指向自己 head-&gt;next = nullptr; // 断开指向下一个节点的连接，保证最终链表的末尾节点的 next 是空节点 return new_head; &#125; // l1 和 l2 为当前遍历的节点，carry 为进位 ListNode* addTwo(ListNode* l1, ListNode* l2, int carry = 0) &#123; if (l1 == nullptr &amp;&amp; l2 == nullptr) &#123; // 递归边界：l1 和 l2 都是空节点 return carry ? new ListNode(carry) : nullptr; // 如果进位了，就额外创建一个节点 &#125; if (l1 == nullptr) &#123; // 如果 l1 是空的，那么此时 l2 一定不是空节点 swap(l1, l2); // 交换 l1 与 l2，保证 l1 非空，从而简化代码 &#125; carry += l1-&gt;val + (l2 ? l2-&gt;val : 0); // 节点值和进位加在一起 l1-&gt;val = carry % 10; // 每个节点保存一个数位 l1-&gt;next = addTwo(l1-&gt;next, (l2 ? l2-&gt;next : nullptr), carry / 10); // 进位 return l1; &#125;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; l1 = reverseList(l1); l2 = reverseList(l2); // l1 和 l2 反转后，就变成【2. 两数相加】了 auto l3 = addTwo(l1, l2); return reverseList(l3); &#125;&#125;; 24. 两两交换链表中的节点 腾讯 CSIG 一面 ✅ LeetCode: 24. 两两交换链表中的节点 给你一个链表，两两交换其中相邻的节点，并返回交换后链表的头节点。你必须在不修改节点内部的值的情况下完成本题（即，只能进行节点交换）。 示例 1： 12输入：head = [1,2,3,4]输出：[2,1,4,3] 四个指针秒了 123456789101112131415161718192021222324252627282930/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* swapPairs(ListNode* head) &#123; if (!head) return head; ListNode dummy(0, head); ListNode* node0 = &amp;dummy; ListNode* node1 = head; while (node1 &amp;&amp; node1-&gt;next) &#123; ListNode* node2 = node1-&gt;next; ListNode* node3 = node2-&gt;next; node2-&gt;next = node1; node1-&gt;next = node3; node0-&gt;next = node2; node0 = node1; node1 = node3; &#125; return dummy.next; &#125;&#125;; 72. 编辑距离 腾讯 CDG 一面 ✅ LeetCode: 72. 编辑距离 给你两个单词 word1 和 word2， 请返回将 word1 转换成 word2 所使用的最少操作数 。 你可以对一个单词进行如下三种操作： 插入一个字符 删除一个字符 替换一个字符 示例 1： 123456输入：word1 = &quot;horse&quot;, word2 = &quot;ros&quot;输出：3解释：horse -&gt; rorse (将 &#x27;h&#x27; 替换为 &#x27;r&#x27;)rorse -&gt; rose (删除 &#x27;r&#x27;)rose -&gt; ros (删除 &#x27;e&#x27;) 递推｜注意边界初始化值 1234567891011121314151617class Solution &#123;public: int minDistance(string word1, string word2) &#123; int m = word1.length(), n = word2.length(); vector&lt;vector&lt;int&gt;&gt; f(m + 1, vector&lt;int&gt;(n + 1)); for (int i = 0; i &lt;= m; i++) f[i][0] = i; for (int j = 0; j &lt;= n; j++) f[0][j] = j; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; f[i + 1][j + 1] = word1[i] == word2[j] ? f[i][j] : min(&#123;f[i][j], f[i + 1][j], f[i][j + 1]&#125;) + 1; &#125; &#125; return f[m][n]; &#125;&#125;; 4. 寻找两个正序数组的中位数 字节 AML 一面 ✅ LeetCode: 4. 寻找两个正序数组的中位数 给定两个大小分别为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。请你找出并返回这两个正序数组的 中位数 。 算法的时间复杂度应该为 O(log (m+n)) 。 示例 1： 123输入：nums1 = [1,3], nums2 = [2]输出：2.00000解释：合并数组 = [1,2,3] ，中位数 2 示例 2： 123输入：nums1 = [1,2], nums2 = [3,4]输出：2.50000解释：合并数组 = [1,2,3,4] ，中位数 (2 + 3) / 2 = 2.5 🧐 分析本质上，我们需要在两个有序数组中，查找第 k 小的数，其中 k &#x3D; (m + n) &#x2F; 2 取上整。 如果 m+n 是奇数，返回第 k 小的数。 如果 m+n 是偶数，返回第 k 小的数和第 k+1 小的数的平均值。 先从最暴力的「排序」做法开始，然后讲解「双指针」做法，最后过渡到「二分查找」做法。 🙋 答疑 1️⃣ 相向双指针｜均匀分组｜当条件「第一组最大值 &lt;&#x3D; 第二组最小值」满足12345678910111213141516171819202122232425class Solution &#123;public: // 相向双指针｜均匀分组｜当条件「第一组最大值 &lt;= 第二组最小值」满足 // Hot 100 中最难的一题 double findMedianSortedArrays(vector&lt;int&gt;&amp; a, vector&lt;int&gt;&amp; b) &#123; if (a.size() &gt; b.size()) swap(a, b); int m = a.size(), n = b.size(); a.insert(a.begin(), INT_MIN); b.insert(b.begin(), INT_MIN); a.push_back(INT_MAX); b.push_back(INT_MAX); int i = 0, j = (m + n + 1) / 2; while (true) &#123; if (a[i] &lt;= b[j + 1] &amp;&amp; b[j] &lt;= a[i + 1]) &#123; int max1 = max(a[i], b[j]); // 第一组最大值 int min2 = min(a[i + 1], b[j + 1]); // 第二组最小值 return (m + n) % 2 ? max1 : (max1 + min2) / 2.0; &#125; i++; j--; &#125; &#125;&#125;; 2️⃣ 用二分查找优化： 由于满足点只有一个, 所以判断条件为 $a[i] &lt;&#x3D; b[j + 1]$12345678910111213141516171819202122232425262728293031class Solution &#123;public: // 二分优化, 由于满足点只有一个, 所以判断条件为 a[i] &lt;= b[j + 1] double findMedianSortedArrays(vector&lt;int&gt;&amp; a, vector&lt;int&gt;&amp; b) &#123; if (a.size() &gt; b.size()) swap(a, b); int m = a.size(), n = b.size(); a.insert(a.begin(), INT_MIN); b.insert(b.begin(), INT_MIN); a.push_back(INT_MAX); b.push_back(INT_MAX); int left = 0, right = m + 1; while (left + 1 &lt; right) &#123; int i = (left + right) / 2; int j = (m + n + 1) / 2 - i; if (a[i] &lt;= b[j + 1]) &#123; left = i; &#125; else &#123; right = i; &#125; &#125; // left == right - 1 int i = left; int j = (m + n + 1) / 2 - i; int max1 = max(a[i], b[j]); int min2 = min(a[i + 1], b[j + 1]); return (m + n) % 2 ? max1 : (max1 + min2) / 2.0; &#125;&#125;; 230. 二叉搜索树中第 K 小的元素 腾讯 WXG 一面 ✅ LeetCode：230. 二叉搜索树中第 K 小的元素 给定一个二叉搜索树的根节点 root ，和一个整数 k ，请你设计一个算法查找其中第 k 小的元素（从 1 开始计数）。 示例 1： 12输入：root = [3,1,4,null,2], k = 1输出：1 1️⃣ 中序遍历：在中序遍历，即「左-根-右」的过程中，每次递归完左子树，就把 k 减少 1，表示我们按照中序遍历访问到了一个节点。如果减一后 k 变成 0，那么答案就是当前节点的值，用一个外部变量 ans 记录。 123456789101112131415161718class Solution &#123;public: int kthSmallest(TreeNode* root, int k) &#123; int ans; auto dfs = [&amp;](this auto&amp;&amp; dfs, TreeNode* node) -&gt; void &#123; if (node == nullptr) &#123; return; &#125; dfs(node-&gt;left); // 左 if (--k == 0) &#123; ans = node-&gt;val; // 根 &#125; dfs(node-&gt;right); // 右 &#125;; dfs(root); return ans; &#125;&#125;; 2️⃣ 中序遍历：直接将所有答案记录到 vector 数组中，返回对应索引值即可。 1234567891011121314151617class Solution &#123;public: vector&lt;int&gt; ans; void preOrder(TreeNode* node) &#123; if (node == nullptr) return; preOrder(node-&gt;left); ans.push_back(node-&gt;val); preOrder(node-&gt;right); &#125; int kthSmallest(TreeNode* root, int k) &#123; preOrder(root); return ans[k - 1]; &#125;&#125;; 354. 俄罗斯套娃信封问题 腾讯 WXG 一面 ✅ LeetCode：354. 俄罗斯套娃信封问题 给你一个二维整数数组 envelopes ，其中 envelopes[i] = [wi, hi] ，表示第 i 个信封的宽度和高度。 当另一个信封的宽度和高度都比这个信封大的时候，这个信封就可以放进另一个信封里，如同俄罗斯套娃一样。 请计算 最多能有多少个 信封能组成一组“俄罗斯套娃”信封（即可以把一个信封放到另一个信封里面）。 注意：不允许旋转信封。 示例 1： 123输入：envelopes = [[5,4],[6,4],[6,7],[2,3]]输出：3解释：最多信封的个数为 3, 组合为: [2,3] =&gt; [5,4] =&gt; [6,7]。 示例 2： 12输入：envelopes = [[1,1],[1,1],[1,1]]输出：1 0️⃣ DP 会超时，只能用二分查找。 1️⃣ 贪心 + 二分查找：先排序，再按照 LIS 二分贪心模板求最长递增子序列。因为二者都必须是递增的，所以第二维度需要逆序排序，使得第一维度相同的多个数，最后一个插入的一定是最小值，这样能嵌套的信封最多。 123456789101112131415161718class Solution &#123;public: int maxEnvelopes(vector&lt;vector&lt;int&gt;&gt;&amp; envelopes) &#123; sort(envelopes.begin(), envelopes.end(), [](const auto&amp; a, const auto&amp; b) &#123; return a[0] &lt; b[0] || (a[0] == b[0] &amp;&amp; a[1] &gt; b[1]); &#125;); vector&lt;int&gt; g; for (auto&amp; e : envelopes) &#123; auto it = lower_bound(g.begin(), g.end(), e[1]); if (it == g.end()) &#123; g.push_back(e[1]); &#125; else &#123; *it = e[1]; &#125; &#125; return g.size(); &#125;&#125;;","tags":["面经","八股文","面试手撕"],"categories":["秋招指南"]},{"title":"✍️ 八股文 @ 计算机网络","path":"/post/秋招指南/2025-network/","content":"1. 键入网址到网页显示，期间发生了什么？ 超参数一面、腾讯 WXG 测开一面 回答模板 当您在浏览器中输入网址并按下回车后，整个过程涉及 TCP&#x2F;IP 协议栈的每一层协作，具体过程如下： 应用层：浏览器解析 URL，生成 HTTP 请求报文（包含请求方法、路径、头部字段等）。随后触发 DNS 查询（通过 UDP 协议），将域名解析为 IP 地址。若访问 HTTPS 站点，还会触发 TLS 握手协商加密参数。 传输层：获取目标 IP 后，操作系统通过 TCP 协议与服务器建立连接（三次握手：SYN → SYN-ACK → ACK）。TCP 为 HTTP 数据提供分段、序列号、确认应答和重传机制，确保可靠传输。连接建立后，HTTP 请求被封装为 TCP 数据段发送。 网络层：TCP 数据段交给 IP 协议处理，添加源&#x2F;目标 IP 地址构成 IP 数据包，通过路由选择算法决定转发路径。可能经过多个路由器（跳数递增、TTL递减），最终抵达目标服务器。 网络接口层：IP 数据包被封装为帧（如以太网帧），添加 MAC 地址头部。通过 ARP 协议查询下一跳路由器或目标服务器的 MAC 地址，经物理网络（如交换机、光纤）传输至下一节点。 服务器端处理：服务器反向解封装帧→IP 包→TCP 段→HTTP 请求，处理后生成 HTTP 响应（状态码、响应头、HTML 等内容），再沿协议栈封装返回。 客户端解析与渲染：浏览器接收响应后，解析 HTML 构建 DOM 树，加载 CSS&#x2F;JS 等子资源（可能触发多次 TCP 连接复用或并发），最终完成页面渲染。 TCP 连接释放：数据传输完成后，通过 TCP 四次挥手（FIN-ACK）安全关闭连接。 详细的过程如下 想必不少小伙伴面试过程中，会遇到「当键入网址后，到网页显示，其间发生了什么」的面试题。 这问题真挺常问的，好几家公司问了这个问题。 接下来以下图较简单的网络拓扑模型作为例子，探究探究期间发生了什么？ (1) HTTP 浏览器做的第一步工作就是解析 URL 首先浏览器做的第一步工作就是要对 URL 进行解析，从而生成发送给 Web 服务器的请求信息。 让我们看看一条长长的 URL 里的各个元素的代表什么，见下图： 所以图中的长长的 URL 实际上是请求服务器里的文件资源。 要是上图中的蓝色部分 URL 元素都省略了，那应该是请求哪个文件呢？ 当没有路径名时，就代表访问根目录下事先设置的默认文件，也就是 /index.html 或者 /default.html 这些文件，这样就不会发生混乱了。 生产 HTTP 请求信息 对 URL 进行解析之后，浏览器确定了 Web 服务器和文件名，接下来就是根据这些信息来生成 HTTP 请求消息了。 (2) DNS通过浏览器解析 URL 并生成 HTTP 消息后，需要委托操作系统将消息发送给 Web 服务器。 但在发送之前，还有一项工作需要完成，那就是查询服务器域名对应的 IP 地址，因为委托操作系统发送消息时，必须提供通信对象的 IP 地址。 有一种服务器就专门保存了 Web 服务器域名与 IP 的对应关系，它就是 DNS 服务器。 域名的层级关系 DNS 中的域名都是用句点来分隔的，比如 www.server.com，这里的句点代表了不同层次之间的界限。 在域名中，越靠右的位置表示其层级越高。 毕竟域名是外国人发明，所以思维和中国人相反，比如说一个城市地点的时候，外国喜欢从小到大的方式顺序说起（如 XX 街道 XX 区 XX 市 XX 省），而中国则喜欢从大到小的顺序（如 XX 省 XX 市 XX 区 XX 街道）。 实际上域名最后还有一个点，比如 www.server.com.，这个最后的一个点代表根域名。 也就是，. 根域是在最顶层，它的下一层就是 .com 顶级域，再下面是 server.com。 所以域名的层级关系类似一个树状结构： 根 DNS 服务器（.） 顶级域 DNS 服务器（.com） 权威 DNS 服务器（server.com） 根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中。 这样一来，任何 DNS 服务器就都可以找到并访问根域 DNS 服务器了。 因此，客户端只要能够找到任意一台 DNS 服务器，就可以通过它找到根域 DNS 服务器，然后再一路顺藤摸瓜找到位于下层的某台目标 DNS 服务器。 域名解析的工作流程 客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP&#x2F;IP 设置中填写的 DNS 服务器地址）。 本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“能告诉我 www.server.com 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。 根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。” 本地 DNS 收到顶级域名服务器的地址后，发起请求问“你能告诉我 www.server.com 的 IP 地址吗？” 顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”。 本地 DNS 于是转向问权威 DNS 服务器：“www.server.com 对应的 IP 是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。 至此，我们完成了 DNS 的解析过程。现在总结一下，整个过程我画成了一个图。 那是不是每次解析域名都要经过那么多的步骤呢？ 当然不是了，还有缓存这个东西的嘛。 浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回； 如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回； 如果没有，再去 hosts 文件看； 也没有，才会去问「本地 DNS 服务器」 (3) 协议栈通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的协议栈。 协议栈的内部分为几个部分，分别承担不同的工作。上下关系是有一定的规则的，上面的部分会向下面的部分委托工作，下面的部分收到委托的工作并执行。 应用程序（浏览器）通过调用 Socket 库，来委托协议栈工作。 协议栈的上半部分有两块，分别是负责收发数据的 TCP 和 UDP 协议，这两个传输协议会接受应用层的委托执行收发数据的操作。 协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。 此外 IP 中还包括 ICMP 协议和 ARP 协议。 ICMP 用于告知网络包传送过程中产生的错误以及各种控制信息。 ARP 用于根据 IP 地址查询相应的以太网 MAC 地址。 IP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。 (4) TCP —— 可靠传输HTTP 是基于 TCP 协议传输的，所以在这我们先了解下 TCP 协议。 TCP 包头格式 我们先看看 TCP 报文头部的格式： 首先，源端口号和目标端口号是不可少的，如果没有这两个端口号，数据就不知道应该发给哪个应用。 接下来有包的序号，这个是为了解决包乱序的问题。 还有应该有的是确认号，目的是确认发出去对方是否有收到。如果没有收到就应该重新发送，直到送达，这个是为了解决丢包的问题。 接下来还有一些状态位。例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。 还有一个重要的就是窗口大小。TCP 要做流量控制，通信双方各声明一个窗口（缓存大小），标识自己当前能够的处理能力，别发送的太快，撑死我，也别发的太慢，饿死我。 除了做流量控制以外，TCP 还会做拥塞控制，对于真正的通路堵车不堵车，它无能为力，唯一能做的就是控制自己，也即控制发送的速度。不能改变世界，就改变自己嘛。 TCP 传输数据之前，要先三次握手建立连接 在 HTTP 传输数据之前，首先需要 TCP 建立连接，TCP 连接的建立，通常称为三次握手。 这个所谓的「连接」，只是双方计算机里维护一个状态机，在连接建立的过程中，双方的状态变化时序图就像这样。 一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。 然后客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。 服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。 客户端收到服务端发送的 SYN 和 ACK 之后，发送对 SYN 确认的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。 服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。 所以三次握手目的是保证双方都有发送和接收的能力。 如何查看 TCP 的连接状态？ TCP 的连接状态查看，在 Linux 可以通过 netstat -napt 命令查看。 TCP 分割数据 如果 HTTP 请求消息比较长，超过了 MSS 的长度，这时 TCP 就需要把 HTTP 的数据拆解成一块块的数据发送，而不是一次性发送所有数据。 MTU：一个网络包的最大长度，以太网中一般为 1500 字节。 MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度。 数据会被以 MSS 的长度为单位进行拆分，拆分出来的每一块数据都会被放进单独的网络包中。也就是在每个被拆分的数据加上 TCP 头信息，然后交给 IP 模块来发送数据。 注：HTTP 头部和消息体是作为一个整体被 TCP 分割的。 TCP 报文生成 TCP 协议里面会有两个端口，一个是浏览器监听的端口（通常是随机生成的），一个是 Web 服务器监听的端口（HTTP 默认端口号是 80， HTTPS 默认端口号是 443）。 在双方建立了连接后，TCP 报文中的数据部分就是存放 HTTP 头部 + 数据，组装好 TCP 报文之后，就需交给下面的网络层处理。 至此，网络包的报文如下图。 (5) IP —— 远程定位TCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成网络包发送给通信对象。 IP 包头格式 我们先看看 IP 报文头部的格式： 在 IP 协议里面需要有源地址 IP 和目标地址 IP： 源地址 IP，即是客户端输出的 IP 地址 目标地址，即通过 DNS 域名解析得到的 Web 服务器 IP 因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的协议号，要填写为 06（十六进制），表示协议为 TCP。 假设客户端有多个网卡，就会有多个 IP 地址，那 IP 头部的源地址应该选择哪个 IP 呢？ 当存在多个网卡时，在填写源地址 IP 时，就需要判断到底应该填写哪个地址。这个判断相当于在多块网卡中判断应该使用哪个一块网卡来发送包。 这个时候就需要根据路由表规则，来判断哪一个网卡作为源地址 IP。 在 Linux 操作系统，我们可以使用 route -n 命令查看当前系统的路由表。 举个例子，根据上面的路由表，我们假设 Web 服务器的目标地址是 192.168.10.200。 首先先和第一条目的子网掩码（Genmask）进行 与运算，得到结果为 192.168.10.0，但是第一个条目的 Destination 是 192.168.3.0，两者不一致所以匹配失败。 再与第二条目的子网掩码进行 与运算，得到的结果为 192.168.10.0，与第二条目的 Destination 192.168.10.0 匹配成功，所以将使用 eth1 网卡的 IP 地址作为 IP 包头的源地址。 那么假设 Web 服务器的目标地址是 10.100.20.100，那么依然依照上面的路由表规则判断，判断后的结果是和第三条目匹配。 第三条目比较特殊，它目标地址和子网掩码都是 0.0.0.0，这表示默认网关，如果其他所有条目都无法匹配，就会自动匹配这一行。并且后续就把包发给路由器，Gateway 即是路由器的 IP 地址。 IP 报文生成 至此，网络包的报文如下图。 (6) MAC —— 两点传输生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 MAC 头部。 MAC 包头格式 MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息。 在 MAC 包头里需要发送方 MAC 地址和接收方目标 MAC 地址，用于两点之间的传输。 一般在 TCP&#x2F;IP 通信里，MAC 包头的协议类型只使用： 0800 ： IP 协议 0806 ： ARP 协议 MAC 发送方和接收方如何确认? 发送方的 MAC 地址获取就比较简单了，MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了。 接收方的 MAC 地址就有点复杂了，只要告诉以太网对方的 MAC 的地址，以太网就会帮我们把包发送过去，那么很显然这里应该填写对方的 MAC 地址。 所以先得搞清楚应该把包发给谁，这个只要查一下路由表就知道了。在路由表中找到相匹配的条目，然后把包发给 Gateway 列中的 IP 地址就可以了。 既然知道要发给谁，按如何获取对方的 MAC 地址呢？ 不知道对方 MAC 地址？不知道就喊呗。 此时就需要 ARP 协议帮我们找到路由器的 MAC 地址。 ARP 协议会在以太网中以广播的形式，对以太网所有的设备喊出：“这个 IP 地址是谁的？请把你的 MAC 地址告诉我”。 然后就会有人回答：“这个 IP 地址是我的，我的 MAC 地址是 XXXX”。 如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址。然后，我们将这个 MAC 地址写入 MAC 头部，MAC 头部就完成了。 好像每次都要广播获取，这不是很麻烦吗？ 放心，在后续操作系统会把本次查询结果放到一块叫做 ARP 缓存的内存空间留着以后用，不过缓存的时间就几分钟。 也就是说，在发包时： 先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。 而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。 查看 ARP 缓存内容 在 Linux 系统中，我们可以使用 arp -a 命令来查看 ARP 缓存的内容。 MAC 报文生成 至此，网络包的报文如下图。 (7) 网卡网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将数字信息转换为电信号，才能在网线上传输，也就是说，这才是真正的数据发送过程。 负责执行这一操作的是网卡，要控制网卡还需要靠网卡驱动程序。 网卡驱动获取网络包之后，会将其复制到网卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列。 起始帧分界符是一个用来表示包起始位置的标记 末尾的 FCS（帧校验序列）用来检查包传输过程是否有损坏 最后网卡会将包转为电信号，通过网线发送出去。 (8) 交换机下面来看一下包是如何通过交换机的。交换机的设计是将网络包原样转发到目的地。交换机工作在 MAC 层，也称为二层网络设备。 交换机的包接收操作 首先，电信号到达网线接口，交换机里的模块进行接收，接下来交换机里的模块将电信号转换为数字信号。 然后通过包末尾的 FCS 校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。 计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，交换机的端口不具有 MAC 地址。 将包存入缓冲区后，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。 交换机的 MAC 地址表主要包含两个信息： 一个是设备的 MAC 地址， 另一个是该设备连接在交换机的哪个端口上。 举个例子，如果收到的包的接收方 MAC 地址为 00-02-B3-1C-9C-F9，则与图中表中的第 3 行匹配，根据端口列的信息，可知这个地址位于 3 号端口上，然后就可以通过交换电路将包发送到相应的端口了。 所以，交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口。 当 MAC 地址表找不到指定的 MAC 地址会怎么样？ 地址表中找不到指定的 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。 这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。 这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后只有相应的接收者才接收包，而其他设备则会忽略这个包。 有人会说：“这样做会发送多余的包，会不会造成网络拥塞呢？” 其实完全不用过于担心，因为发送了包之后目标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写入 MAC 地址表，下次也就不需要把包发到所有端口了。 局域网中每秒可以传输上千个包，多出一两个包并无大碍。 此外，如果接收方 MAC 地址是一个广播地址，那么交换机会将包发送到除源端口之外的所有端口。 以下两个属于广播地址： MAC 地址中的 FF:FF:FF:FF:FF:FF IP 地址中的 255.255.255.255 (9) 路由器 —— 出境大门 路由器与交换机的区别 网络包经过交换机之后，现在到达了路由器，并在此被转发到下一个路由器或目标设备。 这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。 不过在具体的操作过程上，路由器和交换机是有区别的。 因为路由器是基于 IP 设计的，俗称三层网络设备（物理层 + 链路层 + 网络层），路由器的各个端口都具有 MAC 地址和 IP 地址； 而交换机是基于以太网设计的，俗称二层网络设备（物理层 + 链路层），交换机的端口不具有 MAC 地址。 路由器基本原理 路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。 当转发包时，首先路由器端口会接收发给自己的以太网包，然后路由表查询转发目标，再由相应的端口作为发送方将以太网包发送出去。 路由器的包接收操作 首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 FCS 进行错误校验。 如果没问题则检查 MAC 头部中的接收方 MAC 地址，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。 总的来说，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。 查询路由表确定输出端口 完成包接收操作之后，路由器就会去掉包开头的 MAC 头部。 MAC 头部的作用就是将包送达路由器，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会被丢弃。 接下来，路由器会根据 MAC 头部后方的 IP 头部中的内容进行包的转发操作。 转发操作分为几个阶段，首先是查询路由表判断转发目标。 具体的工作流程根据上图，举个例子： 假设地址为 10.10.1.101 的计算机要向地址为 192.168.1.100 的服务器发送一个包，这个包先到达图中的路由器。 判断转发目标的第一步，就是根据包的接收方 IP 地址查询路由表中的目标地址栏，以找到相匹配的记录。 路由匹配和前面讲的一样，每个条目的子网掩码和 192.168.1.100 IP 做 &amp; 与运算后，得到的结果与对应条目的目标地址进行匹配，如果匹配就会作为候选转发目标，如果不匹配就继续与下个条目进行路由匹配。 如第二条目的子网掩码 255.255.255.0 与 192.168.1.100 IP 做 &amp; 与运算后，得到结果是 192.168.1.0，这与第二条目的目标地址 192.168.1.0 匹配，该第二条目记录就会被作为转发目标。 实在找不到匹配路由时，就会选择默认路由，路由表中子网掩码为 0.0.0.0 的记录表示「默认路由」。 路由器的发送操作 接下来就会进入包的发送操作。 首先，我们需要根据路由表的网关列判断对方的地址。 如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，还未抵达终点，还需继续需要路由器转发。 如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明已抵达终点。 知道对方的 IP 地址之后，接下来需要通过 ARP 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收方 MAC 地址。 路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。 接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 0800 （十六进制）表示 IP 协议。 网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。 发送出去的网络包会通过交换机到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。 接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。 不知你发现了没有，在网络包传输的过程中，源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址，因为需要 MAC 地址在以太网内进行两个设备之间的包传输。 (10) 服务器与客户端数据包抵达了服务器，于是服务器开始扒数据包的皮！ 数据包抵达服务器后，服务器会先扒开数据包的 MAC 头部，查看是否和服务器自己的 MAC 地址符合，符合就将包收起来。 接着继续扒开数据包的 IP 头，发现 IP 地址符合，根据 IP 头中协议项，知道自己上层是 TCP 协议。 于是，扒开 TCP 的头，里面有序列号，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。 TCP 头部里面还有端口号， HTTP 的服务器正在监听这个端口号。于是，服务器自然就知道是 HTTP 进程想要这个包，于是就将包发给 HTTP 进程。 服务器的 HTTP 进程看到，原来这个请求是要访问一个页面，于是就把这个网页封装在 HTTP 响应报文里。 HTTP 响应报文也需要穿上 TCP、IP、MAC 头部，不过这次是源地址是服务器 IP 地址，目的地址是客户端 IP 地址。 穿好头部衣服后，从网卡出去，交由交换机转发到出城的路由器，路由器就把响应数据包发到了下一个路由器，就这样跳啊跳。 最后跳到了客户端的城门把守的路由器，路由器扒开 IP 头部发现是要找城内的人，于是又把包发给了城内的交换机，再由交换机转发到客户端。 客户端收到了服务器的响应数据包后，开始扒皮，把收到的数据包的皮扒剩 HTTP 响应报文后，交给浏览器去渲染页面，一份特别的数据包快递，就这样显示出来了！ 最后，客户端要离开了，向服务器发起了 TCP 四次挥手，至此双方的连接就断开了。 总结TCP&#x2F;IP 网络模型共有 4 层，分别是应用层、传输层、网络层和网络接口层，每一层负责的职能如下： 应用层，负责向用户提供一组应用程序，比如 HTTP、DNS、FTP 等; 传输层，负责端到端的通信，比如 TCP、UDP 等； 网络层，负责网络包的封装、分片、路由、转发，比如 IP、ICMP 等； 网络接口层，负责网络包在物理网络中的传输，比如网络包的封帧、 MAC 寻址、差错检测，以及通过网卡传输网络帧等； 网络通信是分层进行的，每一层都只与另一端的对等层进行对话。下层为上层提供服务。这个过程就像寄信： 应用层 (HTTP)：你写好信的内容（HTTP 请求&#x2F;响应）。这包括了 HTTP 头部（如 Content-Type: text&#x2F;html) 和 消息体（如 HTML 代码）。 传输层 (TCP)：TCP 层拿到这封完整的“信”（HTTP 数据），但它发现这封信太长了，一个信封装不下。于是它把信拆分成几个小份，每一份都塞进一个 TCP 信封里。每个 TCP 信封上都写着信息（TCP 头部），比如“这是第几份”、“总共有几份”、“发送方和接收方的端口号”。 网络层 (IP)：IP 层不管 TCP 拆成了几份，它只管拿来一个 TCP 信封，就把它塞进一个更大的 IP 信封里。IP 信封上写着更大的地址信息（IP 头部），比如发送方和接收方的 IP 地址，用于在整个网络上路由。 数据链路层 (MAC)：最后，MAC 层把 IP 信封再塞进一个帧信封里，这个信封上写着在当前局域网内下一站设备的地址（MAC 头部），比如下一个路由器或者交换机的 MAC 地址。这个帧信封的大小受 MTU 限制。 2. 如果 URL 请求的网页响应很慢，可能在哪个环节出现问题？ 腾讯 WXG 测开一面 当 URL 请求的网页响应很慢时，问题可能出现在多个环节，包括客户端、网络传输、服务器端以及内容本身。以下是可能的问题点： 在客户端层面 浏览器缓存过多或配置错误可能拖慢页面加载 操作系统网络栈异常（如 TCP 连接数限制或缓冲区设置不当）也可能导致连接建立缓慢 DNS 客户端缓存污染或硬件资源（如 CPU、内存）不足会进一步加剧延迟 DNS 解析环节可能出现问题 例如本地 DNS 服务器响应缓慢、递归查询超时，或域名解析记录未正确缓存。如果 DNS 服务器故障或域名配置错误，会导致域名到 IP 地址的转换耗时过长 网络传输过程中 路由路径不佳可能导致数据包经过过多跳数，从而增加延迟 带宽瓶颈在用户本地网络或服务器接入端可能成为限制因素，尤其是在传输大文件时 数据包丢失或网络抖动会触发 TCP 重传，降低有效吞吐量，而防火墙或中间设备策略也可能意外丢弃合法流量 服务器端问题包括 负载过高，例如 CPU、内存或 I&#x2F;O 资源饱和，导致无法及时处理请求 应用逻辑性能差，如低效的数据库查询、代码执行缓慢或缓存未命中，会直接拖慢响应速度 后端依赖服务（如第三方 API 或数据库）延迟也可能阻塞整体处理流程 Web 服务器配置不当（如进程数不足或保持连接超时设置不合理）会影响请求处理效率 协议与连接方面 TCP 三次握手或 TLS 协商在高延迟网络中可能显著增加连接建立时间 HTTP&#x2F;1.1 的队头阻塞问题（未启用并行连接时）会导致单个请求延迟影响后续资源加载 CDN 或代理服务器配置错误可能造成请求转发效率低下或缓存失效 内容本身的问题也不容忽视，例如未压缩的大资源（如图片、视频）会增加传输时间，过多阻塞渲染的 JavaScript 或同步加载策略会延迟页面呈现，而重复请求或未优化的资源链接受限於浏览器并发限制。 3. UDP 通信：如果 client 端 sendto 一段 1024 字节的 buf，server 端循环调用 recvfrom(fd,buf,64,0)，能否收完？能的话需要调用几次？不能收完原因是什么？ 腾讯面试题 在 UDP 通信中，sendto() 发送的每一次数据都是一个完整的独立报文，接收端使用 recvfrom(fd, buf, 64, 0) 时，每次只能接收一个完整报文的最多 64 字节，如果报文长度超过了缓冲区大小（如发送端发送了 1024 字节），则接收端只会接收到前 64 字节，超出部分会被系统直接丢弃，无法通过多次 recvfrom() 调用将同一个报文拆分接收，因此在这种情况下接收端无法收完整个报文。 4. tcp 通信：client 端循环调用 send(fd,buf,1) 1024 次发给 server，从 server 端捉包，客户端总共发了几个包过来？ 腾讯面试题 在 TCP 通信中，尽管客户端调用了 1024 次 send(fd, buf, 1) 每次仅发送 1 字节的数据，但由于 TCP 是面向字节流的协议，发送的数据会被内核缓冲区聚合后再发送，而不会直接对应为 1024 个网络包。特别是在默认启用 Nagle 算法的情况下，TCP 会将多次小的数据发送请求进行合并，直到缓冲区满或收到 ACK 才会实际发送出去，因此从服务端抓包来看，最终接收到的数据通常会被合并成更少数量的 TCP 包，远少于 1024 个。这种行为由操作系统的 TCP 堆积机制和网络状况共同决定，即使应用层调用了 1024 次 send()，网络中实际传输的包数可能只有几十个或几百个。 5. 应用层有哪些协议？ HTTP：超文本传输协议 HTTPS：HTTP 的安全版本，在 HTTP 下加入 SSL&#x2F;TLS 层，用于对通信进行加密、认证，确保数据的安全性和完整性 FTP：文件传输协议，用于在客户端和服务器之间进行双向文件传输（上传和下载）。 SMTP：简单邮件传输协议，用于发送邮件以及将邮件从发送人的邮件服务器转发到接收人的邮件服务器 POP3：邮局协议第 3 版，用于从邮件服务器下载邮件到本地计算机，通常下载后会删除服务器上的邮件 IMAP：互联网消息访问协议，更高级的邮件接收协议，允许用户在本地管理服务器上的邮件（如创建、删除、移动邮箱文件夹），邮件始终保留在服务器上 SSH：远程连接协议，用于通过加密的连接安全地远程登录到另一台计算机，并执行命令，是 Telnet 的安全替代品 DNS：域名系统协议，它不是直接为用户服务的，而是为其他应用层协议服务的。它将人类可读的域名（如 www.google.com）转换为机器可读的 IP 地址（如 142.251.42.206） DHCP：动态主机配置协议，自动为网络中的设备分配 IP 地址、子网掩码、默认网关和 DNS 服务器地址，即“插网线就能上网”的基础 SIP：会话发起协议，用于创建、修改和终止包含视频、语音、即时消息等在内的多媒体会话，是很多 VOIP（网络电话）系统的基础 RTP：实时传输协议，通常与 SIP 等协议配合使用，负责实际传输音频和视频流数据 6. TCP 是什么，怎么保证可靠性的？ 腾讯 TEG 一面 TCP（传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议。 它主要通过以下核心机制来保证可靠性的： 确认和重传机制 确认 (ACK)：接收方在成功收到数据包后，会向发送方返回一个确认报文（ACK）。ACK 中包含了期望收到的下一个字节的序列号。 超时重传：发送方发送一个数据包后会启动一个定时器。如果在定时器超时前没有收到对应的 ACK，发送方就认为该数据包丢失，会重新发送它。 快速重传：如果发送方连续收到 3 个相同的 ACK（意味着接收方收到了乱序的包，一直在重复索要某个丢失的包），发送方会立即重传那个被认为丢失的数据包，而不必等待超时。 序列号和确认号：每个字节的数据都被赋予一个唯一的序列号。确认号告诉发送方“我已经成功收到了确认号之前的所有数据，期望下一个收到的数据序列号是这个确认号”。这解决了数据包乱序和确认丢失的问题。 校验和：TCP头部和数据部分都包含一个校验和。接收方会计算校验和，如果与报文中的校验和不匹配，则丢弃该数据包。发送方会因为收不到 ACK 而触发重传，从而解决了数据错误的问题。 流量控制：使用滑动窗口协议来实现。接收方通过 TCP 头部的“窗口大小”字段告诉发送方自己还有多少缓冲区可以接收数据。这防止了发送方发送数据过快，导致接收方缓冲区溢出，从而解决了数据淹没的问题。 拥塞控制：通过一套复杂的算法（如慢启动、拥塞避免、快速恢复）来探测网络当前的承载能力。当发现网络出现拥塞（如丢包）时，会主动降低发送速率，从而减轻网络负担，避免整个网络崩溃。 总结： TCP 通过序列号&#x2F;确认号确保数据有序、不丢；通过校验和确保数据正确；通过流量控制保护接收方；通过拥塞控制保护网络。其可靠性是这一整套机制协同工作的结果。 7. 三次握手如果改成两次握手会怎样？ 腾讯 TEG 一面 核心问题： 无法防止已失效的连接请求报文突然又传送到服务器，从而导致错误和资源浪费。 TCP 三次握手改为两次握手会导致可靠性严重下降，主要引发两个问题：已失效的连接请求和无法同步初始序列号。若只有两次握手，当客户端发送的 SYN 报文因网络延迟而滞留，客户端会重发新 SYN 并建立连接；但延迟的旧 SYN 之后到达服务端时，服务端会误以为是新的连接请求并直接响应，导致服务端资源被无效占用（半连接状态）。此外，两次握手无法确保双方对初始序列号的确认达成一致：服务端无法确认客户端是否收到自己的 SYN-ACK 响应，若该响应丢失，客户端无法感知连接已建立，而服务端却认为连接有效，导致数据单向传输失败。因此，第三次握手的 ACK 是防止历史连接混乱和确保序列号同步的关键。 8. 如果网络条件特别好，能不能两次握手？ 腾讯 TEG 一面 即使在网络条件特别好的环境下，TCP 也不能改为两次握手，原因在于两次握手无法解决历史连接和初始序列号同步确认这两个根本性问题。 首先，历史连接问题无法避免。假设客户端发送了一个 SYN 报文后由于某种原因（如应用层重启）决定放弃连接，但该 SYN 报文因网络延迟稍后才到达服务器。在两次握手模型下，服务器收到后会立即回复 SYN-ACK 并认为连接已建立，分配资源并等待数据传输。然而客户端早已放弃这个连接，不会发送数据，导致服务器资源被长期无效占用（直到超时）。三次握手中的第三次 ACK 是关键：客户端通过它来确认本次连接的有效性，若连接已失效（如收到旧的 SYN-ACK），客户端会发送 RST 复位报文来终止服务端的无效连接。 其次，序列号同步的可靠性无法保证。TCP 依赖序列号来保证数据有序性和可靠性，而初始序列号（ISN）的同步需要双方确认。在两次握手中，服务器无法确认客户端是否成功接收到了自己发送的 SYN-ACK（包含服务器的 ISN）。如果这个 SYN-ACK 丢失，客户端根本不知道服务器已准备就绪，而服务器却认为连接已建立并开始等待数据，此时双方状态不一致。第三次握手的 ACK 正式确认了双方对初始序列号的认可，确保了连接状态的双向同步。 因此，即使网络完美无缺，两次握手在协议设计层面仍存在本质缺陷，无法保证连接的可靠性和一致性。TCP 的三次握手是基于逻辑必要性而非网络质量的设计。第三次握手的开销（一个 ACK 包）极小，与它所带来的连接可靠性保障相比，是完全可以接受的。为了节省这微不足道的开销而引入巨大的连接混乱风险，是绝对不值得的。 9. UPD 传输的数据是不是一个完整报文 网易游戏一面 UDP 是面向报文的传输协议，它以报文（Datagram）为单位进行传输，不分割也不合并。 应用层交给 UDP 一个报文，UDP 添加头部后交给 IP 层发送。接收端收到的数据也一定是一个完整的报文（不会被分片成多个）。 如果报文超过网络传输路径的最大传输单元（MTU），则 IP 层（非 UDP）会对报文分片传输，并在接收端自动重组后再交给 UDP。 10. UDP 如何保证传输效率又不丢包 网易游戏一面 UDP 本身不保证可靠性，也就是说它不会主动处理丢包或重传。 如果应用层需要在 UDP 基础上实现高效可靠传输，需要自己实现： ACK 应答机制（确认重传） 序列号机制（识别丢包、乱序） 流量控制、拥塞控制 实践中，比如实时音视频通话、游戏等场景，更倾向于使用 UDP，偶尔丢包可接受，但延迟必须低，可靠性可以通过应用层算法进行补偿（如丢帧插值、快速重传策略）。 因此 UDP 本身仅保证效率，可靠性需要应用层自己设计补偿机制。 11. TCP 和 UDP 粘包分包，怎么解决？ 网易游戏一面 粘包 分包&#x2F;半包 粘包、分包问题的原因： TCP 是面向流的协议，没有报文边界的概念，数据会合并、分割。 UDP 是面向报文的协议，有天然的报文边界，不存在粘包问题，但仍可能因报文超过 MTU 而发生分片（IP 层分片重组）。 TCP 解决粘包分包的常见方案： 长度字段法：报文头部增加一个字段表示当前报文长度，接收方按长度拆分数据。 分隔符法：在报文末尾增加特殊分隔符标记报文结束（如 HTTP 协议中 \\r ）。 固定长度法：每个消息长度固定。 协议约定：使用标准协议（如 HTTP、Protobuf）明确消息结构。 UDP 是否有粘包问题： UDP 天然不存在粘包问题，但应保证数据小于 MTU，避免 IP 分片。 12. TCP 为什么是四次挥手 网易游戏一面 TCP 四次挥手的原因：TCP 连接是全双工通信，数据在两个方向上可以独立传输，需要分别关闭。 四次挥手的过程： 123456789主动方 被动方 |------- FIN ------&gt;| | | |&lt;------ ACK -------| | | | |（被动方可能仍有数据要发送） |&lt;------ FIN -------| | | |------- ACK ------&gt;| 第一次挥手：主动关闭方发出 FIN，表示我方数据发送完毕。 第二次挥手：被动方发送 ACK，确认收到对方的关闭请求，但此时被动方可能还有数据未发送完。 第三次挥手：被动方发完数据后再发送 FIN，通知主动方自己数据也发送完毕。 第四次挥手：主动方再发送 ACK，确认收到被动方的关闭请求。","tags":["面经","八股文","计算机网络"],"categories":["秋招指南"]},{"title":"✍️ 八股文 @ 场景题","path":"/post/秋招指南/2025-scenario-questions/","content":"记录高频场景题，部分内容自行搜索 快排存在的问题，如何优化？3 种快排基准选择方法： 随机（rand 函数） 固定（队首、队尾） 三数取中（队首、队中和队尾的中间数） 4 种优化方式： 优化 1：当待排序序列的长度分割到一定大小后，使用插入排序 优化 2：在一次分割结束后，可以把与 key 相等的元素聚在一起，继续下次分割时，不用再对与 key 相等元素分割 优化 3：优化递归操作 优化 4：使用并行或多线程处理子序列 写三个线程交替打印 ABC123456789101112131415161718192021222324252627282930313233343536373839#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;#include &lt;condition_variable&gt;class AlternatingPrinter &#123;public: AlternatingPrinter() : current_turn(0) &#123;&#125; void print(char ch, int turn) &#123; for (int i = 0; i &lt; 10; ++i) &#123; // 打印10次循环 std::unique_lock&lt;std::mutex&gt; lock(mtx); cv.wait(lock, [this, turn] &#123; return current_turn % 3 == turn; &#125;); std::cout &lt;&lt; ch; current_turn++; cv.notify_all(); // 通知所有等待线程 &#125; &#125;private: std::mutex mtx; std::condition_variable cv; int current_turn; // 当前轮次，0:A, 1:B, 2:C&#125;;int main() &#123; AlternatingPrinter printer; std::thread t1([&amp;printer] &#123; printer.print(&#x27;A&#x27;, 0); &#125;); std::thread t2([&amp;printer] &#123; printer.print(&#x27;B&#x27;, 1); &#125;); std::thread t3([&amp;printer] &#123; printer.print(&#x27;C&#x27;, 2); &#125;); t1.join(); t2.join(); t3.join(); std::cout &lt;&lt; std::endl; return 0;&#125; 不使用临时变量实现 swap 函数12345void swap_xor(int a, int b) &#123; a ^= b; b ^= a; a ^= b;&#125; ✍️ Top K 问题（可以采取的方法有哪些，各自优点）… ✍️ 8G 的 int 型数据，计算机的内存只有 2G，怎么对它进行排序？… ✍️ 手撕线程安全的单例模式… 手撕 shared_ptr（线程安全）非线程安全的简单实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#include &lt;memory&gt;template&lt;typename T&gt;class smartPtr &#123;private: T *_ptr; size_t* _count;public: smartPtr(T *ptr = nullptr):_ptr(ptr) &#123; if (_ptr) &#123; _count = new size_t(1); &#125; else &#123; _count = new size_t(0); &#125; &#125; smartPtr(const smartPtr &amp;ptr) &#123; if (this != &amp;ptr) &#123; this-&gt;_ptr = ptr._ptr; this-&gt;_count = ptr._count; ++(*this-&gt;_count) ; &#125; &#125; smartPtr&amp; operator=(const smartPtr &amp;ptr) &#123; if (this-&gt;_ptr == ptr._ptr) return *this; if (this-&gt;_ptr) &#123; --(*this-&gt;_count); if (this-&gt;_count == 0) &#123; delete this-&gt;_ptr; delete this-&gt;_count; &#125; &#125; this-&gt;_ptr = ptr._ptr; this-&gt;_count = ptr._count; ++(*this-&gt;_count); return *this; &#125; ~smartPtr() &#123; --(*this-&gt;_count); if (0 == *this-&gt;_count) &#123; delete this-&gt;_ptr; delete this-&gt;_count; &#125; &#125; size_t use_count() &#123; return *this-&gt;_count; &#125; T&amp; operator*() &#123; assert(this-&gt;_ptr == nullptr); return *(this-&gt;_ptr); &#125; T* operator-&gt;() &#123; assert(this-&gt;_ptr == nullptr); return this-&gt;_ptr; &#125;&#125;; 基于原子操作的线程安全实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192#pragma once#include &lt;atomic&gt; // 引入原子操作template &lt;typename T&gt;class shared_ptr &#123;private: T* ptr; // 指向管理的对象 std::atomic&lt;std::size_t&gt;* ref_count; // 原子引用计数 // 释放资源 void release() &#123; // P.S. 这里使用 std::memory_order_acq_rel 内存序，保证释放资源的同步 if (ref_count &amp;&amp; ref_count-&gt;fetch_sub(1, std::memory_order_acq_rel) == 1) &#123; delete ptr; delete ref_count; &#125; &#125;public: // 默认构造函数 shared_ptr() : ptr(nullptr), ref_count(nullptr) &#123;&#125; // 构造函数 // P.S. 这里使用 explicit 关键字，防止隐式类型转换 // shared_ptr&lt;int&gt; ptr1 = new int(10); 不允许出现 explicit shared_ptr(T* p) : ptr(p), ref_count(p ? new std::atomic&lt;std::size_t&gt;(1) : nullptr) &#123;&#125; // 析构函数 ~shared_ptr() &#123; release(); &#125; // 拷贝构造函数 shared_ptr(const shared_ptr&lt;T&gt;&amp; other) : ptr(other.ptr), ref_count(other.ref_count) &#123; if (ref_count) &#123; ref_count-&gt;fetch_add(1, std::memory_order_relaxed); // 引用计数增加，不需要强内存序 &#125; &#125; // 拷贝赋值运算符 shared_ptr&lt;T&gt;&amp; operator=(const shared_ptr&lt;T&gt;&amp; other) &#123; if (this != &amp;other) &#123; release(); // 释放当前资源 ptr = other.ptr; ref_count = other.ref_count; if (ref_count) &#123; ref_count-&gt;fetch_add(1, std::memory_order_relaxed); // 引用计数增加 &#125; &#125; return *this; &#125; // 移动构造函数 // P.S. noexcept 关键字表示该函数不会抛出异常。 // 标准库中的某些操作（如 std::swap）要求移动操作是 noexcept 的，以确保异常安全。 // noexcept 可以帮助编译器生成更高效的代码，因为它不需要为异常处理生成额外的代码。 shared_ptr(shared_ptr&lt;T&gt;&amp;&amp; other) noexcept : ptr(other.ptr), ref_count(other.ref_count) &#123; other.ptr = nullptr; other.ref_count = nullptr; &#125; // 移动赋值运算符 shared_ptr&lt;T&gt;&amp; operator=(shared_ptr&lt;T&gt;&amp;&amp; other) noexcept &#123; if (this != &amp;other) &#123; release(); // 释放当前资源 ptr = other.ptr; ref_count = other.ref_count; other.ptr = nullptr; other.ref_count = nullptr; &#125; return *this; &#125; // 解引用运算符 // P.S. const 关键字表示该函数不会修改对象的状态。 T&amp; operator*() const &#123; return *ptr; &#125; // 箭头运算符 T* operator-&gt;() const &#123; return ptr; &#125; // 获取引用计数 std::size_t use_count() const &#123; return ref_count ? ref_count-&gt;load(std::memory_order_acquire) : 0; &#125; // 获取原始指针 T* get() const &#123; return ptr; &#125; // 重置指针 void reset(T* p = nullptr) &#123; release(); ptr = p; ref_count = p ? new std::atomic&lt;std::size_t&gt;(1) : nullptr; &#125;&#125;; ✍️ 手撕线程池… ✍️ 手撕 string… ✍️ 手撕 ringbuffer… ✍️ 实现一个线程安全的带过期时间的 FIFO Cache… ✍️ 实现一个线程安全的带过期时间的 LRU… ✍️ 一致性哈希… ✍️ 海量数据的 bitmap 使用原理… ✍️ 布隆过滤器原理与优点…","tags":["面经","八股文","场景题"],"categories":["秋招指南"]},{"title":"✍️ 八股文 @ C++","path":"/post/秋招指南/2025-cpp/","content":"✍️ C++ 11 新特性大全：https://zhuanlan.zhihu.com/p/139515439 🔥 C++ 八股文 PDF： C++ 八股文｜GitHub C++ 八股文｜牛客 C++ 八股文｜代码随想录 private 仓库维护了一份「详细版」的八股文，但是篇幅内容过于啰嗦（方便理解），不适合秋招快速复习 public 本文主要交代常考的 C++ 八股文内容 1. 1. gcc 编译流程gcc 编译流程可以概括为四个主要步骤： 首先是预处理，处理源代码中的宏定义和头文件包含等； 接下来是编译，将预处理后的代码转换成汇编代码； 然后是汇编，将汇编代码转换为机器指令的目标文件； 最后是链接，将一个或多个目标文件以及所需的库文件合并在一起，生成最终的可执行文件。 2. C 和 C++ 区别C 和 C++ 的主要区别包括： C 是过程式编程语言，而 C++ 是支持面向对象、泛型以及过程式编程的多范式语言； C++ 在 C 的基础上增加了类、继承、多态、模板、异常处理、命名空间等特性； C 使用函数进行代码组织，而 C++ 引入了类和对象来封装数据与行为； C++ 支持运算符重载和函数重载，C 则不支持； C 使用 malloc&#x2F;free 进行内存管理，C++ 在此基础上增加了 new&#x2F;delete 运算符； 此外，C++ 提供了更严格的类型检查以及标准模板库（STL）来增强代码复用性和安全性。 3. C++ 和 Java 区别C++ 和 Java 的核心区别体现在语言特性、设计哲学和运行机制等方面。 C++ 是一种支持多范式（面向对象、过程式、泛型）的编译型语言，允许直接内存操作和精细控制，但需要开发者手动管理内存，容易引发内存泄漏和指针错误；它提供类、多重继承、运算符重载等特性，但缺乏内置的垃圾回收机制。 Java 是一种纯粹的面向对象解释型语言（通过 JVM 运行），强调代码可移植性和安全性，禁止指针操作并提供自动垃圾回收，减少了内存管理负担；它采用单根继承（所有类继承自 Object）和接口机制，支持反射和动态类加载，但性能通常低于 C++ due to JVM overhead。 此外，C++ 更接近硬件，常用于系统级开发和高性能场景，而 Java 更专注于企业应用和跨平台开发。 4. C++ 中 const 和 static 关键字的作用在 C++ 中，const 关键字用于定义常量，表示一个值在初始化后不可被修改，它可以修饰变量、函数参数、成员变量以及成员函数（表示该函数不会修改类的成员状态）。 而 static 关键字用于控制变量或函数的生命周期与作用域，修饰局部变量时使其在程序整个生命周期内存在且只初始化一次，修饰全局变量或函数时将其作用域限制在当前文件内，修饰类的成员时则实现共享（成员变量被所有对象共享，成员函数可不依赖对象直接调用）。 两者分别从不可变性与持久性&#x2F;共享性两个维度提供不同的语义约束。 5. 说一说 C++ 中四种 cast 转换C++ 中四种类型转换是：static_cast、dynamic_cast、const_cast、reinterpret_cast const_cast：用于将 const 变量转为非 const 变量：常量指针转换为⾮常量指针，并且仍然指向原来的对象；常量引⽤被转换为⾮常量引⽤，并且仍然指向原来的对象。const_cast 去掉类型的 const 或 volatile 属性。 static_cast用于各种隐式转换，但是没有运行时类型检查来保证转换的安全性。 比如非 const 转 const，void* 转指针等，static_cast 还可以用于多态向上转换（如 Derived 转 Base，即子类转基类） 进行向上转换（把派生类指针或引用转换为基类）是安全的 进行向下转换（把基类指针或引用转换为派生类），由于没有运行时类型检查，所以是不安全的 12345678// Base 是 Derived 的基类/父类int main() &#123; Derived* d; Base* base = static_cast&lt;Base*&gt;(d); // 向上类型转换 base-&gt;show(); return 0;&#125; dynamic_cast在进行向下转换时，dynamic_cast 具有类型检查（信息在虚函数中）的功能，比 static_cast 更安全。 只能用于含有虚函数的类，用于类层次间的向上和向下转换（基类转子类），只能转指针或引用，向下转换时： 对于指针，转换失败则返回 nullptr 对于引用，转换失败则抛异常 123456789101112int main() &#123; Base* base = new Derived; // 不使用 static_cast 也可以隐式向上转换 Derived* derive = dynamic_cast&lt;Derived*&gt;(base); // 向下类型转换，使用 dynamic_cast if (derive) &#123; derive-&gt;show(); &#125; else &#123; std::cout &lt;&lt; &quot;Conversion failed!&quot; &lt;&lt; std::endl; &#125; delete base; return 0;&#125; reinterpret_cast几乎什么都可以转，比如将 int 转指针，可能会出问题，尽量少用。 WARNING：reinterpret_cast 本质上依赖于机器，要想安全地使用 reinterpret_cast 必须对涉及的类型和编译器实现转换的过程都非常了解。 为什么不使用 C 的强制转换？C 的强制转换表面上看起来功能强大什么都能转，但是转化不够明确，不能进行错误检查，容易出错。 static_cast 与 dynamic_cast 之间的区别？dynamic_cast 和 static_cast 的主要区别在于类型检查的时间点和安全性： 类型检查时间点：static_cast在编译时进行类型检查，而dynamic_cast在运行时进行类型检查。 安全性：static_cast不执行运行时类型检查，因此如果在类层次结构中进行不安全的向下转换，可能导致未定义行为。相反，dynamic_cast会在运行时检查转换的安全性，如果转换不安全，则返回nullptr或抛出异常，提供更高的安全性。 6. C&#x2F;C++ 的四大内存分区和常量的存储位置四大内存分区：栈、堆、静态存储区（全局变量 + 静态变量 + 常量）和代码区。 1️⃣ 栈区由系统进行内存的管理。主要存放函数的参数以及局部变量。在函数完成执行，系统自动释放栈区内存，不需要用户管理，整个程序的栈区大小可以在编译器中由用户自行设定，VS 中默认的栈区大小为 1M，可以通过 VS 手动更改栈的大小。64 bits 的 Linux 默认栈大小为 10MB，可通过 ulimit -s 临时修改，可通过 ulimit -a 查看。 2️⃣ 堆区由程序员手动申请，手动释放，若不手动释放，程序结束后由系统回收，生命周期是整个程序运行期间。使用 malloc 或者 new 进行堆的申请，堆的总大小为机器的虚拟内存的大小。 说明：new 操作符本质上是使用了 malloc 进行内存的申请，new 和 malloc 的区别如下： malloc 是 C 语言中的函数，而 new 是 C++ 中的操作符。 malloc 申请之后返回的类型是 void*，而 new 返回的指针带有类型。 malloc 只负责内存的分配而不会调用类的构造函数，而 new 不仅会分配内存，而且会自动调用类的构造函数。 堆和栈的区别申请方式不同： 栈是系统自动分配 堆是自己申请和释放的 申请大小限制不同： 栈空间默认 10 MB；栈顶和栈底是之前预设好的，栈是向栈底扩展，大小固定，可以通过 ulimit -a 查看，由 ulimit -s 修改 堆区一般是 1G~4G；堆向高地址扩展，是不连续的内存区域，大小可以灵活调整 申请效率不同： 栈由系统分配，速度快，不会有碎片 堆由程序员分配，速度慢，且会有碎片 栈快还是堆快？毫无疑问是栈快一点。 因为操作系统会在底层对栈提供支持，会分配专门的寄存器存放栈的地址，栈的入栈出栈操作也十分简单，并且有专门的指令执行，所以栈的效率比较高也比较快。 而堆的操作是由 C&#x2F;C++ 函数库提供的，在分配堆内存的时候需要一定的算法寻找合适大小的内存。并且获取堆的内容需要两次访问，第一次访问指针，第二次根据指针保存的地址访问内存，因此堆比较慢。 3️⃣ 静态存储区 静态存储区 &#x3D; 全局数据区 + 常量区 全局数据区：全局变量 + 静态变量，该区域会被自动初始化 常量区：存放常量，不允许修改 静态存储区内的变量在程序编译阶段已经分配好内存空间并初始化。这块内存在程序的整个运行期间都存在，它主要存放 static 静态变量、全局变量和 const 常量。 区分：static 修饰「局部变量」在静态存储区中；const 修饰「局部变量」则是在栈区中。 注意： 这里不区分初始化和未初始化的数据区，是因为静态存储区内的变量若不显示初始化，则编译器会自动以默认的方式进行初始化，即静态存储区内不存在未初始化的变量。 静态存储区内的常量分为常变量和字符串常量，一经初始化，不可修改。静态存储内的常变量是全局变量，与局部常变量不同，区别在于局部常变量存放于栈，实际可间接通过指针或者引用进行修改，而全局常变量存放于静态常量区则不可以间接修改。 字符串常量存储在静态存储区的常量区，字符串常量的名称即为它本身，属于常变量。 数据区的具体划分，有利于我们对于变量类型的理解。不同类型的变量存放的区域不同。后面将以实例代码说明这四种数据区中具体对应的变量。 4️⃣ 代码区存放程序体的二进制代码，比如我们写的函数都是在代码区。 12345678910111213int a = 0;//静态全局变量区char *p1; //编译器默认初始化为NULLvoid main()&#123; int b; //栈 char s[] = &quot;abc&quot;;//栈 char *p2 = &quot;123456&quot;;//123456在字符串常量区，p2在栈上 static int c =0; //c在静态变量区，0为文字常量，在代码区 const int d=0; //栈 static const int d;//静态常量区 p1 = (char *)malloc(10);//分配得来得10字节在堆区。 strcpy(p1, &quot;123456&quot;); //123456放在字符串常量区，编译器可能会将它与p2所指向的&quot;123456&quot;优化成一个地方&#125; 7a. C++ 中 class 的大小由哪些因素决定？在 C++ 中，类的大小由多个因素决定，主要包括： 普通成员变量：类中定义的非静态成员变量会直接影响类的大小。每个成员变量都会占用相应的内存空间。 虚函数：如果类包含虚函数，编译器会为该类添加一个虚函数表（vtable），并在每个对象中添加一个指向该表的指针（vptr），这会增加每个对象的大小。 继承：类的继承关系也会影响其大小。 单一继承：派生类会继承基类的成员变量和成员函数，但不会直接增加对象的大小。 多重继承：派生类继承多个基类时，可能会导致对象中包含多个基类的子对象，从而增加对象的大小。 虚拟继承：为了解决菱形继承问题，编译器可能会在派生类中引入虚拟基类指针，增加对象的大小。 内存对齐：编译器通常会对类的成员变量进行内存对齐，以提高访问效率。这可能导致类的实际大小大于成员变量总和。 分配内存的顺序是按照声明的顺序。 每个变量相对于起始位置的偏移量必须是该变量类型大小的整数倍，不是整数倍空出内存，直到偏移量是整数倍为止。 最后整个结构体的大小必须是里面变量类型最大值的整数倍。 ⚠️ 需要注意的是，类的构造函数、析构函数、静态成员变量、静态成员函数和普通成员函数不会直接影响类的大小。 构造函数和析构函数： 构造函数和析构函数是特殊的成员函数，用于对象的初始化和销毁。 它们的存在不会增加类的实例大小，因为它们在对象创建和销毁时被调用，但并不占用对象的内存空间。 静态成员变量： 静态成员变量属于类本身，而不是类的实例。 它们在类的所有实例之间共享，只有一份存储空间（静态存储区）。 静态成员函数： 静态成员函数也属于类本身，而不是类的实例。 它们在类的所有实例之间共享，只有一份存储空间。 普通成员函数： 普通成员函数是类的成员，但普通成员函数的代码通常存储在程序的代码段中，而不是对象的内存中。 因此，普通成员函数不会影响类的实例大小。 7b. [7a 类似问题] C++ 的对象存储空间是怎么安排的？C++ 中对象的存储取决于： 对象的类型（普通对象、继承对象、虚函数表等） 存储方式（栈、堆、静态存储区） 对齐方式 具体来说： 1️⃣ 普通对象 （1）非静态成员变量 普通对象的非静态成员变量按照 声明顺序 在内存中存储。 编译器会根据 CPU 架构和优化需求进行 内存对齐（alignment），可能会插入填充字节（padding）。 类的大小通常是 最大成员类型的对齐倍数。 示例： 1234567891011#include &lt;iostream&gt;struct A &#123; char c; // 1 字节 int i; // 4 字节&#125;;int main() &#123; std::cout &lt;&lt; sizeof(A) &lt;&lt; std::endl; // 输出可能是 8（对齐） return 0;&#125; 内存布局（假设 4 字节对齐）： 1| c (1B) | padding (3B) | i (4B) | （2）静态成员变量：不属于对象本身，放在静态存储区，在程序启动时分配。 2️⃣ 继承 （1）非虚继承：没有 virtual 派生类对象包括基类的成员变量，存储顺序是： 基类子成员 派生类新增成员 对齐填充 12345678910111213struct Base &#123; int a;&#125;;struct Derived : public Base &#123; char b;&#125;;int main() &#123; std::cout &lt;&lt; sizeof(Derived) &lt;&lt; std::endl; // 可能是 8（对齐）&#125;内存分布：| Base::a (4B) | Derived::b (1B) | padding (3B) | （2）虚继承：基类含有 virtual 方法 **虚基类**存储方式不同，编译器会创建虚基类指针 vptr 以及虚基类表 vtable 来管理它 可能会多一个指向虚基类表的指针，因此对象的大小会变大 123456789101112131415struct Base &#123; int a; virtual void func() &#123;&#125; // 引入虚表&#125;;struct Derived : public Base &#123; char b;&#125;;int main() &#123; std::cout &lt;&lt; sizeof(Derived) &lt;&lt; std::endl; // 可能是 16（虚表指针 + 对齐）&#125;// 假设指针 8 字节| vptr (8B) | Base::a (4B) | padding (3B) | Derived::b (1B) | 3️⃣ 多重继承 非虚多重继承：派生类按继承顺序依次存储多个基类的成员变量。 虚多重继承：对象中会存储多个虚表指针，可能引入 虚基类偏移表。 1234567891011121314151617struct A &#123; int a;&#125;;struct B &#123; double b;&#125;;struct C : public A, public B &#123; char c;&#125;;int main() &#123; std::cout &lt;&lt; sizeof(C) &lt;&lt; std::endl; // 可能是 24（对齐 + 多继承）&#125;| A::a (4B) | padding (4B) | B::b (8B) | C::c (1B) | padding (7B) | 4️⃣ 对象存储方式 栈上对象：普通局部对象，生命周期受到作用域控制 堆上对象：使用 new 关键词分配的对象存储在堆区，需要手动 delete 静态存储区：static 变量存储在静态存储区 5️⃣ 虚函数和 vtable 虚表 如果类中有 虚函数，编译器会为该类生成 虚表（vtable），并在对象中存储 虚指针（vptr），指向该虚表。 虚表存储在静态区，而 vptr 存储在对象头部（通常是对象的第一个成员）。 vptr 使得多态调用能够动态绑定。 ⚠️ 虚指针存储在对象头部；虚表存储在静态存储区。 8. new&#x2F;delete 和 malloc&#x2F;free 有什么区别和联系？ 更多内容（讲得很好）：C++ 种内存管理之 new&#x2F;delete 联系：都可以用来在堆上分配和回收空间，new&#x2F;delete 是操作符，malloc&#x2F;free 是库函数。 执行 new 实际上执行两个过程： 调用 malloc 分配未初始化的内存空间 使用对象的构造函数对空间进行初始化，并返回空间的首地址 执行 delete 实际上也有两个过程： 使用析构函数对对象进行析构 调用 free 释放指针所指向空间的内存 二者区别：new 得到的是经过初始化的空间，而 malloc 得到的是未初始化的空间，所以 new 是 new 一个类型，而 malloc 则是 malloc 一个字节长度的空间。delete 和 free 同理，delete 不仅释放空间还析构对象，delete 一个类型，free 一个字节长度的空间。 对象的自动删除通过之前的分析我们知道，new关键字创建对象并非一步完成，而是通过先分配未初始化内存和调用构造函数初始化两步实现的。那么在这个过程中如果是第一步出错，那么内存分配失败不会调用构造函数，这是没有问题的。但是如果第一步已经完成在堆中已经成功分配了内存之后，在第二步调用构造函数时异常导致创建对象失败（抛出 std::bad_alloc），那么就应该将第一步中申请的内存释放。C++中规定，如果一个对象无法完全构造，那么这个对象就是一个无效对象，也不会调用析构函数。因此为了保证对象的完整性，当通过 new 分配的堆内存对象在构造函数执行过程中出现异常时，就会停止构造函数的执行并且自动调用对应的 delete 运算符来对已经分配好的对内存执行销毁处理，即对象的自动删除技术。 🔥 为什么有了 malloc&#x2F;free 还需要 new&#x2F;delete因为对于非内部数据类型而言，光用 malloc&#x2F;free 无法满足动态对象的要求。对象在创建的同时需要自动执行构造函数，对象在消亡以前要自动执行析构函数。由于 malloc&#x2F;free 是库函数而不是操作符，不在编译器控制权限之内，不能够把执行的构造函数和析构函数的任务强加于 malloc&#x2F;free，所以在 C++ 中需要一个能完成动态内存分配和初始化工作的运算符 new，以及一个能完成清理和释放内存工作的运算符 delete。而且在对非基本数据类型的对象使用的时候，对象创建的时候还需要执行构造函数，销毁的时候要执行析构函数。而 malloc&#x2F;free 是库函数，是已经编译的代码，所以不能把构造函数和析构函数的功能强加给 malloc&#x2F;free，所以 new&#x2F;delete 是必不可少的。 既然 new&#x2F;delete 的功能完全覆盖了 malloc&#x2F;free，为什么 C++ 不把 malloc&#x2F;free 淘汰出局呢？这是因为 C++ 程序经常要调用 C 函数，而 C 程序只能用 malloc&#x2F;free 管理动态内存。 🔥 malloc 与 free 的实现原理（brk()、mmap()）1、在标准 C 库中，提供了 malloc/free 函数分配释放内存，这两个函数底层是由 brk、mmap、munmap 这些系统调用实现的; brk 是将「堆顶」指针向高地址移动，获得新的内存空间； mmap 是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存。 这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。 2、malloc 分配阈值 malloc 小于 128k 的内存，使用 brk 分配内存，将「堆顶」指针往高地址推； malloc 大于 128k 的内存，使用 mmap 分配内存，在堆和栈之间找一块空闲内存分配； brk 分配的内存需要等到高地址内存释放以后才能释放，而 mmap 分配的内存可以单独释放。当最高地址空间的空闲内存超过 128K（可由 M_TRIM_THRESHOLD 选项调节）时，执行内存紧缩操作（trim）。在上一个步骤 free 的时候，发现最高地址空闲内存超过 128K，于是内存紧缩。 3、空闲地址链表：malloc 是从堆里面申请内存，也就是说函数返回的指针是指向堆里面的一块内存。操作系统中有一个记录空闲内存地址的链表。当操作系统收到程序的申请时，就会遍历该链表，然后就寻找第一个空间大于所申请空间的堆结点，然后就将该结点从空闲结点链表中删除，并将该结点的空间分配给程序。 🔥 被 free 回收的内存是立即返回给操作系统吗？ 更详细的内容： 深入理解 glibc malloc: 内存分配器实现原理 xiaolincoding 不一定。被 free 的内存不一定会立刻返回给操作系统，具体行为取决于操作系统的内存管理机制以及 C 语言运行时库（如 glibc）的实现方式。 对于 「malloc 申请的内存，free 释放内存会归还给操作系统吗？」这个问题，我们可以做个总结： malloc 通过 brk() 方式申请的内存，free 释放内存的时候，并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用； malloc 通过 mmap() 方式申请的内存，free 释放内存的时候，会把内存归还给操作系统，内存得到真正的释放。 什么场景下 malloc() 会通过 brk() 分配内存？又是什么场景下通过 mmap() 分配内存？ malloc() 源码里默认定义了一个阈值： 如果用户分配的内存小于 128 KB，则通过 brk() 申请内存； 如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存； 注意，不同的 glibc 版本定义的阈值也是不同的。 1. 内存释放流程当你在 C&#x2F;C++ 中使用 free(ptr) 释放一块内存时： 内存被标记为“空闲”，表示这块内存可以被后续的 malloc 或 calloc 重用。 但它通常不会立即归还给操作系统，而是由内存分配器（如 glibc 的 ptmalloc）保留在用户进程中，用于后续分配。 2. 什么时候会真正返回给操作系统？ 如果释放的是堆顶的内存块（即堆的末端），且满足一定条件，glibc 可能会调用 brk 或 mmap 对应的释放机制（如 munmap）来将这部分内存返回给操作系统。 使用 mmap 分配的大块内存（通常大于一定阈值，比如 128KB），在被 free 时通常会直接使用 munmap 归还给操作系统。 3. glibc 的行为（以 Linux 为例）glibc 的 malloc 有一套复杂的内存池机制，常见策略： 小块内存来自内部的 arena，free 后不会归还操作系统，而是缓存起来以便重用。 大块内存通过 mmap 分配，free 后可能会立即调用 munmap 释放给系统。 4. 查看内存是否释放可以使用工具如： top 或 htop 查看内存使用趋势 valgrind 检查内存泄漏 pmap 查看进程的内存映射情况 mallinfo()（旧）或 malloc_info()（新）来观察 glibc 的内存使用状况 🔥 malloc、realloc、calloc 的区别？1️⃣ malloc 函数 123void* malloc(unsigned int num_size);int *p = malloc(20*sizeof(int)); // 申请 20 个 int 类型的空间； 2️⃣ calloc 函数：省去了人为空间计算；malloc 申请的空间的值是随机初始化的，calloc 申请的空间的值是初始化为 0 的； 123void* calloc(size_t n,size_t size);int *p = calloc(20, sizeof(int)); 3️⃣ realloc 函数：给动态分配的空间分配额外的空间，用于扩充容量。 1void realloc(void *p, size_t new_size); 9. 异常&#x2F;错误处理有几种方法，为什么有些场合要禁用？C++ 提供了多种错误处理机制，主要包括： 返回码：函数通过返回值指示成功或失败，调用者需要检查返回值以确定操作结果。 错误码：使用全局或静态变量存储错误码，调用者需要在每个步骤后检查错误码。 异常处理：使用 try、catch 和 throw 关键字捕获和处理异常，提供结构化的错误处理方式。 在某些场合，可能需要禁用异常处理，原因包括： 性能要求高的场合：异常处理可能引入性能开销，影响程序的执行效率。 嵌入式系统：资源有限，可能不支持异常处理。 编译器不支持：某些编译器可能不支持异常处理。 禁用异常处理可以通过编译器选项实现，例如在 Sun Studio 中使用 -features=no%except 来禁用异常处理。 10. C 相关的问题，什么是野指针，有哪些野指针？野指针是指向「未初始化」或「已释放内存」的指针，使用野指针会导致未定义行为，常见野指针： 未初始化的指针：指针声明后未被初始化，默认值不确定，可能指向任意内存地址 悬垂指针：指向已释放内存的指针，释放内存后未将指针置为 NULL，导致指针仍指向已回收的内存地址 空指针：指针被初始化为 NULL，但在后续使用前未被赋予有效地址，导致解引用时发生错误 为避免野指针，应该在声明指针时进行初始化，并在释放内存后将指针置为 NULL。 在更多结构化的解决方案中，一种流行的避免悬垂指针的技术是使用智能指针，一个智能指针通常使用引用技术来收回对象。还有些技术包括 tombstones 方法和 locks-and-keys 方法。另一个方法是使用 Boehm 垃圾收集器，一种保守的垃圾收集器，取代 C 和 C++ 中的标准内存分配函数。此法通过禁止内存释放函数来完全消除悬垂指针引发的错误，通过收集垃圾来回收对象。 11. 你平常怎么调试代码，你能想到多少方法？调试代码是开发过程中非常重要的一部分，尤其是当出现问题时。调试的方式有很多种，下面是我能想到的常见调试方法： 使用调试器 (Debugger)调试器是一种强大的工具，可以让你在程序运行时暂停执行，检查变量的值、调用堆栈等信息，逐行执行代码来找出错误。常见的调试器包括： GDB (GNU Debugger)：适用于 C&#x2F;C++ 等语言，通过命令行进行调试。 Visual Studio Debugger：适用于 Windows 上的 C++ 和 .NET 程序。 LLDB：用于 macOS 或 Linux 的调试器。 Xcode Debugger：适用于 macOS 和 iOS 应用的调试器。 使用调试器，你可以： 设置断点：暂停程序执行，以检查变量状态和函数调用。 逐步执行代码：逐行执行，查看每一行代码的效果。 检查栈信息和变量的值：实时查看变量的值、函数调用栈、内存内容等。 例如，使用 GDB 调试 C++ 代码时，可以使用以下命令： gdb ./your_program 启动调试器。 break main 在 main() 函数处设置断点。 run 启动程序执行。 step 或 next 逐步执行代码。 插入日志输出 (Logging)在代码中添加日志输出是调试程序的常见方法。你可以在代码中插入 printf、std::cout 或日志库（如 log4cpp, spdlog, glog 等）来输出变量值、函数执行状态和程序流程。 常见做法包括： 输出函数进入与退出的日志。 打印变量值、数据结构的内容。 打印程序的状态和执行的分支。 例如： 1std::cout &lt;&lt; &quot;Value of x: &quot; &lt;&lt; x &lt;&lt; std::endl; 优点： 非常直接和简单。 可以在生产环境中使用（例如在开发版和发布版中配置不同的日志级别）。 缺点： 可能会遗漏某些地方，导致调试信息不够全面。 需要在最终代码中删除或关闭冗余的日志输出。 单元测试 (Unit Testing)单元测试是一种自动化的方式，可以帮助你验证代码的正确性。使用框架如 Google Test（C++）、JUnit（Java）、pytest（Python）等，可以编写测试用例，自动运行测试，并在代码发生变化时及时捕捉错误。 单元测试的优点： 确保代码的每个模块都按预期工作。 能够提前发现潜在问题，特别是在修改代码时。 缺点： 测试用例需要编写和维护，可能需要额外的时间。 需要有较好的测试覆盖率，才能检测到更多的错误。 静态分析工具 (Static Analysis)静态分析工具可以在代码运行之前，扫描代码并检查潜在的错误、内存泄漏、资源管理问题等。例如： Clang Static Analyzer CppCheck SonarQube Coverity 静态分析工具能够检测到： 未初始化的变量。 内存泄漏。 潜在的并发问题。 错误的代码模式等。 代码审查 (Code Review)代码审查是与团队成员或同事一起查看和讨论代码的过程。其他开发者可以帮助你发现代码中的潜在问题或逻辑错误。 代码审查的优点： 多人的视角能够发现更多问题。 通过讨论，能够提升代码质量和团队合作。 集成测试 (Integration Testing)集成测试是测试多个组件（或模块）一起工作时的行为。在多个模块组合工作时，问题可能不是单独模块内部，而是它们之间的交互。集成测试帮助你检查模块之间的接口和数据流。 集成测试通常用来发现： 模块之间的兼容性问题。 数据格式错误。 不正确的模块交互等。 内存泄漏检测工具如果你的程序存在内存泄漏问题，可以使用专门的工具来检测内存的分配和释放： 🔥 Valgrind：广泛用于检测内存泄漏、内存错误等问题，适用于 C&#x2F;C++ 程序。 AddressSanitizer：现代编译器（如 Clang、GCC）提供的工具，可以检测内存相关的错误，包括越界访问、内存泄漏等。 这些工具帮助你找出内存泄漏和错误的内存访问问题，并给出详细的报告。 运行时分析工具运行时分析工具通过收集程序运行时的信息来进行调试和优化。例如： gprof：用于性能分析，查看程序中哪些函数占用了最多的时间。 perf：Linux 下的性能分析工具，帮助查看程序在系统层面的性能瓶颈。 VisualVM：Java 应用程序的性能分析工具，能够分析内存、CPU 和线程使用情况。 条件断点和日志断点在调试过程中，有时你希望仅在满足特定条件时暂停程序。这时可以使用条件断点或日志断点： 条件断点：只有当某个条件成立时，调试器才会停止程序执行。 日志断点：调试器在不停止程序执行的情况下，记录断点信息。 回滚与分支 (Git Bisect)如果你无法确定错误是在哪次提交中引入的，使用 Git 提供的 git bisect 命令来回滚到历史提交并逐步测试，可以帮助定位问题的来源。 通过二分查找算法，git bisect 可以帮助你快速定位到错误引入的那一行代码。 故障注入 (Fault Injection)故障注入是故意在程序中引入故障，以测试程序在面对错误时的反应。例如，可以通过随机生成异常、模拟网络延迟或中断等方式，检查系统的健壮性和错误处理能力。 动态分析与跟踪 (Dynamic Analysis)使用跟踪工具（如 strace, ltrace, dtrace 等）来实时观察程序执行过程中的系统调用和函数调用。这种方式帮助你了解程序在运行时的行为，找出性能瓶颈或其他问题。 12. 什么是 C++ 多态？C++ 多态即使用基类指针或引用来调用子类的重写方法，从而使得同一接口表现不同的行为。 多态优势： 代码复用：通过基类指针或引用，可以操作不同类型的派生类对象，实现代码复用 扩展性：新增派生类时，不需要修改依赖于基类的代码，只需要确保新类正确重写了虚函数 解耦：多态允许程序更加模块化，降低类之间的耦合度 🔥 面试一定要回答「静态多态」+「动态多态」 多态一般就是指继承 + 虚函数实现的多态，对于重载来说，实际原理是编译器为函数生成符号表时的不同规则，重载只是一种语言特性，与多态无关，与面向对象无关，所以如果非要说重载算是多态的一种，那 C++ 中多态可以分为「静态多态」和「动态多态」两种： 静态多态：在编译时期就决定了调用哪个函数，根据参数列表来决定，主要通过函数重载和模板实现 动态多态：通过子类重写父类的虚函数来实现，是运行期间决定调用的函数 动态多态的实现与虚函数表（V-Table），虚函数指针（V-Ptr）相关： 虚函数表（V-Table）：C++ 运行时使用虚函数表来实现多态，每个包含虚函数的类都有一个虚函数表，表中存储了指向类中所有虚函数的指针。 虚函数指针（V-Ptr）：对象中包含一个指向该类虚函数表的指针。 扩展：子类是否要重写父类的虚函数？子类继承父类时，父类的纯虚函数必须重写，否则子类也是一个虚类不可实例化。定义纯虚函数是为了实现一个接口，起到一个规范的作用，规范继承这个类的程序员必须实现这个函数。 13. 什么是虚函数与虚函数指针，C++ 虚函数的实现原理？首先说一下 C++ 中多态的表象：在基类的函数前加上 virtual 关键字，在派生类中重写该函数，运行时将会根据对象的实际类型来调用相应的函数： 如果对象类型是派生类，就调用派生类的函数 如果是基类，就调用基类的函数 虚函数 vtable 与虚函数指针 vptr实际上，当一个类中包含虚函数 virtual 时，编译器就会为该类生成一个虚函数表 vtable，保存该类中虚函数的地址。同样，派生类继承基类，派生类中自然一定有虚函数，所以编译器也会为派生类生成自己的虚函数表 vtable。当我们定义一个派生类对象时，编译器检测到该类型有虚函数，就会为这个派生类对象生成一个虚函数指针 vptr，指向该类型的虚函数表 vtable，虚函数指针 vptr 的初始化是在构造函数中完成的。后续如果有一个基类类型的指针指向派生类，那么当调用虚函数时，就会根据所指真正对象的虚函数表指针 vptr 去寻找虚函数的地址，也就可以调用派生类的虚函数表中虚函数以此实现多态。 补充：如果基类中没有定义成 virtual（只有继承），那么在这种情况调用的则是 Base 中的 func()。因为如果基类和派生类中都没有虚函数 virtual 的定义，那么编译器就会认为不用留给动态多态的机会，就事先进行函数地址的绑定（早绑定 —— 静态绑定），具体过程： 定义了派生类对象，首先构造基类的空间，然后构造派生类的自身内容，形成一个派生类对象 进行类型转换时，直接截取基类的部分内存，编译器认为类型就是基类，那么函数符号表（不同于虚函数表）绑定的函数地址也就是基类中的函数地址，执行的就是基类函数 1234567891011121314151617181920212223242526272829303132333435// 🌟只有 virtual 存在，编译器才会认为存在「多态」class Base &#123;public: // virtual 不存在则只调用 ~Base() virtual ~Base() &#123; // 虚析构函数 // 释放 Base 的资源 cout &lt;&lt; &quot;释放 Base 的资源&quot; &lt;&lt; endl; &#125; // virtual 不存在则只调用 Base func() virtual void func() &#123; cout &lt;&lt; &quot;Base_func()&quot; &lt;&lt; endl; &#125;&#125;;class Derived : public Base &#123;public: // override 可加可不加，有助于编译器检查 ~Derived() override &#123; // 释放 Derived 的资源 cout &lt;&lt; &quot;释放 Derived 的资源&quot; &lt;&lt; endl; &#125; // override 可加可不加，有助于编译器检查 void func() override &#123; cout &lt;&lt; &quot;Derived_func()&quot; &lt;&lt; endl; &#125;&#125;;int main() &#123; Base* ptr = new Derived; ptr-&gt;func(); delete ptr; // 调用时，先执行 Derived::~Derived()，再执行 Base::~Base() return 0;&#125; 123Derived_func()释放 Derived 的资源释放 Base 的资源 C++ 虚函数的内存分布 &amp; 实现原理 以上简要介绍了「虚函数」相关内容（简要介绍了原理），接下来详细阐述实现原理 更多信息：C++ 虚函数的实现基本原理 1234567891011class A &#123; public: virtual void v_a()&#123;&#125; virtual ~A()&#123;&#125; int64_t _m_a;&#125;;int main()&#123; A* a = new A(); return 0;&#125; 如以上代码所示，在 C++ 中定义一个对象 A，那么在内存中的分布大概是如下图这个样子。 首先在主函数的栈帧上有一个 A 类型的指针指向堆里面分配好的对象 A 实例。 对象 A 实例的头部是一个 vtable 指针，紧接着是 A 对象按照声明顺序排列的成员变量（当我们创建一个对象时，便可以通过实例对象的地址，得到该实例的虚函数表，从而获取其函数指针） vptr 指针指向的是代码段中的 A 类型的虚函数表中的第一个虚函数起始地址。 虚函数表 vtable 的结构其实是有一个头部的，叫做 vtable_prefix ，紧接着是按照声明顺序排列的虚函数。 注意到这里有两个虚析构函数，因为对象有两种构造方式，栈构造和堆构造，所以对应的，对象会有两种析构方式，其中堆上对象的析构和栈上对象的析构不同之处在于，栈内存的析构不需要执行 delete 函数，会自动被回收。 typeinfo 存储着 A 的类基础信息，包括父类与类名称，C++关键字 typeid 返回的就是这个对象。 typeinfo 也是一个类，对于没有父类的 A 来说，当前 tinfo 是 class_type_info 类型的，从虚函数指针指向的 vtable 起始位置可以看出。 1️⃣ Example-1｜如果是多继承情况下，编译器如下处理虚函数表｜虚函数的实现原理 拷贝基类的虚函数表，多继承则拷贝每个虚函数基类的虚函数表 多继承会存在一个基类虚函数表和派生类自身虚函数表合并共用，该基类称为派生类的主基类 派生类重写基类虚函数，则替换重写后的虚函数地址 如果有自身虚函数，则追加自身虚函数到自身的虚函数表 其中 D 对象 vptr1 指向的虚函数表合并了「某个基类虚函数表」和「派生类自身虚函数表」，vptr2 则指向另一个基类的虚函数表 2️⃣ Example-2 12345678910111213141516171819class A&#123;private: uint64_t a;public: virtual void A_a()&#123;std::cout &lt;&lt; __func__;&#125;&#125;;class C&#123;private: uint64_t c;public: virtual void C_a()&#123;std::cout &lt;&lt; __func__;&#125;&#125;;class D : public A,public C&#123;private: uint64_t d;public: virtual void D_a()&#123;std::cout &lt;&lt; __func__;&#125;&#125;; class D 的虚函数表 14. 析构函数可以是虚函数吗？什么情况下析构函数必须是虚函数？ 🪞镜像问题： 为什么需要虚析构？虚析构实现原理？ 析构函数一般写成虚函数的原因？ 析构函数可以是虚函数。将析构函数声明为 virtual 虚函数，确保在删除基类指针指向的派生类对象时，能够正确调用派生类的析构函数，避免内存泄漏。 举例来说，一个基类的指针指向一个派生类的对象，在使用完毕准备销毁时，如果基类的析构函数没有定义成 virtual 虚函数，那么编译器根据指针类型就会认为当前对象类型是基类，仅调用基类的析构函数（该对象的析构函数的函数地址早就被绑定为基类的析构函数——静态绑定 &#x2F; 早绑定），派生类的自身内容将无法被析构，造成内存泄漏。如果基类的析构函数定义为虚函数，那么编译器就可以根据实际对象，执行派生类的析构函数，再执行基类的析构函数，成功释放内存。 注释助于理解 123456789101112131415161718192021222324252627282930313233// 🌟只有 virtual 存在，编译器才会认为存在「多态」class Base &#123;public: // virtual 不存在则只调用 ~Base() virtual ~Base() &#123; // 虚析构函数 // 释放 Base 的资源 cout &lt;&lt; &quot;释放 Base 的资源&quot; &lt;&lt; endl; &#125; // virtual 不存在则只调用 Base func() virtual void func() &#123; cout &lt;&lt; &quot;Base_func()&quot; &lt;&lt; endl; &#125;&#125;;class Derived : public Base &#123;public: ~Derived() &#123; // 释放 Derived 的资源 cout &lt;&lt; &quot;释放 Derived 的资源&quot; &lt;&lt; endl; &#125; void func() &#123; cout &lt;&lt; &quot;Derived_func()&quot; &lt;&lt; endl; &#125;&#125;;int main() &#123; Base* ptr = new Derived; ptr-&gt;func(); delete ptr; // 调用时，先执行 Derived::~Derived()，再执行 Base::~Base() return 0;&#125; 123Derived_func() // func() 没定义 virtual 则输出 Base_func()释放 Derived 的资源 // ~Base() 没定义 virtual 则不输出释放 Base 的资源 ⚠️ C++ 默认的析构函数不是虚函数，是因为虚函数需要额外的虚函数表和虚表指针，占用额外的内存。 当类被设计为「基类」，并且可能被继承时，析构函数应当声明为虚函数。如果类不会被继承，则析构函数可以不声明为虚函数。然而，为了代码的健壮性和可维护性，通常建议将基类的析构函数声明为虚函数，即使该类当前不会被继承。 15. 构造函数为什么一般不定义为虚函数1️⃣ 虚函数调用只需要知道“部分信息”，即只需要知道函数接口，而不需要知道对象的具体类型。但是创建对象时，是需要知道对象的完整信息，特别是需要知道创建对象的确切类型，因此构造函数不应该被定义为虚函数。 2️⃣ 从编译器实现虚函数进行多态的方式来看，虚函数调用时通过实例化之后对象的虚函数表指针 vptr 来找到虚函数地址进行调用的，如果说构造函数是虚的，那么虚函数表指针则不存在（因为虚函数指针 vptr 的初始化是在构造函数中完成的），无法找到对应的虚函数表 vtable 来调用虚函数，那么这个调用实际上也是违反了先实例化后调用的准则。 16. 构造函数的执行顺序？析构函数的执行顺序？1️⃣ 构造函数顺序 基类构造函数：如果有多个基类，则构造函数调用顺序是某类在「类派生列表」中出现的顺序，而不是它们在成员初始化表中的顺序 成员类对象构造函数：如果有多个成员类对象，则构造函数的调用顺序是对象在类中被声明的顺序，而不是它们出现在成员初始化表中的顺序 派生类构造函数 类派生列表 1234567class 派生类名:类派生列表 &#123; 成员列表&#125;class Derived : public Base1, public Base2 &#123; 成员列表&#125; 2️⃣ 析构函数顺序 调用派生类的析构函数 调用成员类对象的析构函数 调用基类的析构函数 17. 静态绑定和动态绑定我们首先要知道静态类型和动态类型： 静态类型：在程序中被声明时所采用的类型，在编译期间确定 动态类型：目前所指对象的实际类型，在运行期间确定 关于静态绑定和动态绑定： 静态绑定，又称早绑定，绑定的是静态类型，所对应的函数或属性依赖于对象的静态类型，发生在编译期间。 动态绑定，又称晚绑定，绑定的是动态类型，所对应的函数或属性依赖于动态类型，发生在运行期间。 比如说，virtual 函数是动态绑定的，非虚函数是静态绑定的，缺省参数值也是静态绑定的。 ⚠️ 注意，我们不应该重新定义继承而来的缺省参数，因为即使我们重定义了，也不会起到效果。因为一个基类的指针指向一个派生类对象，在派生类的对象中针对虚函数的参数缺省值进行了重定义， 但是缺省参数值是静态绑定的，静态绑定绑定的是静态类型相关的内容。 18. 纯虚函数纯虚函数是在基类中「声明但不实现」的虚函数，其声明方式是在函数声明的结尾处添加 = 0，类中如果至少包含一个纯虚函数，则该类称为抽象类，抽象类是不能实例化对象的。 纯虚函数的主要作用是定义接口规范，强制要求派生类必须实现这些函数，从而实现借口的统一和标准化。派生类中必须实现继承于基类的纯虚函数，否则含有纯虚函数的类又会是抽象类，无法实例化。 12345678910111213141516171819class Shape &#123;public: virtual void draw() = 0; // 纯虚函数&#125;;class Circle : public Shape &#123;public: // 必须实现，否则该派生类为抽象类，不能实例化 void draw() override &#123; cout &lt;&lt; &quot;Drawing a circle&quot; &lt;&lt; endl; &#125;&#125;;int main() &#123; Shape* shape = new Circle(); shape-&gt;draw(); // 输出：Drawing a circle delete shape; return 0;&#125; 19. 深拷贝和浅拷贝的区别（举例说明深拷贝的安全性）1️⃣ 浅拷贝： 当出现类的等号 = 赋值时，会调用拷贝构造函数，在未显式定义拷贝构造函数的情况下，系统会调用默认的拷贝函数 —— 即浅拷贝，它能够完成成员的复制，当数据成员中没有指针时，浅拷贝是可行的； 但当数据成员中有指针时，如果采用简单的浅拷贝，则两个类中的两个指针指向同一个地址，当对象快要结束时，会调用两次析构函数，从而导致野指针的问题。 1234567891011121314151617181920212223242526272829class ShallowCopy &#123;private: int* data;public: ShallowCopy(int d) : data(new int(d)) &#123;&#125; // 而且在对象结束时，会调用两次析构函数，从而导致野指针问题 ~ShallowCopy() &#123; delete data; &#125; void setData(int d) &#123; *data = d; &#125; int getData() const &#123; return *data; &#125; // 默认拷贝构造函数（浅拷贝） ShallowCopy(const ShallowCopy&amp; source) : data(source.data) &#123;&#125;&#125;;int main() &#123; ShallowCopy obj1(10); ShallowCopy obj2 = obj1; // 使用默认拷贝构造函数 cout &lt;&lt; &quot;obj1 data: &quot; &lt;&lt; obj1.getData() &lt;&lt; endl; cout &lt;&lt; &quot;obj2 data: &quot; &lt;&lt; obj2.getData() &lt;&lt; endl; obj1.setData(20); // 修改 obj1 的数据 cout &lt;&lt; &quot;After modifying obj1&quot; &lt;&lt; endl; cout &lt;&lt; &quot;obj1 data: &quot; &lt;&lt; obj1.getData() &lt;&lt; endl; cout &lt;&lt; &quot;obj2 data: &quot; &lt;&lt; obj2.getData() &lt;&lt; endl; // obj2 数据也被修改了 return 0;&#125; 2️⃣ 深拷贝：在数据成员含有指针时，必须采用深拷贝（自定义拷贝构造函数），在拷贝构造函数中创建一个全新对象，与原对象完全独立。深拷⻉与浅拷⻉之间的区别就在于，深拷⻉会在堆内存中另外申请空间来存储数据，从而解决来野指针的问题。简而言之，当数据成员中有指针时，必需要用深拷⻉更加安全。 12345678910111213141516171819202122232425262728class DeepCopy &#123;private: int *data;public: DeepCopy(int d) : data(new int(d)) &#123;&#125; ~DeepCopy() &#123; delete data; &#125; void setData(int d) &#123; *data = d; &#125; int getData() const &#123; return *data; &#125; // 自定义拷贝构造函数（深拷贝） DeepCopy(const DeepCopy &amp;source) : data(new int(*source.data)) &#123;&#125;&#125;;int main() &#123; DeepCopy obj1(10); DeepCopy obj2 = obj1; // 使用自定义拷贝构造函数 cout &lt;&lt; &quot;obj1 data: &quot; &lt;&lt; obj1.getData() &lt;&lt; endl; cout &lt;&lt; &quot;obj2 data: &quot; &lt;&lt; obj2.getData() &lt;&lt; endl; obj1.setData(20); // 修改 obj1 的数据 cout &lt;&lt; &quot;After modifying obj1&quot; &lt;&lt; endl; cout &lt;&lt; &quot;obj1 data: &quot; &lt;&lt; obj1.getData() &lt;&lt; endl; cout &lt;&lt; &quot;obj2 data: &quot; &lt;&lt; obj2.getData() &lt;&lt; endl; // obj2 数据没有变化 return 0;&#125; 20. 说一下你理解的 C++ 四种智能指针｜shared_ptr 的简易实现 更多信息：C++ 智能指针、知乎 C++ 智能指针 看这两篇，取取交集 在使用 C++ 开发过程中，最容易也是最麻烦的问题便是内存泄漏。相较于 Java、Python 或者 Go 语言都拥有垃圾回收机制，在对象没有引用时就会被系统自动回收而且基本上没有指针的概念，但是 C++ 则要求程序员自己管理内存，这一方面让程序员有更大的自由度但是也会很大影响程序员的开发效率。因此 C++11 标准中新推出了 shared_ptr、unique_ptr 和 weak_ptr 三个智能指针来帮助管理内存。 智能指针就是一个类，当超出了类的作用域时，类会自动调用析构函数，析构函数会自动释放资源，所以智能指针的作用原理就是在函数结束时自动释放内存空间，不需要手动释放。 123456T* get();T&amp; operator*();T* operator-&gt;();T&amp; operator=(const T&amp; val);T* release();void reset (T* ptr = nullptr); 常用接口： T 是模板参数，即传入的类型 get() 用来获取 auto_ptr 封装在内部的指针，也就是获取原生指针 operator*() 重载 *，operator-&gt;() 重载 -&gt;，operator=() 重载 = release() 将 auto_ptr 封装在内部的指针置为 nullptr，但不会破坏指针所指向的内容，函数返回的是内部指针置空之前的值 reset() 直接释放封装的内部指针所指向的内存，如果指定了 ptr 的值，则将内部指针初始化为该值 接下来说说哪四种智能指针： auto_ptr 为 C++98 的方案，C++11 已抛弃 C++11 引入 std::shared_ptr std::weak_ptr std::unique_ptr 0️⃣ auto_ptr C++98 方案，C++11 已抛弃 123auto_ptr&lt;std::string&gt; p1(new string(&quot;string&quot;));auto_ptr&lt;std::string&gt; p2;p2 = p1; // auto_ptr 不会报错 p2 剥夺了 p1 的所有权，但是当程序运行时访问 p1 将会报错，所以 auto_ptr 缺点就是存在潜在的内存崩溃问题。 1️⃣ shared_ptr 共享式智能指针 彻底理解：shared_ptr 是有两层析构： shared_ptr 本身析构会使得指向的共享对象的引用数 -1，当共享对象引用数为 0 时，则调用共享对象本身的析构函数 这样就可以理解循环引用了：共享对象引用还是 1，未调用共享对象本身的析构函数，其中成员 shared_ptr 的析构函数也不会被调用 shared_ptr 能够自动记录共享对象的引用次数，并且在引用计数降至零时自动删除对象，从而防止内存泄漏。每个 shared_ptr 的拷贝都指向相同的内存，在最后一个 shared_ptr 析构的时候其指向的内存资源才会被释放。 shared_ptr 初始化方式： 构造函数 std::make_shared() 辅助函数 reset() 123456std::shared_ptr&lt;int&gt; p(new int(1));std::shared_ptr&lt;int&gt; p2 = p;std::shared_ptr&lt;A&gt; ap = std::make_shared&lt;A&gt;();std::shared_ptr&lt;int&gt; ptr;ptr.reset(new int(1)); 不能将一个原始指针直接赋值给一个智能指针，如：std::shared_ptr&lt;int&gt; p = new int(1)。 对于一个未初始化的智能指针，可以通过调用 reset 方法初始化，当智能指针中有值的时候，调用 reset 方法会使引用计数减 1。当需要获取原指针的时候可以通过 get 方法返回原始指针： 12std::shared_ptr&lt;int&gt; p(new int(1));int *ptr = p.get(); 智能指针初始化时也可以指定删除器，当其引用计数为 0 时将自动调用删除器来释放对象，删除器可以是一个函数对象。如当使用 shared_ptr 管理动态数组时，需要指定删除器，因为 shared_ptr 默认删除器不支持数组对象： 12// lambda 表达式作为删除器std::shared_ptr&lt;int&gt; p(new int[10], [](int *p) &#123; delete []p; &#125;) 关于 shared_ptr 的注意事项： 不要用一个裸指针初始化多个 shared_ptr，会出现 double_free 导致程序崩溃 通过 shared_from_this() 返回 this 指针，不要把 this 指针作为 shared_ptr 返回出来，因为 this 指针本质就是裸指针，通过 this 返回可能会导致重复析构，不能把 this 指针交给智能指针管理。 123456class A &#123; shared_ptr&lt;A&gt; GetSelf() &#123; return shared_from_this(); // return shared_ptr&lt;A&gt;(this); 错误，会导致 double free &#125; &#125;; 尽量使用 std::make_shared&lt;T&gt;()，少用 new 不要 delete get() 返回的裸指针 不是 new 出来的空间要自定义删除器 要避免循环引用，循环引用导致内存永远不会被释放，造成内存泄漏 12345678910111213141516171819202122class A;class B;class A &#123;public: std::shared_ptr&lt;B&gt; b;&#125;;class B &#123;public: std::shared_ptr&lt;A&gt; a;&#125;;int main() &#123; std::shared_ptr&lt;A&gt; ap = std::make_shared&lt;A&gt;(); std::shared_ptr&lt;B&gt; bp = std::make_shared&lt;B&gt;(); ap-&gt;b = bp; bp-&gt;a = ap; // 此时，a 和 b 相互持有对方的 shared_ptr，形成循环引用 // 程序结束时，a 和 b 的引用计数都不会降为零，导致内存泄漏 return 0;&#125; 🌟 解释说明循环引用： 首先循环引用导致 shared_ptr 指向的共享对象 A 和 B 的引用计数都是 2； 在离开作用域后，根据栈后进先出的特点，首先 shared_ptr&lt;B&gt; bp 析构时只减少 B 的引用次数为 1（这里是对象 shared_ptr 析构而非对象 B 析构），由于此时对象 B 的引用次数仍为 1（减为 0 的 B 才会被释放），所以不会调用（对象 B）内部智能指针 a 的析构函数来减少引用，所以也就无法减少 A 的引用次数了。 接着 ap 析构时减少 A 的引用次数为 1，此时 A 的引用仍为 1 不会被析构，所以无法析构其成员对象 b； 最终导致指针永远不会析构，产生了内存泄漏（解决方案就是使用 weak_ptr） 2️⃣ weak_ptr 弱引用智能指针weak_ptr 是一种不控制对象生命周期的智能指针，它指向一个 shared_ptr 管理的对象，它不管理 shared_ptr 内部指针，进行该对象的内存管理的是那个强引用的 shared_ptr。 weak_ptr 只是提供了对管理对象的一个访问手段。weak_ptr 设计的目的是为配合 shared_ptr 而引入的一种智能指针来协助 shared_ptr 工作，纯粹是作为一个旁观者监视 shared_ptr 中管理的资源是否存在，它只可以从一个 shared_ptr 或另一个 weak_ptr 对象构造，它的构造和析构不会引起引用记数的增加或减少。 weak_ptr 是用来解决 shared_ptr 相互引用时的死锁问题，如果说两个 shared_ptr 相互引用，那么这两个指针的引用计数永远不可能下降为 0，也就是资源永远不会释放。它是对对象的一种弱引用，不会增加对象的引用计数，和 shared_ptr 之间可以相互转化： shared_ptr 可以直接赋值给它 它也可以通过调用 lock 函数来获得 shared_ptr 循环引用是当两个智能指针都是 shared_ptr 类型的时候，析构时两个资源引用计数会减 1，但是两者引用计数还是为 1，导致跳出函数时资源没有被释放（析构函数没有被调用），解决办法就是把其中一个改为 weak_ptr 就可以。 总之 weak_ptr 可以用来返回 this 指针和解决循环引用问题。 作用 1：返回 this 指针，上面介绍的 shared_from_this() 其实就是通过 weak_ptr 返回的 this 指针 Q：shared_from_this() 是如何实现的？ A：使用 shared_from_this() 的类需要继承 enable_shared_from_this 类，enable_shared_from_this 类中持有一个类型为 weak_ptr 的成员 _M_weak_this，调用 shared_from_this() 就是将内部持有的 weak_ptr 转成了 shared_ptr。 123456789class enable_shared_from_this&#123; shared_ptr&lt;const _Tp&gt; shared_from_this() const &#123; return shared_ptr&lt;const _Tp&gt;(this-&gt;_M_weak_this); &#125; mutable weak_ptr&lt;_Tp&gt; _M_weak_this;&#125;; 作用 2：解决循环引用问题 1234567891011121314151617181920212223242526272829303132333435363738394041class A &#123; std::shared_ptr&lt;B&gt; bptr; ~A() &#123; cout &lt;&lt; &quot;A delete&quot; &lt;&lt; endl; &#125; void Print() &#123; cout &lt;&lt; &quot;A&quot; &lt;&lt; endl; &#125;&#125;;class B &#123; std::weak_ptr&lt;A&gt; aptr; // 这里改成 weak_ptr // B 对象销毁时才调用（即引用计数为 0 时） ~B() &#123; cout &lt;&lt; &quot;B delete&quot; &lt;&lt; endl; &#125; void PrintA() &#123; if (!aptr.expired()) &#123; // 监视 shared_ptr 的生命周期 auto ptr = aptr.lock(); ptr-&gt;Print(); &#125; &#125;&#125;;int main() &#123; auto aaptr = std::make_shared&lt;A&gt;(); auto bbptr = std::make_shared&lt;B&gt;(); aaptr-&gt;bptr = bbptr; bbptr-&gt;aptr = aaptr; bbptr-&gt;PrintA(); return 0;&#125;// 输出：// A// A delete// B delete 🔥 代码解释：尽管局部变量的析构顺序是按照后进先出的原则，但关键在于“对象的销毁时机”是由引用计数决定的，而不是直接由局部变量析构的顺序决定的： 局部变量析构顺序：在 main 函数中，aaptr 先创建、bbptr 后创建，因此在退出作用域时，bbptr 会先析构，随后 aaptr 析构。 引用计数的影响 创建时，aaptr 持有 A 对象，bbptr 持有 B 对象。 A 对象内部的成员变量 bptr 又持有 B 对象的 shared_ptr，因此 B 对象的引用计数为 2。 B 对象内部的 weak_ptr 不会影响 A 对象的引用计数。 析构过程 当 bbptr 析构时，仅仅减少了 B 对象的引用计数，从 2 变为 1，但 B 对象并没有被销毁，因为 aaptr-&gt;bptr 仍然持有它。 随后 aaptr 析构，导致 A 对象的引用计数从 1 变为 0，从而触发 A 的析构函数，输出 “A delete”。 在 A 的析构过程中，其成员变量 bptr 被析构，从而使 B 对象的引用计数从 1 减为 0。此时，B 对象的析构函数被调用，输出 “B delete”。 3️⃣ unique_ptr 独占式智能指针（替换 auto_ptr）unique_ptr 是一个独占型的智能指针，它不允许其他的智能指针共享其内部的指针： 不允许通过赋值将一个 unique_ptr 拷贝&#x2F;赋值给另外一个 unique_ptr 但是允许通过函数返回给其他的 unique_ptr 或者通过 std::move 来转移到其他的 unique_ptr，这样的话它本身就不再拥有原指针的所有权了 与 shared_ptr 相比，unique_ptr 除了独占性的特点外，还能够指向一个数组：std::unique_ptr&lt;int []&gt; p(new int[10]);。 shared_ptr 与 unique_ptr 的使用需要根据场景决定，如果希望只有一个智能指针管理资源或者管理数组就使用 unique_ptr，如果希望使用多个智能指针管理同一个资源就使用 shared_ptr。 🔥 实现简易的 shared_ptr123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#include &lt;memory&gt;template&lt;typename T&gt;class smartPtr &#123;private: T *_ptr; size_t* _count;public: smartPtr(T *ptr = nullptr):_ptr(ptr) &#123; if (_ptr) &#123; _count = new size_t(1); &#125; else &#123; _count = new size_t(0); &#125; &#125; smartPtr(const smartPtr &amp;ptr) &#123; if (this != &amp;ptr) &#123; this-&gt;_ptr = ptr._ptr; this-&gt;_count = ptr._count; ++(*this-&gt;_count) ; &#125; &#125; smartPtr&amp; operator=(const smartPtr &amp;ptr) &#123; if (this-&gt;_ptr == ptr._ptr) return *this; if (this-&gt;_ptr) &#123; --(*this-&gt;_count); if (this-&gt;_count == 0) &#123; delete this-&gt;_ptr; delete this-&gt;_count; &#125; &#125; this-&gt;_ptr = ptr._ptr; this-&gt;_count = ptr._count; ++(*this-&gt;_count); return *this; &#125; ~smartPtr() &#123; --(*this-&gt;_count); if (0 == *this-&gt;_count) &#123; delete this-&gt;_ptr; delete this-&gt;_count; &#125; &#125; size_t use_count() &#123; return *this-&gt;_count; &#125; T&amp; operator*() &#123; assert(this-&gt;_ptr == nullptr); return *(this-&gt;_ptr); &#125; T* operator-&gt;() &#123; assert(this-&gt;_ptr == nullptr); return this-&gt;_ptr; &#125;&#125;; 21. shared_ptr 的实现，shared_ptr 一定不会导致内存泄漏吗？std::shared_ptr 的实现基于引用计数，每个 shared_ptr 实例持有一个指向控制块的指针，控制块中包含引用计数和所管理对象的指针。 当 shared_ptr 的引用计数降为零时，控制块会删除所管理的对象。 然而，shared_ptr 并非在所有情况下都能防止内存泄漏。 当存在循环引用时，shared_ptr 的引用计数永远不会降为零，导致内存无法被释放，从而引发内存泄漏。 123456789101112131415161718192021222324#include &lt;memory&gt;class A;class B;class A &#123;public: std::shared_ptr&lt;B&gt; b;&#125;;class B &#123;public: std::shared_ptr&lt;A&gt; a;&#125;;int main() &#123; std::shared_ptr&lt;A&gt; a = std::make_shared&lt;A&gt;(); std::shared_ptr&lt;B&gt; b = std::make_shared&lt;B&gt;(); a-&gt;b = b; b-&gt;a = a; // 此时，a 和 b 相互持有对方的 shared_ptr，形成循环引用 // 程序结束时，a 和 b 的引用计数都不会降为零，导致内存泄漏 return 0;&#125; 为了解决循环引用问题，可以使用 std::weak_ptr，它是一种不增加引用计数的智能指针。 std::weak_ptr 用于打破循环引用，避免内存泄漏。 123456789101112131415161718192021222324#include &lt;memory&gt;class A;class B;class A &#123;public: std::weak_ptr&lt;B&gt; b; // 使用 weak_ptr 打破循环引用&#125;;class B &#123;public: std::shared_ptr&lt;A&gt; a;&#125;;int main() &#123; std::shared_ptr&lt;A&gt; a = std::make_shared&lt;A&gt;(); std::shared_ptr&lt;B&gt; b = std::make_shared&lt;B&gt;(); a-&gt;b = b; b-&gt;a = a; // 此时，a 和 b 之间的循环引用被 weak_ptr 打破 // 程序结束时，a 和 b 的引用计数会降为零，内存会被正确释放 return 0;&#125; 或者如果在类之间的引用是单向的（即不会形成循环引用），可以考虑使用 std::unique_ptr。std::unique_ptr 不会引起引用计数问题，因为它是独占的，每个对象只有一个拥有者。 12345678910111213141516171819202122#include &lt;memory&gt;class A;class B;class A &#123;public: std::unique_ptr&lt;B&gt; b; // 改为 unique_ptr&#125;;class B &#123;public: std::shared_ptr&lt;A&gt; a;&#125;;int main() &#123; std::shared_ptr&lt;A&gt; a = std::make_shared&lt;A&gt;(); std::shared_ptr&lt;B&gt; b = std::make_shared&lt;B&gt;(); a-&gt;b = std::move(b); // 转移所有权 // 使用 unique_ptr 的情况下，没有循环引用问题 return 0;&#125; 22. STL 中 vector、list、map 的底层原理实现和适用场景？关于 STL 库中所有的结构的底层实现原理：https://zhuanlan.zhihu.com/p/542115773 顺带了解了 set、map、unordered_map、unordered_set 之间区别： set、map：底层使用红黑树实现，有序，插入、查找、删除的时间复杂度为 $O(logn)$ 优点：有序性，内部实现红黑树使得很多操作都在 $O(logn)$ 时间复杂度下完成 缺点：空间占用率高，需要额外保存父节点、孩子节点和红&#x2F;黑性质 unordered_set、unordered_map：底层使用哈希表实现，无序，查找的时间复杂度为 $O(1)$ 优点：因为内部实现了哈希表，因此其查找速度非常的快 缺点：哈希表的建立比较费时 1️⃣ vector 动态数组 vector 底层是动态数组，元素连续存储在堆上 自动扩容机制： vector 采用几何增长策略（通常是 2 倍扩容） 当 size() == capacity() 时，会申请更大的内存空间，然后拷贝旧数据到新空间 由于 realloc 可能导致数据搬移，push_back() 的均摊时间复杂度为 $O(1)$，但最坏情况 $O(n)$（扩容时） ❓所以有可能 vector 的插入操作可能导致迭代器失效：因为 vector 动态增加大小时，并不是在原空间后增加新空间，而是以原大小两倍在开辟另外一片较大空间，然后将内容拷贝过来，并释放原有空间，所以迭代器失效。 适用场景： ✅ 高效的随机访问（O(1)）。✅ 批量尾部插入&#x2F;删除（push_back()）。❌ 不适合频繁插入&#x2F;删除中间元素（O(n)）。❌ 扩容会导致数据搬移（不适合超大数据集）。 2️⃣ list 双向链表 list 底层是双向链表，每个节点存储数据和两个指针 插入和删除操作非常高效，不影响其他元素 不支持随机访问，必须顺序遍历才能找到某个元素 $O(n)$ 不会发生扩容问题，适合频繁插入&#x2F;删除的场景 适用场景： ✅ 高效插入&#x2F;删除（O(1)，特别是中间位置）。✅ 不关心随机访问，仅需遍历。❌ 不适合频繁随机访问（O(n)）。❌ 额外的指针开销（内存占用比 vector 高）。 3️⃣ map 红黑树 map 底层实现是红黑树（Red-Black Tree），一种自平衡二叉搜索树 key 是有序的 插入、删除、查找 $O(logn)$，因为树的高度是 $O(logn)$ 迭代遍历按照 key 顺序进行 操作 时间复杂度 说明 插入 insert() $O(log n)$ 需要维护红黑树平衡 删除 erase() $O(log n)$ 删除节点后可能需要旋转 查找 find() $O(log n)$ 通过 BST 进行搜索 适用场景： ✅ 需要有序存储的数据结构（默认按照 key 递增）。✅ 需要高效查找、插入、删除（O(log n)）。❌ 不适合频繁变更 key（因为 key 作为 BST 节点的一部分）。❌ 遍历效率比 unordered_map 低（有序存储开销大）。 23. 菱形继承会出现二义性问题，C++ 中如何解决这个问题？❓镜像问题：一个派生类继承两个父类，这两个父类同时有一个共同基类，如果你去调用两个父类的基类对象函数，会有问题吗？怎么解决？ 注：在 Java 中，由于 Java 不支持多重继承，所以菱形继承问题也不存在。 Java 使用接口来替代多重继承，接口只定义了一些抽象的方法，而没有具体的实现。 这是 C++ 多重继承造成的菱形继承问题，如果一个派生类继承了两个拥有相同基类的父类，那么基类的成员会被继承两次，这会导致 “二义性问题” 和 “冗余存储”。 ❌ 编译错误！ 123456789101112131415161718#include &lt;iostream&gt;class Base &#123;public: void show() &#123; std::cout &lt;&lt; &quot;Base::show()&quot; &lt;&lt; std::endl; &#125;&#125;;class Parent1 : public Base &#123;&#125;; // 继承自 Baseclass Parent2 : public Base &#123;&#125;; // 继承自 Base// 多重继承class Derived : public Parent1, public Parent2 &#123;&#125;;int main() &#123; Derived d; d.show(); // ⚠️ 编译错误：二义性 return 0;&#125; 1️⃣ 解决方案一：使用作用域解析符 缺点：Derived 仍然包含 两个 Base 实例，数据冗余，而且每次调用 show() 需要手动指定作用域，不优雅。 123456int main() &#123; Derived d; d.Parent1::show(); // 访问 Parent1 继承的 Base d.Parent2::show(); // 访问 Parent2 继承的 Base return 0;&#125; 2️⃣ 使用虚继承｜最佳方案 ✅ 虚继承是为了让某个类做出声明，承诺愿意共享它的基类，这个被共享的基类就是虚基类 多继承除了造成命名冲突，还有数据冗余等问题，为了解决这些问题，C++ 引进了「虚继承」 这样能够保证 Derived 只含有一个唯一的 Base 实例。 12345678910111213141516171819#include &lt;iostream&gt;class Base &#123;public: void show() &#123; std::cout &lt;&lt; &quot;Base::show()&quot; &lt;&lt; std::endl; &#125;&#125;;// 让 Parent1 和 Parent2 进行虚继承class Parent1 : virtual public Base &#123;&#125;;class Parent2 : virtual public Base &#123;&#125;;// 继承 Parent1 和 Parent2class Derived : public Parent1, public Parent2 &#123;&#125;;int main() &#123; Derived d; d.show(); // ✅ 现在可以直接调用，不会有二义性 return 0;&#125; 不使用 virtual 时 Derived 会有两个 Base 对象，导致二义性问题。 内存浪费（两个 Base 子对象的冗余）。 使用 virtual 继承 Parent1 和 Parent2 不会各自包含 Base 的副本，而是共享同一个 Base 实例。 Derived 只会有一个 Base 实例，所以调用 show() 时不会有二义性。 🔥虚继承是为了让某个类做出声明，承诺愿意共享它的基类，这个被共享的基类就是虚基类！ 使用虚继承解决菱形继承中的命名冲突问题 🔥 虚继承在 C++ 标准库中的实际应用 再看个虚继承的例子，彻底明白虚继承： 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;class Base0 &#123;public: int var0; void fun0() &#123; cout &lt;&lt; &quot;Member of Base0&quot; &lt;&lt; endl; &#125;&#125;;class Base1 : virtual public Base0 &#123;public: int var1;&#125;;class Base2 : virtual public Base0 &#123;public: int var2;&#125;;class Derived : public Base1, public Base2 &#123; //定义派生类Derived public: int var; void fun() &#123; cout &lt;&lt; &quot;Member of Derived&quot; &lt;&lt; endl; &#125;&#125;;int main() &#123; Derived d; d.var0 = 2; //直接访问虚基类的数据成员 d.fun0(); //直接访问虚基类的函数成员 return 0;&#125; ⁉️将 Base0 类作为它的直接派生类 Base1 和 Base2 的虚基类，即 Base1 虚继承 Base0，Base2 虚继承 Base0。之后 Derived 再继承 Base1 和 Base2，在 Derived 对象里面就不会存在 Base0 类的双份的成员。 Derived 对象包含着从 Base1 继承的成员和从 Base2 继承的成员，但是从 Base1 继承的 Base0 成员实际上这个地方放了一个指针，这个指针指向真正的 Base0 成员，Base2 的也是。所以实质上从最远的基类继承过来的成员，在最远派生类中只有一份。 24. 动态编译 vs 静态编译，动态链接 vs 静态链接？在编译和链接过程中，我们可以分为以下几个阶段： 编译（Compilation）：将源代码 .cpp 转换为目标文件 .o。 链接（Linking）：将多个目标文件和库组合成一个可执行文件。 (1) 静态编译 vs 动态编译 静态编译（Static Compilation）：所有代码都在 编译时 确定，并编译成完整的 可执行文件。 动态编译（Dynamic Compilation）：代码可以在 运行时动态生成或加载，例如 JIT（Just-In-Time）编译。 (2) 静态链接 vs 动态链接 静态链接（Static Linking）： 编译时 将所有 库的代码 直接复制到可执行文件中。 生成的可执行文件 较大，但不依赖外部动态库。 动态链接（Dynamic Linking）： 运行时按需加载动态库（.so&#x2F;.dll）。 可执行文件 更小，可以更新动态库而无需重新编译整个程序。 25. 拷贝构造函数与 operator=() 的区别？在 C++ 中，拷贝构造函数 和 赋值运算符 (operator=) 主要区别在于 调用时机和行为。 (1) 拷贝构造函数 作用：用于创建新对象时，用已有对象进行初始化。 调用时机： 用已有对象初始化新对象 函数按值传递参数 函数返回对象（优化前的 NRVO） 示例： 12345678910111213141516class MyClass &#123;public: int data; MyClass(int d) : data(d) &#123;&#125; // 拷贝构造函数 MyClass(const MyClass&amp; other) &#123; data = other.data; std::cout &lt;&lt; &quot;Copy Constructor &quot;; &#125;&#125;;int main() &#123; MyClass obj1(10); MyClass obj2 = obj1; // 拷贝构造&#125; 输出： 12CopyEditCopy Constructor (2) 赋值运算符 operator= 作用：用于 已有对象之间赋值，即一个对象的内容 被另一个对象替换。 调用时机： 两个已存在对象进行赋值时 🔥 a = b; 而不是 MyClass a = b; 示例： 12345678910111213141516171819class MyClass &#123;public: int data; MyClass(int d) : data(d) &#123;&#125; // 赋值运算符 MyClass&amp; operator=(const MyClass&amp; other) &#123; if (this == &amp;other) return *this; // 防止自赋值 data = other.data; std::cout &lt;&lt; &quot;Assignment Operator &quot;; return *this; &#125;&#125;;int main() &#123; MyClass obj1(10); MyClass obj2(20); obj2 = obj1; // 赋值运算符调用&#125; 输出： 1Assignment Operator (3) 主要区别 对比项 拷贝构造函数 赋值运算符 (operator=) 作用 初始化新对象 赋值给已有对象 调用时机 MyClass a = b; a = b; 是否创建新对象 ✅ 是 ❌ 否 默认行为 成员逐一拷贝 成员逐一赋值 (4) 特殊情况 避免自赋值 1if (this == &amp;other) return *this; 支持链式赋值 123456MyClass&amp; operator=(const MyClass&amp; other) &#123; this-&gt;data = other.data; return *this;&#125;obj1 = obj2 = obj3; // 链式赋值 26. 右值引用的主要用途？ 等价于问题：什么情况下会用到右值引用。 右值引用是 C++11 引入的新特性，用于实现移动语义和完美转发： 1️⃣ 实现移动语义在传统 C++ 中，对象的赋值和传递通常涉及深拷贝，这会带来性能开销，通过右值引用，可以触发移动构造函数将资源所有权从一个对象转移到另一个对象（将资源从临时对象移动到新对象），无需深拷贝，避免了不必要的复制和销毁操作。 当一个临时对象或不再使用的资源，需要被高效地“移动”而不是拷贝时，就用到右值引用 12std::vector&lt;int&gt; v1 = &#123;1,2,3&#125;;std::vector&lt;int&gt; v2 = std::move(v1); // 此时v1内容转移给v2，避免深拷贝 2️⃣ 完美转发用于函数模板的完美转发，将参数以原始的形式传递给下一个函数，避免了不必要的复制和类型转换。 模板中利用万能引用（forwarding reference）配合std::forward实现任意类型参数的原始性质传递 1234template&lt;typename T&gt;void wrapper(T&amp;&amp; arg) &#123; func(std::forward&lt;T&gt;(arg)); // 原样传递arg（左值传左值，右值传右值）&#125; 针对「完美转发」，请看如下例子假设我们有两个重载的函数 process，一个接收左值引用，另一个接收右值引用： 1234567void process(int&amp; i) &#123; std::cout &lt;&lt; &quot;左值引用处理: &quot; &lt;&lt; i &lt;&lt; std::endl;&#125;void process(int&amp;&amp; i) &#123; std::cout &lt;&lt; &quot;右值引用处理: &quot; &lt;&lt; i &lt;&lt; std::endl;&#125; 现在，我们希望编写一个模板函数 forwarding，它能够将传入的参数完美地转发给 process，即保持参数的左值或右值属性不变。 不使用完美转发的情况：如果我们直接在模板函数中调用 process(param)，无论传入的是左值还是右值，param 在函数内部都是一个左值，这会导致总是调用接收左值引用的 process 函数： 12345template &lt;typename T&gt;// void forwarding(T param) 也是如此，即右值无法传递进去导致参数不匹配void forwarding(T&amp;&amp; param) &#123; process(param); // param 被视为左值，即右值无法传递进去导致参数不匹配&#125; 使用完美转发的情况：为了实现完美转发，我们需要： 使用万能引用：在模板参数中使用 T&amp;&amp;，使得函数能够同时接收左值和右值。 为了解决这个问题，引入了 std::forward, 将模板函数改成如下形式就可以了, forward 被称为完美转发，根据参数的类型（左值或右值）进行条件转发，保持其原有的值类别。语义上：数据是左值就转发成左值，右值就转发成右值，哪怕在万能引用中也是如此。 实现如下： 123456#include &lt;utility&gt; // std::forwardtemplate &lt;typename T&gt;void forwarding(T&amp;&amp; param) &#123; process(std::forward&lt;T&gt;(param));&#125; 测试代码： 1234567int main() &#123; int a = 10; forwarding(a); // 传入左值 forwarding(20); // 传入右值 forwarding(std::move(a)); // 将左值转换为右值 return 0;&#125; 输出结果： 123左值引用处理: 10右值引用处理: 20右值引用处理: 10 补充：左值引用（&amp;）与右值引用（&amp;&amp;）在 C++11 中提出了右值引用，作用是为了和左值引用区分开来，其作用是: 右值引用限制了其只能接收右值，可以利用这个特性从而提供重载，这是右值引用有且唯一的特性，限制了接收参数必为右值, 这点常用在 move construct 中，告诉别人这是一个即将消失的对象的引用，可以瓜分我的对象东西，除此之外，右值引用就没有别的特性了。 12345class Base&#123;public: Base(const Base&amp; b)&#123;...&#125; //copy construct Base(Base&amp;&amp; b)&#123;...&#125; //move construct&#125;; 然后，一个右值引用变量在使用上就变成了左值，已经不再携带其是右引用这样的信息，只是一个左值，这就是引用在c++中特殊而且复杂的一点，引用在 c++ 中是一个特别的类型，因为它的值类型和变量类型不一样, 左值/右值引用变量的值类型都是左值, 而不是左值引用或者右值引用。 1234567int val = 0;int&amp; val_left_ref = val; int&amp;&amp; val_right_ref = 0;// 引用必须在初始化时绑定到一个有效的对象，且绑定后无法更改val_left_ref = 0; // val_left_ref 此时是 int，而不是 int&amp;val_right_ref = 0; // val_right_ref 此时是 int， 而不是 int&amp;&amp; 🔥 补充：万能引用（T&amp;&amp;）模板中的 T&amp;&amp; 不同于普通的右值引用，而是万能引用，其既能接收左值又能接收右值。 12345678910111213template&lt;typename T&gt;void emplace_back(T&amp;&amp; arg) &#123;&#125;Class Base &#123;&#125;;int main() &#123; Base a; emplace_back(a); // ok emplace_back(Base()); // also ok return 0;&#125; 这种特性常用在容器元素的增加上，利用传参是左值还是右值进而在生成元素的时候调用 copy construct 还是 move construct，比如说 vector 的 emplace_back。 所以为什么需要 std::forwad？ 模板的万能引用只是提供了能够接收同时接收左值引用和右值引用的能力，但是引用类型的唯一作用就是限制了接收的类型，后续使用中都退化成了左值，我们希望能够在传递过程中保持它的左值或者右值的属性, 如果不使用 forward，直接按照下面的方式写就会导致问题。 12345template &lt;typename T&gt;// void forwarding(T param) 也是如此，即右值无法传递进去导致参数不匹配void forwarding(T&amp;&amp; param) &#123; process(param); // param 被视为左值，即右值无法传递进去导致参数不匹配&#125; 所以为了解决这个问题引入了 std::forward，将模板函数改成如下形式，即可实现完美转发： 1234template &lt;typename T&gt;void forwarding(T&amp;&amp; param) &#123; process(std::forward&lt;T&gt;(param));&#125; 27. C++ 中有哪些锁？ 更多参考：如何避免死锁、介绍几种经典的锁 从种类上分：普通锁、读写锁、递归锁 从实现上分：互斥锁、自旋锁、信号量、条件变量 互斥锁（Mutex）🌟互斥锁是在抢锁失败的情况下主动放弃 CPU 进入睡眠状态直到锁的状态改变时再唤醒，而操作系统负责线程调度，为了实现锁的状态发生改变时唤醒阻塞的线程或者进程，需要把锁交给操作系统管理，所以互斥锁在加锁操作时涉及上下文的切换。互斥锁实际的效率还是可以让人接受的，加锁的时间大概 100ns 左右，而实际上互斥锁的一种可能的实现是先自旋一段时间，当自旋的时间超过阀值之后再将线程投入睡眠中，因此在并发运算中使用互斥锁（每次占用锁的时间很短）的效果可能不亚于使用自旋锁。 互斥锁（Mutex）：用于保护共享资源，确保任一时刻只有一个线程访问资源。 信号量（Semaphore）：一种特殊的计数器，可以同时允许多个线程访问有限的共享资源。 互斥锁相当于信号量初值为 1 的特殊情况；信号量允许多个线程并发访问资源（初值 &gt; 1）。 123456std::mutex mtx;void foo() &#123; std::lock_guard&lt;std::mutex&gt; lock(mtx); // 临界区操作&#125; 应用场景： 保护关键资源（如共享变量） 控制资源的访问量 条件锁&#x2F;条件变量（Condition Variable）🌟互斥锁一个明显的缺点是他只有两种状态：锁定和非锁定。而条件变量通过允许线程阻塞和等待另一个线程发送信号的方法弥补了互斥锁的不足，他常和互斥锁一起使用，以免出现竞态条件。当条件不满足时，线程往往解开相应的互斥锁并阻塞线程然后等待条件发生变化。一旦其他的某个线程改变了条件变量，他将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程。总的来说互斥锁是线程间互斥的机制，条件变量则是同步机制。 条件变量用于线程间通信，当某个条件满足后再唤醒等待线程。 1234567891011121314151617181920#include &lt;mutex&gt;#include &lt;condition_variable&gt;std::mutex mtx;std::condition_variable cv;bool ready = false;void wait_thread() &#123; std::unique_lock&lt;std::mutex&gt; lock(mtx); cv.wait(lock, []()&#123; return ready; &#125;); // 等待条件满足 // 执行后续任务&#125;void signal_thread() &#123; &#123; std::lock_guard&lt;std::mutex&gt; lock(mtx); ready = true; // 修改条件 &#125; cv.notify_one(); // 通知等待线程&#125; 应用场景： 生产者-消费者模型 线程等待某条件满足才能执行 自旋锁（Spin Lock）🌟如果线程无法取得锁，线程不会立刻放弃 CPU 时间片，而是一直循环尝试获取锁，直到获取为止。如果别的线程长时期占有锁那么自旋就是在浪费 CPU 做无用功，但是自旋锁一般应用于加锁时间很短的场景，这个时候效率比较高。 线程在等待资源时不会挂起或睡眠，而是不断循环检测锁状态（忙等待） 123456789101112#include &lt;atomic&gt;class SpinLock &#123; std::atomic_flag lock_ = ATOMIC_FLAG_INIT;public: void lock() &#123; while (lock_.test_and_set(std::memory_order_acquire)); &#125; void unlock() &#123; lock_.clear(std::memory_order_release); &#125;&#125;; 应用场景： 临界区非常短小 多核 CPU、短暂等待资源的情况 读写锁（Read-Write Lock）允许多个线程同时进行读操作，但写操作必须独占访问。 特点： 读锁共享：多个读线程并发执行 写锁独占：写线程执行时不能有其他读、写线程存在 123456789101112131415// C++17 的 shared_mutex#include &lt;shared_mutex&gt;std::shared_mutex rw_mutex;int shared_data = 0;void reader() &#123; std::shared_lock&lt;std::shared_mutex&gt; lock(rw_mutex); // 读取shared_data&#125;void writer() &#123; std::unique_lock&lt;std::shared_mutex&gt; lock(rw_mutex); shared_data++; // 写操作&#125; 应用场景：大量读、少量写的场景（如配置文件读取，缓存数据等） 递归锁（Recursive Mutex）同一线程可以多次获取同一个锁，但必须释放相同次数后才完全解锁。 特点： 避免了同一线程递归调用中因反复加锁而引起的死锁问题 相比普通锁，多了一些额外开销 1234567891011#include &lt;mutex&gt;std::recursive_mutex r_mutex;void recursive_function(int n) &#123; std::lock_guard&lt;std::recursive_mutex&gt; lock(r_mutex); if (n &gt; 0) &#123; recursive_function(n - 1); // 递归调用 &#125; // 临界区操作&#125; 应用场景：函数递归调用或函数间的相互调用都可能再次尝试获取同一锁 28. 如何用 C++ 实现一个读写锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;mutex&gt;#include &lt;condition_variable&gt;class RWLock &#123;private: std::mutex mtx_; std::condition_variable cv_; int readers_; // 正在读取的线程数量 int writers_waiting_; // 等待写入的线程数量 bool writing_; // 当前是否有写线程public: RWLock() : readers_(0), writers_waiting_(0), writing_(false) &#123;&#125; // 读锁定 void lock_read() &#123; std::unique_lock&lt;std::mutex&gt; lock(mtx_); // 当有写操作进行中或等待中的写操作时等待 cv_.wait(lock, [this]() &#123; return !writing_ &amp;&amp; writers_waiting_ == 0; &#125;); ++readers_; &#125; // 读解锁 void unlock_read() &#123; std::unique_lock&lt;std::mutex&gt; lock(mtx_); if (--readers_ == 0) &#123; cv_.notify_all(); &#125; &#125; // 写锁定 void lock_write() &#123; std::unique_lock&lt;std::mutex&gt; lock(mtx_); ++writers_waiting_; cv_.wait(lock, [this]() &#123; return !writing_ &amp;&amp; readers_ == 0; &#125;); --writers_waiting_; writing_ = true; &#125; // 写解锁 void unlock_write() &#123; std::unique_lock&lt;std::mutex&gt; lock(mtx_); writing_ = false; cv_.notify_all(); &#125;&#125;; 使用实例： 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;vector&gt;#include &lt;chrono&gt;RWLock rwlock;int shared_data = 0;void reader(int id) &#123; rwlock.lock_read(); std::cout &lt;&lt; &quot;Reader &quot; &lt;&lt; id &lt;&lt; &quot; reads value: &quot; &lt;&lt; shared_data &lt;&lt; &quot; &quot;; std::this_thread::sleep_for(std::chrono::milliseconds(100)); rwlock.unlock_read();&#125;void writer(int id) &#123; rwlock.lock_write(); ++shared_data; std::cout &lt;&lt; &quot;Writer &quot; &lt;&lt; id &lt;&lt; &quot; updated value to: &quot; &lt;&lt; shared_data &lt;&lt; &quot; &quot;; std::this_thread::sleep_for(std::chrono::milliseconds(150)); rwlock.unlock_write();&#125;int main() &#123; std::vector&lt;std::thread&gt; threads; // 启动读线程 for (int i = 0; i &lt; 5; ++i) &#123; threads.emplace_back(reader, i); &#125; // 启动写线程 for (int i = 0; i &lt; 3; ++i) &#123; threads.emplace_back(writer, i); &#125; for (auto &amp;t : threads) &#123; t.join(); &#125; return 0;&#125; 以上实现倾向于写优先（有写操作等待时，不允许新的读操作）。 可以通过修改逻辑实现读优先或公平性策略，例如： 去除 writers_waiting_ == 0 的约束实现读优先。 更复杂的公平策略则需要额外的数据结构管理等待顺序。 实际应用中，推荐使用现有的成熟实现，例如： C++17 起的标准库提供的 std::shared_mutex（标准的读写锁实现）： 12345678910111213#include &lt;shared_mutex&gt;std::shared_mutex rw_mutex;void reader() &#123; std::shared_lock lock(rw_mutex); // 读锁 // 读取数据&#125;void writer() &#123; std::unique_lock lock(rw_mutex); // 写锁 // 修改数据&#125; 29. 引用和指针的区别，是否能加 const，作用是什么？指针：存储变量的内存地址，可以为空（nullptr），需要通过解引用操作符*访问指针指向的值。指针可以在运行时重新指向不同的对象。指针可以有多级。 引用：是变量的别名，必须在初始化时绑定到一个有效的对象，且绑定后无法更改。引用不能为空，始终指向初始化时绑定的对象。引用只有一级。 const修饰： 指针：const可以修饰指针本身或指针指向的对象。 指向常量的指针：const int* ptr &#x2F; int const* ptr 表示指针指向的值是常量，不能通过该指针修改值，但可以改变指针本身的指向。 常量指针：int* const ptr表示指针本身是常量，不能改变指针的指向，但可以通过指针修改指向的值。 指向常量的常量指针：const int* const ptr表示指针本身和指针指向的值都是常量，既不能修改指针的指向，也不能修改指向的值。 引用：引用本身不能是常量，但可以引用一个常量对象。 指向常量的引用：const int&amp; ref表示引用绑定到一个常量值，不能通过该引用修改值。常量引用常用于函数参数，允许函数接受常量或非常量实参而不进行拷贝。 30. 哈希桶满了怎么办？哈希表（如 unordered_map）在插入元素后，如果负载因子（load_factor，即元素个数&#x2F;桶数量）超过阈值（通常是1.0左右），将触发扩容（rehash）： 重新分配更多的 bucket（一般是原来容量的2倍或更多）。 重新计算元素位置（rehash），将原有元素重新插入新的 bucket 中。 扩容时性能开销较大 $O(n)$。 因此，为了减少扩容次数，可以提前使用 reserve 或 rehash 提高效率。 12unordered_map&lt;int, int&gt; umap;umap.reserve(1000); // 提前预留空间，避免频繁扩容 31. AVL vs. 红黑树AVL 树（严格平衡二叉树）： 左右子树高度差绝对不能超过1。 插入删除频繁时，旋转调整成本较高（严格的平衡限制）。 查询效率略优于红黑树（更平衡），但插入删除的开销稍高。 适用于对查询操作要求极高，但修改频率较低的场景。 红黑树（弱平衡二叉树）： 平衡规则相对宽松，允许一定的高度差异。 插入删除操作旋转调整较少，综合效率更高。 广泛应用于 C++ 中的 STL map、set 等数据结构中。 更适用于插入删除较频繁的场景。 如果场景读多写少，要求非常严格的平衡，AVL 树适合。 如果场景写操作频繁，对读写整体性能要求更均衡，红黑树更合适。 32. move() 底层原理std::move() 的底层原理实际上非常简单，它本身并不真正执行移动，而是一个类型转换工具，用来将左值（lvalue）强制转换为右值引用（rvalue reference），从而允许移动语义发生。 一、源码分析（典型实现）在C++标准库中，std::move() 一般可实现为如下模板函数： 1234template &lt;typename T&gt;constexpr std::remove_reference_t&lt;T&gt;&amp;&amp; move(T&amp;&amp; arg) noexcept &#123; return static_cast&lt;std::remove_reference_t&lt;T&gt;&amp;&amp;&gt;(arg);&#125; 上述代码可以解析为： T&amp;&amp; arg：这是一个万能引用（forwarding reference），能够绑定到左值或右值。 remove_reference_t&lt;T&gt;：移除模板参数 T 可能带有的引用限定符，保证返回的确实是一个右值引用类型。 static_cast&lt;remove_reference_t&lt;T&gt;&amp;&amp;&gt;：进行强制类型转换，将传入参数从左值转换为右值引用。 二、原理分析std::move() 本身没有发生移动动作，它只是一个类型转换工具： 转换前：变量（对象）本身是左值，只能调用拷贝构造函数或拷贝赋值。 转换后：变量变为右值引用，具备调用移动构造函数或移动赋值的资格。 本质是告诉编译器：“这里的对象我不再需要了，可以放心进行资源的移动操作。” 例如： 123std::string str1 = &quot;Hello&quot;;std::string str2 = std::move(str1); // str1 的内容被“窃取”，str2 可能直接接管内部缓冲区，而非复制 三、实际的“移动”如何发生？实际的移动（资源转移）是通过被调用对象的移动构造函数或移动赋值运算符实现的，而不是通过std::move()实现： 例如，std::string 的移动构造函数的伪代码： 1234567// 移动构造函数示意string(string&amp;&amp; other) noexcept &#123; data_ = other.data_; size_ = other.size_; other.data_ = nullptr; // 原对象失去所有权 other.size_ = 0;&#125; std::move() 提供右值引用，而真正资源转移的逻辑，由类的移动构造或移动赋值完成。 四、注意事项 std::move()不会清空对象： 调用std::move()后的对象处于有效但未指定状态（valid but unspecified state），通常对象变为空或默认状态。 你可以继续赋值或析构，但不应该继续访问对象原先的资源。 移动语义要求类本身支持移动构造或移动赋值： 若类本身未定义移动构造或移动赋值，调用std::move() 仍然可能降级成拷贝。 问题 结论 std::move()本质是什么？ 类型转换函数，从左值转为右值引用 真正的移动操作在哪里发生？ 类的移动构造函数或移动赋值运算符 调用后原对象的状态？ 有效但未指定 std::move() 本身几乎没有开销，它只是一个编译期的类型转换工具，真正的开销和行为由类型本身的移动构造和赋值函数决定。 33. 可执行文件加载到内存里，其内存布局是怎样的？当可执行文件（如Linux ELF格式）加载到内存中运行时，其典型内存布局为： 从低地址到高地址顺序： 内存段 功能说明 代码段（text segment） 存放程序的机器指令（只读、可执行） 数据段（data segment） 已初始化的全局变量和静态变量 BSS段（bss segment） 未初始化或初值为零的全局变量和静态变量 堆（Heap） 动态分配的内存（由低地址向高地址增长） ↕️ （动态增长空间） 栈（Stack） 函数调用栈帧（由高地址向低地址增长） 代码段：函数指令 数据段：全局或静态变量（初值不为0） BSS段：全局或静态变量（初值为0或未初始化） 堆段：动态内存（malloc&#x2F;new） 栈段：函数调用的局部变量、调用返回地址、临时变量等 文件映射段：包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关） 34. 宏定义与函数的区别？ 宏在预处理阶段完成替换，之后被替换的文本参与编译，相当于直接插入了代码，运行时不存在函数调用，执行起来更快；函数调用在运行时需要跳转到具体调用函数。 宏定义属于在结构中插入代码，没有返回值；函数调用具有返回值。 宏定义参数没有类型，不进行类型检查；函数参数具有类型，需要检查类型。 35. 宏定义 define 与 typedef 的区别？ 宏主要用于定义常量及书写复杂的内容；typedef 主要用于定义类型别名。 宏替换发生在编译阶段之前（预处理阶段），属于文本插入替换；typedef 是编译的一部分。 宏不检查类型；typedef 会检查数据类型。 注意对指针的操作，typedef char * p_char 和 #define p_char char * 区别巨大。 36. 变量声明与定义的区别？ 声明仅仅是把变量的声明的位置及类型提供给编译器，并不分配内存空间 定义要在定义的地方为其分配存储空间 相同变量可以在多处声明（外部变量 extern），但只能在一处定义。 37. strlen 和 sizeof 的区别？ sizeof 参数可以是任何数据的类型或者数据（sizeof 参数不退化） strlen 参数只能是字符指针且结尾是’\\0’的字符串 123456int main() &#123; const char* str = &quot;Hello World&quot;; cout &lt;&lt; sizeof(str) &lt;&lt; endl; // 指针字节：8 cout &lt;&lt; strlen(str) &lt;&lt; endl; // 字符串长度(不包含&#x27;\\0&#x27;)：11 return 0;&#125; 38. final 和 override override：指定了子类的这个虚函数是重写的父类的，如果你名字不小心打错了的话，编译器是不会编译通过的 final：当某个类不希望被继承，或者某个虚函数不希望被重写，那么可以在类名和虚函数后添加 final 关键字，添加 final 关键字后被继承或重写，编译器会报错 12345678910111213141516class Base &#123; virtual void foo();&#125;; class A : public Base &#123; void foo() final; // foo 被 override 并且是最后一个 override，在其子类中不可以重写&#125;;// 指明 B 是不可以被继承的class B final : public A &#123; void foo() override; // Error: 在 A 中已经被 final 了&#125;;// Error: B is finalclass C : public B &#123;&#125;; 39. C 与 C++ 的类型安全类型安全很大程度上可以等价于内存安全，类型安全的代码不会试图访问自己没被授权的内存区域。“类型安全”常被用来形容编程语言，其根据在于该门编程语言是否提供保障类型安全的机制；有的时候也用“类型安全”形容某个程序，判别的标准在于该程序是否隐含类型错误。 类型安全的编程语言与类型安全的程序之间，没有必然联系。好的程序员可以使用类型不那么安全的语言写出类型相当安全的程序，相反的，差一点儿的程序员可能使用类型相当安全的语言写出类型不太安全的程序。绝对类型安全的编程语言暂时还没有。 C 的类型安全C 只在局部上下文中表现出类型安全，比如试图从一种结构体的指针转换成另一种结构体的指针时，编译器将会报告错误，除非使用显式类型转换。然而，C 中相当多的操作是不安全的。以下是两个十分常见的例子： 1️⃣ printf 格式输出：下述代码中，使用 %d 控制整型数字的输出，没有问题，但是改成 %f 时，明显输出错误，再改成 %s 时，运行直接报 segmentation fault 错误 123456#include &lt;stdio.h&gt;int main() &#123; printf(&quot;%d &quot;, 10); // 10 printf(&quot;%f &quot;, 10); // 0.00 return 0;&#125; 2️⃣ malloc 函数返回值：malloc 是 C 中进行内存分配的函数，它的返回类型是 void* 即空类型指针，常常有这样的用法 char* pStr = (char*)malloc(100 * sizeof(char))，这里明显做了显式的类型转换。类型匹配尚且没有问题，但是一旦出现 int* pInt = (int*)malloc(100 * sizeof(char)) 就很可能带来一些问题，而这样的转换 C 并不会提示错误。 C++ 类型安全如果 C++ 使用得当，它将远比 C 更有类型安全性。相比于 C 语言，C++ 提供了一些新的机制保障类型安全： 操作符 new 返回的指针类型严格与对象匹配，而不是 void* C 中很多以 void* 为参数的函数可以改写为 C++ 模板函数，而模板是支持类型检查的 引入 const 关键字代替 #define constants，它是有类型、有作用域的，而 #define constants 只是简单的文本替换 一些 #define 宏可被改写为 inline 函数，结合函数的重载，可在类型安全的前提下支持多种类型，当然改写为模板也能保证类型安全 C++ 提供了 dynamic_cast 关键字，使得转换过程更加安全，因为 dynamic_cast 比 static_cast 涉及更多具体的类型检查 40. 内联函数 inline 和宏定义 define 的区别？ 在使用时，宏只做简单字符串替换（预处理，即编译前）；而内联函数可以进行参数类型检查（编译时），且具有返回值 内联函数在编译时直接将函数代码嵌入到目标代码中，省去函数调用的开销来提高执行效率，并且进行参数类型检查，具有返回值，可以实现重载 宏定义时要注意书写（参数要括起来）否则容易出现歧义，内联函数不会产生歧义 内联函数有类型检测、语法判断等功能，而宏没有 内联函数适用场景: 使用宏定义的地方都可以使用 inline 函数 作为类成员接口函数来读写类的私有成员或者保护成员，会提高效率 41. 什么是大小端存储，以及如何用代码判断大小端？大端存储：字数据的高字节存储在低地址中 小端存储：字数据的低字节存储在低地址中 例如：32bit 的数字 0x12345678 所以在 Socket 编程中，往往需要将操作系统所用的小端存储的 IP 地址转换为大端存储，这样才能进行网络传输 小端模式中的存储方式为 大端模式中的存储方式为 了解了大小端存储的方式，如何在代码中进行判断呢？ 123456789101112#include &lt;iostream&gt;using namespace std;int main()&#123; int a = 0x1234; //由于 int 和 char 的长度不同，借助 int 型转换成 char 型，只会留下低地址的部分 char c = (char)(a); if (c == 0x12) cout &lt;&lt; &quot;big endian&quot; &lt;&lt; endl; else if(c == 0x34) cout &lt;&lt; &quot;little endian&quot; &lt;&lt; endl;&#125; 42. C++ 中有几种类型的 new？(1) plain new言下之意就是普通的new，就是我们常用的new，在C++中定义如下： 12void* operator new(std::size_t) throw(std::bad_alloc);void operator delete(void *) throw(); 因此 plain new 在空间分配失败的情况下，抛出异常 std::bad_alloc 而不是返回 NULL，因此通过判断返回值是否为 NULL 是徒劳的。 (2) nothrow newnothrow new 在空间分配失败的情况下是不抛出异常，而是返回 NULL，定义如下： 12void * operator new(std::size_t, const std::nothrow_t&amp;) throw();void operator delete(void*) throw(); (3) placement new 字节校招问题：placement new 是什么？ 一般来说，使用 new 申请空间时，是从系统的“堆”中分配空间。申请所得的空间的位置是根据当时的内存的实际使用情况决定的。但是，在某些特殊情况下，可能需要在已分配的特定内存创建对象，这就是所谓的 “定位放置 new” （placement new）操作。 定位放置 new 操作的语法形式不同于普通的 new 操作。例如，一般都用如下语句 A* p = new A; 申请空间，而 placement new 操作则使用如下语句 A* p = new (ptr)A; 申请空间，其中 ptr 就是程序员指定的内存首地址。 用定位放置 new 操作，既可以在栈（stack）上生成对象，也可以在堆（heap）上生成对象，如本例就是在栈上生成一个对象。 优势：复用已有内存空间； 场景题：如果有这样一个场景，我们需要大量的申请一块类似的内存空间，然后又释放掉，比如在一个 Server 中对于客户端的请求，每个客户端的每一次上行数据我们都需要为此申请一块内存，当我们处理完请求给客户端下行回复时释放掉该内存，表面上看者符合 C++ 的内存管理要求，没有什么错误，但是仔细想想很不合理，为什么我们每个请求都要重新申请一块内存呢，要知道每一次内存的申请，系统都要在内存中找到一块合适大小的连续的内存空间，这个过程是很慢的（相对而言)，极端情况下，如果当前系统中有大量的内存碎片，并且我们申请的空间很大，甚至有可能失败。为什么我们不能共用一块我们事先准备好的内存呢？可以的，我们可以使用 placement new 来构造对象，那么就会在我们指定的内存空间中构造对象。 这种 new 允许在一块已经分配成功的内存上重新构造对象或对象数组。placement new 不用担心内存分配失败，因为它根本不分配内存，它做的唯一一件事情就是调用对象的构造函数。定义如下： 12void* operator new(size_t, void*);void operator delete(void*, void*); 使用 placement new 需要注意两点： palcement new 的主要用途就是反复使用一块较大的动态分配的内存来构造不同类型的对象或者他们的数组 placement new 构造起来的对象数组，要显式的调用他们的析构函数来销毁（析构函数并不释放对象的内存），千万不要使用 delete，这是因为 placement new 构造起来的对象或数组大小并不一定等于原来分配的内存大小，使用 delete 会造成内存泄漏或者之后释放内存时出现运行时错误 1234567891011121314151617181920212223242526272829303132#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;class ADT &#123; int i; int j;public: ADT() &#123; i = 10; j = 100; cout &lt;&lt; &quot;ADT construct i=&quot; &lt;&lt; i &lt;&lt; &quot; j=&quot;&lt;&lt;j &lt;&lt;endl; &#125; ~ADT() &#123; cout &lt;&lt; &quot;ADT destruct&quot; &lt;&lt; endl; &#125;&#125;;int main() &#123; char *p = new(nothrow) char[sizeof ADT + 1]; if (p == NULL) &#123; cout &lt;&lt; &quot;alloc failed&quot; &lt;&lt; endl; &#125; ADT *q = new(p) ADT; //placement new:不必担心失败，只要p所指对象的的空间足够ADT创建即可 //delete q;//错误!不能在此处调用delete q; q-&gt;ADT::~ADT();//显示调用析构函数 delete[] p; return 0;&#125;//ADT construct i=10 j=100//ADT destruct 43. C++ 11 新特性有哪些？ 自动类型推导（auto 关键字）：编译器可根据变量初始化表达式自动推导其类型，简化代码编写。 decltype 关键字：用于获取表达式的类型，常与 auto 结合使用，以推导复杂类型。 右值引用和移动语义、move 函数：通过右值引用（&amp;&amp;）支持移动构造和移动赋值，提高资源管理和程序性能。 初始化列表：引入统一的列表初始化语法，允许使用花括号对变量进行初始化，增强初始化的灵活性和可读性。 nullptr 关键字：引入新的空指针常量，替代原有的 NULL，提高类型安全性。 强类型枚举（enum class）：提供作用域限定的枚举类型，避免与其他标识符冲突，并增强类型安全性。 constexpr 关键字：允许在编译期计算常量表达式，提高程序效率。 Lambda 表达式：支持匿名函数，方便定义内联的回调或操作，简化代码结构。 范围 for 循环：引入基于范围的 for 循环，简化对容器或数组的遍历操作。 智能指针：新增 std::unique_ptr 和改进的 std::shared_ptr，提供安全的资源管理机制，减少内存泄漏风险。 线程支持库：标准库中加入多线程支持，包括线程管理、互斥量、条件变量等，方便进行并发编程。 std::tuple：提供固定大小的多元组，允许存储多个不同类型的值，增强数据结构的表达能力。 正则表达式库：标准库新增正则表达式支持，方便进行字符串匹配和处理。 std::array：提供固定大小的数组封装，结合了数组的性能和容器的功能性。 std::unordered_map 和 std::unordered_set：新增无序关联容器，基于哈希表实现，提供平均常数时间的查找和插入性能。 std::chrono 时间库：引入时间处理库，提供时钟、时间点、时间间隔等功能，方便进行时间相关的操作。 static_assert：在编译期进行断言检查，确保代码满足特定条件，提高代码的可靠性。 std::function 和 std::bind：提供通用的函数包装器和绑定器，支持函数对象、成员函数和自由函数的统一调用。 用户定义字面量：允许为标准类型和自定义类型定义字面量后缀，增强代码的可读性和表达能力。 alignas 和 alignof 关键字：提供对齐控制和查询功能，确保数据在内存中的对齐方式符合特定要求。 explicit 关键字：体现显示转换和隐式转换上的概念要求 std::atomic&lt;T&gt; 是 C++11 引入的原子类型，用于在多线程中安全地读写变量 还有虚函数 override、容器非成员函数 swap、新的 bitset 位运算… 44. C++ class 与 C struct 的区别？ C 语言不支持继承和多态 1️⃣ 默认访问权限不同 C struct 默认权限为 public C++ class 默认权限为 private C++ struct 默认权限 public 2️⃣ 成员函数 C++ 中的 struct 和 class 都可包含成员函数 C 中的 struct 只能包含数据，不能包含成员函数 C++ 的 class 与 struct 都支持模板、虚函数、多态、构造函数、析构函数、重载操作符等高级特性，这些都是 C 中 struct 不具备的功能。 以上谈论的是 C struct 和 C++ class 的区别，接下来聊一聊 C++ struct 和 C++ class 的区别。 在 C++ 中，class 和 struct 的功能几乎是等价的（除了默认访问权限不同），继承时： struct 的继承默认是 public 继承 class 的继承默认是 private 继承 通常情况下，如果类主要用于表示数据结构，不需要封装和访问控制，且所有成员均为 public，则常用 struct；如果强调封装、访问控制，需要私有或受保护成员时，则倾向于用 class。 45. 怎么优化系统性能 合理使用缓存机制，如内存缓存、Redis 等 利用多线程或多进程技术，让更多的处理器核心参与计算，提升吞吐量 选择高效的算法和数据结构可以显著提升系统性能 编写高质量的代码，避免冗余计算，减少函数调用和内存分配，合理使用同步和异步操作 采用集群等高可用架构，避免单点故障，确保系统在高负载下仍能稳定运行 负载均衡，通过将请求分配到多台服务器上，避免单一服务器的性能瓶颈 使用消息队列实现高并发下的异步处理，削峰填谷，缓解系统压力 perf 工具查看系统性能瓶颈 开启编译优化 -O2、-O3 以下展开介绍几个主要的优化点。 内存管理优化减少内存分配与释放次数： 频繁的堆内存分配和释放会严重拖慢程序，甚至导致内存碎片。应尽量重用对象、使用内存池等技术来降低分配开销。例如，在 C++ 中可以实现对象池，预先分配一定数量的对象，在需要时复用它们而不是每次 new 和 delete。对于生命周期较短且数量巨大的对象，尽可能分配在栈上而非堆上，因为栈上的分配&#x2F;回收开销远小于堆（注意栈有大小限制，过大的对象还是要放在堆上）。在 Java&#x2F;Python 等有垃圾回收的语言中，无法手动管理内存，但可以通过减少不必要的临时对象创建来减轻 GC 压力。 避免不必要的数据拷贝：数据拷贝不仅耗费 CPU 时间，还增加内存占用。在C&#x2F;C++中，尽量通过指针、引用传递大对象，或使用移动语义（std::move）来避免昂贵的深拷贝。例如，将函数参数改为 const std::vector&lt;T&gt;&amp; 引用而不是传值，可以省去一遍拷贝的成本。 提高内存访问局部性： 尽量使用连续内存的数据结构，有利于 CPU 缓存命中率。例如，相比链表，数组或动态数组（如 std::vector）在遍历时连续访问内存，对缓存更友好。访问内存时，如果数据分散，CPU缓存无法有效预取，性能会下降。因此，应尽量使常用的数据在内存中连续存放。对于需要处理大批量数据的场景，可以考虑将“数组的结构”转变为“结构的数组”以提高向量化和缓存性能。这种优化在需要对大量对象的某个字段进行批量操作时特别有效，因为连续的内存布局可以充分利用 SIMD 指令和缓存行。 控制内存使用与回收： 注意避免内存泄漏和不必要的内存占用。未释放的内存不仅浪费资源，还可能导致系统频繁进行垃圾回收或交换，从而严重影响性能。应使用恰当的数据结构来节省内存，例如在需要存储大量布尔值时使用位图&#x2F;位集而不是布尔数组。 I&#x2F;O 优化尽量减少 I&#x2F;O 调用次数： 外部I&#x2F;O（磁盘读写、网络通信）往往比内存操作慢几个数量级。优化I&#x2F;O的一个基本原则是减少系统调用频次。例如，与其逐字节写入文件，不如积累一定数据后一次写入（批处理）；读文件时尽量使用批量读取或流式读取来降低调用开销。将零散的小I&#x2F;O操作合并为较少的几次大操作，可以大幅降低每次调用的固定成本，提高总体吞吐量。 使用缓冲和缓存： 缓冲是在内存中暂存数据，凑够一定量再进行 I&#x2F;O 缓存则是将经常访问的数据暂存内存，以避免重复从慢速存储获取 异步和并行 I&#x2F;O： 传统同步I&#x2F;O会阻塞执行线程，等待操作完成。通过异步 I&#x2F;O，程序可以在等待I&#x2F;O的同时去处理其他任务，从而提高整体效率和响应性。另外，对于磁盘 I&#x2F;O 密集型任务，合理利用操作系统的内存映射文件（mmap）也能提升效率，因为操作系统会自动预读和缓存文件内容，且内存映射减少了用户态&#x2F;内核态的数据拷贝。 性能分析与瓶颈定位在展开具体优化工作之前，识别性能瓶颈是关键的一步。盲目优化往往事倍功半，甚至优化了非瓶颈部分而徒增代码复杂度。因此建议利用各种分析工具（Profiler）来定位程序中的“热区”和问题点。 CPU Profiling：常用 GNU gprof 工具对应用程序进行采样分析，生成函数级别的耗时报告。在Linux上可以使用 perf 工具对程序采集更底层的性能数据（如CPU周期、缓存未命中等）。跨平台的工具如 Intel VTune, AMD uProf 提供更高级的性能分析（包括线程并发、微架构瓶颈）。另外，Valgrind 的 Callgrind 模块也能分析代码热点和调用关系，并可借助KCachegrind等可视化工具查看分析结果。 内存和资源分析：使用 Valgrind 的 Memcheck 工具可以检测内存泄漏和非法内存访问，这有助于消除由于内存问题导致的异常行为和性能下降。Massif 是 Valgrind 的堆分析器，可以跟踪程序堆内存使用随时间的变化，找出高峰时占用大的代码路径。对于更复杂的内存分析，可以借助 Google Perf Tools（gperftools）中的 heap profiler 或 Dr. Memory 等工具。在需要分析缓存行为时，Valgrind 的 Cachegrind 模块可以模拟CPU缓存，报告缓存命中率，帮助调整数据结构以提高缓存友好度。 46. 说说移动构造函数与拷贝构造函数 我们用对象 a 初始化对象 b，之后对象 a 我们就不再使用了，但是对象 a 的空间还在（在析构之前），既然拷贝构造函数实际上就是把 a 对象的内容复制一份到 b 中，那么为什么我们不能直接使用 a 的空间呢？这样就避免了新的空间的分配，大大降低了构造的成本。这就是移动构造函数设计的初衷。 ‼️拷贝构造函数中，对于指针，我们一定要采用深拷贝；而移动构造函数中，对于指针，我们采用浅拷贝。 移动构造函数的参数 &amp;&amp; 和拷贝构造函数 &amp; 不同：拷贝构造函数的参数是一个左值引用，但是移动构造函数的初值是一个右值引用。意味着，移动构造函数的参数是一个右值或者将亡值的引用。也就是说，只用一个右值或者将亡值初始化另一个对象的时候，才会调用移动构造函数。而那个 move() 语句，就是将一个左值变成一个将亡值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;iostream&gt;#include &lt;string&gt;class MyString &#123;public: // 构造函数 MyString() : str(nullptr), len(0) &#123;&#125; // 构造函数 MyString(const char* s) : str(nullptr), len(0) &#123; if (s != nullptr) &#123; len = strlen(s); str = new char[len + 1]; strcpy(str, s); &#125; &#125; // 拷贝构造函数: 有指针则采用深拷贝 MyString(const MyString&amp; other) : str(nullptr), len(0) &#123; if (other.str != nullptr) &#123; len = other.len; str = new char[len + 1]; strcpy(str, other.str); &#125; &#125; // 移动构造函数: 采用浅拷贝 MyString(MyString&amp;&amp; other) noexcept &#123; str = other.str; len = other.len; other.str = nullptr; other.len = 0; &#125; // 析构函数 ~MyString() &#123; if (str != nullptr) &#123; delete[] str; str = nullptr; len = 0; &#125; &#125;private: char* str; size_t len;&#125;;int main() &#123; MyString s1(&quot;Hello&quot;); // 调用构造函数 MyString s2(s1); // 调用拷贝构造函数 MyString s3(std::move(s1)); // 调用移动构造函数 return 0;&#125; 47. C++ 中指针参数传递和引用参数传递有什么区别？底层原理是什么？ 恍然大悟 (1) 指针参数传递本质上是值传递，它所传递的是一个地址值值传递过程中，被调函数的形式参数作为被调函数的局部变量处理，会在栈中开辟内存空间以存放由主调函数传递进来的实参值，从而形成了实参的一个副本（替身）。 值传递的特点是，被调函数对形式参数的任何操作都是作为局部变量进行的，不会影响主调函数的实参变量的值（即使是形参指针地址变了，实参指针地址都不会变）。 123456789101112131415161718#include &lt;iostream&gt;using namespace std;void changePointer(int* ptr) &#123; int b = 20; ptr = &amp;b; // 仅改变了形参指针的指向，实参指针不变&#125;int main() &#123; int a = 10; int* p = &amp;a; cout &lt;&lt; &quot;Before function call: &quot; &lt;&lt; *p &lt;&lt; endl; // 输出 10 changePointer(p); cout &lt;&lt; &quot;After function call: &quot; &lt;&lt; *p &lt;&lt; endl; // 仍然输出 10，不是 20 return 0;&#125; (2) 引用参数传递过程中，被调函数的形式参数也作为局部变量在栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址被调函数对形参（本体）的任何操作都被处理成间接寻址，即通过栈中存放的地址访问主调函数中的实参变量（根据别名找到主调函数中的本体）。 因此，被调函数对形参的任何操作都会影响主调函数中的实参变量。 二者区别1) 引用传递和指针传递是不同的，虽然他们都是在被调函数栈空间上的一个局部变量： 但是任何对于引用参数的处理都会通过一个间接寻址的方式操作到主调函数中的相关变量。 而对于指针传递的参数，如果改变被调函数中的指针地址，它将应用不到主调函数的相关变量。🔥 如果想通过指针参数传递来改变主调函数中的相关变量（地址），那就得使用指向指针的指针或者指针引用。 2) 从编译的角度来讲，程序在编译时分别将指针和引用添加到符号表上，符号表中记录的是变量名及变量所对应地址。 指针变量在符号表上对应的地址值为指针变量的地址值，而引用在符号表上对应的地址值为引用对象的地址值（与实参名字不同，地址相同）。 符号表生成之后就不会再改，因此指针可以改变其指向的对象（指针变量中的值可以改），而引用对象则不能修改。 48. C++ 中类成员的访问权限和继承权限问题访问权限① public: 用该关键字修饰的成员表示公有成员，该成员不仅可以在类内可以被访问，在类外也是可以被访问的，是类对外提供的可访问接口； ② private: 用该关键字修饰的成员表示私有成员，该成员仅在类内可以被访问，在类体外是隐藏状态； ③ protected: 用该关键字修饰的成员表示保护成员，保护成员在类体外同样是隐藏状态，但是对于该类的派生类来说，相当于公有成员，在派生类中可以被访问。 继承方式① 若继承方式是 public，基类成员在派生类中的访问权限保持不变，也就是说，基类中的成员访问权限，在派生类中仍然保持原来的访问权限； ② 若继承方式是 private，基类所有成员在派生类中的访问权限都会变为私有 (private) 权限； ③ 若继承方式是 protected，基类的共有成员 public 和保护成员 protected 在派生类中的访问权限都会变为保护 (protected) 权限，私有成员在派生类中的访问权限仍然是私有 (private) 权限。 49. 定义与声明的区别如果是指「变量」的声明和定义： 从编译原理上来说，声明是仅仅告诉编译器，有个某类型的变量会被使用，但是编译器并不会为它分配任何内存。 而定义就是分配了内存。 如果是指「函数」的声明和定义： 声明：一般在头文件里，对编译器说我有一个函数叫 function() 让编译器知道这个函数的存在。 定义：一般在源文件里，具体就是函数的实现过程写明函数体。 50. 你知道 strcpy 与 memcpy 的区别吗1、复制的内容不同： strcpy 只能复制字符串 而 memcpy 可以复制任意内容，例如字符数组、整型、结构体、类等 2、复制的方法不同： strcpy 不需要指定长度，它遇到被复制字符的串结束符 &quot;\\0&quot; 才结束，所以容易溢出 memcpy 则是根据其第 3 个参数决定复制的长度。 3、用途不同： 通常在复制字符串时用 strcpy 而需要复制其他类型数据时则一般用 memcpy 51. volatile 关键字的作用面试回答volatile 的意思是“脆弱的”，表明它修饰的变量的值十分容易被改变，所以编译器就不会对这个变量进行优化（CPU 的优化是让该变量存放到 CPU 寄存器而不是内存），进而提供稳定的访问。每次读取 volatile 的变量时，系统总是会从内存中读取这个变量，并且将它的值立刻保存。 解释C&#x2F;C++ 中的 volatile 关键字和 const 对应，用来修饰变量，通常用于建立语言级别的 memory barrier。 volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素更改，比如：操作系统、硬件或者其它线程等。遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问。声明时语法：int volatile vInt; 当要求使用 volatile 声明的变量的值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。而且读取的数据立刻被保存。 123456789101112131415#include &lt;stdio.h&gt; void main()&#123; volatile int i = 10; int a = i; printf(&quot;i = %d&quot;, a); __asm &#123; mov dword ptr [ebp-4], 20h &#125; int b = i; printf(&quot;i = %d&quot;, b);&#125; 12i = 10i = 32 // 如果没有 volatile 关键字修饰则该值为 10 ✅ volatile 用在如下的几个地方： 中断服务程序中修改的供其它程序检测的变量需要加 volatile。 多任务环境下各任务间共享的标志应该加 volatile：当两个线程都要用到某一个变量且该变量的值会被改变时，应该用 volatile 声明，该关键字的作用是防止优化编译器把变量从内存装入 CPU 寄存器中。如果变量被装入寄存器，那么两个线程有可能一个使用内存中的变量，一个使用寄存器中的变量，这会造成程序的错误执行。volatile 的意思是让编译器每次操作该变量时一定要从内存中真正取出，而不是使用已经存在寄存器中的值。 存储器映射的硬件寄存器通常也要加 volatile 说明，因为每次对它的读写都可能有不同意义。 52. 如果有一个空类，它会默认存在哪些函数？1234Empty(); // 缺省构造函数 //Empty( const Empty&amp; ); // 拷贝构造函数 //~Empty(); // 析构函数 //Empty&amp; operator=( const Empty&amp; ); // 赋值运算符 // 53. const char* 与 string 之间的区别string 是 C++ 标准库里面其中一个，封装了对字符串的操作，实际操作过程我们可以用 const char* 给 string 类初始化。 三者之间的转化关系如下： 123456789101112131415161718192021222324252627// 1. string 转 const char*string s = “abc”;const char* c_s = s.c_str();// 2. const char* 转 string, 直接赋值即可const char* c_s = “abc”;string s(c_s);// 3. string 转 char* string s = “abc”;const int len = s.length();char* c;c = new char[len + 1];strcpy(c, s.c_str());// 4. char* 转 string, 直接赋值即可char* c = “abc”;string s(c);// 5. const char* 转 char*const char* cpc = “abc”;char* pc = new char[strlen(cpc) + 1];strcpy(pc, cpc);// 6. char* 转 const char*, 直接赋值即可char* pc = “abc”;const char* cpc = pc; 54. static_cast 比 C 语言中的转换好在哪里？ 更加安全； 更直接明显，能够一眼看出是什么类型转换为什么类型，容易找出程序中的错误；可清楚地辨别代码中每个显式的强制转；可读性更好，能体现程序员的意图。 55. delete 和 delete[] 区别？ delete 只会调用一次析构函数。 delete[] 会调用数组中每个元素的析构函数。 56. 为什么不把所有函数写成内联函数？内联函数以代码复杂为代价，它以省去函数调用的开销来提高执行效率。所以一方面如果内联函数体内代码执行时间相比函数调用开销较大，则没有太大的意义；另一方面每一处内联函数的调用都要复制代码，消耗更多的内存空间，因此以下情况不宜使用内联函数： 函数体内的代码比较长，将导致内存消耗代价 函数体内有循环，函数执行时间要比函数调用开销大 57. 哪些函数不能是虚函数？ 构造函数：构造函数初始化对象，派生类必须知道基类函数干了什么，才能进行构造；当有虚函数时，每一个类有一个虚表，每一个对象有一个虚表指针，虚表指针在构造函数中初始化。 内联函数：内联函数表示在编译阶段进行函数体的替换操作，而虚函数意味着在运行期间进行类型确定，所以内联函数不能是虚函数。 静态函数：静态函数不属于对象属于类，静态成员函数没有 this 指针，因此静态函数设置为虚函数没有任何意义。 友元函数：友元函数不属于类的成员函数，不能被继承。对于没有继承特性的函数没有虚函数的说法。 普通函数：普通函数不属于类的成员函数，不具有继承特性，因此普通函数没有虚函数。 58. 什么原因造成内存泄露，你怎么避免&#x2F;解决内存泄露？1️⃣ 什么是内存泄露？在程序运行过程中不再使用的对象没有被正确释放，从而导致程序使用的内存不断增加，最终导致程序异常退出或内存分配失败。 2️⃣ 什么原因造成内存泄露？ 忘记释放内存：分配了内存但没有释放 异常 &#x2F; 逻辑处理不当：写了内存释放代码，但最后未执行到 循环引用：使用智能指针 shared_ptr 造成内存泄露 3️⃣ 如何避免&#x2F;解决内存泄露 ‼️ 内存泄露一般是因为分配了内存但没有释放，要解决这个问题，我通常从以下几个层面入手： 我会用 RAII 机制管理资源（构造时分配，析构时释放） 能用智能指针（unique_ptr, shared_ptr）的地方绝不手动 new&#x2F;delete，同时要注意避免循环引用（使用弱引用） 对于资源管理比较复杂的类，我会写好析构函数，并考虑拷贝&#x2F;移动语义，防止资源重复释放或泄露 正确捕获处理异常 &#x2F; 回滚式编程：编写异常安全的代码非常困难 解决内存泄露本质上就是：该释放的要释放，生命周期清楚，用好工具，写好代码。我平时更倾向于用智能指针来管理资源，基本上能从根上避免大部分内存泄露问题。 4️⃣ 如何定位内存泄露 🔗参考链接： Linux内存泄露定位1：valgrind篇 Linux内存泄露定位2：mtrace篇 Linux内存泄露定位3：hook+backtrace篇 Linux内存泄露定位4：eBPF+uprobes篇 静态检测工具：检查代码中是否出现内存泄露， cppcheck clang-tidy valgrind 需要调试信息 -g valgrind --leak-check=full 可执行程序 可视 valgrind 为虚拟机，将可执行程序当作文件来处理，读取二进制文件的内容，进行指令解析并执行 hook + backtrace：侵入式（可能会引起程序异常） hook 住内存分配和释放接口 每次申请内存都记录一下，每次释放时也记录一下，然后再把这两种记录进行一个对比，把相同的去掉，剩下就是 eBPF + uprobes：非侵入式（内核中进行统计，不会影响程序） 不需要调试信息 原理与上一种相同，但是不是侵入式，运行在内核 59. C++ 写了析构函数，系统会帮我们生成默认移动构造函数这些吗（介绍 C++ 六个特殊成员函数）写了析构函数，系统可能不再自动生成“移动构造”和“移动赋值”函数了，但拷贝构造和拷贝赋值通常还是会生成的。 在 C++ 里，有六个所谓的“特殊成员函数”： 默认构造函数 MyClass() 析构函数 ~MyClass() 拷贝构造函数 MyClass(const MyClass&amp; other) 拷贝赋值函数 MyClass&amp; operator=(const MyClass&amp; other) 移动构造函数（C++11 起）MyClass(MyClass&amp;&amp; other) noexcept 移动赋值函数（C++11 起）MyClass&amp; operator=(MyClass&amp;&amp; other) noexcept 如果你自己写了一个析构函数，那编译器就认为你要自己管理资源了。所以出于安全考虑，它不会再自动生成移动构造函数和移动赋值函数了，你得自己写，或者用 = default 显式声明。 12MyClass(MyClass&amp;&amp;) = default;MyClass&amp; operator=(MyClass&amp;&amp;) = default; 60. C++ 右值引用和移动拷贝(赋值)函数的作用右值引用和移动语义是在 C++11 之后引入的，目的是优化性能，避免不必要的资源拷贝。 以前在 C++98 里，如果你把一个对象传给另一个对象，哪怕那个对象马上就要销毁了，编译器也只能做拷贝，哪怕里面的数据非常大，比如堆上几百 MB 的数组，也得老老实实拷贝一份，非常浪费性能。 而右值引用的出现，让编译器能识别出“这是一个临时对象”，你可以放心地把它的资源“抢过来”用，而不是复制一份。 移动构造函数 MyClass(MyClass&amp;&amp; a) noexcept 和移动赋值操作符 MyClass&amp; operator=(MyClass&amp;&amp; a) noexcept 的作用就是： 移动构造：当一个临时对象要变成另一个对象时，直接“接管”它的内部资源，比如把指针地址拿过来，然后把原对象的指针清空，这样就不需要重新分配和复制内存。 移动赋值：和移动构造类似，不过是用于对象已经存在的情况下，把另一个临时对象的资源拿过来，原来的资源先释放，然后再接管。 61. C++ 线程 thread_local 的作用是什么？ 它是线程单独拥有的资源，没办法作为共享资源 thread_local 是 C++11 引入的存储类型说明符，用于为每个线程创建独立的变量副本。 使用场景： 每个线程都需要使用一个自己的变量（如缓存、计数器等），避免同步。 类似于线程的“全局变量”，但互不干扰。 示例： 1thread_local int counter = 0; ✅ 示例场景：日志系统中用 thread_local 缓存上下文 在多线程程序中，很多系统会给每个线程维护一份独立的日志信息，比如线程 ID、调用栈、临时日志缓存等。如果所有线程都用一个共享变量，会导致锁竞争、效率低下。 这时候就可以用 thread_local 给每个线程一份独立副本！ 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;string&gt;class Logger &#123;public: static void log(const std::string&amp; message) &#123; log_context += message + &quot; &quot;; &#125; static void flush() &#123; std::cout &lt;&lt; &quot;[Thread &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot;] &quot;; std::cout &lt;&lt; log_context &lt;&lt; std::endl; log_context.clear(); &#125;private: static thread_local std::string log_context; // 每个线程一份&#125;;thread_local std::string Logger::log_context;void thread_task(int id) &#123; Logger::log(&quot;Start work in thread &quot; + std::to_string(id)); Logger::log(&quot;Doing some work...&quot;); Logger::log(&quot;Finish work in thread &quot; + std::to_string(id)); Logger::flush();&#125;int main() &#123; std::thread t1(thread_task, 1); std::thread t2(thread_task, 2); t1.join(); t2.join(); return 0;&#125; 62. 如何定义一个只能在堆上（栈上）生成对象的类？只能在堆上方法：将析构函数设置为私有 原因：C++ 是静态绑定语言，编译器管理栈上对象的生命周期，编译器在为类对象分配栈空间时，会先检查类的析构函数的访问性。若析构函数不可访问，则不能在栈上创建对象。 只能在栈上方法：将 new 和 delete 重载为私有 原因：在堆上生成对象，使用 new 关键词操作，其过程分为两阶段：第一阶段，使用 new 在堆上寻找可用内存，分配给对象；第二阶段，调用构造函数生成对象。将 new 操作设置为私有，那么第一阶段就无法完成，就不能够在堆上生成对象。 63. 递归过深会造成什么问题，OOM 吗？递归过深确实可能引发一些严重问题，但不一定是 OOM（Out of Memory）。更常见的问题是栈溢出（Stack Overflow）。 ✅ 栈溢出（Stack Overflow） 每次函数调用都会在调用栈上分配一块内存来保存函数的执行上下文（如局部变量、返回地址等）。 如果递归层级太深，调用栈不断增长，最终会超过系统分配给程序的栈空间上限（跟默认「线程栈」大小相关）。 此时程序会抛出 StackOverflowError（Java） 或 Segmentation Fault（C&#x2F;C++），或者 RecursionError（Python）。 ❌ 而不是 OOM（Out of Memory） OOM 通常是指 堆内存 耗尽，例如大量创建对象、数组或内存泄漏。 除非每层递归都分配了大量堆内存（比如在每层递归里 new 很大的对象），否则递归本身并不会直接造成 OOM。 递归过深导致的栈溢出，和线程的栈大小直接相关：每个线程在启动时，操作系统会为它分配一块固定大小的栈内存（线程栈），专门用于保存函数调用帧，如果递归太深，每层调用都占用一点栈空间，栈就会被用完，最终导致栈溢出。线程栈大小是有限的，不同语言&#x2F;平台有不同的默认值如下： Java 一般是 1MB（可通过 -Xss 参数设置） Linux 上的原生线程（如 pthread）默认栈大小通常是 8MB Python 受限于解释器的默认递归深度（sys.getrecursionlimit()） 64. 如何获取前 K 个最大元素？这个问题是数据结构与算法中的经典题目之一，常用于考察排序、堆、优先队列的应用。以下是几种常见的解法及其时间复杂度分析： 解法一：排序法（适合数据量不大）思路： 直接对数组进行排序 取前 K 个元素 1234567#include &lt;vector&gt;#include &lt;algorithm&gt;std::vector&lt;int&gt; topKSort(std::vector&lt;int&gt;&amp; nums, int k) &#123; std::sort(nums.begin(), nums.end(), std::greater&lt;int&gt;()); return std::vector&lt;int&gt;(nums.begin(), nums.begin() + k);&#125; 时间复杂度： 排序时间复杂度：O(n log n) 空间复杂度：O(1) 解法二：最小堆（推荐，适合大数据）思路： 使用大小为 K 的最小堆来保存当前最大的 K 个元素 遍历整个数组，若当前元素比堆顶大，则替换堆顶 123456789101112131415161718192021222324252627#include &lt;vector&gt;#include &lt;queue&gt;std::vector&lt;int&gt; topKHeap(const std::vector&lt;int&gt;&amp; nums, int k) &#123; if (k == 0) return &#123;&#125;; std::priority_queue&lt;int, std::vector&lt;int&gt;, std::greater&lt;int&gt;&gt; minHeap; for (int num : nums) &#123; if (minHeap.size() &lt; k) &#123; minHeap.push(num); &#125; else if (num &gt; minHeap.top()) &#123; minHeap.pop(); minHeap.push(num); &#125; &#125; std::vector&lt;int&gt; result; while (!minHeap.empty()) &#123; result.push_back(minHeap.top()); minHeap.pop(); &#125; std::sort(result.rbegin(), result.rend()); // 可选：从大到小排序 return result;&#125; 时间复杂度： 时间复杂度：O(n log k) 构建堆：O(k) 遍历其余 $n - k$ 个元素，每次 O(log k)：总共 O((n-k) log k) 空间复杂度：O(k) 🔥 解法三：快排的思想（Top-K 问题，适合不要求完整排序）思路： 类似快速排序中的分区（partition），选定一个“枢轴”，将大于 pivot 的放左边，小于的放右边 不断递归，直到找到第 K 个最大的数为止 12345678910111213141516171819202122232425262728293031#include &lt;vector&gt;#include &lt;cstdlib&gt; // for rand()int partition(std::vector&lt;int&gt;&amp; nums, int left, int right) &#123; int pivot = nums[right], i = left; for (int j = left; j &lt; right; ++j) &#123; if (nums[j] &gt;= pivot) &#123; std::swap(nums[i], nums[j]); ++i; &#125; &#125; std::swap(nums[i], nums[right]); return i;&#125;void quickSelect(std::vector&lt;int&gt;&amp; nums, int left, int right, int k) &#123; if (left &gt;= right) return; int pivotIndex = partition(nums, left, right); if (pivotIndex == k) return; else if (pivotIndex &lt; k) quickSelect(nums, pivotIndex + 1, right, k); else quickSelect(nums, left, pivotIndex - 1, k);&#125;std::vector&lt;int&gt; topKQuickSelect(std::vector&lt;int&gt;&amp; nums, int k) &#123; quickSelect(nums, 0, nums.size() - 1, k); return std::vector&lt;int&gt;(nums.begin(), nums.begin() + k);&#125; 时间复杂度： 平均：O(n) 最坏（退化成链表）：O(n^2) 空间复杂度：O(1)（递归栈不计） ✅ 总结对比 方法 时间复杂度 空间复杂度 适用场景 排序法 O(n log n) O(1) 数据量小，代码简单 最小堆 O(n log k) O(k) 数据量大，k 远小于 n 快速选择 平均 O(n) O(1) 不关心顺序，只要前 K 大 65. 堆和栈在操作系统底层的实现？堆与栈、进程虚拟内存空间分布【速度、安全】栈是用于管理函数调用、局部变量等的高效内存区域，由操作系统自动管理 【动态、灵活】堆是用于动态分配的内存区域，由程序员手动管理（或者通过垃圾回收机制管理 — java） ⚙️ 在 32 位机器上，进程虚拟内存空间分布如下： 栈为什么适合函数调用：严格的顺序性，嵌套调用不会乱。 递归调用过深，栈会发生什么：栈溢出、触发 SIGSEGV 信号，程序崩溃。 🔥 栈在操作系统底层的实现 线程创建时，操作系统为其创建栈空间（默认 8 MB）—— 分成进程栈与线程栈 进程栈（主线程栈）在进程启动时创建 线程栈通过 pthread_create、clone 系统调用创建 栈的使用：只需要移动栈指针 硬件支持：寄存器 x86 下 栈顶指针 rsp 栈底指针 rbp 操作系统管理： 函数调用时，先将参数压栈 执行 call 指令，将返回地址（返回上一级函数的下一条指令）压栈 创建栈帧，保存旧的 rbp，设置新的 rbp 可能为局部变量分配空间（清理局部变量等的栈空间） 恢复之前的 rbp 和 rsp，ret 指令弹出返回地址 🔥 堆在操作系统底层的实现本质为 malloc 机制： 当分配内存的大小 $&lt;128KB$ 时，先从内存池获取，否则通过 brk 系统调用从堆区分配内存，回收时则回收到内存池 当分配内存的大小 $\\ge 128KB$ 时，通过 mmap 系统调用从文件映射区分配内存，回收时通过 munmap 释放内存 为什么栈的分配速度比堆快？栈只需要移动指针，堆需要查找空闲块、处理碎片和系统调用 多线程程序中，堆和栈如何隔离？栈是线程私有的，无需隔离； 堆是进程共享的，需同步机制如锁🔒 66. C++ mutable 关键字 腾讯 wxg 一面 1️⃣ C++ mutable 用于修饰非静态成员函数，使得该成员变量可以在 const 成员函数中允许被修改 2️⃣ 同时也可以用于修饰 lambda 表达式，可以去掉函数调用操作符后 const 关键字，从而可以在 lambda 函数体内可以修改按值捕获的外部变量。 67. 详解内存对齐（如何 padding）及其原因 腾讯 csig 一面 求 sizeof(S) 的大小并解析，以及为什么进行内存对齐。 123456789101112struct B &#123; int b; char c;&#125;;typedef struct &#123; int a; char b; short c; char d; B e;&#125; S; 在 C&#x2F;C++ 中，结构体的大小与成员排列不仅取决于每个成员的大小，还受到**内存对齐（Alignment）**的影响，具体规则如下： 每个成员变量的地址必须是其类型对齐大小（对齐边界）的整数倍。 结构体本身的总大小必须是其最大对齐单位的整数倍。 编译器会在必要的位置插入 **padding（填充字节）**来满足上述要求，以提高内存访问效率。 对结构体 S 的内存布局分析 结构体 B 的分析： 12345struct B &#123; int b; // 4 bytes, offset 0 char c; // 1 byte, offset 4 // padding 3 bytes to align struct B size to 8&#125;; 成员 int b 对齐为 4 字节，偏移量为 0。 成员 char c 占 1 字节，偏移量为 4。 为满足结构体 B 总大小为最大对齐成员（4 字节）的倍数，需要在末尾添加 3 字节填充。 所以 sizeof(B) == 8 结构体 S 的分析： 123456789typedef struct &#123; int a; // 4 bytes, offset 0 char b; // 1 byte, offset 4 // padding 1 byte, to align next &#x27;short&#x27; to 2 bytes short c; // 2 bytes, offset 6 char d; // 1 byte, offset 8 // padding 3 bytes, to align next &#x27;B&#x27; to 4 bytes B e; // 8 bytes, offset 12&#125; S; int a: 占 4 字节，从 offset 0 开始。 char b: 占 1 字节，offset &#x3D; 4。 padding 1 字节，使得 short c 对齐到 2 的倍数（offset &#x3D; 6）。 short c: 占 2 字节，offset &#x3D; 6。 char d: 占 1 字节，offset &#x3D; 8。 padding 3 字节，使得结构体 B e 对齐到 4 字节边界（offset &#x3D; 12）。 B e: 占 8 字节（因为 sizeof(B) == 8），offset &#x3D; 12。 最后 offset &#x3D; 12 + 8 &#x3D; 20 因此： sizeof(S) == 20（假设最后总大小为 21 字节，需要 padding 到 24 字节） 68. *(int *)0 = 0 的含义？*(int *)0 = 0; 这行代码的意思是：将整数值 0 写入内存地址 0 所指向的地方，也就是将值 0 存储到内存的 地址 0。 (int *) 0：把整数 0 强转为 int* 类型的指针 *(int *) 0：对地址 0 进行解引用，访问该地址存储的内容 *(int *) 0 = 0：对地址 0 存储的内容赋值为 0，试图写入值 0 到地址 0 在几乎所有现代操作系统中，地址 0 是无效的地址，属于操作系统保留的内存区域。 尝试访问（特别是写入）地址 0 会导致段错误（Segmentation Fault），程序异常终止。 在某些低层次编程或嵌入式开发中，地址 0 可能用于特殊用途，但在普通用户态程序中，这样写没有任何合法理由，通常是： 故意制造崩溃（例如测试信号处理）。 调试用，或者模拟空指针解引用的错误。 考察面试者对指针、内存访问的理解（比如本题）。 69. 宏定义展开12345678#define SQR(x) (x * x)int main()&#123; int a, b = 3; a = SQR(b + 2); printf(&quot;a = %d &quot;, a); return 0;&#125; 输出为 a = 11 而非 a = 25，宏展开后为 a = (b + 2 * b + 2)，所以结果为 a = 11 70. 假设有一个位图数据结构定义为 uint32_t bitmap[BSIZE];，请写出用于判断位图中第 bit 位是否为 1 的如下宏的实现#define is_bit_set(bit) ((bitmap[(bit)/32] &amp; (1U &lt;&lt; ((bit)%32))) != 0) 解释：一个 uint32_t 只能表示 32 位，题目 bitmap 用的是 uint32_t 数组，所以采用 /32 找到在第几个 uint32_t 中，%32 找到在第几位。 71. 读写锁与读优先&#x2F;写优先 读写锁和传统互斥锁的区别在于，能支持多个读线程并发执行 在多线程编程中，读锁和写锁通常是配合**读写锁（读写互斥锁）**使用的，目的是在多个线程并发访问共享资源时提供更高的效率。简单来说，**读锁（共享锁）允许多个线程同时读取资源，但不允许写操作；而写锁（独占锁）**则是排他的，同一时间只能有一个线程持有写锁，且写锁期间不允许任何其他线程读或写这个资源。 这个机制的好处在于：在读多写少的场景下，我们不必像传统互斥锁那样每次都加排它锁，而是可以让多个读线程并发执行，提升性能。 具体的使用场景比如： 读锁适合的场景：多个线程同时查询一个共享缓存、配置文件、数据库快照等，数据是只读的，不会被修改。 写锁适合的场景：当某个线程需要更新缓存、修改配置或写入日志文件等操作时，为了避免其他线程读到不一致的数据，就需要加写锁。 在 C++ 中，像 std::shared_mutex 就是一个典型的读写锁实现，可以配合 std::shared_lock 和 std::unique_lock 分别实现读锁和写锁。 读&#x2F;写优先是基于读写锁中的策略选择而已，不要搞混了 在使用读写锁时，读优先和写优先指的是当读线程和写线程同时竞争锁资源时，系统会优先允许哪一类线程先获取锁。 读优先的策略意味着：如果当前有读线程在读，或者有新的读线程请求读锁，就会优先满足它们，哪怕有写线程已经在等待。这种策略的好处是读性能非常高，适合“读远远多于写”的场景。但问题是如果读操作持续不断，写线程可能会长时间得不到执行，造成“写饥饿”。 写优先则反过来：一旦有写线程在等待，新的读线程就要等写线程先执行完。这种方式能保证写操作不会被饿死，但也意味着读线程可能会频繁被阻塞，尤其在写比较多时，整体并发度会下降。 还有一种是公平策略，就是无论读还是写，谁先请求谁先执行。这种方式平衡了读写，防止任何一方饿死，但也可能带来一点性能损耗。 实际使用中，选择哪种策略要看业务特点： 如果系统是典型的读多写少，比如缓存、配置系统，用读优先可以提升整体吞吐； 如果写操作比较关键，比如数据库更新或者日志记录，写优先更合适； 如果两者都重要，或者对延迟比较敏感，可以用公平策略。 C++ 标准库里的 std::shared_mutex 是不保证写优先的，如果确实要实现写优先或者公平策略，可能需要第三方库（比如 Boost）或者平台相关的原语。 72. 多线程之间是如何通信的？线程之间怎么交互的？ &lt;mutex&gt; 和 &lt;condition_variable&gt; 答案就是条件变量 多线程之间的通信和交互主要是通过共享内存来实现的，也就是说多个线程可以访问同一个进程的内存空间，从而读写同一份数据。但因为线程可能同时访问同一块数据，会产生竞态条件，所以通常需要同步机制来保证数据的一致性和正确性。 常用的同步方式包括互斥锁（mutex）、读写锁（rwlock）、信号量（semaphore）、条件变量（condition variable）等，这些机制帮助线程协调访问顺序，防止数据冲突。 此外，线程间还可以通过消息队列、事件通知等方式传递信息，尤其在异步或生产者-消费者模式中常见。现代操作系统和语言运行时通常提供了丰富的线程同步和通信工具，确保线程间可以高效且安全地交互和协作。 73. 关于使用 == 比较 double 类型在 C++ 中处理double类型时，我们需要理解： 为什么不能直接用==比较浮点数（浮点数为什么是近似存储的） 如何正确比较浮点数 1. 为什么不能直接用 == 比较浮点数在计算机中的存储是近似值而非精确值，double 通常使用 64 位存储（1 符号位 + 11 指数位 + 52 尾数位)，像 0.1 这样的十进制小数无法精确表示为二进制分数，存储时必须进行舍入（截断无限循环部分），导致微小误差。 1234567891011121314151617#include &lt;iostream&gt;#include &lt;cmath&gt;#include &lt;iomanip&gt;int main() &#123; double a = 0.1; double b = 0.2; double sum = a + b; std::cout &lt;&lt; std::setprecision(20); std::cout &lt;&lt; &quot;0.1 in memory: &quot; &lt;&lt; a &lt;&lt; std::endl; std::cout &lt;&lt; &quot;0.2 in memory: &quot; &lt;&lt; b &lt;&lt; std::endl; std::cout &lt;&lt; &quot;0.1 + 0.2 = &quot; &lt;&lt; sum &lt;&lt; std::endl; std::cout &lt;&lt; &quot;0.3 in memory: &quot; &lt;&lt; 0.3 &lt;&lt; std::endl; return 0;&#125; 输出可能类似于： 12340.1 in memory: 0.100000000000000005550.2 in memory: 0.20000000000000001110.1 + 0.2 = 0.300000000000000044410.3 in memory: 0.2999999999999999889 所以使用 == 比较是容易出错的。 1234567891011121314#include &lt;iostream&gt;int main() &#123; double x = 0.1 + 0.2; double y = 0.3; if (x == y) &#123; std::cout &lt;&lt; &quot;Exactly equal &quot;; &#125; else &#123; std::cout &lt;&lt; &quot;Not exactly equal &quot;; // 通常会输出这个 &#125; return 0;&#125; 2. 正确的浮点数比较方法 绝对误差比较 1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;cmath&gt;#include &lt;cfloat&gt; // 对于 DBL_EPSILONbool nearlyEqual(double a, double b, double absEpsilon = 1e-12) &#123; return std::fabs(a - b) &lt;= absEpsilon;&#125;int main() &#123; double x = 0.1 + 0.2; double y = 0.3; if (nearlyEqual(x, y)) &#123; std::cout &lt;&lt; &quot;Equal within tolerance &quot;; // 会输出这个 &#125; else &#123; std::cout &lt;&lt; &quot;Not equal &quot;; &#125; return 0;&#125; 3. 什么时候可以使用 == 直接比较在C++中，虽然大多数情况下不推荐直接用==比较浮点数，但在以下特定情况下可以安全使用（当你能 100% 确定数值来源和没有经过任何浮点运算时，才用==）： 比较精确赋值的相同字面值 123double a = 5.0;double b = 5.0;if (a == b) &#123; /* 总是true */ &#125; 比较整数范围内的值 123double x = 42.0; // 没有小数部分double y = 42.0;if (x == y) &#123; /* 总是true */ &#125; 比较特殊浮点值 1234567// 比较正负无穷大double inf1 = std::numeric_limits&lt;double&gt;::infinity();double inf2 = std::numeric_limits&lt;double&gt;::infinity();if (inf1 == inf2) &#123; /* 总是true */ &#125;// 比较零值if (0.0 == -0.0) &#123; /* 总是true，尽管符号不同 */ &#125; 比较编译期常量表达式： 123constexpr double PI = 3.141592653589793;constexpr double PI_2 = PI / 2;if (PI_2 == 1.5707963267948966) &#123; /* 编译期计算，总是true */ &#125; 比较未经过算术运算的相同变量： 123double val = getValue(); // 假设返回固定值if (val == val) &#123; /* 检测NaN的惯用方法 */ &#125;// 如果val是NaN，这个条件会是false ⚠️ 特别注意，以下情况绝不应该使用==： 1234567891011121314// 经过算术运算的结果if (0.1 + 0.2 == 0.3) &#123; /* 可能false */ &#125;// 从不同计算路径得到的结果double a = calculateA();double b = calculateB();if (a == b) &#123; /* 危险 */ &#125;// 循环累积的结果double sum = 0.0;for (int i = 0; i &lt; 10; ++i) &#123; sum += 0.1;&#125;if (sum == 1.0) &#123; /* 可能false */ &#125; 74. 堆与栈的优缺点比较栈 - Stack优点： 快速分配&#x2F;释放：栈内存的分配和释放只是移动栈指针，速度快 自动管理：函数返回时自动释放，无需手动管理 缓存友好：栈数据通常位于缓存热点区域，访问速度快 不会产生碎片：严格的 LIFO 顺序避免了内存碎片问题 线程安全：每个线程有自己的栈，无需同步 缺点 大小有限：栈空间通常较小（几 MB），不适合大对象 生命周期固定：只能在函数调用期间存在，不能跨函数使用 灵活性差：无法动态调整大小，必须是编译时已知的大小 容易溢出：递归过深或大对象可能导致栈溢出（stack overflow） 堆 - Heap优点： 大容量：可用内存通常远大于栈空间 动态分配：可以在运行时决定分配大小和生命周期 全局可访问：分配的内存可以被程序任何部分访问 灵活性高：可以动态调整大小(如realloc) 适合大数据：能够处理大型数据结构 缺点： 分配速度慢：需要寻找合适的内存块，可能涉及系统调用 手动管理特性：堆内存需要显式分配 (new/malloc) 和释放 (delete/free)，存在内存泄漏风险 内存碎片：频繁分配释放可能导致碎片 同步开销：多线程环境下需要同步机制 缓存不友好：堆分配的数据可能分散在内存各处 使用建议 优先使用栈：适合小型、短生命周期的数据 必要时用堆：大型数据或需要长生命周期时使用 75. 关于 shared_ptr 的注意事项（20. 智能指针）关于 shared_ptr 的注意事项： 不要用一个裸指针初始化多个 shared_ptr，会出现 double_free 导致程序崩溃 通过 shared_from_this() 返回 this 指针，不要把 this 指针作为 shared_ptr 返回出来，因为 this 指针本质就是裸指针，通过 this 返回可能会导致重复析构，不能把 this 指针交给智能指针管理。 尽量使用 std::make_shared&lt;T&gt;()，少用 new 不要 delete get() 返回的裸指针 不是 new 出来的空间要自定义删除器 要避免循环引用，循环引用导致内存永远不会被释放，造成内存泄漏（不在赘述） 1. 不要用一个裸指针初始化多个 shared_ptr（会导致 double free）问题场景： 123int* raw_ptr = new int(42);std::shared_ptr&lt;int&gt; sp1(raw_ptr);std::shared_ptr&lt;int&gt; sp2(raw_ptr); // 危险！ 两个独立的 shared_ptr 会各自维护一个引用计数控制块（相互独立） 当 sp1 和 sp2 销毁时都会尝试释放 raw_ptr，导致 双重释放（double free） 结果通常是程序崩溃或未定义行为 正确做法： 123456789// 方法1：直接使用 make_shared// make_shared 一次性分配内存，包含控制块（引用计数、弱引用计数等）；对象存储空间（存储实际值 42）auto sp1 = std::make_shared&lt;int&gt;(42);auto sp2 = sp1; // 只是复制指针并增加引用计数，两个 shared_ptr 指向同一个控制块，共享所有权// 方法2：如果必须从裸指针创建，确保只创建一次 shared_ptrint* raw_ptr = new int(42);std::shared_ptr&lt;int&gt; sp1(raw_ptr);std::shared_ptr&lt;int&gt; sp2 = sp1; // 复制的是控制块指针，不是重新创建控制块，共享同一个控制块 2. 正确使用 shared_from_this() 而不是直接返回 this 指针问题场景： 123456789class BadExample &#123;public: std::shared_ptr&lt;BadExample&gt; get_this() &#123; return std::shared_ptr&lt;BadExample&gt;(this); // 危险！ &#125;&#125;;auto obj = std::make_shared&lt;BadExample&gt;();auto another_ref = obj-&gt;get_this(); // 创建了独立的控制块 这会创建两个独立的 shared_ptr 控制块 当两个 shared_ptr 销毁时都会尝试析构同一个对象 正确做法： 123456789class GoodExample : public std::enable_shared_from_this&lt;GoodExample&gt; &#123;public: std::shared_ptr&lt;GoodExample&gt; get_this() &#123; return shared_from_this(); // 安全 &#125;&#125;;auto obj = std::make_shared&lt;GoodExample&gt;();auto another_ref = obj-&gt;get_this(); // 共享同一个控制块 3. 优先使用 std::make_shared&lt;T&gt;() 而不是 new问题场景： 12345// 不推荐std::shared_ptr&lt;MyClass&gt; sp(new MyClass(arg1, arg2));// 推荐auto sp = std::make_shared&lt;MyClass&gt;(arg1, arg2); 优势： 性能更好：单次内存分配（对象 + 控制块） 异常安全：不会在 new 和 shared_ptr 构造之间发生泄漏 代码更简洁：不需要重复类型名称 缓存友好：对象和控制块内存相邻 例外情况： 需要自定义删除器时 需要指定特殊的内存分配方式时 4. 不要 delete get() 返回的裸指针问题场景： 12345auto sp = std::make_shared&lt;int&gt;(42);int* raw_ptr = sp.get();delete raw_ptr; // 灾难性错误！// 当 sp 超出作用域时，会再次尝试删除已删除的内存 shared_ptr 仍然拥有内存所有权 手动 delete 会导致： double free 控制块状态不一致 未定义行为（通常崩溃） 正确做法： 123auto sp = std::make_shared&lt;int&gt;(42);int* raw_ptr = sp.get();// 仅使用 raw_ptr 进行读取/写入操作，绝不手动删除它 5. 非 new 分配的内存需要自定义删除器问题场景： 1234567// 从 malloc 分配的内存void* mem = malloc(1024);std::shared_ptr&lt;void&gt; sp(mem); // 错误！会用 delete 而不是 free// 文件指针FILE* fp = fopen(&quot;file.txt&quot;, &quot;r&quot;);std::shared_ptr&lt;FILE&gt; sp(fp); // 错误！会用 delete 而不是 fclose 正确做法： 12345678910// 使用自定义删除器（lambda 表达式作为删除器）void* mem = malloc(1024);std::shared_ptr&lt;void&gt; sp(mem, free); // 使用 free 作为删除器FILE* fp = fopen(&quot;file.txt&quot;, &quot;r&quot;);std::shared_ptr&lt;FILE&gt; sp(fp, [](FILE* f) &#123; fclose(f); &#125;);// 对于数组int* arr = new int[10];std::shared_ptr&lt;int&gt; sp(arr, [](int* p) &#123; delete[] p; &#125;); 常见删除器场景： C 风格内存分配（malloc/calloc/realloc）→ 使用 free 文件操作（fopen）→ 使用 fclose 系统资源（套接字、句柄等）→ 使用对应的释放函数 数组 → 使用 delete[] 6. 避免循环引用导致的内存泄露问题场景 112345678910111213141516171819202122class A;class B;class A &#123;public: std::shared_ptr&lt;B&gt; b;&#125;;class B &#123;public: std::shared_ptr&lt;A&gt; a;&#125;;int main() &#123; std::shared_ptr&lt;A&gt; ap = std::make_shared&lt;A&gt;(); std::shared_ptr&lt;B&gt; bp = std::make_shared&lt;B&gt;(); ap-&gt;b = bp; bp-&gt;a = ap; // 此时，a 和 b 相互持有对方的 shared_ptr，形成循环引用 // 程序结束时，a 和 b 的引用计数都不会降为零，导致内存泄漏 return 0;&#125; 问题场景 21234567891011class Node &#123;public: std::shared_ptr&lt;Node&gt; next; std::shared_ptr&lt;Node&gt; prev; // 双向链表导致循环引用 ~Node() &#123; std::cout &lt;&lt; &quot;Node destroyed &quot;; &#125;&#125;;auto node1 = std::make_shared&lt;Node&gt;();auto node2 = std::make_shared&lt;Node&gt;();node1-&gt;next = node2;node2-&gt;prev = node1; // 循环引用形成！ 当 node1 和 node2 离开作用域时： node1 的引用计数从 1→0？不，因为 node2-&gt;prev 还持有引用（实际从 2→1） node2 的引用计数同样从 2→1 结果：两者引用计数永远不为 0，内存永远不会释放 123node1 [refcount=2] --&gt; Node1对象 ↑next ↓prevNode2对象 &lt;-- [refcount=2] node2 解决方案：weak_ptr 123456789101112class SafeNode &#123;public: std::shared_ptr&lt;SafeNode&gt; next; std::weak_ptr&lt;SafeNode&gt; prev; // 使用weak_ptr ~SafeNode() &#123; std::cout &lt;&lt; &quot;SafeNode destroyed &quot;; &#125;&#125;;auto node1 = std::make_shared&lt;SafeNode&gt;();auto node2 = std::make_shared&lt;SafeNode&gt;();node1-&gt;next = node2;node2-&gt;prev = node1; // weak_ptr不会增加引用计数 何时会出现循环引用？ 双向链表、树结构等复杂数据结构 对象相互持有对方的 shared_ptr 父子对象互相强引用 观察者模式中主体和观察者互相持有 76. std::shared_ptr 可以通过 std::make_shared 和直接使用 new 表达式构造，二者有什么区别？在 C++ 中，std::shared_ptr 可以通过 std::make_shared 和直接使用 new 表达式构造，但二者在内存管理、性能和异常安全性方面有显著区别： 12345// 推荐方式：高效且安全auto sp1 = std::make_shared&lt;int&gt;(42);// 不推荐：性能更低且可能泄漏std::shared_ptr&lt;int&gt; sp2(new int(42)); 1. 内存分配方式 make_shared：一次性分配内存，同时存储对象本身和控制块（引用计数等）。这是更高效的内存布局，减少了内存碎片和分配次数 1auto sp = std::make_shared&lt;Widget&gt;(args...); // 单次分配 new + shared_ptr 构造函数：需要两次内存分配，一次为对象（new），另一次为控制块（由 shared_ptr 构造函数触发） 1std::shared_ptr&lt;Widget&gt; sp(new Widget(args...)); // 两次分配 2. 性能差异 make_shared 更快：单次内存分配减少了开销，尤其当频繁创建&#x2F;销毁 shared_ptr 时更明显。 new 额外开销：两次分配可能引入性能损耗（尤其是对小型对象）。 解释 每次 new&#x2F;malloc 都是一次系统调用：操作系统需要查找合适的内存块、更新内存管理数据结构（如空闲链表），可能触发缺页中断或内核态切换，这些操作本身就有固定开销。两次分配就会有双倍开销。 从内存局部性角度来看： make_shared 的内存是连续的，对象和控制块在单块内存中紧密排列，缓存命中率更高。 new 的内存可能是分散的，对象和控制块位于不同内存区域，访问时可能触发多次缓存加载，同时产生更多内存碎片。 3. 异常安全性 make_shared 是异常安全的：若构造函数抛出异常，不会发生内存泄漏（因为内存已由智能指针系统托管）。 1process(std::make_shared&lt;Widget&gt;(a, b), may_throw()); // 安全 new 可能泄漏：如果 new 成功但 shared_ptr 构造前发生异常，对象不会被释放： 1process(std::shared_ptr&lt;Widget&gt;(new Widget(a, b)), may_throw()); // 可能泄漏 4. 对象生命周期的影响 make_shared 的延迟释放：对象内存和控制块是连续的，即使引用计数归零，对象占用的内存可能直到控制块也被释放时才归还（例如弱引用 weak_ptr 仍存在时）。 new 的独立释放：对象内存和控制块分离，对象内存会在引用计数归零时立即释放，控制块则等待所有 weak_ptr 释放后才回收。 5. 使用场景限制 必须用 new 的情况：需要自定义删除器或需从已有裸指针构造时。 1std::shared_ptr&lt;Widget&gt; sp(new Widget, custom_deleter); 优先用 make_shared：默认情况下推荐使用，除非有特殊需求。 总结 特性 make_shared new + shared_ptr 内存分配次数 1 次 2 次 异常安全 是 否（可能泄漏） 内存释放时机 对象和控制块一起释放 对象先释放，控制块后释放 自定义删除器 不支持 支持 最佳实践：默认使用 make_shared，除非需要自定义删除器或特殊内存管理。 77. shared_ptr 的引用计数是在栈还是堆？在 std::shared_ptr 的实现中，引用计数（控制块）存储在堆上，为了共享这个这个 reference count 值。 shared_ptr 和 weak_ptr 可能被拷贝、传递到不同的作用域（如函数调用、线程间共享）。如果引用计数在栈上，它会在栈帧销毁时被释放，导致其他指针无法正确跟踪计数。 make_shared 会将对象数据和引用计数分配在同一块堆内存中 new + shared_ptr 则是将对象数据和引用计数分配在两块独立的堆内存 虽然引用计数本身在堆上，但 shared_ptr 的实例（即指针对象本身）可以存储在栈上 总结 存储位置 内容 原因 堆内存 引用计数（控制块）、对象数据 需要动态生命周期管理，支持多指针共享，跨作用域存活。 栈内存 shared_ptr 实例本身 栈对象自动析构，通过析构函数减少堆上的引用计数，必要时释放对象内存。 78. 基类的虚函数可以声明为 private 吗基类的虚函数可以声明为 private，但这会影响其可访问性和多态行为的使用方式。 语法允许，但访问受限从语法层面，C++ 允许虚函数为 private，编译器不会报错。 派生类不能通过基类指针&#x2F;引用直接访问 private 虚函数（违反访问控制规则） 多态行为仍然有效如果基类提供公有方法调用私有虚函数，派生类重写该私有虚函数后，多态仍能正常工作。 派生类重写 foo() 时也必须为 private（访问权限可以更宽松，但不能更严格）。 1234567891011121314151617class Base &#123;public: void callFoo() &#123; foo(); &#125; // 公有接口调用私有虚函数private: virtual void foo() &#123; std::cout &lt;&lt; &quot;Base::foo&quot;; &#125;&#125;;class Derived : public Base &#123;private: void foo() override &#123; std::cout &lt;&lt; &quot;Derived::foo&quot;; &#125; // 重写私有虚函数&#125;;int main() &#123; Base* ptr = new Derived; ptr-&gt;callFoo(); // 输出 &quot;Derived::foo&quot;（多态生效） delete ptr;&#125; 对比其他权限 虚函数权限 派生类能否直接调用 派生类能否重写 外部代码能否调用 public ✅ ✅ ✅ protected ✅ ✅ ❌ private ❌ ✅（需同权限或更宽松） ❌ 79. 如果有 100 个对象，vector、list、map 哪个占用内存高这个问题本质上考察 STL 容器的内存占用特性。假设我们存放 100 个对象（比如大小相同的自定义类对象），不同容器的内存开销差别主要来自于元素存储方式和额外的结构体开销。 1. vector 存储方式：底层是 动态数组，所有元素连续存放。 额外开销： 仅仅是 vector 自身维护的三个指针（begin&#x2F;end&#x2F;capacity_end），常见实现 24 字节左右。 可能有 容量冗余（capacity ≥ size），但不是很大。 内存占用： 接近 100 × sizeof(对象)，几乎没有额外 per-element 的开销。 在三者中最节省内存。 2. list 存储方式：双向链表，每个节点独立分配。 额外开销： 每个节点除了存放对象，还要存放两个指针（prev&#x2F;next），常见实现 16 字节或更多。 由于频繁分配，可能带来额外的 堆分配和内存碎片开销。 内存占用： 大约 100 × (sizeof(对象) + 2 × sizeof(指针))，比 vector 高不少。 在这三者里通常是最浪费内存的。 3. map（通常是红黑树） 存储方式：红黑树节点，每个节点存放 (key, value)，还有指针和颜色信息。 额外开销： 一个节点要维护 父、左、右指针（3 个指针 &#x3D; 24 字节）+ 颜色位（通常填充到 4 字节）。 还要存放键和值对象。 内存占用： 大约 100 × (sizeof(key) + sizeof(value) + 3 × sizeof(指针) + padding)。 如果 key&#x2F;value 很小（比如 int&#x2F;int），开销主要是结构体本身，比 list 更大。 结论（内存占用比较）在存放 100 个对象时，三者大致的内存占用从低到高为：vector &lt; list &lt; map vector：最节省空间，几乎没有额外 per-element 开销。 list：由于链表节点指针和堆分配，开销中等。 map：红黑树节点开销更大（指针 + 平衡因子等），通常是最高的。 80. 虚函数表和虚函数指针存储在哪里？虚函数表（vtable） 位置： 编译器生成的全局静态表，在程序的 只读数据区（.rodata） 或类似的静态存储区域。 每个包含虚函数的类（以及其派生类）通常对应一张或多张虚函数表。 表的内容是 函数指针数组，指向该类对应的虚函数实现。 特点： 程序运行时不会修改表的位置，只会改变对象中的指针指向哪一张表。 继承 + 覆盖虚函数时，子类的 vtable 会覆盖父类条目。 虚函数指针（vptr） 位置： 在 对象实例的内存中，通常存放在对象的头部。 每个对象都有一个 vptr，指向对应类的 vtable。 如果类有多个虚继承&#x2F;多继承，可能会有多个 vptr。 初始化： 编译器在构造函数中插入代码，把对象的 vptr 指向正确的 vtable。 析构时，也会相应调整 vptr 以保证多态析构正确。 举例与总结123456789class Base &#123;public: virtual void foo();&#125;;class Derived : public Base &#123;public: void foo() override;&#125;; 程序里会生成两张 vtable： Base 的 vtable，里面有 &amp;Base::foo Derived 的 vtable，里面有 &amp;Derived::foo Base 或 Derived 对象实例的内存中，都会有一个 vptr 指针，指向相应的 vtable。 总结 虚函数表（vtable）：编译器生成的全局静态表，存放在只读数据段。 虚函数指针（vptr）：存放在对象实例内存中（通常在开头），指向该对象对应的 vtable。 81. 多线程编程一般用哪些库函数？C 语言层面 POSIX Threads (pthread)：pthread_create、pthread_join、pthread_mutex_lock、pthread_cond_wait 等，Linux&#x2F;Unix 常用。 C11 标准库：thrd_create、mtx_lock（但在实际项目里用得少）。 C++ 层面 C++11 标准库： std::thread（线程创建&#x2F;管理） std::mutex、std::recursive_mutex、std::timed_mutex（互斥量） std::lock_guard、std::unique_lock（RAII 封装锁） std::condition_variable（条件变量） std::future &#x2F; std::promise &#x2F; std::async（任务并发模型） 82. 为什么需要锁？什么时候需要多线程？举个例子 为什么需要锁 多线程共享内存 → 存在 竞态条件（race condition）。 如果两个线程同时读写同一变量，可能导致数据不一致。 锁（mutex） 的作用就是保证某段代码在同一时刻只有一个线程能进入，维持数据一致性。 什么时候需要多线程 计算密集型任务：利用多核 CPU，提高吞吐量（例如矩阵运算、图像处理）。 I&#x2F;O 密集型任务：一个线程阻塞 I&#x2F;O 时，其他线程可以继续执行（例如服务器同时处理多个客户端请求）。 举例 写一个多线程日志系统： 多个工作线程处理业务逻辑，把日志消息写入一个共享队列。 一个单独线程从队列取日志写文件。 共享队列必须加锁，否则多线程写入会导致数据错乱。 83. 多线程场景下出现内存泄漏怎么调试解决？ 原因 某些线程申请的内存没有释放，线程退出后仍然占用。 使用 TLS（线程局部存储）或全局变量，线程结束时忘记清理。 线程之间交互复杂，某些分支忘记释放内存。 常见调试手段 工具： valgrind --tool=memcheck（Linux） asan（AddressSanitizer） gdb 策略： 用 RAII（C++）避免手动 new/delete。 尽量使用智能指针（std::unique_ptr、std::shared_ptr）。 保证线程退出时执行清理逻辑（析构函数&#x2F;pthread_cleanup_push）。 分而治之：把怀疑的线程单独跑，缩小问题范围。 下文详细介绍下「gdb 多线程调试」与「打日志 + 线上定位 + 复现副本」这两种方式。 当然能用 gdb 调多线程，而且线上定位常常要配合“打日志 + 复现副本”的办法一起用。下面给你一套“面试可讲、实际可用”的流程和要点。 (1) 用 gdb 调多线程的实用套路基本操作（本地或 attach 线上进程）12345678910111213# 运行时调试gdb ./your_program(gdb) run ...# 附加到线上/本地正在跑的进程gdb -p &lt;PID&gt;# 一次性抓所有线程的栈(gdb) thread apply all bt(gdb) thread apply all bt full # 带局部变量(gdb) info threads # 线程列表(gdb) thread &lt;id&gt; # 切换线程(gdb) bt # 当前线程回溯 让单步&#x2F;断点更可控（避免线程乱切）12(gdb) set scheduler-locking on # 单步时不让其它线程抢占（on/step可选）(gdb) set pagination off 条件断点 &#x2F; 竞争点观察1234567# 只在指定线程/条件触发(gdb) break file.cpp:123 if pthread_self() == target_tid &amp;&amp; counter &lt; 0# 监视内存写（找“谁改了这个变量/指针”）(gdb) watch some_global_ptr(gdb) rwatch x # 读监视(gdb) awatch x # 读写监视 线程与锁问题的专招 死锁&#x2F;卡住：先 gdb -p PID，再 thread apply all bt full 看各线程卡在什么锁&#x2F;条件变量处；很多时候能直接看出两个线程的互相等待链。 条件变量：在 pthread_cond_wait、pthread_mutex_lock 处下断点或打条件断点，确认唤醒与加锁顺序。 跟踪线程创建：记录是谁创建了问题线程。 12345(gdb) break pthread_create(gdb) commands&gt; bt&gt; c&gt; end 核心转储（coredump）事后排查1234ulimit -c unlimited# 触发崩溃后gdb ./your_program core(gdb) thread apply all bt full 也可以线上“留存一份 core”，再在离线环境慢慢剖析。 录制&#x2F;重放 rr（Linux）：rr record ./prog，复现后用 rr replay 进 gdb，可时间回溯到变量被改写的一刻，定位数据竞争&#x2F;时序问题非常好用。 gdb 的 record full 也能用，但 rr 更稳定。 (2) 打日志→线上定位→复现副本→看日志这是大厂很常见、也很靠谱的生产级排障方法： 打结构化日志（并带上标识） 必带：时间戳、线程ID、请求ID&#x2F;traceID、关键状态（队列长度、锁等待时长、对象地址&#x2F;指针等）。 在锁关键点打点：lock acquire start/ok/timeout、cond wait/signal、enqueue/dequeue、state transition。 遇到潜在死锁，记录锁名&#x2F;顺序和持有时长，方便识别锁顺序反转。 定位线上问题副本 用日志把异常请求&#x2F;异常时间窗圈出来（比如特定用户、某个 shard、某台机器）。 从线上环境抽一个最小有问题的副本（相同配置&#x2F;数据切片&#x2F;版本&#x2F;流量）到灰度或隔离环境。 这样能在不影响大盘的情况下复现，同时你可以随意加日志、开更高日志级别、甚至 attach gdb。 看日志 + 还原时序 通过 traceID 串起多个线程&#x2F;模块的跨调用链，按照时间戳排序，重放“谁先拿了哪个锁、谁等在 cond 上”，从而定位竞态&#x2F;死锁&#x2F;饥饿。 日志中记录的内存地址&#x2F;对象ID可以让你把若干条看似无关的日志对应到同一对象实例。 必要时动用在线栈 现场卡死时，用 gdb -p PID 或运维脚本（比如发送信号触发 backtrace() dump 全线程栈）把全线程栈打印出来，和日志时间窗对比，锁点一目了然。 修复后再灰度验证 在副本&#x2F;灰度环境验证“日志告警消失、锁等待时长下降、吞吐恢复”，再全量。 这套方法的核心是：用日志重建并发时序，用副本规避线上风险，用 gdb&#x2F;栈&#x2F;录制补齐细节。 84. 程序的内存布局是怎样的？ 一个典型 C&#x2F;C++ 程序在内存里的分布大致如下： 代码段：包括二进制可执行代码，通常只读，还可共享（多个进程运行同一程序时只存一份）； 静态存储区：数据段 + BSS 段 数据段：包括已初始化的静态常量和全局变量； BSS 段：包括未初始化的静态变量和全局变量； 堆（比如 malloc/new）：包括动态分配的内存，从低地址开始向上增长，程序员负责管理，容易泄露； 文件映射区（比如 mmap）：包括共享库、文件映射、匿名映射、共享内存等； 栈：包括局部变量和函数调用的上下文（参数、返回地址）等，函数调用或返回会自动分配与释放后。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小； 内核空间（对用户程序不可见） 上图中的内存布局可以看到，代码段下面还有一段内存空间的（灰色部分），这一块区域是「保留区」，之所以要有保留区这是因为在大多数的系统里，我们认为比较小数值的地址不是一个合法地址，例如，我们通常在 C 的代码里会将无效的指针赋值为 NULL。因此，这里会出现一段不可访问的内存保留区，防止程序因为出现 bug，导致读或写了一些小内存地址的数据，而使得程序跑飞。 在这 7 个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 malloc() 或者 mmap()，就可以分别在堆和文件映射段动态分配内存。 85. delete 释放内存的时候并不知道内存大小，如何释放？ 涉及 new 和 delete 源码及流程 链接：pdd 二面 delete 运算符在释放内存时确实不需要显式指定大小，因为它依赖底层的内存管理器来跟踪分配块的信息。当使用 new 分配内存时，内存管理器（如 glibc 的分配器）会在返回给用户的内存块前端或尾部存储额外的元数据（如分配大小、cookie 等），这些信息对用户透明。调用 delete 时，运算符会根据传入的指针向前偏移一定位置来读取这些元数据，从而确定需要释放的内存块实际大小和边界，确保正确释放。因此，用户无需手动传递大小，所有细节由内存管理器和编译器生成的代码处理。 86. 一个空类大小是多少？如果有构造函数和析构函数呢？如果有虚函数？ 腾讯 TEG 一面 Q1：一个空类大小是多少？ 在 C++ 中，一个空类（没有任何非静态成员变量和虚函数）的大小通常为 1 字节。这是因为编译器需要为每个对象分配一个唯一的地址标识，以确保不同对象在内存中拥有 distinct 的地址。如果大小为 0，可能导致多个对象地址相同，违反语言标准。需要注意的是，如果空类作为基类被继承，可能会发生空基类优化（EBO），此时基子对象不占用额外空间，从而节省内存。 Q2：如果空类只有构造函数和析构函数，该类大小是多少？ 大小仍然是 1 个字节。 构造函数和析构函数是普通的成员函数，它们的代码并不存储在每一个对象实例中。这些函数在编译后位于代码段，所有该类的对象共享同一份函数代码。调用它们时，编译器会隐式地传入一个指向当前对象的 this 指针。因此，添加普通的成员函数（包括构造和析构）不会影响对象实例的大小。 Q3：如果空类只有虚函数，该类大小是多少？ 在 64 位系统上，大小通常是 8 字节（一个指针的大小）；在 32 位系统上，通常是 4 字节。 一旦一个类拥有虚函数，它就会拥有一个虚函数表（vtable），并且编译器会自动为该类的每一个对象实例添加一个隐藏的成员变量 —— 虚表指针（vptr）。这个 vptr 指向类的 vtable，用于在运行时实现多态（动态绑定）。因此，对象的大小会增加一个指针的开销。 87. 指针的大小是多少？指针的大小不取决于它指向的数据类型，而完全取决于目标平台的寻址能力。 在 32 位平台上，指针的大小是 4 字节，因为它需要能表示 $2^{32}$ 个不同的内存地址。 在 64 位平台上，指针的大小是 8 字节，用于表示 $2^{64}$ 个地址空间。 无论是指向 int、char 还是一个拥有虚函数的复杂类对象，所有数据指针的大小都遵循这个规则（函数指针可能在某些平台上有所不同）。 88. 内存对齐了解过吗，我如果不想对齐，怎么办？ 腾讯 TEG 一面 内存对齐是编译器和硬件为了提升访问效率而实施的策略。 如果不想对齐，可以通过编译器指令强制取消填充（如 GCC&#x2F;Clang 的 __attribute__((packed)) 或 MSVC 的 #pragma pack(1)），使结构体成员紧凑排列。但这样做有风险：未对齐访问在 x86 架构上会导致性能下降（多次内存访问），在其他架构（如 ARM）上可能直接触发硬件异常造成崩溃。除非有特殊需求（如协议解析或节省内存），否则不建议禁用对齐。 89. 讲讲 unordered_map 和 map 的底层实现和区别 腾讯 TEG 一面 区别 特性 std::map std::unordered_map 底层数据结构 红黑树 (一种自平衡的二叉搜索树) 哈希表 (数组 + 链表&#x2F;红黑树) 元素顺序 元素按 key 排序 (默认 std::less，即升序) 元素无序 (顺序取决于哈希函数) 搜索时间复杂度 O(log n) 平均 O(1)，最坏情况 O(n) 插入时间复杂度 O(log n) 平均 O(1)，最坏情况 O(n) 删除时间复杂度 O(log n) 平均 O(1)，最坏情况 O(n) 迭代器稳定性 稳定（除非删除元素，否则迭代器始终有效） 插入&#x2F;删除可能使所有迭代器失效 需要为 key 定义 operator&lt; 或 自定义比较器 std::hash 哈希函数 和 operator== 相等比较 内存占用 通常较低（树节点开销） 通常较高（需要维护数组桶和链表） 常用场景 需要元素有序、顺序遍历、或要求最坏情况性能稳定 需要快速查找、插入、删除，且不关心顺序 底层实现详解map - 基于红黑树 (Red-Black Tree) 数据结构： 本质上是一颗二叉搜索树 (BST)，这意味着任何节点的左子树所有节点的 key 都小于该节点的 key，右子树所有节点的 key 都大于该节点的 key。这使得中序遍历树时，可以得到有序的 key 序列。 它更具体地是一颗红黑树。红黑树是一种自平衡的二叉搜索树。它通过为节点添加颜色属性（红或黑）和定义一系列旋转和重新着色的规则，来确保树始终保持大致平衡（没有一条路径会比其他路径长两倍以上）。 如何工作： 插入：首先像普通的 BST 一样找到插入位置。插入新节点后（初始为红色），可能会破坏红黑树的平衡性质（如出现两个连续的红色节点）。这时需要通过旋转（左旋、右旋）和重新着色来恢复平衡。 查找：从根节点开始，与当前节点的 key 比较。如果小于，进入左子树；如果大于，进入右子树；如果相等，则找到。由于树是平衡的，查找路径长度最多为树的高度 O(log n)。 删除：同样先找到节点，执行 BST 删除操作后，可能会破坏平衡，需要再次通过旋转和重新着色来调整。 优点：元素始终有序，支持范围查询（如lower_bound()），提供了稳定的 O(log n) 操作时间。 缺点：平均速度比哈希表慢，因为常数因子较大（需要多次比较和可能的内存跳跃）。 unordered_map - 基于哈希表 (Hash Table) 数据结构： 一个数组（通常称为“桶”bucket 数组），数组的每个元素是一个链表的头指针（或一棵小红黑树的根节点）。 在 C++11 中，标准要求使用“开链法”解决哈希冲突。在极端情况下（一个桶里元素太多），标准允许该桶用树 instead of 链表来实现，以避免最坏性能。 如何工作： 插入： 对 key 进行哈希函数计算，得到一个整型的哈希值。 用这个哈希值 % 桶的数量 来确定元素应该放在哪个桶里（即数组的哪个索引）。 将键值对添加到这个桶对应的链表（或树）的末尾。 查找： 同样先计算 key 的哈希值，找到对应的桶。 然后遍历这个桶里的链表（或树），使用operator== 进行精确匹配。 重新哈希 (Rehashing)： 当元素数量超过负载因子(load factor) * 桶的数量时，容器会自动进行重新哈希。 这会创建一个新的、更大的桶数组，然后将所有现有元素重新计算哈希并插入到新的数组中。 这个过程会使所有迭代器失效！ 优点：平均情况下的查找、插入、删除速度极快，接近常数时间 O(1)。 缺点： 元素无序。 最坏情况下的性能是 O(n)（例如所有 key 都哈希到同一个桶里）。 迭代器不稳定（重新哈希会导致失效）。 需要为 key 类型提供良好的哈希函数。 如何选择？ 使用 std::map 当： 你需要元素按 key 排序。 你需要按顺序遍历元素。 你无法定义一个好的哈希函数 for your key type。 你非常关心最坏情况的性能（保证 O(log n)），而不是平均情况。 使用 std::unordered_map 当： 查找速度是首要任务。 你不需要维护元素的任何顺序。 你愿意并且能够为你的 key 类型定义一个高效的哈希函数（例如，基本类型和std::string已有内置哈希）。 90. 介绍一下B树&#x2F;B+树&#x2F;红黑树及其对应的应用场景有哪些B 树B 树是一种多路平衡搜索树，它的每个节点可以拥有多于两个的子节点，这使得它能够保持矮胖的树形结构。 B 树的设计核心是为了减少磁盘 I&#x2F;O 次数，因为它一个节点的大小通常设置为一个磁盘页的大小，一次磁盘读取就能加载一个包含多个键的巨大节点，然后在内核中进行高效的二分查找。 所以它特别适合用于文件系统和数据库（如 MySQL 的 InnoDB 存储引擎）的索引，这些场景下数据量巨大无法全部装入内存，需要频繁与磁盘交换数据。 B+ 树B+树是 B 树的一种变体，也是目前数据库和文件系统索引的事实标准。 它与 B 树的主要区别在于：首先，它的所有数据记录都只存储在叶子节点上，内部节点只存放键作为导航用的索引；其次，叶子节点之间通过指针相连形成了一个有序链表。 这样的设计带来了几个巨大优势：一是内部节点能存放更多的键，使得树更矮，查询需要的磁盘 I&#x2F;O 更少；二是范围查询性能极高，一旦找到范围的起点，只需顺着叶子节点的链表遍历即可，而不需要像 B 树那样回溯到上层节点。 所以 MySQL 的 InnoDB 引擎、MongoDB、以及几乎所有关系型数据库的索引都在用 B+树。 红黑树红黑树则是一种二叉平衡搜索树，它通过复杂的旋转和变色规则来维持大致的平衡，确保从根到任意叶子节点的最长路径不会超过最短路径的两倍，从而保证了最坏情况下搜索、插入、删除操作的时间复杂度都是 $O(log n)$。 它的主要优势在于内存中操作的效率非常高，且维护平衡的代价相对于严格的 AVL 树更小（旋转次数更少）。 因此，它的应用场景主要集中在内存计算领域，比如 C++ STL 中的 map 和 set 就是用红黑树实现的，此外还有 Linux 系统的进程调度器 Completely Fair Scheduler (CFS) 也用红黑树来管理进程队列。 91. 智能指针申请的空间是在堆上还是在栈上？智能指针（unique_ptr、shared_ptr）本身是一个栈上的对象，但它所管理的内存是在堆上申请的。 92. 介绍下 vector 动态扩容机制std::vector 的动态扩容机制是其核心特性之一，旨在平衡内存使用与操作效率。 其本质在于管理三个核心属性：size（当前元素数量）、capacity（当前分配的内存可容纳的元素数量）和分配策略（通常按固定因子增长，如2倍或1.5倍）。 当执行 push_back 或 emplace_back 等插入操作时，若当前 size 已达到 capacity，则触发扩容流程： 计算新容量：根据预定义的增长因子（Growth Factor，通常为2）确定新的容量值（new_capacity = old_capacity * growth_factor）。 分配新内存：在自由存储区（堆）上申请一块更大的、连续的内存空间，其大小足以容纳 new_capacity 个元素。 迁移数据：将原有内存中的所有元素移动（若移动构造函数为 noexcept）或拷贝到新内存的起始位置。此步骤会调用各元素的构造函数，是扩容过程中开销最大的操作，时间复杂度为 O(N)。 释放旧内存：销毁原内存中的对象并释放原有内存块。 更新内部状态：将内部指针指向新内存块，并将 capacity 更新为 new_capacity，最后在尾部构造新插入的元素。 此机制确保了插入操作的摊还时间复杂度为 O(1)。尽管单次扩容成本较高，但由于容量呈指数级增长，扩容频率迅速下降，从而将总成本均摊到多次操作上。 需要注意的是，扩容会使所有指向原 vector 元素的迭代器、指针和引用失效，因为数据的存储地址已发生改变。因此，在已知元素数量的场景下，使用 reserve() 预先分配足够容量是避免多次冗余扩容、提升性能的最佳实践。 93. vector 的 push_back 和 emplace_back 的区别？push_back 和 emplace_back 的核心区别在于构造对象的时机和方式。 push_back 接受一个已存在的对象，并将其拷贝（左值）或移动（右值）到容器末尾，这个过程中可能产生临时对象的开销。 emplace_back 则直接接受构造参数，通过完美转发在容器末尾的内存中原地构造对象，省去了创建临时对象的步骤，避免了不必要的拷贝或移动操作，因此性能更高。 在大多数情况下，尤其是插入临时对象或构造代价较高的对象时，应优先选用 emplace_back。 94. 关于 vector 迭代器失效当 vector 的底层存储发生改变，尤其是内存重新分配时，指向其元素的迭代器、指针和引用都会变得不可用。 以下是导致 vector 迭代器失效的几种主要情况： 1. 插入元素 (insert, emplace, push_back, emplace_back)插入操作是否导致迭代器失效，取决于是否触发了重新分配（Reallocation）。 导致重新分配：如果插入新元素后，size() 超过了 capacity()，vector 会申请一块新的更大的内存，并将所有现有元素移动或拷贝到新内存中，然后释放旧内存。 后果：所有迭代器、指针、引用都会失效，包括 begin(), end() 以及所有指向元素的迭代器。 未导致重新分配：如果插入后 size() &lt;= capacity()，则只需要将插入点之后的所有元素向后移动。 后果：所有指向插入点之后元素的迭代器、指针、引用都会失效。插入点之前的迭代器仍然有效。 2. 删除元素 (erase, pop_back)删除元素会改变序列，为了保持内存连续，需要将被删除元素之后的所有元素向前移动。 后果：所有指向被删除元素及其之后元素的迭代器、指针、引用都会失效。被删除元素之前的迭代器仍然有效。 特别注意：erase() 函数会返回一个指向被删除元素之后第一个有效元素的新迭代器，你可以利用它来安全地继续遍历。 3. 改变容量 (reserve, resize, shrink_to_fit)任何可能改变 vector 容量（capacity）的操作都可能引起内存重新分配。 reserve(n)：如果 n &gt; capacity()，则会申请新内存并进行数据迁移，导致全部失效。 shrink_to_fit()：请求减少容量以匹配大小，实现可能会进行重新分配，导致全部失效。 resize(n)： 如果 n &gt; capacity()（需要扩容），则全部失效。 如果只是增大 size() 但未触发重分配，则 end() 迭代器会失效。 如果是减小 size()，则被“抹去”的那些元素的迭代器会失效。 4. 交换 (swap)当两个 vector 进行交换时，它们的底层数据指针会互换。 迭代器、指针、引用不会失效，但它们会交换归属。原来指向容器 A 中元素的迭代器，在交换后指向的是容器 B 中的元素，反之亦然。 5. 清空 (clear)clear() 函数会移除所有元素，并将 size() 设为 0。它不保证会改变 capacity()。 所有指向被清除元素的迭代器、指针、引用都会失效。因为元素对象已经被销毁了。 95. C++ 不同权限继承分别会有怎样的表现？C++ 的继承有 public、protected、private 三种方式： public 继承：基类的 public 成员仍然是 public，protected 成员仍然是 protected； protected 继承：基类的 public 和 protected 成员都变成 protected； private 继承：基类的 public 和 protected 成员都变成 private。 96. 单例模式的概念和实现？懒汉式&#x2F;饿汉式？线程安全？ 概念 单例模式（Singleton）是一种创建型设计模式，保证一个类在系统中只有一个实例，并提供一个全局访问点。 典型实现方式是将构造函数设为 private，在类内维护一个静态指针或引用，并通过一个 static 方法获取实例。 这样可以确保外部无法随意构造对象，而只能通过该方法获得同一个实例。 懒汉式：在第一次调用 getInstance() 时才创建实例，节省内存，但需要考虑多线程时的同步问题。 饿汉式：在程序启动时就初始化实例，线程安全且实现简单，但可能造成资源浪费。 线程安全懒汉式：通常通过加锁（如 mutex）或使用双重检查锁（DCLP）来保证多线程下实例只被创建一次，同时避免每次访问都加锁带来的性能损耗。 97. 虚函数定义为析构函数能避免内存泄露的实现原理是什么？当基类指针指向派生类对象并通过 delete 释放时，如果基类的析构函数不是虚函数，那么只会调用基类析构函数，派生类部分无法正确析构，导致资源未释放从而造成内存泄露。而将析构函数声明为虚函数后，析构时会触发虚函数表的动态绑定，先调用派生类的析构函数，再调用基类析构函数，确保对象的所有资源被正确释放。 更多内容，请关注牛客面经～…","tags":["C++","面经","八股文"],"categories":["秋招指南"]},{"title":"✍️ 八股文 @ 操作系统","path":"/post/秋招指南/2025-os/","content":"1. 进程、线程、协程的区别？进程提供强隔离但开销大，线程平衡了资源共享和调度效率，协程则以极低开销实现高并发但局限于单线程内。 实际应用中可根据任务需求（计算密集型 vs. I&#x2F;O 密集型）、隔离性要求和性能目标选择合适机制。 进程进程是操作系统进行资源分配和保护的基本单位。 每个进程拥有独立的虚拟地址空间、文件描述符、系统资源（如打开的文件和信号处理程序）以及安全上下文（例如用户 ID 和权限）。 进程之间的内存空间是隔离的，一个进程的崩溃通常不会直接影响其他进程，这种隔离性提高了系统的稳定性和安全性。 进程间的通信（IPC）需要借助操作系统提供的机制，如管道、消息队列、共享内存或套接字，这些方式通常涉及较高的开销。 进程的创建和销毁需要分配或回收大量资源（如页表和文件描述符表），上下文切换时需保存和恢复完整的 CPU 状态（包括寄存器、内存映射等），因此效率较低。 🔥【场景】进程适用于需要强隔离性的任务，例如运行独立的应用程序或服务。 线程线程是进程内的执行单元，一个进程可以包含多个线程。 所有线程共享同一进程的地址空间和系统资源（如全局变量、打开的文件和堆内存），但每个线程拥有独立的栈空间、寄存器状态和线程局部存储。 由于共享内存，线程间可以直接读写同一数据，但这也引入了竞态条件和数据一致性问题，因此必须使用同步机制（如互斥锁、信号量或条件变量）来协调访问。 线程的创建和上下文切换由操作系统内核调度器管理，切换时只需保存和恢复线程独有的状态（如栈指针和寄存器），开销比进程小，但仍需在用户态和内核态之间切换。 🔥【场景】线程适合用于需要共享数据的并发任务，例如图形界面应用中的后台计算或 I&#x2F;O 操作。 协程协程是一种用户态的轻量级线程，其调度完全由程序控制（而非操作系统内核）。 协程在同一个线程内执行，共享该线程的所有资源，但拥有独立的栈上下文（通常大小可自定义且远小于线程栈）。 协程的切换无需陷入内核，而是通过代码中的显式让步（yield）或事件循环来触发，仅需保存和恢复少量寄存器状态（如程序计数器和栈指针），因此开销极低，每秒可支持百万次切换。 然而，协程无法利用多核 CPU 的并行能力，若需跨核执行仍需结合多线程或多进程。 🔥【场景】协程适用于高并发的 I&#x2F;O 密集型任务（如网络服务或异步编程），通过非阻塞操作和协作式调度最大化 CPU 利用率。 2. 进程通信的方式是什么？进程间通信（IPC）用于在不同进程之间传递数据和信号，常见的 IPC 方式包括： 管道（匿名&#x2F;命名） 消息队列 共享内存 信号量 信号 Socket 套接字 匿名管道是一种半双工的通信方式，数据只能单向流动，通常用于具有亲缘关系的进程之间，例如父子进程。它可以看成是一种特殊的文件，但只存在于内存中。 命名管道与管道类似，但它提供了一个路径名与之关联，允许无亲缘关系的进程之间进行通信。 消息队列是消息的链表，存放在内核中并由消息队列标识符标识。它允许一个或多个进程向队列中写入消息，其他进程从队列中读取消息，克服了管道只能承载无格式字节流以及缓冲区大小受限等缺点。 共享内存允许多个进程访问同一块内存空间，这是最快的一种进程通信方式，因为数据不需要在进程之间复制。但需要配合信号量等同步机制来避免多个进程同时读写时造成的冲突。 信号量是一个计数器，用于控制多个进程对共享资源的访问，通常作为一种锁机制来防止多个进程同时访问一个共享资源。 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生，比如中断处理。 套接字是一种通用的进程间通信机制，不仅可用于同一台机器上的进程通信，也可用于不同机器之间的网络通信。它支持多种协议，如 TCP 和 UDP，提供了灵活而强大的通信能力。 3. 线程通信&#x2F;同步的方式是什么？Linux 系统提供了五种用于线程通信的方式：互斥锁、读写锁、条件变量、自旋锁和信号量。 互斥锁（Mutex）：互斥量从本质上说是一把锁，在访问共享资源前对互斥量进行加锁，在访问完成后释放互斥量上的锁。对互斥量进行加锁以后，任何其他试图再次对互斥锁加锁的线程将会阻塞直到当前线程释放该互斥锁。如果释放互斥锁时有多个线程阻塞，所有在该互斥锁上的阻塞线程都会变成可运行状态，第一个变为运行状态的线程可以对互斥锁加锁，其他线程将会看到互斥锁依然被锁住，只能回去再次等待它重新变为可用。 条件变量（Condition Variables）：条件变量是在多线程程序中用来实现 “等待–&gt;唤醒” 逻辑常用的方法。条件变量利用线程间共享的全局变量进行同步的一种机制，主要包括两个动作：一个线程等待”条件变量的条件成立”而挂起；另一个线程使“条件成立”。为了防止竞争，条件变量的使用总是和一个互斥锁结合在一起。线程在改变条件状态前必须首先锁住互斥量，函数 pthread_cond_wait 把自己放到等待条件的线程列表上，然后对互斥锁解锁（这两个操作是原子操作）。在函数返回时，互斥量再次被锁住。 自旋锁（Spinlock）：自旋锁通过 CPU 提供的 CAS 函数（Compare And Swap），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。一般加锁的过程，包含两个步骤：第一步，查看锁的状态，如果锁是空闲的，则执行第二步；第二步，将锁设置为当前线程持有。使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。CAS 函数就把这两个步骤合并成一条硬件级指令，形成原子指令，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。这里的「忙等待」可以用 while 循环等待实现，不过最好是使用 CPU 提供的 PAUSE 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。 信号量（Semaphores）：信号量可以是命名的（有名信号量）或无名的（仅限于当前进程内的线程），用于控制对资源的访问次数。通常信号量表示资源的数量，对应的变量是一个整型（sem）变量。另外，还有两个原子操作的系统调用函数来控制信号量的，分别是：P 操作：将 sem 减 1，相减后，如果 sem &lt; 0，则进程&#x2F;线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；V 操作：将 sem 加 1，相加后，如果 sem &lt;&#x3D; 0，唤醒一个等待中的进程&#x2F;线程，表明 V 操作不会阻塞； 读写锁（Read-Write Locks）：读写锁从字面意思我们也可以知道，它由「读锁」和「写锁」两部分构成，如果只读取共享资源用「读锁」加锁，如果要修改共享资源则用「写锁」加锁。所以，读写锁适用于能明确区分读操作和写操作的场景。读写锁的工作原理是：当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。所以说，写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线程同时持有。知道了读写锁的工作原理后，我们可以发现，读写锁在读多写少的场景，能发挥出优势。 屏障（Barrier）：同步多个线程的执行阶段，所有线程到达屏障点后才继续执行（如 pthread_barrier_wait）。 总结，线程通信方式主要依赖于共享内存下的各种同步原语和消息传递机制，这些机制协同工作保证了线程间数据的正确性和程序的并发性。 4. 进程上下文切换会发生什么？进程上下文切换场景有哪些？发生进程切换时操作系统会： 保存当前进程上下文：操作系统将当前运行进程的 CPU 状态（包括程序计数器、寄存器内容、栈指针、内存映射表等）保存到其进程控制块（PCB）中。 调度新进程：调度器从就绪队列中选择下一个要运行的进程，并加载其 PCB 中存储的上下文信息。 恢复新进程上下文：将新进程的寄存器值、程序计数器、栈指针等重新载入 CPU，并切换内存地址空间（更新页表寄存器或 TLB）。 切换内核栈：将内核栈指针指向新进程的内核栈，确保系统调用和中断处理能正确执行。 更新系统状态：刷新进程调度相关数据（如时间戳、优先级），并可能处理信号或待处理中断。 进程上下文切换有哪些场景： 时间片耗尽：当前进程用完调度器分配的时间片（如 CFS 调度器），被迫让出 CPU。 更高优先级进程就绪：高优先级进程进入可运行状态（如实时任务），抢占当前低优先级进程。 主动阻塞：进程因等待资源（如 I&#x2F;O 操作完成、互斥锁释放、信号量申请）主动放弃 CPU。 中断处理：硬件中断（如磁盘读写完成、网络包到达）触发中断服务程序，可能唤醒其他高优先级进程。 系统调用返回：某些系统调用（如阻塞式 read）返回时，内核可能调度其他进程。 异常事件：进程触发异常（如缺页故障），需等待操作系统处理完毕后再恢复执行。 5. 平时会看哪些系统指标？常看这些核心系统指标： CPU 相关指标：CPU 使用率（包括用户态、内核态、空闲时间）、负载平均值（load average）反映系统整体负载压力，上下文切换次数（context switches）和中断频率（interrupts）可帮助判断调度开销和硬件活动。 内存相关指标：内存使用率、可用内存（available memory）、交换分区使用情况（swap usage）以及页错误率（page faults）和内存换入&#x2F;换出（swap in&#x2F;out）能揭示内存压力与潜在瓶颈。 磁盘 I&#x2F;O 指标：磁盘利用率、读写吞吐量（throughput）、IOPS（每秒 I&#x2F;O 操作数）以及响应时间（latency）和队列深度（queue depth）可用于评估存储性能是否达标。 网络相关指标：网络接口的带宽使用率、数据包发送&#x2F;接收速率、错误包和丢包率（packet loss）、TCP 连接数及重传率能反映网络连通质量和负载。 进程与线程指标：运行中进程数量、线程数量、僵尸进程（zombie processes）以及关键进程的 CPU 和内存占用情况。 系统整体指标：启动时间、系统调用频率（system calls）、文件描述符使用量（file descriptors）以及温度与电源状态（适用于物理机）。 可通过 top、vmstat、iostat、netstat、dstat、htop、pidstat、sar 等工具查看。 6. CPU 中断数量怎么看？如果 CPU 中断数量分配不均匀怎么办？一、如何查看中断数量？1cat /proc/interrupts 每一行是一个中断源（如网卡、定时器、磁盘等） 每列是一个 CPU 核心 数字表示该中断在某 CPU 上被处理的次数 二、什么是“中断不均匀”？ 某个中断（特别是网卡）集中在某个 CPU 上处理 导致该核负载高、其他核闲置 常见于 网卡中断（eth0）偏向 CPU 0 三、怎么解决中断不均匀？ 一句话：可以绑中断到线程还是进程，然后再绑核。 方法一：中断绑定（IRQ Affinity） 绑定中断到特定 CPU 核，或进行负载均衡： 1echo 2 &gt; /proc/irq/XX/smp_affinity # 绑定到 CPU1 2 表示 CPU1，1 表示 CPU0，3 表示 CPU0+CPU1（按位） 可以用脚本自动平衡多个中断源到多个核上。 方法二：使用 RPS &#x2F; RFS（软中断调度） RPS：Receive Packet Steering，用于软中断在多核间分散 配置 /sys/class/net/eth0/queues/rx-*/rps_cpus 指定核 方法三：开启多队列网卡（RSS） RSS（Receive Side Scaling）：硬件级多队列分发中断 需网卡和驱动支持，查看： 12ethtool -l eth0 # 查看队列ethtool -x eth0 # 查看中断队列分配 CPU 中断不均衡会导致某核过载，通过 IRQ 绑定、RPS&#x2F;RFS、RSS 技术可将中断负载均衡到多个 CPU，提高性能。 7. 用户态和内核态的区别？内核态和用户态是操作系统中的两种运行模式。它们的主要区别在于权限和可执行的操作： 在用户态下，进程仅能执行非特权指令，无法直接访问硬件设备或敏感的内核资源（如内存管理单元、I&#x2F;O 端口），若需执行特权操作（如文件读写、网络通信）必须通过系统调用接口向内核发起请求，由内核代理完成。这种模式限制了用户程序的行为，防止其意外破坏系统或其他进程。 在内核态下，代码可执行所有CPU指令（包括特权指令），直接操作硬件资源（如内存分配、设备驱动管理），并完全控制系统关键数据结构（如进程调度表、文件系统缓存）。操作系统内核及部分底层驱动运行于此模式，确保核心任务的完整性和高效性。 内核态的底层操作主要包括：内存管理、进程管理、设备驱动程序控制、系统调用等。这些操作涉及到操作系统的核心功能，需要较高的权限来执行。 两种模式的切换通过硬件陷阱机制（如软中断、系统调用）触发：当用户程序发起系统调用时，CPU 自动从用户态切换到内核态，内核完成请求后返回结果并切换回用户态。这种设计既隔离了用户程序的错误影响，又保证了系统服务的可控提供。 分为内核态和用户态的原因主要有以下几点： 安全性：通过对权限的划分，用户程序无法直接访问硬件资源，从而避免了恶意程序对系统资源的破坏。 稳定性：用户态程序出现问题时，不会影响到整个系统，避免了程序故障导致系统崩溃的风险。 隔离性：内核态和用户态的划分使得操作系统内核与用户程序之间有了明确的边界，有利于系统的模块化和维护。 8. 你说到进程是分配资源的基本单位，那么这个资源指的是什么？虚拟内存、CPU 时间片、文件句柄、信号量等资源。 9. 进程切换和线程切换的区别？进程切换涉及完整的上下文切换，包括保存和恢复进程的私有资源，如虚拟内存地址空间（需切换页表或刷新 TLB）、寄存器状态、内核栈、文件描述符表以及信号处理设置等。因为进程拥有独立的地址空间，切换后需要更新内存管理单元（MMU）的映射关系，这一操作通常需要较长时间且可能因 TLB 失效导致性能下降。此外，进程切换必然需要从用户态陷入内核态，由操作系统调度器完成。 线程切换则发生在同一进程内部，因此无需切换虚拟地址空间（页表保持不变）、文件描述符表等进程级资源。只需保存和恢复线程的私有上下文，如寄存器值、栈指针以及线程局部存储。由于资源共享，线程切换的开销显著低于进程切换，且在某些情况下（如用户级线程）甚至无需陷入内核，由用户空间的线程库即可完成调度。 10. 进程的五种状态如何切换（进程状态图）？ 一个完整的进程状态的变迁如下图： 再来详细说明一下进程的状态变迁： NULL -&gt; 创建状态：一个新进程被创建时的第一个状态； 创建状态 -&gt; 就绪状态：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的； 就绪态 -&gt; 运行状态：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程； 运行状态 -&gt; 结束状态：当进程已经运行完成或出错时，会被操作系统作结束状态处理； 运行状态 -&gt; 就绪状态：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行； 运行状态 -&gt; 阻塞状态：当进程请求某个事件且必须等待时，例如请求 I&#x2F;O 事件； 阻塞状态 -&gt; 就绪状态：当进程要等待的事件完成时，它从阻塞状态变到就绪状态； 11. 64 bits 的 Linux 默认栈大小？在 64 位的 Linux 系统上，默认的线程栈大小通常是 8 MB。这个值并不是由内核直接规定的，而是取决于具体的 pthread 线程库的实现（比如 glibc），大多数主流发行版都将其默认设置为 8 MB。 你可以通过命令 ulimit -s 来查看当前 shell 环境下线程栈的默认大小（以 KB 为单位），通常它显示为 8192。需要注意的是，这个 ulimit 设置是针对进程的主线程以及由当前 shell 启动的程序的新线程的默认值，而在程序中通过 pthread_create 创建新线程时，如果不显式指定栈大小，也会默认使用这个 8 MB 的值。 12. 进程调度算法有哪些？1️⃣ 先来先服务调度算法最简单的一个调度算法，就是非抢占式的先来先服务算法。每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。 FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I&#x2F;O 繁忙型作业的系统。 2️⃣ 最短任务优先调度算法最短作业优先调度算法同样也是顾名思义，它会优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。这显然对长作业不利，很容易造成一种极端现象。比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行（饥饿）。 3️⃣ 高响应比优先调度算法前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。 而高响应比优先调度算法主要是权衡了短作业和长作业。 每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式：$$优先权&#x3D;\\frac{等待时间+要求服务时间}{要求服务时间}$$从上面的公式，可以发现： 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行； 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会。 4️⃣ 时间片轮转调度算法最古老、最简单、最公平且使用最广的算法就是时间片轮转调度算法。 每个进程被分配一个时间段，称为时间片（Quantum)，即允许该进程在该时间段中运行。 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程； 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换； 另外，时间片的长度就是一个很关键的点： 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率； 如果设得太长又可能引起对短作业进程的响应时间变长。 通常时间片设为 20ms~50ms 通常是一个比较合理的折中值。 5️⃣ 最高优先级调度算法前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。 但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级调度算法。 进程的优先级可以分为，静态优先级或动态优先级： 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化； 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。 该算法也有两种处理优先级高的方法，非抢占式和抢占式： 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。 但是依然有缺点，可能会导致低优先级的进程永远不会运行。 6️⃣ 多级反馈队列调度算法多级反馈队列调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。 顾名思义： 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列 来看看，它是如何工作的： 设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短； 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成； 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行； 可以发现，对于短作业可能可以在第一级队列很快被处理完。 对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。 13. 除了互斥锁你还知道什么锁？分别应用于什么场景？还有读写锁、自旋锁、条件变量、信号量。 读写锁：读写锁允许多个线程同时读取共享资源，但只允许一个线程进行写操作。适用于读操作频繁、写操作较少的场景，可以提高并发性能。 自旋锁：自旋锁是一种忙等待锁，线程在获取锁时不会进入阻塞状态，而是循环忙等待直到获取到锁。适用于临界区很小且锁的持有时间很短的场景，避免线程频繁切换带来的开销。 条件变量：条件变量用于线程间的同步和通信。它通常与互斥锁一起使用，线程可以通过条件变量等待某个条件满足，当条件满足时，其他线程可以通过条件变量发送信号通知等待线程。 信号量：信号量是一种计数器，用于控制对共享资源的访问。它可以用来限制同时访问资源的线程数量，或者用语线程间的同步。 14. 死锁发生条件是什么？死锁只有同时满足以下四个条件才会发生： 互斥条件：互斥条件是指多个线程不能同时使用同一个资源。 持有并等待条件：持有并等待条件是指，当线程 A 已经持有了资源 1，又想申请资源 2，而资源 2 已经被线程 C 持有了，所以线程 A 就会处于等待状态，但是线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1。 不可剥夺条件：不可剥夺条件是指，当线程已经持有了资源 ，在自己使用完之前不能被其他线程获取，线程 B 如果也想使用此资源，则只能在线程 A 使用完并释放后才能获取。 环路等待条件：环路等待条件指的是，在死锁发生的时候，两个线程获取资源的顺序构成了环形链。 15. 如何避免死锁？避免死锁问题就只需要破环其中一个条件就可以，最常见的并且可行的就是使用资源有序分配法，来破环环路等待条件。 那什么是资源有序分配法呢？线程 A 和 线程 B 获取资源的顺序要一样，当线程 A 是先尝试获取资源 A，然后尝试获取资源 B 的时候，线程 B 同样也是先尝试获取资源 A，然后尝试获取资源 B。也就是说，线程 A 和 线程 B 总是以相同的顺序申请自己想要的资源。 16. 聊一聊银行家算法系统发生死锁是很正常的，我们需要主动去预防死锁，即进行有序的资源分配，使用银行家算法。 银行家算法是最有代表性的避免死锁的算法。 为什么叫银行家算法呢？就是这个算法的逻辑很像银行放贷的逻辑，也就是尽可能避免坏账的出现。 银行家算法的业务逻辑如下。 不负荷执行：一个进程的最大需求量不超过系统拥有的总资源数，才会被接纳执行。 可分期：一个进程可以分期请求资源，但总请求书不可超过最大需求量。 推迟分配：当系统现有资源数小于进程需求时，对进程的需求可以延迟分配，但总让进程在有限时间内获取资源。 听起来有点绕，我们还是举个例子来说明：假如系统中有三类互斥资源 R1、R2、R3，可用资源数分别是 9、8、5，在指定时刻有 P1、P2、P3、P4 和 P5 这五个进程，这些进程的对三类互斥资源的最大需求量和已分配资源数如下表所示，那么系统如何先后运行这五个进程，不会发生死锁问题？ 进程 最大需求量（R1、R2、R3） 已分配资源数（R1、R2、R3） P1 6 5 2 1 2 1 P2 2 2 1 2 1 1 P3 8 1 1 2 1 0 P4 1 2 1 1 2 0 P5 3 4 4 1 1 3 首先分析首次需求的资源，系统剩余可用资源数分别是 2、1、0，各进程需要的资源数如下表所示。 资源 R1 的剩余可用资源数 &#x3D; 9 - 1 - 2 - 2 - 1 - 1 &#x3D; 2。 资源 R2 的剩余可用资源数 &#x3D; 8 - 2 - 1 - 1 - 2 - 1 &#x3D; 1。 资源 R3 的剩余可用资源数 &#x3D; 5 - 1 - 1 - 0 - 0 - 3 &#x3D; 0。 进程 最大需求量 已分配资源数 首次分配需要的资源数（前者-后者） P1 6 5 2 1 2 1 5 3 1 P2 2 2 1 2 1 1 0 1 0 P3 8 1 1 2 1 0 6 0 1 P4 1 2 1 1 2 0 0 0 1 P5 3 4 4 1 1 3 2 3 1 根据银行家算法不负荷原则【一个进程的最大需求量不超过系统拥有的总资源数，才会被接纳执行】，优先给进程 P2 执行，因为剩余的 0 1 0 资源够让 P2 执行。 经过一系列分析和资源试分配后… 得到安全执行顺序为 p2 =&gt; p4 =&gt; p5 =&gt; p1 =&gt; p3 或 p2 =&gt; p4 =&gt; p5 =&gt; p3 =&gt; p1。 银行家算法的核心思想，就是在分配给进程资源前，首先判断这个进程的安全性，也就是预执行，判断分配后是否产生死锁现象。如果系统当前资源能满足其执行，则尝试分配，如果不满足则让该进程等待。 通过不断检查剩余可用资源是否满足某个进程的最大需求，如果可以则加入安全序列，并把该进程当前持有的资源回收；不断重复这个过程，看最后能否实现让所有进程都加入安全序列。安全序列一定不会发生死锁，但没有死锁不一定是安全序列。 17. 乐观锁和悲观锁有什么区别？乐观锁（不加锁、匹配版本号或时间戳、适用读多写少、无锁编程）： 基本思想：乐观锁假设多个事务之间很少发生冲突，因此在读取数据时不会加锁，而是在更新数据时检查数据的版本（如使用版本号或时间戳），如果版本匹配则执行更新操作，否则认为发生了冲突。 使用场景：乐观锁适用于读多写少的场景，可以减少锁的竞争，提高并发性能。例如，数据库中的乐观锁机制可以用于处理并发更新同一行数据的情况。 悲观锁（加锁、适用写多）： 基本思想：悲观锁假设多个事务之间会频繁发生冲突，因此在读取数据时会加锁，防止其他事务对数据进行修改，直到当前事务完成操作后才释放锁。 使用场景：悲观锁适用于写多的场景，通过加锁保证数据的一致性。例如，数据库中的行级锁机制可以用于处理并发更新同一行数据的情况。 乐观锁适用于读多写少的场景，通过版本控制来处理冲突；而悲观锁适用于写多的场景，通过加锁来避免冲突。 互斥锁、自旋锁、读写锁，都是属于悲观锁。 这里举一个场景例子：在线文档。 我们都知道在线文档可以同时多人编辑的，如果使用了悲观锁，那么只要有一个用户正在编辑文档，此时其他用户就无法打开相同的文档了，这用户体验当然不好了。 那实现多人同时编辑，实际上是用了乐观锁，它允许多个用户打开同一个文档进行编辑，编辑完提交之后才验证修改的内容是否有冲突。 怎么样才算发生冲突？这里举个例子，比如用户 A 先在浏览器编辑文档，之后用户 B 在浏览器也打开了相同的文档进行编辑，但是用户 B 比用户 A 提交早，这一过程用户 A 是不知道的，当 A 提交修改完的内容时，那么 A 和 B 之间并行修改的地方就会发生冲突。 服务端要怎么验证是否冲突了呢？通常方案如下： 由于发生冲突的概率比较低，所以先让用户编辑文档，但是浏览器在下载文档时会记录下服务端返回的文档版本号； 当用户提交修改时，发给服务端的请求会带上原始文档版本号，服务器收到后将它与当前版本号进行比较，如果版本号不一致则提交失败，如果版本号一致则修改成功，然后服务端版本号更新到最新的版本号。 实际上，我们常见的 SVN 和 Git 也是用了乐观锁的思想，先让用户编辑代码，然后提交的时候，通过版本号来判断是否产生了冲突，发生了冲突的地方，需要我们自己修改后，再重新提交。 乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。 18. 虚拟内存？虚拟地址空间？使用虚拟内存的优点？虚拟内存是一种内存管理技术，它会使程序自己认为自己拥有一块很大且连续的内存，而实际上这些内存可能分布在物理内存和磁盘上，在需要时进行数据交换。 优点： 通过分页和交换技术，将暂时不用的内存页暂存到磁盘，可以弥补物理内存大小的不足； 保证进程之间的隔离性和安全性（检测并防止内存访问越界等）； 虚拟内存空间连续，简化了编程和内存管理，无需关心物理内存的实际分布情况； 支持共享内存，不同进程的虚拟地址可映射到相同的物理内存页，实现高效的数据共享。 缺点： 当系统物理内存不足时，操作系统需要将部分页面写入磁盘（换出）并从磁盘中加载需要的页面（换入），这会带来较高的磁盘 I&#x2F;O 开销，严重时会导致“抖动”，使系统响应速度下降； 虚拟内存还需要维护页表来管理虚拟地址与物理地址之间的映射，这也会占用一定的内存和 CPU 资源。 虚拟地址空间是针对于每个单一进程所能访问的内存地址范围，通常被划分为代码段、数据段、堆、栈和内存映射区域等部分。 19. 介绍一下操作系统内存管理操作系统设计了虚拟内存，每个进程都有自己的独立的虚拟内存，我们所写的程序不会直接与物理内打交道。Linux 是通过对内存分页的方式来管理内存，分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小，每一页的大小为 4KB，虚拟地址与物理地址之间通过页表来映射，页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的工作。而当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。 20. 程序的内存布局是怎样的？ 通过这张图你可以看到，用户空间内存，从低到高分别是 6 种不同的内存段： 代码段：包括二进制可执行代码，通常只读，还可共享（多个进程运行同一程序时只存一份）； 静态存储区：数据段 + BSS 段 数据段：包括已初始化的静态常量和全局变量； BSS 段：包括未初始化的静态变量和全局变量； 堆（比如 malloc/new）：包括动态分配的内存，从低地址开始向上增长，程序员负责管理，容易泄露； 文件映射区（比如 mmap）：包括共享库、文件映射、匿名映射、共享内存等； 栈：包括局部变量和函数调用的上下文（参数、返回地址）等，函数调用或返回会自动分配与释放后。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小； 内核空间（对用户程序不可见） 上图中的内存布局可以看到，代码段下面还有一段内存空间的（灰色部分），这一块区域是「保留区」，之所以要有保留区这是因为在大多数的系统里，我们认为比较小数值的地址不是一个合法地址，例如，我们通常在 C 的代码里会将无效的指针赋值为 NULL。因此，这里会出现一段不可访问的内存保留区，防止程序因为出现 bug，导致读或写了一些小内存地址的数据，而使得程序跑飞。 🔥 在这 7 个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 malloc() 或者 mmap()，就可以分别在堆和文件映射段动态分配内存。 21. 堆与栈的区别，以及各自优缺点？栈由编译器自动管理，内存分配和释放通过指针的移动完成，速度极快。它用于存储局部变量、函数参数和返回地址，数据遵循后进先出的顺序，生命周期与函数调用周期一致，函数结束时自动释放。栈的大小通常有限，过度使用可能导致栈溢出。 堆由程序员手动管理，内存分配和释放需要显式操作，速度相对较慢。它用于动态分配的内存，生命周期由程序员控制，数据无需遵循特定顺序，但管理不当可能导致内存泄漏或碎片化。堆的大小受系统虚拟内存限制，容量远大于栈。 栈的优点是高效且无碎片，但容量有限且灵活性低；堆的优点是容量大且灵活，但管理复杂且容易引发错误。 22. fork() 会复制哪些东西当调用 fork() 创建子进程时，操作系统会复制父进程的整个虚拟地址空间（包括代码、数据、堆和栈）、执行上下文（如寄存器状态）、打开的文件描述符表、信号处理设置、进程权限属性以及资源限制配置，形成一份几乎完全相同的副本。不过，子进程会拥有独立的进程 ID 和父进程 ID，且不会继承父进程的未决信号、定时器或文件锁。 现代系统通过写时复制 COW 技术优化性能：初始时父子进程共享物理内存页，仅当任一进程尝试修改某页时，内核才为该页创建实际副本，从而避免不必要的内存复制开销。 23. 写时复制是什么？节省了哪些资源？ 写时复制（Copy-on-Write, COW）是一种高效的内存管理优化技术，其核心思想是允许多个进程或线程共享同一份物理内存数据，直到其中某个进程试图修改这些数据时，系统才会为该进程分配新的物理内存并复制原始数据，从而避免不必要的提前复制开销。 在具体实现中，当父进程调用 fork() 创建子进程时，操作系统并不会立即复制父进程的整个地址空间到新的物理内存中，而是让子进程共享父进程的物理内存页，同时将这些页标记为写时复制状态。此时，父子进程的页表项均指向相同的物理内存页，但权限被设置为只读。当任一进程（父进程或子进程）尝试对共享页进行写操作时，会触发页错误异常（page fault），内核中的页错误处理程序会识别这是由写时复制引起的，随后为执行写操作的进程分配一个新的物理页，复制原始数据内容，并更新该进程的页表以指向新页且恢复可写权限，最后重新执行导致异常的写指令。 写时复制技术显著减少了进程创建（如 fork()）和内存复制（如 mmap() 私有映射）的开销，尤其在大内存进程中效果明显，因为它延迟了实际复制操作到真正需要时才发生，节省了时间和物理内存资源。典型的应用场景包括快速进程创建、内存快照、虚拟机管理及某些数据结构（如字符串实现中的共享缓冲区）。 24. malloc 1KB 和 1MB 有什么区别？1KB（小内存）：通常通过 glibc 的 ptmalloc 分配器从线程的本地缓存（fast bins 或 small bins） 中直接分配，这些缓存来源于预先从堆（heap）中申请的内存块（chunk）。分配速度快，无需直接与内核交互。 1MB（大内存）：可能超过 mmap 阈值（默认一般为 128KB），分配器会直接使用 mmap 系统调用从操作系统中申请独立的内存映射区域，而非从堆区分配。释放时同样通过 munmap 直接返还操作系统。 25. free 释放内存会归还给操作系统吗？free() 的行为并不是由 C 语言标准直接规定的，而是由底层的内存管理器（通常是 glibc 的 malloc 实现，即 ptmalloc2）决定的。它的核心目标是平衡性能（减少系统调用和锁竞争）和内存效率。 当我们调用 free 函数释放一块动态分配的内存时，这个过程并非简单直接地将内存交还给操作系统，而是由底层的内存管理器（如 glibc 中的 ptmalloc）负责处理。具体来说，内存管理器会将被释放的内存块标记为空闲状态，并保留在进程的堆空间中，ptmalloc 将其加入到自己的空闲内存双向链表中。这样做的目的是为了优化性能：如果程序后续再次申请类似大小的内存，管理器可以迅速从空闲链表中分配一块，避免了频繁向操作系统申请内存的系统调用开销，同时 ptmalloc 也会尝试对小块内存进行合并，避免过多的内存碎片。 只有在某些特定条件下，内存管理器才会将内存真正归还给操作系统。例如，当释放的内存块非常大（比如超过 128KB，这类大块内存通常由 mmap 分配而非堆分配）时，管理器可能会直接使用 munmap 系统调用将其释放回操作系统。此外，如果堆顶（即堆空间的末端）存在大量连续的空闲内存，管理器也可能通过 sbrk 系统调用来降低堆顶指针，从而缩减进程的堆空间，将这部分空闲内存返还给系统。但需要注意的是，由于内存碎片的存在，堆中部即使有空闲内存也难以被归还，因为操作系统要求归还的内存必须是地址连续的。因此，free 的行为是内存管理器在性能和系统资源占用之间的一种权衡策略。 26. malloc 是如何分配内存的（介绍一下 brk 和 mmap）？malloc 是 C 标准库中用于动态分配内存的函数，其具体实现依赖于底层的内存分配器（如 glibc 的 ptmalloc）。它的分配通过多级缓存和堆&#x2F;mmap 混合策略优化不同尺寸的内存分配，在用户态管理内存池以减少系统调用次数，同时尝试平衡性能与碎片化问题。 以下是其核心分配机制： 1. 小内存分配（通常 ≤ 128KB） 线程本地缓存（Tcache）：首先检查线程本地缓存（每个线程独享的无锁结构），从中快速获取所需大小的内存块。若命中则直接返回，避免全局锁竞争。 Fast Bins &#x2F; Small Bins：若 Tcache 未命中，则根据请求大小从对应的 Fast Bins（小内存单链表，LIFO）或 Small Bins（固定大小链表）中查找空闲块。Fast Bins 通常不合并碎片以提升分配速度。 堆区分配：若以上缓存均无可用块，分配器会通过 brk() 系统调用扩展进程的堆空间，从堆顶申请一大块内存，并将其分割为所需尺寸返回给用户。 2. 大内存分配（通常 &gt; 128KB） 直接使用 mmap() 系统调用：分配器会绕过堆管理，直接通过 mmap 从操作系统申请独立的内存映射区域。此类内存释放时通过 munmap 立即归还系统，避免堆碎片化。 3. 分配器的优化策略 内存块（chunk）对齐：返回的内存块通常按 16 字节对齐（64 位系统），满足硬件和算法效率需求。 碎片管理：释放后的内存块会根据邻居是否空闲进行合并，减少内存碎片。但 Fast Bins 中的块暂不合并以加速小内存分配。 多级缓存：通过 Tcache、Fast Bins、Unsorted Bins、Small Bins、Large Bins 等多级链表缓存不同尺寸的空闲块，适配不同分配模式。 4. brk 与 mmap brk()：用于扩展或收缩堆空间，频繁调用可能引发内存碎片。 mmap()：用于大内存或匿名映射，每次调用涉及内核态切换，开销较大但隔离性好。 brk mmap 27. 操作系统内存不足的时候会发生什么（如何避免预读失效和缓存污染） 触发内核回收机制 页面回收（Page Reclaim）：内核优先回收干净页（Clean Page，如文件读缓存）和空闲页，直接丢弃或重新关联。 脏页回写（Writeback Dirty Pages）：将脏页（Dirty Page，被修改过的缓存）异步写入磁盘，然后回收为空闲页。 交换（Swapping）：将不活跃的匿名页（进程堆栈数据）换出到磁盘交换分区（Swap），释放物理内存。 OOM Killer（Out-of-Memory Killer）：若回收后仍不足，内核根据进程的 oom_score（基于内存占用、优先级等）强制终止某些进程，释放内存。 应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。 当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， CPU 就会产生缺页中断，进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler（缺页中断函数）处理。 缺页中断处理函数会看是否有空闲的物理内存，如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系。 如果没有空闲的物理内存，那么内核就会开始进行回收内存的工作，回收的方式主要是两种：直接内存回收和后台内存回收。 后台内存回收（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行。 直接内存回收（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。 如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 —— 触发 OOM（Out of Memory）机制。 OOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。 申请物理内存的过程如下图： 系统内存紧张的时候，就会进行回收内存的工作，那具体哪些内存是可以被回收的呢？ 🔥 主要有两类内存可以被回收，而且它们的回收方式也不同。 文件页（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存。 匿名页（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们回收的方式是通过 Linux 的 Swap 机制，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。 文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，其中： active_list 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页； inactive_list 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页（预取页）； 有了这两个 LRU 链表后，预读页就只需要加入到 inactive_list 区域的头部，当页被真正访问的时候，才将页插入 active_list 的头部，同时将 active_list 尾部页淘汰到 inactive_list 头部中；如果预读的页一直没有被访问，就会从 inactive_list 移除，这样就不会影响 active_list 中的热点数据。 越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。 但是如果还是使用「只要数据被访问一次，就将数据加入到活跃 LRU 链表头部」这种方式的话，那么还存在缓存污染的问题：当我们在批量读取数据的时候，由于数据被访问了一次，这些大量数据都会被加入到「活跃 LRU 链表」里，然后之前缓存在活跃 LRU 链表里的热点数据全部都被淘汰了，如果这些大量的数据在很长一段时间都不会被访问的话，那么整个活跃 LRU 链表就被污染了。 前面的 LRU 算法只要数据被访问一次，就将数据加入活跃 LRU 链表，这种 LRU 算法进入活跃 LRU 链表的门槛太低了！正是因为门槛太低，才导致在发生缓存污染的时候，很容易就将原本在活跃 LRU 链表里的热点数据淘汰了。所以，只要我们提高进入到活跃 LRU 链表的门槛，就能有效地保证活跃 LRU 链表里的热点数据不会被轻易替换掉。 Linux 操作系统是这样提高门槛的：在内存页被访问第二次的时候，才将页从 inactive_list 升级到 active_list 里。 提高了进入活跃 LRU 链表的门槛后，就很好了避免缓存污染带来的影响。在批量读取数据时候，如果这些大量数据只会被访问一次，那么它们就不会进入到活跃 LRU 链表，也就不会把热点数据淘汰，只会待在非活跃 LRU 链表中，后续很快也会被淘汰。 28. 页面置换算法有哪些？页面置换算法的功能是，当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页。 那其算法目标则是尽可能减少页面的换入换出的次数，常见的页面置换算法有如下几种： 最佳页面置换算法（OPT） 先进先出置换算法（FIFO） 最近最久未使用的置换算法（LRU） 时钟页面置换算法（Clock） 最不常用置换算法（LFU） 1️⃣ 最佳页面置换算法（OPT）最佳页面置换算法基本思路是，置换在「未来」最长时间不访问的页面。 所以，该算法实现需要计算内存中每个逻辑页面的「下一次」访问时间，然后比较，选择未来最长时间不访问的页面。 我们举个例子，假设一开始有 3 个空闲的物理页，然后有请求的页面序列，那它的置换过程如下图： 在这个请求的页面序列中，缺页共发生了 7 次（空闲页换入 3 次 + 最优页面置换 4 次），页面置换共发生了 4 次。这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。 2️⃣ 先进先出置换算法（FIFO）既然我们无法预知页面在下一次访问前所需的等待时间，那我们可以选择在内存驻留时间很长的页面进行中置换，这个就是「先进先出置换」算法的思想。还是以前面的请求的页面序列作为例子，假设使用先进先出置换算法，则过程如下图： 在这个请求的页面序列中，缺页共发生了 10 次（页面置换共发生了 7 次），跟最佳页面置换算法比较起来，性能明显差了很多。 3️⃣ 最近最久未使用的置换算法（LRU）最近最久未使用（LRU）的置换算法的基本思路是，发生缺页时，选择最长时间没有被访问的页面进行置换，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。 这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。还是以前面的请求的页面序列作为例子，假设使用最近最久未使用的置换算法，则过程如下图： 在这个请求的页面序列中，缺页共发生了 9 次（页面置换共发生了 6 次），跟先进先出置换算法比较起来，性能提高了一些。 虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。 4️⃣ 时钟页面置换算法（Clock）那有没有一种即能优化置换的次数，也能方便实现的算法呢？ 时钟页面置换算法就可以两者兼得，它跟 LRU 近似，又是对 FIFO 的一种改进。 该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。 当发生缺页中断时，算法首先检查表针指向的页面： 如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置； 如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止； 时钟页面置换算法的工作流程图： 5️⃣ 最不常用置换算法（LFU）最不常用（LFU）算法，这名字听起来很调皮，但是它的意思不是指这个算法不常用，而是当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰。 它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。 看起来很简单，每个页面加一个计数器就可以实现了，但是在操作系统中实现的时候，我们需要考虑效率和硬件成本的。 要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。 但还有个问题，LFU 算法只考虑了频率问题，没考虑时间的问题，比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。 那这个问题的解决的办法还是有的，可以定期减少访问的次数，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就说，随着时间的流失，以前的高访问次数的页面会慢慢减少，相当于加大了被置换的概率。 29. 什么是中断？中断是计算机系统中一种重要的事件处理机制，当硬件设备或软件程序需要处理器立即处理某个事件时，会向 CPU 发送一个信号，强制暂停当前正在执行的程序，转而去执行与该事件相关的特定处理程序（称为中断处理程序或中断服务例程），待该程序执行完毕后再恢复之前被暂停的任务。 中断的核心目的是提高处理器的效率，使其不必持续轮询设备状态，而是由外设在需要时主动通知 CPU，从而实现异步事件处理和并发执行。中断可分为两类： 硬件中断：由外部设备（如键盘、鼠标、磁盘控制器、网卡）通过物理信号线触发，例如用户按下键盘按键或网卡接收到数据包时，会立即向 CPU 发送中断请求（IRQ），CPU 根据中断编号查找并执行对应的驱动处理程序。 软件中断：由程序执行特定指令（如系统调用、陷阱或异常）触发，例如应用程序请求操作系统服务（如读写文件）时通过软中断陷入内核，或发生除零错误等异常时强制切换处理流程。 中断处理过程涉及保存当前执行上下文（如寄存器状态）、跳转到中断向量表指定的地址、执行处理程序，最后恢复上下文并返回原任务。这一机制是现代操作系统实现多任务、设备驱动和实时响应的基础。 30. 讲讲中断的流程 中断触发：硬件设备（如键盘、网卡）或软件（通过 int 指令）发出中断信号。硬件中断通过中断控制器（如 APIC）汇总后发送给 CPU。 中断响应：CPU 在每个指令执行结束后检查是否有中断请求。若有且未被屏蔽（可屏蔽中断），则暂停当前程序，保存当前执行上下文（包括程序计数器 PC、寄存器等状态到内核栈），并关闭中断（防止嵌套中断干扰现场保存）。 中断路由：CPU 根据中断号查询中断描述符表（IDT），找到对应的中断服务程序（ISR） 的入口地址。 执行中断处理程序：跳转到 ISR 执行具体的中断处理逻辑（如从键盘缓冲区读取按键值、处理网络数据包）。此时可能分为两部分： 上半部：在中断关闭状态下执行紧急任务（如响应硬件、拷贝数据），要求快速完成。 下半部：通过软中断、任务队列或工作队列等机制延迟处理非紧急任务（如数据处理），此时会重新开启中断。 恢复现场：ISR 执行完毕后，从内核栈恢复之前保存的上下文（寄存器等状态）。 31. 中断的类型有哪些？中断可以根据其来源和触发方式分为以下几类： 硬件中断：由外部硬件设备触发，通过中断请求线（IRQ）向 CPU 发送信号。例如键盘输入、鼠标移动、磁盘 I&#x2F;O 完成或网络数据包到达。硬件中断可进一步分为： 可屏蔽中断：可通过设置 CPU 标志位（如 IF 位）临时屏蔽，例如大多数外设中断。 非可屏蔽中断：用于处理硬件紧急事件（如内存错误、电源故障），无法通过软件屏蔽。 软件中断：由程序执行特定指令主动触发，用于实现系统调用或异常处理。例如： 系统调用：用户程序通过 int 0x80 或 syscall 指令陷入内核，请求操作系统服务。 陷阱：用于调试（如断点中断 int 3）或功能调用。 异常：由 CPU 在执行指令时检测到错误或特殊条件时自动触发，属于同步中断。例如： 故障：可修复的错误（如缺页异常），处理后可重新执行指令。 陷阱：执行后继续下一条指令（如调试断点）。 中止：严重错误（如硬件故障），导致进程终止。 伪中断：由硬件错误或信号干扰导致的无效中断请求，中断控制器需过滤此类信号。 32. 你了解过哪些 I&#x2F;O 模型？ 阻塞 I&#x2F;O：这是最基础的模型。当应用程序发起一个 I&#x2F;O 操作（如 read 系统调用）时，线程会被挂起（阻塞），直到操作系统内核将数据完全准备好并复制到用户空间缓冲区后，线程才被唤醒继续执行。在此期间，该线程无法执行任何其他任务。模型简单，但并发性能差，需要为每个连接创建大量线程。 非阻塞 I&#x2F;O：应用程序发起 I&#x2F;O 操作后，如果数据尚未就绪，内核会立即返回一个错误（如 EWOULDBLOCK），而不是阻塞线程。应用程序需要不断地轮询（polling）内核，询问数据是否准备就绪。这种方式避免了线程阻塞，但轮询会消耗大量 CPU 资源，效率低下。 I&#x2F;O 多路复用：这是目前高并发网络应用中最主流的模型。应用程序通过调用 select, poll, 或 epoll 等系统函数，将一个或多个文件描述符（socket）的监听委托给内核。内核会监视这些描述符，当其中任何一个有数据就绪时，就通知应用程序。应用程序收到通知后再进行实际的 I&#x2F;O 操作（如 recv）。这使得一个线程可以同时管理多个 I&#x2F;O 连接，极大地提高了系统的并发能力。它常被称为 Reactor 模式。 信号驱动 I&#x2F;O：应用程序通过 fcntl 系统调用为一个文件描述符开启信号驱动模式，并指定一个信号（如 SIGIO）。当内核数据就绪时，它会向应用程序发送一个信号。应用程序在信号处理函数中进行 I&#x2F;O 操作。这种方式避免了轮询，但信号处理本身比较复杂，且在大流量场景中信号队列可能溢出，因此并不常用。 异步 I&#x2F;O：这是真正的异步模型。应用程序发起一个 I&#x2F;O 操作（如 aio_read）后立即返回，内核会负责完成包括数据准备和从内核空间拷贝到用户空间在内的所有工作。整个操作完成后，内核会通过信号或回调函数通知应用程序。这与信号驱动 I&#x2F;O 的关键区别在于：信号驱动 I&#x2F;O 是内核通知我们“何时可以开始”进行 I&#x2F;O 操作，而异步 I&#x2F;O 是内核通知我们“I&#x2F;O 操作已经完成”。Linux 原生 AIO 支持有限，更多使用像 io_uring 这样的新一代异步接口。 33. 讲一讲 I&#x2F;O 多路复用，以及 select、poll、epoll 的区别？ wxg 一面 视频链接：腾讯面试:请描述 select、poll、epoll 这三种 I&#x2F;O 多路复用技术的执行原理 推荐阅读：图解 | 深入揭秘 epoll 是如何实现 IO 多路复用的！ I&#x2F;O 多路复用是一种 I&#x2F;O 的处理方式，指的是复用一个线程处理多个 socket 中的事件。能够复用资源，防止创建过多线程导致的上下文切换的开销。 我们熟悉的 select&#x2F;poll&#x2F;epoll 内核提供给用户态的多路复用系统调用，进程可以通过一个系统调用函数从内核中获取多个事件。 select&#x2F;poll&#x2F;epoll 是如何获取网络事件的呢？在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。 select、poll ✅ select 图解 ✅ poll 图解 select 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。 所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。 select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。 poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。 但是 poll 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。 epollLinux 2.6 版本诞生了 epoll 模型，彻底解决了 select&#x2F;poll 性能不足的问题 ✅ epoll 图解 先复习下 epoll 的用法。如下的代码中，先用 epoll_create 创建一个 epoll 对象 epoll_fd，再通过 epoll_ctl 将需要监视的 socket 添加到 epoll_fd 中，最后调用 epoll_wait 等待数据。 1234567891011121314int s = socket(AF_INET, SOCK_STREAM, 0);bind(s, ...);listen(s, ...);// epoll_fdint epfd = epoll_create(...);epoll_ctl(epfd, ...); //将所有需要监听的socket添加到epfd中while(1) &#123; int n = epoll_wait(...); for(接收到数据的socket)&#123; //处理 &#125;&#125; epoll 通过两个方面，很好解决了 select&#x2F;poll 的问题： 第一点，epoll 在内核里使用「红黑树」来跟踪进程所有待检测的文件描述字，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 $O(logn)$。而 select&#x2F;poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select&#x2F;poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。 第二点，epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，内核通过回调函数将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select&#x2F;poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。 从下图你可以看到 epoll 相关的接口作用： epoll 的方式即使监听的 Socket 数量越多的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了，上限就为系统定义的进程打开的最大文件描述符个数。因而，epoll 被称为解决 C10K 问题（服务器同时处理10,000个客户端连接的挑战）的利器。 34. epoll 的边缘触发和水平触发有什么区别？epoll 支持两种事件触发模式，分别是边缘触发（edge-triggered，ET）和水平触发（level-triggered，LT）。 这两个术语还挺抽象的，其实它们的区别还是很好理解的。 使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完； 使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取； 举个例子，你的快递被放到了一个快递箱里，如果快递箱只会通过短信通知你一次，即使你一直没有去取，它也不会再发送第二条短信提醒你，这个方式就是边缘触发；如果快递箱发现你的快递没有被取出，它就会不停地发短信通知你，直到你取出了快递，它才消停，这个就是水平触发的方式。 这就是两者的区别，边缘触发的意思是只有第一次满足条件的时候才触发，之后就不会再传递同样的事件了；水平触发的意思是只要满足事件的条件，比如内核中有数据需要读，就一直不断地把这个事件传递给用户。 如果使用边缘触发模式，I&#x2F;O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会循环从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，边缘触发模式一般和非阻塞 I&#x2F;O 搭配使用，程序会一直执行 I&#x2F;O 操作，直到系统调用（如 read 和 write）返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK。 如果使用水平触发模式，当内核通知文件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后，没必要一次执行尽可能多的读写操作。 一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。 35. coredump 是什么，什么时候触发 coredumpcoredump 是程序由于异常或者 bug 在运行时异常退出或者终止，在一定的条件下生成的一个叫做 core 的文件，这个 core 文件会记录程序在运行时的内存，寄存器状态，内存指针和函数堆栈信息等等。对这个文件进行分析可以定位到程序异常的时候对应的堆栈调用信息。 coredump 产生的条件： shell 资源控制限制，使用 ulimit -c 命令查看 shell 执行程序时的资源 ，如果为 0，则不会产生 coredump。可以用 ulimit -c unlimited 设置为不限大小。 读写越界，包括：数组访问越界，指针指向错误的内存，字符串读写越界 使用了线程不安全的函数，读写未加锁保护 错误使用指针转换 堆栈溢出 36. 什么是零拷贝？传统 IO 的工作方式，从硬盘读取数据，然后再通过网卡向外发送，我们需要进行 4 上下文切换，和 4 次数据拷贝，其中 2 次数据拷贝发生在内存里的缓冲区和对应的硬件设备之间，这个是由 DMA 完成，另外 2 次则发生在内核态和用户态之间，这个数据搬移工作是由 CPU 完成的。 为了提高文件传输的性能，于是就出现了零拷贝技术，它通过一次系统调用（sendfile 方法）合并了磁盘读取与网络发送两个操作，降低了上下文切换次数。另外，拷贝数据都是发生在内核中的，天然就降低了数据拷贝的次数。 零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。 总体来看，零拷贝技术可以把文件传输的性能提高至少一倍以上。 37. Linux I&#x2F;O 栈 参考链接： Linux 系统中 I&#x2F;O 操作的数据读写流程介绍 Linux I&#x2F;O 栈｜读写流程 程序的内存分布，其中包括内核空间（在内存中），联想一下即可理解。 linux I&#x2F;O 存储栈分为 7 层: VFS 虚拟文件层: 在各个具体的文件系统上建立一个抽象层，屏蔽不同文件系统的差异。 PageCache 层: 为了缓解内核与磁盘速度的巨大差异。 映射层 Mapping Layer: 内核必须从块设备上读取数据，Mapping layer 要确定在物理设备上的位置。 通用块设备层: 通用块层处理来自系统其他组件发出的块设备请求，包含了块设备操作的一些通用函数和数据结构。 I&#x2F;O 调度层： IO 调度层主要是为了减少磁盘 IO 的次数，增大磁盘整体的吞吐量，队列中多个 bio 进行排序和合并。 块设备驱动层: 每一类设备都有其驱动程序，负责设备的读写。 物理设备层: 物理设备层有 HDD、SSD、Nvme 等磁盘设备。 38. 一次完整的 I&#x2F;O 读请求处理链路🔥 下面是一个完整的、详细的 I&#x2F;O 请求处理链路（以一次文件读取操作为例）： 应用调用 read() → 触发系统调用进入内核。 VFS 根据文件类型调用文件系统的 read_iter 方法。 文件系统检查 Page Cache： 命中：直接拷贝数据到用户缓冲区。 未命中：创建 bio 请求，提交到块层。 I&#x2F;O 调度器合并&#x2F;排序请求后，下发到 SCSI 中层。 设备驱动将请求转换为硬件命令，提交给控制器。 设备通过 DMA 读取数据到内存，触发中断通知完成。 中断处理程序唤醒原始请求，数据被填入 Page Cache 并返回用户态。 1. 系统调用接口（VFS 层） 作用：为用户空间（如 libc 库）提供统一的系统调用接口（如 read(), write(), io_uring_enter）。 关键组件：虚拟文件系统（VFS）。它抽象了所有文件系统和设备的操作，为上层提供统一的 file_operations 函数指针接口（如 read_iter, write_iter）。 2. 文件系统层 作用：处理与特定文件系统（如 ext4、XFS、Btrfs）相关的逻辑，如路径解析、权限检查、元数据管理。 关键步骤： 将文件的偏移量和大小转换为块设备上的逻辑块地址（LBA）。 通过 Page Cache 缓存文件和目录数据，减少直接磁盘访问。 若请求的数据已在 Page Cache 中（缓存命中），则直接返回；否则触发缺页异常，发起 I&#x2F;O 请求。 3. 块 I&#x2F;O 层 作用：管理 I&#x2F;O 调度、合并请求，并转换为统一的块 I&#x2F;O 请求（struct bio）。 关键组件： Page Cache：通过 address_space 操作与文件系统交互。 I&#x2F;O 调度器（如 mq-deadline、Kyber、BFQ）：对 I&#x2F;O 请求进行排序、合并（Merge）、重排（Sort），以减少磁盘寻道时间并保证公平性。 块设备映射：处理分区、软件 RAID（如 mdadm）或逻辑卷（LVM）。 4. SCSI&#x2F;设备映射层 作用：将块 I&#x2F;O 请求转换为特定设备驱动可理解的格式。 关键组件： SCSI 子系统：为 SATA、SAS、NVMe 等设备提供统一的中层抽象（即使是非 SCSI 设备也通常接入此框架）。 设备映射器（Device Mapper）：支持加密（dm-crypt）、快照（dm-snapshot）、多路径（dm-multipath）等高级功能。 5. 设备驱动层 作用：直接与物理硬件控制器（如 NVMe、SATA AHCI）交互，通过 DMA 将数据从内存传输到设备。 关键步骤： 将 I&#x2F;O 请求转换为设备特定的命令描述符。 通过写入控制器的寄存器或门铃（Doorbell）来提交命令。 处理设备完成中断，并向上层通知 I&#x2F;O 完成。 6. 硬件层 物理设备：如 NVMe SSD、SATA HDD、网络存储（通过 iSCSI 等）。 数据传输：通常通过 DMA（直接内存访问）在设备和内存之间传输数据，无需 CPU 参与。 新范式：io_uring 作用：提供高性能异步 I&#x2F;O 接口，绕过传统内核路径的部分开销。 核心机制： 通过一对环形队列（提交队列 SQ 和完成队列 CQ）在用户态和内核态之间传递请求和结果。 支持轮询模式（Polling），避免中断开销，进一步降低延迟。 39. write 怎么保证写入的持久性？在 Linux 中，一个简单的 write() 系统调用并不能保证数据真正持久化到物理存储设备上。要确保写入的持久性，必须理解内核的缓存机制并显式地采取额外措施。 1. 为什么 write() 不能保证持久性？ Page Cache 缓冲：write() 系统调用默认会将数据写入内核的 Page Cache 后就立即返回成功。这意味着数据并未立刻写入磁盘，而是停留在易失性内存中。 延迟写入 Write Back：内核通过“延迟写入”策略来优化性能：定期（由 dirty_writeback_centisecs 控制）或根据内存压力，将脏页异步刷回磁盘。在此期间若系统崩溃（断电、内核恐慌），这些数据会丢失。 2. 如何保证写入持久性？方法 1：同步写入（O_SYNC）在打开文件时使用 O_SYNC 标志： 1fd = open(&quot;file.txt&quot;, O_WRONLY | O_SYNC); 作用：每次 write() 都会阻塞调用者，直到数据及其元数据（如 inode 大小、修改时间）完全写入物理磁盘后才返回。 缺点：性能极差，每次写入都需等待磁盘 I&#x2F;O 完成（延迟通常为毫秒级）。 方法 2：显式刷盘（fsync() &#x2F; fdatasync()）在 write() 后调用： 12write(fd, data, size);fsync(fd); // 或 fdatasync(fd); fsync()：确保文件数据和元数据都持久化到磁盘。 fdatasync()：仅保证数据持久化，元数据（如访问时间）可能不立即刷盘，性能稍好。 优点：可批量写入后一次性刷盘，比 O_SYNC 性能更好。 方法 3：直接 I&#x2F;O（O_DIRECT）在打开文件时使用 O_DIRECT 标志： 1fd = open(&quot;file.txt&quot;, O_WRONLY | O_DIRECT); 作用：绕过 Page Cache，直接与磁盘交换数据。但需用户自行处理对齐限制（缓冲区地址、大小需对齐磁盘扇区，通常 512B&#x2F;4KB）。 注意：O_DIRECT 仅避免缓存，但写入成功返回仅表示数据已提交到磁盘驱动器的缓存（可能仍在易失性缓存中）。若要真正持久化，仍需结合 fsync()。 40. Linux 内存布局 Linux 进程内存分布 在 Linux 操作系统中，虚拟地址空间的内部又被分为内核空间和用户空间两部分，不同位数的系统，地址空间的范围也不同。比如最常见的 32 位和 64 位系统，如下所示。通过这里可以看出： 32 位系统的内核空间占用 1G，位于最高处，剩下的 3G 是用户空间； 64 位系统的内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。 虽然每个进程都各自有独立的虚拟内存，但是每个虚拟内存中的内核地址，其实关联的都是相同的物理内存。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。 接下来，进一步了解虚拟空间的划分情况，用户空间和内核空间划分的方式是不同的，内核空间的分布情况就不多说了。我们看看用户空间分布的情况，以 32 位系统为例，用一张图来表示它们的关系： 通过这张图你可以看到，用户空间内存从低到高分别是 6 种不同的内存段： 代码段，包括二进制可执行代码； 数据段，包括已初始化的静态常量和全局变量； BSS 段，包括未初始化的静态变量和全局变量； 堆段，包括动态分配的内存，从低地址开始向上增长； 文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关 (opens new window)）； 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小； 上图中的内存布局可以看到，代码段下面还有一段内存空间的（灰色部分），这一块区域是「保留区」，之所以要有保留区这是因为在大多数的系统里，我们认为比较小数值的地址不是一个合法地址，例如，我们通常在 C 的代码里会将无效的指针赋值为 NULL。因此，这里会出现一段不可访问的内存保留区，防止程序因为出现 bug，导致读或写了一些小内存地址的数据，而使得程序跑飞。 在这 7 个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 malloc() 或者 mmap() ，就可以分别在堆和文件映射段动态分配内存。 41. malloc 分配的是物理内存吗？不是的，malloc() 分配的是虚拟内存。 如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的，这样就不会占用物理内存了。 只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存和物理内存之间的映射关系。 42. 在 4GB 物理内存的机器上，申请 8GB 内存会发生什么？ 腾讯 CSIG 一面 在 32位&#x2F;64位 操作系统环境下，申请的虚拟内存超过物理内存后会怎么样？ 在 32 位操作系统，因为进程最大只能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。 在 64 位操作系统，因为进程最大只能申请 128 TB 大小的虚拟内存，即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。 程序申请的虚拟内存，如果没有被使用，它是不会占用物理空间的。当访问这块虚拟内存后，操作系统才会进行物理内存分配。 如果申请物理内存大小超过了空闲物理内存大小，就要看操作系统有没有开启 Swap 机制： 如果没有开启 Swap 机制，程序就会直接 OOM； 如果有开启 Swap 机制，程序可以正常运行。 43. 生产者消费者问题 腾讯 WXG 一面 下面讨论的是「单生产者单消费者」问题，那如果是「多生产者多消费者」问题呢？ 生产者之间的竞争（互斥）：多个生产者可能同时尝试向缓冲区写入数据。 消费者之间的竞争（互斥）：多个消费者可能同时尝试从缓冲区读取数据。 生产者-消费者问题描述： 生产者在生成数据后，放在一个缓冲区中； 消费者从缓冲区取出数据处理； 任何时刻，只能有一个生产者或消费者可以访问缓冲区； 缓冲区空时，消费者必须等待生产者生成数据； 缓冲区满时，生产者必须等待消费者取出数据。说明生产者和消费者需要同步。 那么我们需要三个信号量，分别是： 互斥信号量 mutex：用于互斥访问缓冲区，初始化值为 1； 资源信号量 fullBuffers：用于消费者询问缓冲区是否有数据，有数据则读取数据，初始化值为 0（表明缓冲区一开始为空）； 资源信号量 emptyBuffers：用于生产者询问缓冲区是否有空位，有空位则生成数据，初始化值为 n （缓冲区大小）； 代码 44. 哲学家就餐问题方案一只要有一个哲学家进入了「临界区」，也就是准备要拿叉子时，其他哲学家都不能动，只有这位哲学家用完叉子了，才能轮到下一个哲学家进餐。 方案二让偶数编号的哲学家「先拿左边的叉子后拿右边的叉子」，奇数编号的哲学家「先拿右边的叉子后拿左边的叉子」。 45. 读者-写者问题前面的「哲学家进餐问题」对于互斥访问有限的竞争问题（如 I&#x2F;O 设备）一类的建模过程十分有用。 另外，还有个著名的问题是「读者-写者」，它为数据库访问建立了一个模型。 读者-写者的问题描述： 「读-读」允许：同一时刻，允许多个读者同时读 「读-写」互斥：没有写者时读者才能读，没有读者时写者才能写 「写-写」互斥：没有其他写者时，写者才能写 读者优先使用信号量的方式来尝试解决： 信号量 wMutex：控制写操作的互斥信号量，初始值为 1； 读者计数 rCount：正在进行读操作的读者个数，初始化为 0； 信号量 rCountMutex：控制对 rCount 读者计数器的互斥修改，初始值为 1； 上面的这种实现，是读者优先的策略，因为只要有读者正在读的状态，后来的读者都可以直接进入，如果读者持续不断进入，则写者会处于饥饿状态。 写者优先那既然有读者优先策略，自然也有写者优先策略： 只要有写者准备要写入，写者应尽快执行写操作，后来的读者就必须阻塞； 如果有写者持续不断写入，则读者就处于饥饿； 在方案一的基础上新增如下变量： 信号量 rMutex：控制读者进入的互斥信号量，初始值为 1； 信号量 wDataMutex：控制写者写操作的互斥信号量，初始值为 1； 写者计数 wCount：记录写者数量，初始值为 0； 信号量 wCountMutex：控制 wCount 互斥修改，初始值为 1； 46. 磁盘调度算法 每个扇区是 512 字节，多个具有相同编号的磁道形成一个圆柱，称之为磁盘的柱面。 磁盘调度算法的目的很简单，就是为了提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的。 寻道的时间是磁盘访问最耗时的部分，如果请求顺序优化的得当，必然可以节省一些不必要的寻道时间，从而提高磁盘的访问性能。 假设有下面一个请求序列，每个数字代表磁道的位置： 98，183，37，122，14，124，65，67 初始磁头当前的位置是在第 53 磁道。 接下来，分别对以上的序列，作为每个调度算法的例子，那常见的磁盘调度算法有： 先来先服务算法 最短寻道时间优先算法 扫描算法 循环扫描算法 LOOK 与 C-LOOK 算法 1️⃣ 先来先服务先来先服务（First-Come，First-Served，FCFS），顾名思义，先到来的请求，先被服务。 请求顺序：98，183，37，122，14，124，65，67 先来先服务算法总共移动了 640 个磁道的距离，这么一看这种算法，比较简单粗暴，但是如果大量进程竞争使用磁盘，请求访问的磁道可能会很分散，那先来先服务算法在性能上就会显得很差，因为寻道时间过长。 2️⃣ 最短寻道时间优先最短寻道时间优先（Shortest Seek First，SSF）算法的工作方式是，优先选择从当前磁头位置所需寻道时间最短的请求 请求顺序：65，67，37，14，98，122，124，183 磁头移动的总距离是 236 磁道，相比先来先服务性能提高了不少。 但这个算法可能存在某些请求的饥饿，因为本次例子我们是静态的序列，看不出问题，假设是一个动态的请求，如果后续来的请求都是小于 183 磁道的，那么 183 磁道可能永远不会被响应，于是就产生了饥饿现象，这里产生饥饿的原因是磁头在一小块区域来回移动。 3️⃣ 扫描算法最短寻道时间优先算法会产生饥饿的原因在于：磁头有可能再一个小区域内来回得移动。 为了防止这个问题，可以规定：磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向，这就是扫描（Scan）算法。 这种算法也叫做电梯调度算法，比如电梯保持按一个方向移动，直到在那个方向上没有请求为止，然后改变方向。 那么，假设扫描调度算先朝磁道号减少的方向移动，具体请求则会是下列从左到右的顺序：37，14，0，65，67，98，122，124，183 磁头先响应左边的请求，直到到达最左端（0 磁道）后，才开始反向移动，响应右边的请求。 扫描调度算法性能较好，不会产生饥饿现象，但是存在这样的问题，中间部分的磁道会比较占便宜，中间部分相比其他部分响应的频率会比较多，也就是说每个磁道的响应频率存在差异。 4️⃣ 循环扫描算法扫描算法使得每个磁道响应的频率存在差异，那么要优化这个问题的话，可以总是按相同的方向进行扫描，使得每个磁道的响应频率基本一致。 循环扫描（Circular Scan, CSCAN ）规定：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且返回中途不处理任何请求，该算法的特点，就是磁道只响应一个方向上的请求。 请求顺序：65，67，98，122，124，183，199，0，14，37 磁头先响应了右边的请求，直到碰到了最右端的磁道 199，就立即回到磁盘的开始处（磁道 0），但这个返回的途中是不响应任何请求的，直到到达最开始的磁道后，才继续顺序响应右边的请求。 循环扫描算法相比于扫描算法，对于各个位置磁道响应频率相对比较平均。 5️⃣ LOOK 与 C-LOOK 算法我们前面说到的扫描算法和循环扫描算法，都是磁头移动到磁盘「最始端或最末端」才开始调换方向。 那这其实是可以优化的，优化的思路就是磁头在移动到「最远的请求」位置，然后立即反向移动。 那针对 SCAN 算法的优化则叫 LOOK 算法，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中会响应请求。 而针对 C-SCAN 算法的优化则叫 C-LOOK，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中不会响应请求。 47. 内存对齐？内存对齐发生在哪一层？我可以不对齐吗？ 字节跳动 · 基础架构一面 腾讯 TEG 一面 内存对齐的本质目的是：为了让 CPU 访问内存时更加高效，避免跨越多个存储单元（比如 cache line 或总线周期），减少访问次数和性能开销。 不对齐会导致： 读取数据跨多个内存块或 cache line； 可能需要多次访存、数据拼接； 某些平台（如 ARM）甚至直接报错。 为什么内存对齐能减少访存次数？ 现代 CPU 是以“块”单位读取数据的，比如 64 字节的 cache line。 如果数据起始地址对齐，就能在一个 cache line 内读完，一次访问就搞定；但如果不对齐，数据可能跨两个块，就会导致： CPU 需要 两次访问 才拿到完整数据； 多占用一次 cache、总线带宽； 增加延迟、降低效率。 所以对齐能保证数据落在一个块内，提高命中率，减少访存。 内存对齐是在哪一存储层次对齐的？ 主要是在这两个层次【🔥字节面试官说是在 L1 Cache，主要还是为了在同一个 cacheline 中访问】： 内存 → Cache（尤其是 L1 Cache）之间：为了避免数据跨多个 cache line（通常是 64 字节）导致多次 cache 访问 总线传输层（memory bus）：CPU 和内存之间的数据传输有对齐要求，总线通常按 4 字节、8 字节或更大位宽传输数据，不对齐可能增加传输次数或触发异常 不是针对寄存器本身，寄存器只是最终使用数据的地方。对齐主要作用在数据加载阶段（load from memory），不是计算阶段。 48. CPU 读取数据的工作流？CPU 读取数据时，首先在高速缓存（L1&#x2F;L2&#x2F;L3）中查找，若命中则直接返回；若未命中，则通过内存管理单元（MMU）将虚拟地址转换为物理地址，并访问主存（DRAM）加载数据块（缓存行），同时将其填入缓存。 若数据不在主存，会触发缺页异常，由操作系统从磁盘交换空间调入所需内存页，再重新执行访问。 49. 计算机存储层次结构各层的典型访问粒度和时延 存储层次 访问粒度 访问时延 备注 CPU 寄存器 4-8 字节 ~0.3-0.5 ns 直接与ALU交互，速度最快 L1 缓存 64 字节（缓存行） ~0.5-1 ns 分指令与数据缓存，核心独享 L2 缓存 64 字节（缓存行） ~3-10 ns 通常为核心独享或共享 L3 缓存 64 字节（缓存行） ~10-20 ns 多核心共享，容量更大 主存 (DRAM) 4KB (页) &#x2F; 64字节 ~50-100 ns 通过内存总线访问，需MMU转换虚拟地址 SSD (NVMe) 4KB (页) ~10-100 μs 需通过PCIe总线，涉及驱动和中断处理 HDD (磁盘) 512B-4KB (扇区) ~5-10 ms 含寻道时间和旋转延迟，机械操作慢 网络存储 可变 (通常≥1KB) ~1-100 ms 受网络延迟和协议开销影响极大","tags":["面经","八股文","操作系统"],"categories":["秋招指南"]},{"title":"2025 互联网秋招进行时指南","path":"/post/秋招指南/2025-autumn-recruitment/","content":"面试篇精简化回答一般面试主要由以下几个环节组成： 自我介绍 个人项目 项目介绍 重点难点新颖点 知识点深挖 八股文问答 手撕算法题 并不是每一场面试都会按照这几个环节来，不同的公司可能各自的侧重点不同，比如腾讯会把重点放在八股文问答环节，考察你对基础知识的掌握。 但不管怎样，我们在面试前都可以按照这个流程来去准备，并且在这个过程中，我们一定要养成一个能力：用最精练的语言回答问题。 这句话很好理解，例如自我介绍时，要尽可能在 1 分钟左右将自己的背景、荣誉、论文、奖项等有助于突出个人优势的经历展现出来，这点相信大家都有所准备。但是对于个人项目介绍环节，有些人可能会因为项目体量稍大、涉及知识点稍多等原因开始进行长篇大论式的介绍，这是非常忌讳的，过多的阐述反而会让人找不到重点，大部分面试官也都没有耐心听你讲很多，所以建议大家私下准备时可以手动对项目做个精简的总结，比较推荐的做法是「仿照论文」的写法： XX 是一个关于 XX 方面的项目，主要实现了 XX（挑最核心的）能力，该项目实现过程中遇到的重点难点为 XX，为了解决该问题，本文采用了 XX 的方法，对比业内现有方案，本项目的优势主要在于 XX。 当然简历上项目的写法也可以按照这个格式，不过纵使项目涉及的点很多也不要写过多内容，挑最核心的就可以，其余内容在面试官深入挖掘该项目时再进行补充即可。 精简化回答的能力体现出的是个人思维的敏捷性以及言语表达能力，面试官也尤为在意，因此面试者应该日常注重培养该能力。 记录并总结每一场面试中国的学生们最擅长的就是考试，每一场考试后我们会总结出错题和遗漏的知识点来查漏补缺，同时还会购买一些辅助资料来学习专家为我们总结的知识点，又或是买一些真题卷来为考试做模拟演练，不管怎样，我们的目的只有一个，那就是在下一场考试做得更好。 面试也是同样的道理，在秋招中我们可能会经历数十场面试，在每一次面试结束后我们都应该回顾这场面试的主要内容并记录下答得不好的地方，面试后再通过搜集资料对这些问题进行修正，在之后的每一场面试前我们都应该重新回顾这些内容。 除开从亲身参与的面试中获取经验外，我们还可以在牛客等平台去看别人分享的面试记录，如果发现有自己不懂的地方也应该及时记录下来，并且在空余的时间，我们可以发散思维，从自己记录的内容里引申出一些面试可能会涉及的别的认识点，这样可以逐步扩充我们的知识库。 上述记录并总结的过程推荐借助 AI 来高效完成。 总结 offer 选择篇具体岗位方向的决定（技术➕业务）虽然我们在面试前已经确定了未来就业的一个大致方向，例如是算法岗还是研发岗，但对于具体细致的方向很多人没有一个明确的想法，实际上岗位投递时我们能选择某个岗位但至于具体做哪方面的内容也是不确定的，这样就会导致大家在收到多个 offer 后会很纠结到底该怎么选择。 但不管怎么样，任何岗位的职责都可以被定义为业务➕技术的组合，这里可以拿抖音举例，大公司一般都会建设一套庞大的研发体系，上层重业务，下层重技术，其对应的发展路线也是截然不同的。 对于基础架构岗位比如数据库内核分布式存储等，业务与技术是高度重合的，你需要 follow 业内最先进的技术并想办法应用到你的工作中，因此掌握并应用技术就是你的业务。 对于业务研发岗位技术与业务重合度要小很多，你的工作中可能不会涉及到很高大上的技术（代码主要涉及 crud），但你的重心需要 focus 在业务模型中，对于重业务的岗位其业务模型是相当复杂的，你在工作中的成长主要是对整个业务模型有更深入的了解。 关于二者孰好孰坏很难给个结论，有人觉得做纯技术岗完全是给业务打工，毕竟技术是要服务于业务的，但也有很多人觉得业务岗纯 crud 岗，没什么技术含量，当然实际情况是复杂的，我这里主要是想给大家做一个更细致的说明，至于具体的抉择大家可以参考下图给出的三个关注点，另外我们拿到 offer 后最好让 hr 安排一个员工跟我们对接了解一下具体工作内容，而不是直接在网上求助，网友只能给一个模糊的答案。 当然，我觉得校招方向的选择也不用太过于纠结，职业生涯才刚开始，未来还有很多机会，所以放心大胆的做决定吧。 薪资 argue关于薪资的等级普遍被划分为「白菜、SP、SSP」三个等级，那如何拿到高等级呢？本人特别优异是一方面，学会与 hr 博弈是另一方面，hr 的绩效就是用尽可能少的钱招到优秀的人力，如果你别无选择，哪怕你真的很优秀 hr 也会压低你的薪资，因此建议 offer 能多拿就多拿。 致 2026 年毕业正在秋招的你 下文链接：timeErrors 秋招并非完全和它的名字一样，秋招并非是只有秋天才招聘，近些年来夏天也会招聘 我是 25 年毕业的，当年拿过一些 ssp，比如阿里云啥的，当然是比较久远的事了，现在进厂了，虽然才入职一个来月，但和当年很不一样了，时间就很紧张，一些准备上的东西我就不说了，比如什么时候投递，简历怎么写，怎么准备笔试，八股等等，牛客上都有很好的经验贴之类，我挑一些我认为很重要的点来讲吧，下面是个人感受和观点，并不一定正确，仅供参考。 简单来讲就是：想好目的，降低预期，接受现实。 最重要的就是心态，不要过度提高自己的预期，也不要因为一两次失利而气馁。 于秋招而言，特别是从业于互联网，根据我院我熟知的周围起码二三十人去大厂的人来看，几乎没有人可以最终选出来一个满意的 offer，大部分人都是选了个差不多可以接受的，尽管大家基本都是 5、6 个 offer 往上，且基本都有 ssp，而且非常普遍的一个现象就是来互联网的大家都很累，只是谁更累而已，据我观察，十点左右走是一个比较符合大家从公司跑路的时间，不乏有干到 1、2 点甚至 3、4 点的人。 所以去互联网，只有钱多累，和钱少累两种，而且要么是心累，要么身体累，更有甚者两者都累，两者都累建议尽早跑。 于工作而言，因为去哪里都很累，所以其他因素就不得不考虑，这些年进厂的感受，应该着重考虑下面几点： 心累 &gt; 身体累，即组里的氛围是很需要看中的，如果你的老板或者同事天天 pua 你，总是告诉你你什么都干不好，那我想干起来也是相当难受的。但恰巧这一点是最难判断的，你问老板组里氛围怎么样，就和问买水果的老板这瓜甜不甜一样，老板肯定说没有不甜的瓜。身体累顾名思义，就是加班，这里建议问问 HR，加班是调休还是双倍薪资，给自己卖一个合适的预期，比如有人就喜欢双倍薪资，有人就喜欢调休，当然绝大多数人都不喜欢加班，但这不是没办法吗 业务稳定&#x2F;上升，业务稳定，意味着你要做的工作不会特别赶，简称你可以早点下班，少加点班，因为需求不会那么多和那么着急，反正业务用了很多年，也不差这一会，但这也有可能意味着你的晋升或者跳槽认可度略低，这点很容易理解，晋升是因为前面可能有很多老兵排着，跳槽和工作量某种程度上挂钩，产出少了自然不好包装自己。业务上升又是另一个极端，产品迭代快，需求多，需求高强度的加班。但在互联网，并不是你干的多就升的快，只是业务稳定&#x2F;上升代表着这个部门突然消失的概率要小些，也意味着你不容易试用期就被裁掉（如果业务稳定的部门突然招了很多人，需要警惕下，老板估计是要整什么大活了） 拥抱变化，互联网总是很喜欢拥抱变化，即你曾经或许实习的组氛围什么都不错，但你真正入职可能就变了，一年在互联网里是很长的一段时间，一年前京东还不搞外卖，淘宝还没有闪购，deepseek 还没有出世，百度还在讲闭源模型一定比开源牛逼，gpt 还是稳压 gemini。身边有不少人，要么入职的时候组没了，要么那个组多发了 hc，结果 ta 入职到别的组去了等等。当然这种事情也可以和老板 HR 确认，只是说怎么确认都会有不确定性，做好拥抱变化的准备，随遇而安吧 offer 选择 如果决定来互联网，有大厂选大厂，这意味着你的机动性会更高些，谁也不知道入职后会不会踩坑，大厂会比中小厂在跳槽的时候容错会更高些，如果都是大厂，除了上面几点外，其余就是向钱看了，至于什么大厂间不同的 title，toc&#x2F;tob，核不核心，其实没那么重要，自己干的舒服是最重要的，舒服这个定义现在很廉价，就是一个正常的老板，正常的业务，正常的同事而已，但实现这一点很难。 所以我建议，一定要想好自己为什么要来互联网，你的目标是什么，这一点很重要，人还是需要一点理想主义的，如果为了狠狠赚一笔来，其实会在工作中怀疑自己：我真的需要这么多钱吗？因为大多数人是没有时间花掉这些钱的，至于白菜，sp，ssp 的分级，其实在扣完一大堆税到手后，并没有想象中差距那么大。 ✍️ 比较是偷走幸福的贼~ 以及脉脉等平台上的消息需要甄别下，很多老哥喜欢反串，很多消息保真，但更多消息是不保真的，工作是没有十全十美的，现在想要找一个晋升快，氛围好，不累，没杂活的组，几乎是不存在的。就是大家最终选的 offer 一定是或多或少有坑的，只是看最终能接受什么样的坑。此外针对于大部门的好坏评价基本上和自己无关，大部门可以理解为 +3 及以上这种，这种体量下，不可能有任何一个大部门永远保持无差评，但自己的入职后体验基本上只取决于你的 +1 和 mt 怎么样。 一年前的时候面百度，当时刚从阿里出来，面试管说，别因为某些人&#x2F;事把自己对技术的一份热爱磨灭了，那样生活就失去了很多乐趣，不好的地方可以尽早换，不管是在福报厂还是宇宙厂还是兄弟厂，人活的自在开心有价值是最重要的，否则都是浮云了。 个人的命运，当然要靠自我奋斗，但也要考虑到历史的行程，但不幸的是，现在历史的进程并不乐观。 我引用一段话作为结尾吧：在比较小的时候，大约就是初中高中吧，我对自己人生结果充满幻想和期待。但慢慢长大之后，方才意识到生活是如此复杂，我不得不学着对内心的期望放手，曾经的梦想在残酷的现实面前变得褪色。此时，怜悯自己显得很重要，或许你可以对自己说“我也想要做得更好”以及“就让它这样吧，其实这样也好”。 是的，我已经做得足够好了，因为至少现在我还爱着自己｡","tags":["C++","面经","大厂","秋招"],"categories":["秋招指南"]},{"title":"2025.08.09 网易雷火笔试题","path":"/post/秋招指南/20250809-netease-leihuo/","content":"题解链接：https://mp.weixin.qq.com/s/b2qohQxoMJk8Kysswtc7mQ 测评链接：https://niumacode.com/training/143 1. 部门旅游今年小师妹将再次组织大家进行一次精彩的部门旅游。为了确保每位员工能够顺利参与，现有三个不同的旅游团可供选择。每个旅游团的人数限制各不相同，员工可根据自己的喜好选择报名的旅游团。为了公平起见，系统将采用先到先得的原则进行处理。 报名规则如下： 每位员工可以根据喜好报名参加1到3个旅游团。 报名时，如果首选的旅游团已满员，系统将自动尝试加入员工的次选旅游团。 如果员工所选择的所有旅游团均已满员，则该员工无法参加此次旅游。 输入描述 第一行包含一个整数 N，表示员工的数量（1 ≤ N ≤ 10000）。 第二行包含三个整数，分别表示旅游团 A、B、C 的最大名额（1 ≤ A, B, C ≤ 10000）。 接下来的 N 行，每行包含： 一个字符串，表示员工的 ID（由字母和数字组成，并且互不相同） ID 长度 &lt;&#x3D; 13。 一个整数 X（1 ≤ X ≤ 3），表示该员工选择的旅游团数量。 X 个字符（A&#x2F;B&#x2F;C），表示员工选择的旅游团的优先级，优先级高的选择在前。 输出描述 按 A,B,C 三个团的顺序输出三行，每行一个整数，表示这个团最终的人数 a，接下来是 a 个字符串，表示进入这个团的员工 ID， 请按照报名顺序输出。 示例 1 输入： 12345642 1 1zhang01 2 A Bchen01 1 Bli02 3 B C Ayang 2 B A 输出： 1232 zhang01 yang1 chen011 li02 示例 2 输入： 12345642 1 1zhang01 2 A Bchen01 2 A Bli02 3 A B Cyang 2 B A 输出： 1232 zhang01 chen011 li020 代码：模拟 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;string&gt;using namespace std;int main() &#123; int employeeCount; cin &gt;&gt; employeeCount; int maxA, maxB, maxC; cin &gt;&gt; maxA &gt;&gt; maxB &gt;&gt; maxC; vector&lt;string&gt; groupA, groupB, groupC; for (int i = 0; i &lt; employeeCount; ++i) &#123; string employeeID; int choiceCount; cin &gt;&gt; employeeID &gt;&gt; choiceCount; vector&lt;char&gt; choices(choiceCount); for (auto&amp; choice : choices) &#123; cin &gt;&gt; choice; &#125; for (char choice : choices) &#123; if (choice == &#x27;A&#x27; &amp;&amp; groupA.size() &lt; maxA) &#123; groupA.push_back(employeeID); break; &#125; else if (choice == &#x27;B&#x27; &amp;&amp; groupB.size() &lt; maxB) &#123; groupB.push_back(employeeID); break; &#125; else if (choice == &#x27;C&#x27; &amp;&amp; groupC.size() &lt; maxC) &#123; groupC.push_back(employeeID); break; &#125; &#125; &#125; cout &lt;&lt; groupA.size(); for (const string&amp; id : groupA) &#123; cout &lt;&lt; &quot; &quot; &lt;&lt; id; &#125; cout &lt;&lt; &quot; &quot;; cout &lt;&lt; groupB.size(); for (const string&amp; id : groupB) &#123; cout &lt;&lt; &quot; &quot; &lt;&lt; id; &#125; cout &lt;&lt; &quot; &quot;; cout &lt;&lt; groupC.size(); for (const string&amp; id : groupC) &#123; cout &lt;&lt; &quot; &quot; &lt;&lt; id; &#125; cout &lt;&lt; &quot; &quot;; return 0;&#125; 2. 战力极差的最小值在《无主星渊》的竞技宇宙中，来自各个星系的顶尖战队齐聚一堂，准备迎战传说中的最终 BOSS。每个星系派出了最精锐的战队，共 n 支战队，每支战队有 m 名成员，每位成员的战力值分别为 $p_1, p_2, …, p_m$。为了组成最强的终极挑战队，你需要从每支战队中各选 1 名成员（共 n 人），但团队配合至关重要。经过无数次模拟战斗，联盟科学家发现：战力越均衡的团队，越能激发协同共鸣。因此，选拔规则如下：在所有可能的组队方案中，选择战力极差（最大值 - 最小值）最小的方案，确保团队以最平衡的状态迎战 BOSS。 你的任务：计算所有可能的组队方案中，战力极差的最小值。 输入描述 第一行两个正整数 $n (0 &lt; n &lt;&#x3D; 3000)$、$m (0 &lt; m &lt;&#x3D; 100)$，分别表示队伍数量与每只战队中的成员数量。 之后 $n$ 行，每行输入 $m$ 个数字 $p_i (0 &lt; p_i &lt; 1e9)$，代表战队中成员的战力值。 输出描述 所有可能的组队方案中，战力极差的最小值 示例 1 输入： 121 11 输出： 10 示例 2 输入： 12343 410 15 24 260 9 12 205 18 22 30 输出： 14 代码：滑动窗口 我们需要从 n 支战队中各选 1 名成员，组成一个 n 人团队。在所有可能的组队方案中，找到战力极差（最大值 - 最小值）最小的方案。 解题思路 暴力法不可行：直接枚举所有可能的组合（共 $m^n$ 种）显然不现实，因为 n 和 m 可能较大（n ≤ 3000，m ≤ 100）。 排序 + 滑动窗口： 将每支战队的成员战力值排序。 将所有战队的成员合并到一个列表，并记录每个成员所属的战队。 对这个合并后的列表按战力值排序。 使用滑动窗口，找到一个窗口，其中包含所有 n 支战队的至少一个成员，且窗口的极差最小。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;climits&gt;#include &lt;unordered_map&gt;using namespace std;int main() &#123; int n, m; cin &gt;&gt; n &gt;&gt; m; vector&lt;vector&lt;int&gt;&gt; teams(n, vector&lt;int&gt;(m)); for (int i = 0; i &lt; n; ++i) &#123; for (int j = 0; j &lt; m; ++j) &#123; cin &gt;&gt; teams[i][j]; &#125; sort(teams[i].begin(), teams[i].end()); // 每支战队内部排序 &#125; // 合并所有成员，并记录所属战队 vector&lt;pair&lt;int, int&gt;&gt; members; // (value, team_id) for (int i = 0; i &lt; n; ++i) &#123; for (int val : teams[i]) &#123; members.emplace_back(val, i); &#125; &#125; // 按战力值排序 sort(members.begin(), members.end()); int left = 0; unordered_map&lt;int, int&gt; team_count; int min_diff = INT_MAX; for (int right = 0; right &lt; members.size(); ++right) &#123; int team = members[right].second; team_count[team]++; // 当窗口包含所有战队时，尝试移动left while (team_count.size() == n) &#123; int current_diff = members[right].first - members[left].first; if (current_diff &lt; min_diff) &#123; min_diff = current_diff; &#125; // 移动left int left_team = members[left].second; team_count[left_team]--; if (team_count[left_team] == 0) &#123; team_count.erase(left_team); &#125; left++; &#125; &#125; cout &lt;&lt; min_diff &lt;&lt; endl; return 0;&#125; 3. 金矿采集在《无主星渊》的太空战场中，玩家需操控飞船从起点 (S) 出发，在 n×m 的网格中以最短时间采集所有的金矿。飞船每次仅能向上下左右四个方向移动一个网格，金矿可以以任何先后顺序被采集，飞船到达金矿后可以选择立即采集也可以选择路过。一共有 k 个金矿，金矿初始的矿产值为 Xi，当飞船采集到 a(0&lt;&#x3D;a&lt;&#x3D;k) 个金矿后，每移动一步，所有未被采集的金矿都会减少 a 点矿产值，当金矿的矿产值减少到 1 的时候将不再减小。需要你帮玩家算一下，玩家最多可以采集到金矿的总价值。 网格包含以下元素： #：不可穿越的障碍物 .：可自由航行的太空区域 1~5：表示 $k$ 个金矿的编号 S：飞船起点 输入描述 首行：n m k (1 ≤ n, m ≤ 50, 1≤ k ≤5) 后续 $n$ 行，每行 $m$ 个字符表示 $n*m$ 的网格的信息 最后一行是 $k$ 个整数，第 $i$ 个数表示编号为 $i$ (1&lt;&#x3D;i&lt;&#x3D;k) 的金矿的初始矿产值 Xi (1&lt;&#x3D; Xi &lt;&#x3D;1000) 输出描述 玩家最多可以采集到的金矿总矿产值，数据保证所有金矿都可以到达 示例 1 输入： 12345675 7 3S.....3##.......##.....1....2..#...10 20 30 输出： 141 示例 2 输入： 1234564 4 1.....##..##.S##1100 输出： 1100 示例 3 输入： 12345675 7 3S.....3##.......##.....1....2..#...40 1 1 输出： 142 代码：BFS + 全排列枚举 (1) 数据输入与预处理 读取网格地图，记录起点 S 和金矿的位置（保存到 positions 数组）。 金矿编号为 1 到 goldCount，起点编号为 0。 (2) BFS 计算最短路径 对每个金矿（包括起点）运行 BFS，计算到其他所有金矿的最短路径步数： 使用 distances[i][j] 表示从位置 i 到位置 j 的最短步数。 通过BFS遍历地图，跳过障碍物和边界。 (3) 全排列搜索最优顺序 生成所有金矿的排列顺序（1 到 goldCount的全排列）。 对每种顺序计算总得分： 从起点（last = 0）出发。 对于第 k 个金矿 order[k]： 累加步数惩罚：minus += stepCount * k。 计算当前金矿得分：max(initialValues[order[k]] - minus, 1)。 更新当前位置 last。 记录所有顺序中的最大得分 maxTotal。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#include &lt;bits/stdc++.h&gt;using namespace std;vector&lt;string&gt; grid;int rows, cols, goldCount;const int INF = 0x3f3f3f3f;int main() &#123; ios::sync_with_stdio(0); cin.tie(0); cin &gt;&gt; rows &gt;&gt; cols &gt;&gt; goldCount; grid.resize(rows); for (auto&amp; row : grid) &#123; cin &gt;&gt; row; &#125; vector&lt;int&gt; initialValues(goldCount + 1); for (int i = 1; i &lt;= goldCount; ++i) &#123; cin &gt;&gt; initialValues[i]; &#125; vector&lt;pair&lt;int, int&gt;&gt; positions(goldCount + 1, &#123;-1, -1&#125;); pair&lt;int, int&gt; startPos; for (int i = 0; i &lt; rows; ++i) &#123; for (int j = 0; j &lt; cols; ++j) &#123; if (grid[i][j] == &#x27;S&#x27;) &#123; startPos = &#123;i, j&#125;; &#125; else if (isdigit(grid[i][j])) &#123; int goldId = grid[i][j] - &#x27;0&#x27;; positions[goldId] = &#123;i, j&#125;; &#125; &#125; &#125; auto bfs = [](int startX, int startY) &#123; vector&lt;vector&lt;int&gt;&gt; dist(rows, vector&lt;int&gt;(cols, INF)); queue&lt;pair&lt;int, int&gt;&gt; q; q.push(&#123;startX, startY&#125;); dist[startX][startY] = 0; vector&lt;vector&lt;int&gt;&gt; directions = &#123;&#123;0, 1&#125;, &#123;1, 0&#125;, &#123;0, -1&#125;, &#123;-1, 0&#125;&#125;; while (!q.empty()) &#123; auto [x, y] = q.front(); q.pop(); for (auto&amp; dir : directions) &#123; int newX = x + dir[0]; int newY = y + dir[1]; if (newX &lt; 0 || newX &gt;= rows || newY &lt; 0 || newY &gt;= cols) &#123; continue; &#125; if (grid[newX][newY] == &#x27;#&#x27; || dist[newX][newY] != INF) &#123; continue; &#125; dist[newX][newY] = dist[x][y] + 1; q.push(&#123;newX, newY&#125;); &#125; &#125; return dist; &#125;; positions[0] = startPos; int totalPoints = goldCount + 1; vector&lt;vector&lt;int&gt;&gt; distances(totalPoints, vector&lt;int&gt;(totalPoints)); for (int i = 0; i &lt; totalPoints; ++i) &#123; auto dist = bfs(positions[i].first, positions[i].second); for (int j = 0; j &lt; totalPoints; ++j) &#123; distances[i][j] = dist[positions[j].first][positions[j].second]; &#125; &#125; vector&lt;int&gt; order(goldCount); iota(order.begin(), order.end(), 1); int maxTotal = 0; do &#123; int minus = 0, total = 0, last = 0; for (int i = 0; i &lt; goldCount; ++i) &#123; int currentGold = order[i]; int stepCount = distances[last][currentGold]; minus += stepCount * i; total += max(initialValues[currentGold] - minus, 1); last = currentGold; &#125; maxTotal = max(maxTotal, total); &#125; while (next_permutation(order.begin(), order.end())); cout &lt;&lt; maxTotal &lt;&lt; endl; return 0;&#125; 4. 篮球游戏你正在篮球场上与其他玩家玩一场游戏。你需要站在看台边，用推车接住从看台上扔下来的篮球。 篮球上标有不同的积分，你接到后就获得了对应的积分。但是其中有一部分玩家他们会扔其他种类的球，如果你不小心接到了这些球，你就需要停在原地 3 秒。期间你只能等待时间过去，或者正好有球进入车筐中。如果你在停止期间又接到了非篮球的球类，不论之前你的停止时间还剩多少，它都会重新刷新为 3 秒。 所有的球类都会在1 秒的时间里下落 1 格高度，而你也可以在 1s 时间里向左或者向右移动一格，或者不动。当车筐与球重合时，表示你接到了球，你可以在一个位置同时接到多个球。 一开始，你可以选择任意的位置，那么你怎么规划你的移动路线，能够使得接到的球总积分最高呢？ 输入描述 第一行有两个整数 n (1 &lt;&#x3D; n &lt;&#x3D; 100)，m (1 &lt;&#x3D; m &lt;&#x3D; 1000)，n 表示可以接到的球以及人可以站立的横向长度，m 表示扔出的球的总数 接下来 m 行，每行四个整数 $v_i (0 &lt;&#x3D; v_i &lt;&#x3D; 1e5)，x_i (0 &lt;&#x3D; x_i &lt; n)，y_i (0 &lt; y_i &lt;&#x3D; 1000)，t_i (0 &lt; t_i &lt;&#x3D; 1000)$，$v_i$ 表示球的积分，$x_i$ 表示物品的横向坐标，$y_i$ 表示物品的初始高度，$t_i$ 表示物品开始掉落的时间。当接收到 $v_i&#x3D;&#x3D;0$ 的球时，会使你困在原地 3 秒，如果此时已经处于被困住的状态，则时间会重置为 3 秒 输出描述 一个整数，表示可以接到的球的最大总积分 示例 1 输入： 123410 33 5 3 30 3 2 11 0 10 6 输出： 14 示例 2 输入： 1210 10 3 2 1 输出： 10 代码：动态规划 这是一个动态规划问题，我们需要在时间和空间维度上规划接球路线，最大化获得的积分，同时处理”定身”状态的干扰。 时间处理：所有球的下落时间被预处理为 time_start + height，即球到达底部的时间。 状态表示：dp[pos][stun] 表示在位置 pos 且剩余定身时间为 stun 时的最大得分 定身状态有 4 种可能：0(无定身),1,2,3 状态转移： 无定身时：可以左移、右移或不动 有定身时：只能不动，定身时间减 1 接到非篮球 (v&#x3D;0) 时：强制将定身时间设为 3 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596#include &lt;bits/stdc++.h&gt;using namespace std;constexpr int MAX_TIME = 2000;constexpr long long NEG_INF = -(1LL &lt;&lt; 60);int main() &#123; ios::sync_with_stdio(false); cin.tie(nullptr); int positions, events; cin &gt;&gt; positions &gt;&gt; events; // scores[time][pos]: 当前时刻和位置能获得的分数总和 vector&lt;vector&lt;int&gt;&gt; scores(MAX_TIME + 1, vector&lt;int&gt;(positions, 0)); // traps[time][pos]: 是否存在非篮球，触发定身 vector&lt;vector&lt;bool&gt;&gt; traps(MAX_TIME + 1, vector&lt;bool&gt;(positions, false)); for (int i = 0; i &lt; events; ++i) &#123; int value, pos, height, time_start; cin &gt;&gt; value &gt;&gt; pos &gt;&gt; height &gt;&gt; time_start; int landing_time = time_start + height; scores[landing_time][pos] += value; if (value == 0) &#123; // 非篮球触发定身 traps[landing_time][pos] = true; &#125; &#125; // dp[pos][stun]: 最大得分，stun表示剩余定身秒数（0~3） vector&lt;vector&lt;long long&gt;&gt; dp(positions, vector&lt;long long&gt;(4, NEG_INF)); // 初始状态：任何位置未定身，分数为0 for (int i = 0; i &lt; positions; ++i) &#123; dp[i][0] = 0; &#125; long long answer = 0; for (int time = 0; time &lt;= MAX_TIME; ++time) &#123; vector&lt;vector&lt;long long&gt;&gt; next_dp(positions, vector&lt;long long&gt;(4, NEG_INF)); for (int pos = 0; pos &lt; positions; ++pos) &#123; for (int stun = 0; stun &lt;= 3; ++stun) &#123; long long curr_score = dp[pos][stun]; if (curr_score == NEG_INF) continue; int new_stun = (stun == 0) ? 0 : stun - 1; // 如果没有被定身，可以移动 if (stun == 0) &#123; if (pos &gt; 0) &#123; next_dp[pos - 1][new_stun] = max(next_dp[pos - 1][new_stun], curr_score + scores[time][pos - 1]); &#125; if (pos + 1 &lt; positions) &#123; next_dp[pos + 1][new_stun] = max(next_dp[pos + 1][new_stun], curr_score + scores[time][pos + 1]); &#125; &#125; // 原地等待 next_dp[pos][new_stun] = max(next_dp[pos][new_stun], curr_score + scores[time][pos]); &#125; &#125; // 处理定身刷新逻辑 for (int pos = 0; pos &lt; positions; ++pos) &#123; // 更新答案 for (int stun = 0; stun &lt;= 3; ++stun) &#123; if (next_dp[pos][stun] &gt; answer) &#123; answer = next_dp[pos][stun]; &#125; &#125; if (traps[time][pos]) &#123; // 非篮球出现，所有未满3秒定身状态强制变成3秒定身 long long max_stun3 = next_dp[pos][3]; for (int stun = 0; stun &lt; 3; ++stun) &#123; if (next_dp[pos][stun] != NEG_INF) &#123; max_stun3 = max(max_stun3, next_dp[pos][stun]); next_dp[pos][stun] = NEG_INF; &#125; &#125; next_dp[pos][3] = max_stun3; if (next_dp[pos][3] &gt; answer) &#123; answer = next_dp[pos][3]; &#125; &#125; &#125; dp = move(next_dp); &#125; cout &lt;&lt; answer &lt;&lt; &quot; &quot;; return 0;&#125;","tags":["秋招","笔试","网易"],"categories":["秋招指南"]},{"title":"从一次 double free 深入理解 shared_ptr 的原理与最佳实践","path":"/post/C++/from-double-free-to-shared_ptr/","content":"在使用 C++ 开发过程中，最容易也是最麻烦的问题便是内存泄漏。相较于 Java、Python 或者 Go 语言都拥有垃圾回收机制，在对象没有引用时就会被系统自动回收而且基本上没有指针的概念，但是 C++ 则要求程序员自己管理内存，这一方面让程序员有更大的自由度但是也会很大影响程序员的开发效率。因此 C++11 标准中新推出了 shared_ptr、unique_ptr 和 weak_ptr 三个智能指针来帮助管理内存。 智能指针就是一个类，当超出了类的作用域时，类会自动调用析构函数，析构函数会自动释放资源，所以智能指针的作用原理就是在函数结束时自动释放内存空间，不需要手动释放。 笔者在排查一个 double free 问题时，重新回顾了 shared_ptr 的工作原理，以及列出一些注意事项，本文着重介绍 shared_ptr，其他智能指针不过多赘述。 shared_ptr 本质shared_ptr 能够自动记录共享对象的引用次数，并且在引用计数降至 $0$ 时自动删除对象，从而防止内存泄漏。每个 shared_ptr 的拷贝都指向相同的内存，在最后一个 shared_ptr 析构的时候其指向的内存资源才会被释放。 本质上 shared_ptr 是有两层析构： shared_ptr 本身析构会使得指向的共享对象的引用数 $-1$，当共享对象引用数为 $0$ 时，则调用共享对象本身的析构函数 这样就可以理解循环引用了：共享对象引用还是 $1$ 时，未调用共享对象本身的析构函数，其中成员 shared_ptr 的析构函数也不会被调用 shared_ptr 初始化方式： 构造函数 std::make_shared() 辅助函数 reset() 1234567std::shared_ptr&lt;int&gt; p(new int(1));std::shared_ptr&lt;int&gt; p2 = p;std::shared_ptr&lt;A&gt; ap = std::make_shared&lt;A&gt;();// 对于一个未初始化的智能指针，可以通过调用 reset 方法初始化std::shared_ptr&lt;int&gt; ptr;ptr.reset(new int(1)); 不能将一个原始指针直接赋值给一个智能指针，如：std::shared_ptr&lt;int&gt; p = new int(1)。 对于一个未初始化的智能指针，可以通过调用 reset 方法初始化，当智能指针中有值的时候，调用 reset 方法会使引用计数减 $1$。当需要获取原指针的时候可以通过 get 方法返回原始指针： 12std::shared_ptr&lt;int&gt; p(new int(1));int *ptr = p.get(); 智能指针初始化时也可以指定删除器，当其引用计数为 $0$ 时将自动调用删除器来释放对象，删除器可以是一个函数对象。 比如当使用 shared_ptr 管理动态数组时，需要指定删除器，因为 shared_ptr 默认删除器不支持数组对象： 12// lambda 表达式作为删除器std::shared_ptr&lt;int&gt; p(new int[10], [](int *p) &#123; delete []p; &#125;) shared_ptr 注意事项关于 shared_ptr 的注意事项： 不要用一个裸指针初始化多个 shared_ptr，会出现 double_free 导致程序崩溃 通过 shared_from_this() 返回 this 指针，不要把 this 指针作为 shared_ptr 返回出来，因为 this 指针本质就是裸指针，通过 this 返回可能会导致重复析构，不能把 this 指针交给智能指针管理。 尽量使用 std::make_shared&lt;T&gt;()，少用 new 不要 delete get() 返回的裸指针 不是 new 出来的空间要自定义删除器 要避免循环引用，循环引用导致内存永远不会被释放，造成内存泄漏（不在赘述） 1. 不要用一个裸指针初始化多个 shared_ptr（会导致 double free）问题场景： 123int* raw_ptr = new int(42);std::shared_ptr&lt;int&gt; sp1(raw_ptr);std::shared_ptr&lt;int&gt; sp2(raw_ptr); // 危险！ 两个独立的 shared_ptr 会各自维护一个引用计数控制块（相互独立） 当 sp1 和 sp2 销毁时都会尝试释放 raw_ptr，导致 双重释放（double free） 结果通常是程序崩溃或未定义行为 正确做法： 123456789// 方法1：直接使用 make_shared// make_shared 一次性分配内存，包含控制块（引用计数、弱引用计数等）；对象存储空间（存储实际值 42）auto sp1 = std::make_shared&lt;int&gt;(42);auto sp2 = sp1; // 只是复制指针并增加引用计数，两个 shared_ptr 指向同一个控制块，共享所有权// 方法2：如果必须从裸指针创建，确保只创建一次 shared_ptrint* raw_ptr = new int(42);std::shared_ptr&lt;int&gt; sp1(raw_ptr);std::shared_ptr&lt;int&gt; sp2 = sp1; // 复制的是控制块指针，不是重新创建控制块，共享同一个控制块 2. 正确使用 shared_from_this() 而不是直接返回 this 指针问题场景： 123456789class BadExample &#123;public: std::shared_ptr&lt;BadExample&gt; get_this() &#123; return std::shared_ptr&lt;BadExample&gt;(this); // 危险！ &#125;&#125;;auto obj = std::make_shared&lt;BadExample&gt;();auto another_ref = obj-&gt;get_this(); // 创建了独立的控制块 这会创建两个独立的 shared_ptr 控制块 当两个 shared_ptr 销毁时都会尝试析构同一个对象 正确做法： 123456789class GoodExample : public std::enable_shared_from_this&lt;GoodExample&gt; &#123;public: std::shared_ptr&lt;GoodExample&gt; get_this() &#123; return shared_from_this(); // 安全 &#125;&#125;;auto obj = std::make_shared&lt;GoodExample&gt;();auto another_ref = obj-&gt;get_this(); // 共享同一个控制块 3. 优先使用 std::make_shared&lt;T&gt;() 而不是 new问题场景： 12345// 不推荐std::shared_ptr&lt;MyClass&gt; sp(new MyClass(arg1, arg2));// 推荐auto sp = std::make_shared&lt;MyClass&gt;(arg1, arg2); 优势： 性能更好：单次内存分配（对象 + 控制块） 异常安全：不会在 new 和 shared_ptr 构造之间发生泄漏 代码更简洁：不需要重复类型名称 缓存友好：对象和控制块内存相邻 例外情况： 需要自定义删除器时 需要指定特殊的内存分配方式时 4. 不要 delete get() 返回的裸指针问题场景： 12345auto sp = std::make_shared&lt;int&gt;(42);int* raw_ptr = sp.get();delete raw_ptr; // 灾难性错误！// 当 sp 超出作用域时，会再次尝试删除已删除的内存 shared_ptr 仍然拥有内存所有权 手动 delete 会导致： double free 控制块状态不一致 未定义行为（通常崩溃） 正确做法： 123auto sp = std::make_shared&lt;int&gt;(42);int* raw_ptr = sp.get();// 仅使用 raw_ptr 进行读取/写入操作，绝不手动删除它 5. 非 new 分配的内存需要自定义删除器问题场景： 1234567// 从 malloc 分配的内存void* mem = malloc(1024);std::shared_ptr&lt;void&gt; sp(mem); // 错误！会用 delete 而不是 free// 文件指针FILE* fp = fopen(&quot;file.txt&quot;, &quot;r&quot;);std::shared_ptr&lt;FILE&gt; sp(fp); // 错误！会用 delete 而不是 fclose 正确做法： 12345678910// 使用自定义删除器（lambda 表达式作为删除器）void* mem = malloc(1024);std::shared_ptr&lt;void&gt; sp(mem, free); // 使用 free 作为删除器FILE* fp = fopen(&quot;file.txt&quot;, &quot;r&quot;);std::shared_ptr&lt;FILE&gt; sp(fp, [](FILE* f) &#123; fclose(f); &#125;);// 对于数组int* arr = new int[10];std::shared_ptr&lt;int&gt; sp(arr, [](int* p) &#123; delete[] p; &#125;); 常见删除器场景： C 风格内存分配（malloc/calloc/realloc）→ 使用 free 文件操作（fopen）→ 使用 fclose 系统资源（套接字、句柄等）→ 使用对应的释放函数 数组 → 使用 delete[] 6. 避免循环引用导致的内存泄露问题场景 112345678910111213141516171819202122class A;class B;class A &#123;public: std::shared_ptr&lt;B&gt; b;&#125;;class B &#123;public: std::shared_ptr&lt;A&gt; a;&#125;;int main() &#123; std::shared_ptr&lt;A&gt; ap = std::make_shared&lt;A&gt;(); std::shared_ptr&lt;B&gt; bp = std::make_shared&lt;B&gt;(); ap-&gt;b = bp; bp-&gt;a = ap; // 此时，a 和 b 相互持有对方的 shared_ptr，形成循环引用 // 程序结束时，a 和 b 的引用计数都不会降为零，导致内存泄漏 return 0;&#125; 问题场景 21234567891011class Node &#123;public: std::shared_ptr&lt;Node&gt; next; std::shared_ptr&lt;Node&gt; prev; // 双向链表导致循环引用 ~Node() &#123; std::cout &lt;&lt; &quot;Node destroyed &quot;; &#125;&#125;;auto node1 = std::make_shared&lt;Node&gt;();auto node2 = std::make_shared&lt;Node&gt;();node1-&gt;next = node2;node2-&gt;prev = node1; // 循环引用形成！ 当 node1 和 node2 离开作用域时： node1 的引用计数从 1→0？不，因为 node2-&gt;prev 还持有引用（实际从 2→1） node2 的引用计数同样从 2→1 结果：两者引用计数永远不为 0，内存永远不会释放 123node1 [refcount=2] --&gt; Node1对象 ↑next ↓prevNode2对象 &lt;-- [refcount=2] node2 解决方案：weak_ptr 123456789101112class SafeNode &#123;public: std::shared_ptr&lt;SafeNode&gt; next; std::weak_ptr&lt;SafeNode&gt; prev; // 使用weak_ptr ~SafeNode() &#123; std::cout &lt;&lt; &quot;SafeNode destroyed &quot;; &#125;&#125;;auto node1 = std::make_shared&lt;SafeNode&gt;();auto node2 = std::make_shared&lt;SafeNode&gt;();node1-&gt;next = node2;node2-&gt;prev = node1; // weak_ptr不会增加引用计数 何时会出现循环引用？ 双向链表、树结构等复杂数据结构 对象相互持有对方的 shared_ptr 父子对象互相强引用 观察者模式中主体和观察者互相持有 手撕 shared_ptr｜面试高频场景题1. 非线程安全的简单实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#include &lt;memory&gt;template&lt;typename T&gt;class smartPtr &#123;private: T *_ptr; size_t* _count;public: smartPtr(T *ptr = nullptr):_ptr(ptr) &#123; if (_ptr) &#123; _count = new size_t(1); &#125; else &#123; _count = new size_t(0); &#125; &#125; smartPtr(const smartPtr &amp;ptr) &#123; if (this != &amp;ptr) &#123; this-&gt;_ptr = ptr._ptr; this-&gt;_count = ptr._count; ++(*this-&gt;_count) ; &#125; &#125; smartPtr&amp; operator=(const smartPtr &amp;ptr) &#123; if (this-&gt;_ptr == ptr._ptr) return *this; if (this-&gt;_ptr) &#123; --(*this-&gt;_count); if (this-&gt;_count == 0) &#123; delete this-&gt;_ptr; delete this-&gt;_count; &#125; &#125; this-&gt;_ptr = ptr._ptr; this-&gt;_count = ptr._count; ++(*this-&gt;_count); return *this; &#125; ~smartPtr() &#123; --(*this-&gt;_count); if (0 == *this-&gt;_count) &#123; delete this-&gt;_ptr; delete this-&gt;_count; &#125; &#125; size_t use_count() &#123; return *this-&gt;_count; &#125; T&amp; operator*() &#123; assert(this-&gt;_ptr == nullptr); return *(this-&gt;_ptr); &#125; T* operator-&gt;() &#123; assert(this-&gt;_ptr == nullptr); return this-&gt;_ptr; &#125;&#125;; 2. 基于原子操作的线程安全实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192#pragma once#include &lt;atomic&gt; // 引入原子操作template &lt;typename T&gt;class shared_ptr &#123;private: T* ptr; // 指向管理的对象 std::atomic&lt;std::size_t&gt;* ref_count; // 原子引用计数 // 释放资源 void release() &#123; // P.S. 这里使用 std::memory_order_acq_rel 内存序，保证释放资源的同步 if (ref_count &amp;&amp; ref_count-&gt;fetch_sub(1, std::memory_order_acq_rel) == 1) &#123; delete ptr; delete ref_count; &#125; &#125;public: // 默认构造函数 shared_ptr() : ptr(nullptr), ref_count(nullptr) &#123;&#125; // 构造函数 // P.S. 这里使用 explicit 关键字，防止隐式类型转换 // shared_ptr&lt;int&gt; ptr1 = new int(10); 不允许出现 explicit shared_ptr(T* p) : ptr(p), ref_count(p ? new std::atomic&lt;std::size_t&gt;(1) : nullptr) &#123;&#125; // 析构函数 ~shared_ptr() &#123; release(); &#125; // 拷贝构造函数 shared_ptr(const shared_ptr&lt;T&gt;&amp; other) : ptr(other.ptr), ref_count(other.ref_count) &#123; if (ref_count) &#123; ref_count-&gt;fetch_add(1, std::memory_order_relaxed); // 引用计数增加，不需要强内存序 &#125; &#125; // 拷贝赋值运算符 shared_ptr&lt;T&gt;&amp; operator=(const shared_ptr&lt;T&gt;&amp; other) &#123; if (this != &amp;other) &#123; release(); // 释放当前资源 ptr = other.ptr; ref_count = other.ref_count; if (ref_count) &#123; ref_count-&gt;fetch_add(1, std::memory_order_relaxed); // 引用计数增加 &#125; &#125; return *this; &#125; // 移动构造函数 // P.S. noexcept 关键字表示该函数不会抛出异常。 // 标准库中的某些操作（如 std::swap）要求移动操作是 noexcept 的，以确保异常安全。 // noexcept 可以帮助编译器生成更高效的代码，因为它不需要为异常处理生成额外的代码。 shared_ptr(shared_ptr&lt;T&gt;&amp;&amp; other) noexcept : ptr(other.ptr), ref_count(other.ref_count) &#123; other.ptr = nullptr; other.ref_count = nullptr; &#125; // 移动赋值运算符 shared_ptr&lt;T&gt;&amp; operator=(shared_ptr&lt;T&gt;&amp;&amp; other) noexcept &#123; if (this != &amp;other) &#123; release(); // 释放当前资源 ptr = other.ptr; ref_count = other.ref_count; other.ptr = nullptr; other.ref_count = nullptr; &#125; return *this; &#125; // 解引用运算符 // P.S. const 关键字表示该函数不会修改对象的状态。 T&amp; operator*() const &#123; return *ptr; &#125; // 箭头运算符 T* operator-&gt;() const &#123; return ptr; &#125; // 获取引用计数 std::size_t use_count() const &#123; return ref_count ? ref_count-&gt;load(std::memory_order_acquire) : 0; &#125; // 获取原始指针 T* get() const &#123; return ptr; &#125; // 重置指针 void reset(T* p = nullptr) &#123; release(); ptr = p; ref_count = p ? new std::atomic&lt;std::size_t&gt;(1) : nullptr; &#125;&#125;;","tags":["C++","shared_ptr","内存泄露"],"categories":["C++"]},{"title":"AI Infra 与 Infra","path":"/post/AI-Infra/ai-infra-vs-traditional-infra/","content":"随着大模型技术的爆发，AI Infra 已成为基础设施领域的核心战场。过去 1 年多的时间，QQ 基础架构算法工程团队落地了多个大模型应用，包括语音合成大模型、内容理解多模态大模型、生成式推荐大模型，跑通大模型训练到推理的全链路。那 AI Infra 真的是和传统 Infra 差异很大的新体系吗，还是说它其实是过去 Infra 经验的演化？ 本文将分享传统后台工程师积累的技术栈和方法论，如何延续并迁移到 AI 系统，并系统性拆解 AI Infra 的硬件、软件、训练和推理挑战。 硬件演进经济基础决定上层建筑。软件层面的架构设计，无法脱离硬件约束。了解现代 AI 硬件特性非常有必要。 一台高性能的 GPU 服务器可以换一套深圳房子 从 CPU 为中心到 GPU 为中心传统基础设施以 CPU 为核心，通过多线程和微服务构建分布式系统，处理高并发请求（如 Web 服务），这些都有成熟的方法论了（如“海量服务之道”），主要工作是逻辑事务的处理，瓶颈在网络 I&#x2F;O 和 CPU 核心数量。发展到今天，硬件已经很少是制约 CPU 系统设计的瓶颈。 而 AI Infra 以 GPU 为核心，其设计目标从逻辑事务处理转向高吞吐浮点计算。 此时 CPU 多线程被 GPU 并行计算替代，内存被显存替代。 如下图所示，H20 单卡 96GB 显存，可以提供 44TFLOPS 的单精度浮点运算，算力和访存带宽是主流 CPU 数十倍甚至数百倍。每台机器安装 8 卡 &#x3D; 768GB 显存，另外还有 CPU 192 核 384 线程 + 2.3 TB 内存。 GPU 成为核心是因为 LLM 大模型每次生成一个 token，都需要读取全量的模型参数。传统的【CPU + 内存】的算力和带宽无法满足如此恐怖的计算密度，计算和通信都必须转移（offload）到 GPU 内完成。 CPU 成为数据搬运工和“辅助处理器”。 为了更直观地理解这个计算密度，做一个简单的计算。不考虑计算的延时，LLM 大模型生成一个 token 的耗时公式计算为：$$计算耗时&#x3D;\\frac{模型参数量*数据精度}{显存带宽}$$以 DeepSeek-R1-671B-A37B-FP8 模型为例，计算一个 token 耗时： H20：37B × 1byte ÷ 4000GB&#x2F;s &#x3D; 9 ms CPU：37B × 1byte ÷ 64GB&#x2F;s &#x3D; 578 ms 从“去 IOE”到“AI 大型机”显而易见，我们的现在身处新的一轮烈火烹油的硬件革命的历史进程中，各种专用硬件、专用网络层出不穷。DeepSeek-R1 和 QWen3-235B 千亿级参数训练需千卡 GPU 集群协同，通过专用网络互联构建“AI 超算”，其设计逻辑与以前的 IBM 大型机惊人相似——以硬件集中化换取极致性能与可靠性。 IBM 大型机 传统 Infra 的分布式理念貌似在 AI 时代失效了？ 传统 Infra 追求横向扩展，而 AI Infra 呈现“AI 大型机”特性，是因为传统后台服务的可以容忍毫秒级延迟，但 AI 集群不行，GPU 的算力是 CPU 的数百倍，微秒级的延时等待也会造成很大的算力损耗，需要硬件的高度集成。在可预见的 1-3 年的未来，这样的专用硬件 + 网络的集中式架构很难发生比较大的改变。 回顾历史，我们总是在寻求科技平权。前人推动“去 IOE”（IBM 小型机、Oracle 数据库、EMC 存储），用分布式廉价 x86 PC 机替代集中式高端硬件，本质上是利用软件创新重构一个高可用 + 低成本的互联网基础设施。”AI 大型机”是技术发展必由之路，但不是终极形态。长期（5 年）来看，必然会出现 “AI 去 NVIDIA 化”，重演“去 IOE”的历史。 软件演进说完硬件体系的革命，接下来再关注下软件层面的变化。 相比传统后台应用的增删查改，AI 应用的新范式是模型训练和推理 模型训练：通过海量数据拟合出一个复杂的神经网络模型 模型推理：利用训练好的神经网络模型进行运算，输入的新数据来获得新的结论 举个例子，训练就是根据 &lt;年龄, 身高&gt; 的分布使用最小二乘法拟合模型 y = ax + b，推理就是利用这个模型 y = ax + b，输入一个新的年龄，预测身高。 深度学习框架 工欲善其事，必先利其器 传统后台应用依赖 tRPC 或 Spring 等微服务框架，帮助我们屏蔽负载均衡、网络通信等底层细节，我们可以把精力放在业务实现上。 与之相似，AI 应用则依赖深度学习框架。如果没有深度学习框架，我们就可能陷入在茫茫的数学深渊中，挣扎于痛苦的 GPU 编程泥潭里。有了深度学习框架，我们才可以把所有精力花在设计模型和创新本身上，而不用关注底层的实现细节，极大降低了 AI 应用的门槛。 大家可能听说过不同的深度学习框架——Tensorflow，PyTorch。现在是 2025 年，不用纠结选哪个，因为 PyTorch 就是 AI 模型训练、推理的深度学习框架的事实标准，开源模型和代码都是 PyTorch 一边倒。 得益于动态计算图、自动微分和丰富的 Tensor 操作算子，PyTorch 能帮助我们快速实现模型设计。如下图所示，只需要描述模型结构 + 待学习的网络参数，不需要关心数学计算和 GPU 编程的细节。 GPU 编程绝大部分的 AI 应用，的确不需要我们手写数学计算的 GPU 代码。但为了满足模型创新的需求，有必要学习 GPU 编程。 例如 Meta 发布的 HSTU 生成式推荐模型，核心的 hstu_attn 计算： 如果直接用 PyTorch 框架算子组合实现，则时间复杂度为 $O(M * N^2)$ ，其中 $M$ 和 $N$ 是一个数量级，相当于 $O(N^3)$ 但是通过自定义内核，可以优化到 $O(N^2)$ 在 GPU 核心上运行的代码片段称为内核。编写高性能的 CUDA 内核需要丰富的经验，并且学习曲线陡峭。 如何理解 SIMD 和 SIMT 因为我们习惯于传统 CPU 编程处理串行的计算任务（即 SIMD, Single Instruction Multiple Data），通过多线程提高并发度。而 GPU 采用 SIMT (Single Instruction Multiple Thread) 架构，有大量计算单元（CUDA Cores）和数万个线程，但是被分组后的线程同一时刻只能执行相同的指令。这与传统 CPU 的串行思维、不同线程处理不同任务，存在根本性冲突，导致 GPU 编程学习难度大。 现实生活中的 SIMT 架构 现在推荐使用 Triton 编程语言完成 GPU kernel 的开发，它提供类似 Python 的语法，无需深入理解 GPU 硬件细节（如线程调度、共享内存管理），而且和 PyTorch 深度学习框架的生态结合更好。推荐这个 Triton-Puzzles-Lite 项目用作 Triton 的入门学习。 Python 编程正如客户端开发离不开 Kotlin&#x2F;Objective-C，AI Infra 编程的第一公民就是 Python。 PyTorch 深度学习框架的设计哲学强调 Python 优先 。 以前大部分模型还可以轻松导出 ONNX、TorchScript 等用 C++ 部署，现在随着对模型的细粒度优化和控制越来越多，比如 KV Cache、MoE&#x2F;模型并行、复杂的 if&#x2F;for 控制流、自定义 Triton 算子等，模型越来越难以脱离 Python 的控制部署。 模型训练 de 挑战我们一直追求更大的模型，DeepSeek-R1 有数千亿参数，使用了数十万亿 token 的训练数据，涉及算力、存储、通信等多维度的工程挑战。有了 PyTorch 深度学习框架，只是 AI 应用落地的万里长征第一步。接下来我们将讨论深度学习框架之上的模型训练的挑战。 存得下DeepSeek-R1 模型大小为 670GB，而一台 GPU 服务器有 8 张 H20 卡，提供 768GB 显存，足够存下一个完整的 DeepSeek 模型。那整个行业为什么还投入大量的人力物力，顶着通信延时造成的算力损耗，也要建设分布式 GPU 集群？ 核心原因是单台 GPU 服务器“存不下”。 显存刺客：中间激活如下图所示的模型，x1/x2/x3/x4 这些中间变量就是“中间激活”。它们是神经网络前向传播的“堆栈帧”—— 记录每一层处理后的数据快照，确保反向传播可回溯梯度，根据预测误差调整模型权重，最小化损失函数。 这些中间激活为什么会成为“显存刺客”？是因为中间激活的空间复杂度是和输入数据长度正相关的，特别的，对于 LLM 来说是 $O(N^2)$，正比于输入数据长度的平方，这是一个指数爆炸式增长的数字。类似函数递归不断增长的“堆栈帧”导致的内存溢出，我们遇到了 AI Infra 的 OOM（Out of Memory）挑战。 借助 PyTorch 的 profiler 工具，我们可以直观地看到这个 OOM。下图是训练过程中不同阶段的显存分配，包括： 模型参数（Parameter） 优化器状态（Optimizer State） 中间激活（Activation） 梯度（Gradient） 在前向传播结束后出现一个显存占用（中间激活）的尖峰，远大于模型参数本身。 模型并行**传统后台服务使用分片（Sharding）策略解决单机存不下的问题。**与之相似，AI Infra 提出“模型并行”，就是将单个大模型拆分为多个子模块，并分布到不同 GPU 上协同工作，通过通信来共享数据。有不同的“拆分模型”策略，例如按模型模块划分，按张量（Tensor）划分的，也可以将多种拆分方法结合起来一起使用。PyTorch 深度学习框架和开源方案 Megatron 都能帮助我们高效地实现模型并行。 不同的模型并行策略 算得快建设分布式 GPU 集群的原因，一个是因为“单机存不下”，另外一个是提升训练速度。但简单的机器堆叠，算力不一定有线性的增长。因为分布式训练并不是简单地把原来一个 GPU 做的事情分给多个 GPU 各自做。需要协调多个 GPU 机器计算任务分配，GPU 机器之间的数据传输会引入网络 I&#x2F;O 和通信开销，降低训练速度。 通信计算重叠如下图所示的常规训练时序是串联式的，存在许多网络 I&#x2F;O，GPU 利用率低，训练速度慢。我们希望 GPU 大部分时间都在计算，而不是花在数据传输或等待其他 GPU 的工作上。 传统后台服务我们通过多线程或异步 I&#x2F;O 避免阻塞 CPU 主线程。与之相似，AI Infra 提出通信计算重叠的方法论。 GPU 编程模型中有流（stream）的概念，一个流表示一个 GPU 操作队列，该队列中的操作将以添加到流中的先后顺序而依次执行。不同流之间可以并行执行，那么通过令计算和通信操作加入不同的流中，可以做到二者的执行在时间上重叠。例如 TorchRec 的训练流水线能帮助我们实现高效的通信计算重叠。 模型推理 de 挑战AI 模型训练成本很高，优秀如 DeepSeek 也要烧掉 500 万美金，但再贵也只是一劳永逸的。而模型推理的成本更高，因为用户越多，AI 模型推理次数越多，总成本越高。AI Infra 模型推理面对的挑战和传统 Infra 非常相似，主要是 2 个挑战： 高吞吐（降本） 低延时（增效） 降低延时现在的 AI 模型越来越多地直面终端用户，需要和用户进行实时的交互，例如文本对话和语音合成。模型推理耗时过高，会直接造成用户体验受损，用户流失与转化率下降。 传统后台服务我们使用链接复用、缓存、柔性等技术降低系统响应时间。AI Infra 也有相似的做法。 CUDA Graph在 GPU 编程模型中，CPU 和 GPU 是异构的，CPU 通过 API（例如 CUDA API） 向 GPU 提交任务，然后异步等待 GPU 的计算结果返回。GPU 收到任务后，会执行内核启动、内存拷贝、计算等操作。这个过程中，涉及到 CPU 与 GPU 之间的通信、驱动程序的处理以及 GPU 任务的调度等环节，会产生一定的延迟。 CPU 与 GPU 通信 模型推理需要执行大量重复的 GPU 操作，每个的 GPU 操作都要重复执行上述环节，这些非核心的 GPU 开销会成倍数地放大，影响最终响应时间。 在传统后台服务，我们使用 Redis 的 Lua 脚本封装多个 Redis 操作和计算逻辑，一次提交，减少网络开销。与之相似，AI Infra 利用 CUDA Graph 技术将多个 GPU 操作转化为一个有向无环图（DAG），然后一次性提交整个 DAG 提交到 GPU 执行，由 GPU 自身来管理这些操作的依赖关系和执行顺序，从而减少 CPU 与 GPU 之间的交互开销。 多个 GPU 内核启动转化为 CUDA Graph KV Cache —— 空间换时间LLM 大模型推理存在大量矩阵乘法运算，且高度依赖上下文信息。每次推理都需要将之前生成过的词重新输入模型进行计算（即上下文）。这种计算方式使得复杂度达到了 $O(N^2)$，其中必然存在大量的重复计算。 例如，给定“天气”，模型会逐个预测剩下的字，假设接下来预测的两个字为“真好。 将“真”拼接到“天气”的后面，即新的输入为“天气真”，再预测“好”。 KV Cache 的部分 观察到，经过多次预测后，X @ W_K 和 X @ W_V 的结果上半部分都是相同的，这是由于 LLM 模型结构的特殊设计导致的。这些重复计算的结果可以缓存（即 KV Cache）下来，空间换时间，减少计算量。几乎所有的 LLM 推理框架都支持了 KV Cache，例如 vLLM 。 流式响应有时候模型推理延时实在避免不了，可以从工程交互上想办法。 传统后台服务的 RPC 通信是一问一答方式，这种方式不太适合语音合成或者文本对话的场景。因为大模型推理需要几秒～几十秒，如果等待模型推理结束才展示结果，用户会等待较长的时间，体验很差。 流式响应就是当模型推理计算得到第一个 token 或者第一个音频帧的时候，立马展示或者播放给用户，同时后续的模型推理结果在已经建立的 TCP 流上继续顺序传输。工程上从关注模型推理的整体耗时，改为关注首 token 或首个音频帧的耗时。几乎所有的 LLM 推理框架都支持了流式响应。 提高吞吐量提高吞吐量是程序员在传统 Infra 领域孜孜不倦的追求，因为更高的吞吐量意味着更低的机器成本。实现 AI 应用的高吞吐本质上就是提高昂贵的 GPU 的利用率，让 GPU 单位时间能完成更多的任务。 尽管模型推理需要执行万亿次浮点运算，但 GPU 有大量的计算单元（CUDA Cores），单个请求的模型推理很难令 GPU 利用率达到饱和。 提高 GPU 利用率有 2 个方法：传统批处理和连续批处理。这里的“传统批处理”是相对于“连续批处理”这样的新型批处理方式而言的。 传统批处理 其实传统后台服务也大量使用了批处理，例如 Redis 的 MGet 命令，单次请求就完成所有 key 的获取，将 N 次网络往返（RTT）压缩为1次。 与之相似，模型推理的批处理就是将多个输入样本打包（batch），将原本串行的 N 次轻量的推理计算，合并为 1 次重量的计算，实现单位时间内处理更多的请求，提高了 GPU 利用率。 “打包输入样本”是一个共性需求，大部分推理框架都提供该功能，例如 Triton Inference Server 的 Batcher. 模型批量推理流程图 连续批处理传统批处理类似“固定班次的公交车”：乘客（请求）必须等待发车时间（组建一个 batch），发车后所有乘客同步前进。即使有乘客提前下车（短请求完成），车辆仍需等待所有乘客到达终点（长请求完成）才能返程接新乘客。传统批处理存在着资源浪费：GPU 要等待长请求处理完，不能处理新的请求而空闲。 这个问题在 LLM 应用领域显得特别突出，因为不同用户请求 Prompt，模型的回答结果长度差异巨大，如果使用传统批处理，GPU 空闲率很高。这个本质上是个任务调度问题，传统后台服务我们使用工作窃取算法（Work Stealing）解决线程空闲问题，与之相似，AI Infra 提出“连续批处理”解决这个问题。 连续批处理类似“随时随地拼车的顺风车”，每辆车（GPU）在行程中可随时上&#x2F;下客： 新乘客（请求）直接加入当前车辆的空位（空闲计算单元） 已完成的乘客立即下车（释放资源） 几乎所有的 LLM 推理框架都支持了连续批处理能力，例如 vLLM 的 Continuous Batching. 连续批推理流程图 AI Infra vs. Infra AI Infra 入门教程：https://github.com/stas00/ml-engineering/ 关于传统 Infra 和 AI Infra 的差异，总的来说就是觉得这套东西和传统 Infra 差太远了。很多熟悉网络，计算，存储等传统 infra 的工程师，会觉得自己原来的经验在 AI 场景里难以直接利用，尤其是看到 GPU，KV Cache，3D parallelism 这些新概念时，容易产生一种感觉完全换了一套体系的落差感。 我个人感觉这些看法其实挺有代表性的，反映出很多工程师对 AI Infra 的第一印象：陌生，高门槛，甚至有些割裂感。下文就想聊聊我的一些粗浅的理解。AI Infra 真的是和传统 Infra 差异很大的新体系吗，还是说它其实是过去 Infra 经验的演化？ 传统 Infra 与 AI Infra 概念✅ 我的答案是：差异其实不大。AI Infra 是对传统 Infra 在新场景下的重构与延展。AI Infra 面对的工程挑战，例如计算、存储、通信，大部分是新时代的老问题，我们在传统 Infra 领域都能找到对应的场景和解决思路。差异只在于战场从 CPU 转移到 GPU，传统后台工程师积累的方法论，依然可以衔接到 AI Infra。 🌟 如果从表面看起来，传统 Infra 和 AI Infra 确实很不一样： 设计目标从逻辑事务处理转向高吞吐浮点计算 传统 Infra 处理的是 web request，数据存储，和分布式服务协调 而 AI Infra（特别是大模型）更多围绕的是 GPU 推理，KV Cache 管理，以及大模型训练框架等全新领域 请求形态也不一样 web request 通常是毫秒级的 request，stateless 而 LLM 推理一个 session 往往持续数秒甚至更久（随着 context window 和模型大小增加），还要动态维护 token-level 的上下文状态 tech stack 看起来也不同 传统用的是 Kubernetes + Docker 现在大家在用 GPU, vLLM, DeepSpeed, FlashAttention, Triton, NCCL 这些仅仅从名字上听起来就很高大上的架构 从这点来看，说传统经验无法直接迁移确实没错，但这只是表面的现象，不是本质。 🔥 本质其实没变，仍然是系统设计和资源调度的问题 回到工程本身，其实我们仍然在面对和传统 Infra 极其类似的问题： 如何调度资源（从 CPU&#x2F;内存 变成了 GPU 显存） 如何处理高并发请求（从 http resource request ，变成了 prompt request） 我们来看一组对比： 传统 Infra 概念 AI Infra 相对应概念 Data Sharding Data Parallelism Load Balancer MoE Router OS Paging vLLM 的 KV Cache 分页机制 MoE Router：将 token 分发给多个 expert network，保证某一些 expert 不会overload（Deepseek，llama-4 使用的架构） 这些机制其实都是传统 Infra 思维方式在 AI 场景中的利用。 🌰 拿 vLLM 举个例子：它像是给 LLM 写了一个操作系统，用来调度页面（KV Cache），管理进程（Request），本质上是引用了 OS 的内存管理 Principles 用来管理 KV Cache。 Infra 的“三大难题”：Scaling &amp; Sharding &amp; Copying所有系统的底层挑战，基本都绕不开这三个关键词： Scaling（扩展）：系统如何支持更大的规模和更高的并发？ 在传统 Infra 中，这意味着如何横向扩展服务器，部署更多容器，使用负载均衡（load balancing）来分散请求 在 AI Infra 中，这些问题转化为如何通过数据并行，模型并行，流水线并行来分布和执行 GPU workload，以支持超大模型的训练以及 large number of inference requests Sharding（切片）：系统如何切分状态和计算，以实现并行处理？ 在数据库系统中，这是将数据按照主键或范围切分到不同的分区，以支持高吞吐访问 在 AI Infra 中，sharding 变成了对模型参数，KV Cache，activation，gradients，以及 optimizer states 的 split，比如 tensor parallelism 和 KV Paging 等，是实现分布式推理和训练的前提 Copying（复制）：系统如何高效同步数据或状态？ 传统系统中，复制体现在数据库副本同步或者缓存预热，以及 Kafka Replication 在 AI Infra 中，复制的代价更加显著，比如 data parallelism 怎么 copy model to different GPUs（所以会有 ZeRO optimization 来 shard 参数，gradient 等等），通常需要依赖高性能通信机制（比如 RDMA 和 NCCL） 这些挑战的本质没有变：仍然是如何高效并且低成本地协调跨不同机器的资源。但在 AI Infra 中，由于 GPU 显存 limited，large context window，以及模型参数量大，它们变得更加脆弱和重要，也更需要更好的工程策略去解决这些问题。 The Core of Infra: Cost Estimation and Identifying Key Issues after Deployment (from Jeff Dean)Google 的 Jeff Dean 曾整理出一份广为流传的延迟参考 Key Numbers Every Programmer Should Know。这些数据强调：在设计基础设施时，需要通过 estimate latency 来部署基础 system。 深入理解这些延迟数据，能让你在系统设计时更加 aware 真正的 bottleneck 是什么，这样也能在部署后迅速找到性能 bottleneck，然后及时修复。 延迟参考值 操作 延迟范围 L1 缓存访问 ~0.5 ns L2 缓存访问 ~7 ns 主内存访问 ~100 ns 压缩 1 KB（Snappy） ~3 µs 通过 1 Gbps 网络发 1 KB ~10 µs SSD 随机读 4 KB ~150 µs 数据中心内往返延迟 ~0.5 ms 顺序读取 1 MB SSD 数据 ~1 ms 磁盘 seek ~10 ms 读取 1 MB 磁盘数据 ~20 ms 跨洋网络延迟 ~150 ms 这些数值会随硬件不同而略有不同，但是相对的数量级非常值得记住，这是做系统设计时最基本的参考。 在 AI Infra 中的 mapping Token-level KV Cache：GPU 全局显存访问 多个 GPU 通信：通过 NCCL&#x2F;RDMA 进行同步 跨机（cross server）通信：比如在多个 server 之间调度推理任务 为什么会估算很重要？就像在基础数据结构与算法课程中，我们必须熟练掌握各种数据结构以及算法的时间与空间复杂度，如： 哈希查找 Average Time Complexity 是 $O(1)$ 快排是 $O(nlog⁡n)$ 在数据库系统中，需要算 disk I&#x2F;O 次数以及 index cost estimate。或者像以上的这些延迟参考值，应该是每一位做传统 infra 都应该牢牢记住并且经常会用到的。 🕙 在 AI Infra，我们也同样也需要估算大致**延迟（Latency）与带宽（Bandwidth）**方面的数字，以便： 事前估算：训练一个模型需要多少时间，推理吞吐量，token latency 都应基于这些 latency numbers 进行初步估计 事后诊断：部署之后，如果性能不是很好，理解这些延迟能帮助你快速定位瓶颈究竟在哪里（是 communication，memory bandwidth，or compute bound？） 案例参考：据说 Meta 在训练 LLaMA 系列模型时，GPU 报错或任务失败每几十分钟就会发生一次。因此，高质量的 log, error tracing 和 profiling 工具，对 LLM training Infra 稳定性至关重要。 🔥 非常推荐大家看一下李博杰的这篇博客（4090 适合做 training or inference 吗？）。这篇博客通过数据&#x2F;模型大小以及 gpu compute&#x2F;memory&#x2F;通讯层面，讲解了为什么 4090 不适合用于 training，但适合用于 inference。 🔥 真正有经验的 Infra 工程师，不仅仅是能搭件一个 working 的系统，而是有能力去从头到尾追踪每一个延迟点，把系统之间的关联和可能存在的 bottleneck 拆解成一系列可量化的问题，并在上线后持续做 cost&#x2F;performance profiling。这正是 AI Infra （或者传统 Infra）对工程基本功要求极高的原因。 结语感觉现在有很多讨论 AI Infra，并且有点把它过度“神化”了。 是的，LLM 的发展带来了新形态，新需求，和新的资源瓶颈（主要是 GPU memory 和 communication bottleneck，GPU 本身设计就是算力非常强，因为有非常多的 cores）。但是，解决这些问题的工程本质从来没有变：系统的目标仍然是优化资源利用（降低成本），保障 service 的稳定性，提升吞吐量以及响应能力。 而这些问题，在传统 Infra 中我们已经解决过很多次了。只不过这次，我们需要重新设计整个框架，让它在 GPU 上，高并发 LLM 请求下，仍然能够跑得快，跑得稳。 AI Infra 的门槛确实高，但是它的高门槛不在于你熟不熟悉神经网络，而在于你能不能把已有的工程能力（system design thinking and implementation skills）转化为新的问题的视角。 如果你做过网络通信：你会发现 NCCL 的 ring topology 其实跟设计高性能集群异构调度非常像 如果你知道缓存以及 OS Paging，你会非常快地理解 KV Cache 的重要性以及管理思路 如果你写过服务调度器，那 dynamic batching 会让你产生一种这是流水线并发的熟悉感 我越来越觉得，AI Infra 是对传统 Infra 知识体系的一种融合以及拓展，是一些旧的问题在新的范式中的 rephrasing；真正有竞争力的 AI Infra 工程师，不是只懂如何调个 prompt 或者跑个 inference&#x2F;finetuning，而是能把底层系统逻辑与模型特性融合起来的人 这种 shift of thinking 并不容易，但如果你愿意去搭建起传统 Infra → AI infra 的 mental map，会发现很多传统经验看起来和 AI 毫不相干的东西，其实都有非常相似的部分（俗话说，换汤不换药）。 所以，传统 Infra 的经验&#x2F;思维同样适用于 AI Infra，它们两之间有很多关联。","tags":["AI Infra","Infra"],"categories":["AI-Infra"]},{"title":"🎓 OI Wiki","path":"/post/OI-Wiki/wiki/","content":"心血来潮做这么一个专栏，不止 LeetCode &amp; Codeforces，2026 敬请期待。","tags":["C++","OI","ACM"],"categories":["OI-Wiki"]},{"title":"堆（优先队列）","path":"/post/数据结构与算法/priority_queue/","content":"✅ 优先队列 priority_queue 更多关于优先队列的知识，请跳转至：https://en.oi-wiki.org/lang/pb-ds/pq/ 大顶堆：priority_queue&lt;int&gt; pq 小顶堆：priority_queue&lt;int, vector&lt;int&gt;, greater&lt;&gt;&gt; pq 相关例题： 1046. 最后一块石头的重量 347. 前 K 个高频元素 🔥239. 滑动窗口最大值（还可以手动构造一个单调队列，使用 deque 数据结构） 🔥295. 数据流的中位数 🔥480. 滑动窗口中位数 __gnu_pbds :: priority_queue附： 官方文档地址——复杂度及常数测试 123#include &lt;ext/pb_ds/priority_queue.hpp&gt;using namespace __gnu_pbds;__gnu_pbds ::priority_queue&lt;T, Compare, Tag, Allocator&gt; 模板形参： T : 储存的元素类型 Compare : 提供严格的弱序比较类型 Tag 是 __gnu_pbds 提供的不同的五种堆，Tag 参数默认是 pairing_heap_tag，这五种分别是： pairing_heap_tag ：配对堆，官方文档认为在非原生元素（如自定义结构体&#x2F; std :: string &#x2F; pair ) 中，配对堆表现最好 binary_heap_tag ：二叉堆，官方文档认为在原生元素中二叉堆表现最好，不过我测试的表现并没有那么好 binomial_heap_tag ：二项堆，二项堆在合并操作的表现要优于配对堆*但是其取堆顶元素的 rc_binomial_heap_tag ：冗余计数二项堆 thin_heap_tag ：除了合并的复杂度都和 Fibonacci 堆一样的一个 tag Allocator ：空间配置器，由于 OI 中很少出现，故这里不做讲解 由于本篇文章只是提供给学习算法竞赛的同学们，故对于后四个 tag 只会简单的介绍复杂度，第一个会介绍成员函数和使用方法。 经作者本机测试堆的基础操作，结合 GNU 官方的复杂度测试，Dijkstra 测试，都表明：至少对于 OIer 来讲，除了配对堆（即默认 tag）的其他四个 tag 都是鸡肋，要么没用，要么常数大到不如 std 的，且有可能造成 MLE，故这里只推荐用默认的配对堆。同样，配对堆也优于 algorithm 库中的 make_heap() 。 构造方式要注明命名空间因为和 std 的类名称重复。 12345__gnu_pbds ::priority_queue&lt;int&gt; __gnu_pbds::priority_queue&lt;int, greater&lt;int&gt; &gt;__gnu_pbds ::priority_queue&lt;int, greater&lt;int&gt;, pairing_heap_tag&gt;__gnu_pbds ::priority_queue&lt;int&gt;::point_iterator id; // 迭代器// 在 modify 和 push 的时候都会返回一个 point_iterator，下文会详细的讲使用方法id = q.push(1); 成员函数 push() : 向堆中压入一个元素，返回该元素位置的迭代器。 pop() : 将堆顶元素弹出。 top() : 返回堆顶元素。 size() 返回元素个数。 empty() 返回是否非空。 modify(point_iterator, const key) : 把迭代器位置的 key 修改为传入的 key ，并对底层储存结构进行排序。 erase(point_iterator) : 把迭代器位置的键值从堆中擦除。 join(__gnu_pbds :: priority_queue &amp;other) : 把 other 合并到 *this 并把 other 清空。 时间复杂度使用的 tag 决定了每个操作的时间复杂度： 239. 滑动窗口最大值给你一个整数数组 nums，有一个大小为 k 的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的 k 个数字。滑动窗口每次只向右移动一位。 返回 滑动窗口中的最大值 。 1234567891011输入：nums = [1,3,-1,-3,5,3,6,7], k = 3输出：[3,3,5,5,6,7]解释：滑动窗口的位置 最大值--------------- -----[1 3 -1] -3 5 3 6 7 3 1 [3 -1 -3] 5 3 6 7 3 1 3 [-1 -3 5] 3 6 7 5 1 3 -1 [-3 5 3] 6 7 5 1 3 -1 -3 [5 3 6] 7 6 1 3 -1 -3 5 [3 6 7] 7 12345678910111213141516171819class Solution &#123;public: vector&lt;int&gt; maxSlidingWindow(vector&lt;int&gt;&amp; nums, int k) &#123; // entry: &lt;val, idx (whether_expired)&gt; priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, less&lt;&gt;&gt; pq; for (int i = 0; i &lt; k; i++) &#123; pq.emplace(nums[i], i); &#125; vector&lt;int&gt; ans&#123;pq.top().first&#125;; for (int i = k; i &lt; nums.size(); i++) &#123; pq.emplace(nums[i], i); while (pq.top().second &lt;= i - k) &#123; pq.pop(); &#125; ans.push_back(pq.top().first); &#125; return ans; &#125;&#125;; 295. 数据流的中位数中位数是有序整数列表中的中间值。如果列表的大小是偶数，则没有中间值，中位数是两个中间值的平均值。 例如 arr = [2,3,4] 的中位数是 3 。 例如 arr = [2,3] 的中位数是 (2 + 3) / 2 = 2.5 。 实现 MedianFinder 类: MedianFinder() 初始化 MedianFinder 对象。 void addNum(int num) 将数据流中的整数 num 添加到数据结构中。 double findMedian() 返回到目前为止所有元素的中位数。与实际答案相差 10-5 以内的答案将被接受。 12345678910111213输入[&quot;MedianFinder&quot;, &quot;addNum&quot;, &quot;addNum&quot;, &quot;findMedian&quot;, &quot;addNum&quot;, &quot;findMedian&quot;][[], [1], [2], [], [3], []]输出[null, null, null, 1.5, null, 2.0]解释MedianFinder medianFinder = new MedianFinder();medianFinder.addNum(1); // arr = [1]medianFinder.addNum(2); // arr = [1, 2]medianFinder.findMedian(); // 返回 1.5 ((1 + 2) / 2)medianFinder.addNum(3); // arr[1, 2, 3]medianFinder.findMedian(); // return 2.0 123456789101112131415161718192021222324252627class MedianFinder &#123;private: priority_queue&lt;int&gt; left; // 大顶堆 priority_queue&lt;int, vector&lt;int&gt;, greater&lt;&gt;&gt; right; // 小顶堆public: MedianFinder() &#123;&#125; void addNum(int num) &#123; // 分类讨论, 并且合并为最终两种情况 if (left.size() == right.size()) &#123; right.push(num); left.push(right.top()); right.pop(); &#125; else &#123; left.push(num); right.push(left.top()); left.pop(); &#125; &#125; double findMedian() &#123; return (left.size() + right.size()) % 2 ? left.top() : static_cast&lt;double&gt;(left.top() + right.top()) / 2; &#125;&#125;; 480. 滑动窗口中位数中位数是有序序列最中间的那个数。如果序列的长度是偶数，则没有最中间的数；此时中位数是最中间的两个数的平均数。 例如： [2,3,4]，中位数是 3 [2,3]，中位数是 (2 + 3) / 2 = 2.5 给你一个数组 nums，有一个长度为 k 的窗口从最左端滑动到最右端。窗口中有 k 个数，每次窗口向右移动 1 位。你的任务是找出每次窗口移动后得到的新窗口中元素的中位数，并输出由它们组成的数组。 给出 nums &#x3D; [1,3,-1,-3,5,3,6,7]，以及 k &#x3D; 3。 12345678窗口位置 中位数--------------- -----[1 3 -1] -3 5 3 6 7 1 1 [3 -1 -3] 5 3 6 7 -1 1 3 [-1 -3 5] 3 6 7 -1 1 3 -1 [-3 5 3] 6 7 3 1 3 -1 -3 [5 3 6] 7 5 1 3 -1 -3 5 [3 6 7] 6 因此，返回该滑动窗口的中位数数组 [1,-1,-1,3,5,6]。 1️⃣ 哈希表 + 逻辑删除12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273class Solution &#123;public: priority_queue&lt;int&gt; left; // 滑动窗口中左半部分 priority_queue&lt;int, vector&lt;int&gt;, greater&lt;&gt;&gt; right; // 滑动窗口中右半部分 unordered_map&lt;int, int&gt; mp; // 用于逻辑删除 double get(int k) &#123; if (k % 2) return left.top(); else return ((long long)left.top() + right.top()) / 2.0; &#125; vector&lt;double&gt; medianSlidingWindow(vector&lt;int&gt;&amp; nums, int k) &#123; for (int i = 0; i &lt; k; i++) &#123; int x = nums[i]; if (left.size() == right.size()) &#123; right.push(x); left.push(right.top()); right.pop(); &#125; else &#123; left.push(x); right.push(left.top()); left.pop(); &#125; &#125; vector&lt;double&gt; ans&#123;get(k)&#125;; for (int i = k; i &lt; nums.size(); i++) &#123; int balance = 0; // right.size() - left.size() // [fake] delete int l_num = nums[i - k]; mp[l_num]++; if (!left.empty() &amp;&amp; l_num &lt;= left.top()) &#123; balance++; &#125; else &#123; balance--; &#125; // add if (!left.empty() &amp;&amp; nums[i] &lt;= left.top()) &#123; left.push(nums[i]); balance--; &#125; else &#123; right.push(nums[i]); balance++; &#125; // adjust if (balance &gt; 0) &#123; left.push(right.top()); right.pop(); &#125; else if (balance &lt; 0) &#123; right.push(left.top()); left.pop(); &#125; // delete while (!left.empty() &amp;&amp; mp[left.top()] &gt; 0) &#123; mp[left.top()]--; left.pop(); &#125; while (!right.empty() &amp;&amp; mp[right.top()] &gt; 0) &#123; mp[right.top()]--; right.pop(); &#125; ans.push_back(get(k)); &#125; return ans; &#125;&#125; 2️⃣ 懒删除堆 本题等价于：295. 数据流的中位数 + 懒删除堆 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107template&lt;typename T, typename Compare = less&lt;T&gt;&gt;class LazyHeap &#123; priority_queue&lt;T, vector&lt;T&gt;, Compare&gt; pq; unordered_map&lt;T, int&gt; remove_cnt; // 每个元素剩余需要删除的次数 size_t sz = 0; // 实际大小 // 正式执行删除操作 void apply_remove() &#123; while (!pq.empty() &amp;&amp; remove_cnt[pq.top()] &gt; 0) &#123; remove_cnt[pq.top()]--; pq.pop(); &#125; &#125;public: size_t size() &#123; return sz; &#125; // 删除 void remove(T x) &#123; remove_cnt[x]++; // 懒删除 sz--; &#125; // 查看堆顶 T top() &#123; apply_remove(); return pq.top(); &#125; // 出堆 T pop() &#123; apply_remove(); sz--; T x = pq.top(); pq.pop(); return x; &#125; // 入堆 void push(T x) &#123; if (remove_cnt[x] &gt; 0) &#123; remove_cnt[x]--; // 抵消之前的删除 &#125; else &#123; pq.push(x); &#125; sz++; &#125; // push(x) 然后 pop() T push_pop(T x) &#123; apply_remove(); pq.push(x); x = pq.top(); pq.pop(); return x; &#125;&#125;;class Solution &#123;public: vector&lt;double&gt; medianSlidingWindow(vector&lt;int&gt;&amp; nums, int k) &#123; int n = nums.size(); vector&lt;double&gt; ans(n - k + 1); LazyHeap&lt;int&gt; left; // 最大堆 LazyHeap&lt;int, greater&lt;int&gt;&gt; right; // 最小堆 for (int i = 0; i &lt; n; i++) &#123; // 1. 进入窗口 int in = nums[i]; if (left.size() == right.size()) &#123; left.push(right.push_pop(in)); &#125; else &#123; right.push(left.push_pop(in)); &#125; int l = i + 1 - k; if (l &lt; 0) &#123; // 窗口大小不足 k continue; &#125; // 2. 计算答案 if (k % 2) &#123; ans[l] = left.top(); &#125; else &#123; ans[l] = ((long long) left.top() + right.top()) / 2.0; &#125; // 3. 离开窗口 int out = nums[l]; if (out &lt;= left.top()) &#123; left.remove(out); if (left.size() &lt; right.size()) &#123; left.push(right.pop()); // 平衡两个堆的大小 &#125; &#125; else &#123; right.remove(out); if (left.size() &gt; right.size() + 1) &#123; right.push(left.pop()); // 平衡两个堆的大小 &#125; &#125; &#125; return ans; &#125;&#125;;","tags":["LeetCode","数据结构"],"categories":["数据结构与算法"]},{"title":"[EuroSys'24] Volley","path":"/post/科研/eurosys-24-volley/","content":"Paper: Volley: Accelerating Write-Read Orders in Disaggregated Storage Motivation为了减少访问远程存储带来的 I&#x2F;O 开销，计算服务器通常会使用一部分 DRAM 作为写回缓存，来存储应用数据和缓冲频繁访问的数据。当缓存满时，如果需要读取新的数据，就必须腾出空间。这就需要进行缓存驱逐操作，将缓存中的脏页写回到远程存储设备，然后再从远程存储设备读取所需的数据。由于读取操作必须等待写入操作完成，这种顺序执行导致了 I&#x2F;O 操作的停滞： 写入操作完成后，读取操作才能开始（否则导致脏页被读取页覆盖，从而造成数据不一致性） 这种等待时间在高并发的环境中尤为明显，因为现代高性能网络和存储设备（如支持 200Gbps 带宽的 RDMA NIC 和每秒处理百万次 I&#x2F;O 请求的 NVMe SSD）可以同时处理多个 I&#x2F;O 请求。 当系统不能并行执行写入和读取操作时，这些高性能设备的潜力无法得到充分利用，从而导致整体性能下降。 当增加 Cache 大小，evict 比例会增大（违反直觉 —— Even counter-intuitively），这会进一步扩大有序读写的性能开销。 目前有两种直接的方法来缓解这种读写有序性带来性能开销： 利用多个后台清理线程：但是随着缓存的频繁访问，脏块还是会聚集因为处理写命令操作需要很长时间 利用 NIC target offload 模式，它提供了更短的 I&#x2F;O 路径，但是实验表明它仍然无法有效解决 NVMe-oF 中有序读写导致的 I&#x2F;O 停顿 读写顺序在回写缓存中很常见，一旦需要保证读写顺序，性能就会被严重影响。 NVMe-over-Fabrics 协议（NVMe-oF）NVMe-over-Fabrics（NVMe-oF）是一种流行的远程存储访问协议，它扩展自 NVMe 协议，以其低延迟（微秒级）和高并行性而闻名 。 NVMe-oF 协议有两个主要组件： 发起端（initiator） 目标端（target） 发起端首先连接到目标端暴露的存储设备，创建提交队列和完成队列，然后通过提交队列发送 I&#x2F;O 命令，并通过完成队列接收执行结果。NVMe-oF 支持多种网络传输方式，包括 RDMA 和 TCP 。 在 NVMe-oF 协议中，写操作和读操作的流程如下： Write I&#x2F;O Operation： 发起方将 64B NVMe 命令写入预注册的内存缓冲区并发出 RDMA_SEND 命令。发送数据有两种选择：push &amp; pull。 pull：目标端通过 RDMA_READ 从发起端拉取数据，这要求 NVMe 命令包含发起端虚拟内存地址所呈现的数据源地址。 push：发起者将封装内的数据块与 I&#x2F;O 命令一起搭载，并使用 RDMA_SEND 将它们一起发送。这样，RDMA 使用 scatter-gather 列表来排列 NVMe 命令和数据块。 Target 组装新的 NVMe 写命令，源地址为自己的数据块虚拟内存地址，并将该命令下发到本地 SSD。 Target 从本地 SSD 获取完成响应，并通过 RDMA_SEND 组装一个完成条目来通知initiator完成。 Read I&#x2F;O Operation： Read I&#x2F;O 操作的工作流程与 Write I&#x2F;O 操作类似。发起方使用 RDMA_SEND 向目标方发送读取命令。然后，目标从其本地 SSD 读取数据块。最后，它使用 RDMA_WRITE 向发起者发送数据块，并使用 RDMA_SEND 发送完成响应。 ⭐RDMD_WRITE 与 RDMA_SEND 的区别： RDMA_WRITE 操作是将数据从本地内存直接写入到远程节点的内存。此操作由本地节点（发起端）发起，并且直接在远程节点的内存中指定位置写入数据，无需目标端的 CPU 参与。 RDMA_SEND 操作是将数据从本地内存发送到远程节点，并由远程节点的应用程序处理。接收到的数据会放入目标端的接收缓冲区，由目标端的 CPU 进行处理。 🌀NVMe-oF 支持两种模式，具体取决于 CPU 的参与情况（图 2）。 CPU 模式：所有命令和数据块首先传输到 CPU 内存，然后发送到 SSD NIC target offload 模式：I&#x2F;O 命令和数据块直接从 NIC 发送到 SSD，绕过 CPU。还可以启用推送，通过一起发送 I&#x2F;O 命令和数据块来传输小尺寸的封装内数据块。 与 CPU 模式相比，卸载模式提供了更短的 I&#x2F;O 路径。首先，对于非持久写请求，当数据块到达 NIC 而不是 SSD 时，卸载模式向发起者返回完成响应。其次，绕过 CPU 减少了每个 I&#x2F;O 操作的 PCIe 往返次数。 Volley DesignVolley 协议通过允许写入和读取操作同时进行，解决了上述问题。具体来说： Volley 将写读顺序的关键部分最小化到驱动程序级别，这意味着只在写操作的数据块即将被覆盖时，才会严格遵守顺序。 这样，其他组件可以并行处理写入和读取操作，充分利用现代网络和存储硬件的高性能。 在 Volley 协议中，一个 Storage Server 包含多个 Target，每个 Target 配备了多个 NVMe SSDs 。 每个 Storage Server 包含多个 Target：这些 Target 处理从 Initiator 接收到的 I&#x2F;O 命令。 每个 Target 配备多个 NVMe SSDs：这些 SSD 用于存储数据块，执行读写操作。 主要工作流程如下图，主要凭借多个 Target 之间的协作完成，一个 Target 用于写入，一个 Target 用于读取，二者同时进行，当写入完的 Target 就通知读取的 Target 可以返回给 Initiator。注意，尽管 Read④ 可能比 Write④ 先返回给 Initiator，但这不影响 Initiator 按顺序完成 Write 和 Read。 感觉整体设计做了一个不错的 Trick，但是行之有效。 Evaluation V-TriCache 是专为计算场景（如超大规模数据处理、数据分析等）设计的缓存系统。它的主要目的是优化内存管理，尤其是在物理内存不足以容纳所有工作负载时。 V-Cache 是为虚拟机存储设计的用户态写回缓存系统，旨在优化虚拟机的存储性能，特别是当虚拟机需要频繁进行读写操作时。 使用 V-TriCache 和 V-Cache 的主要原因在于它们能够有效利用 Volley 协议带来的并行处理优势，减少传统逐出-获取顺序带来的性能瓶颈，从而在计算和存储场景中显著提升系统性能和效率。 SOTA (state-of-the-art)","tags":["EuroSys"],"categories":["科研"]},{"title":"[FAST'20] An Empirical Guide of Persistent Memory","path":"/post/科研/fast-20-empirical-guide-of-pm/","content":"Paper: An Empirical Guide to the Behavior and Use of Scalable Persistent Memory Slide: View the slides 0. 持久化内存调研企业级 SSD 可以提供 10 微秒级别的响应时间，DRAM 的响应时间大约是 100 纳秒这个级别。SSD 的响应时间和 DRAM 有着差不多 100 倍的差距。而 DRAM 和最后一级 CPU Cache 的响应时间只有 8~10 倍的差距。很明显，DRAM 和 SSD 之间存在比较巨大的性能鸿沟。所以在设计应用程序的时候，需要特别注意 I&#x2F;O 相关的操作，避免 I&#x2F;O 成为系统的性能瓶颈。 PMEM 提供亚微秒级别的延迟时间。从成本、性能、容量上看，PMEM 是位于 DRAM 和 SSD 之间的一层存储。PMEM 的出现，填补了 DRAM 和 SSD 之间的性能鸿沟，同时也将影响存储软件的架构设计。 「学术界」在很早以前就开始了对持久化内存的研究，比如： NOVA: A Log-structured File System for Hybrid Volatile&#x2F;Non-volatile Main Memories Bztree: A High-performance Latchfree Range Index for Non-volatile Memory Let’s talk about storage: Recovery methods for nonvolatile memory database systems …… 但以前没有真实的持久化内存硬件，只能基于软件模拟器进行仿真测试。直到 2019 年 4 月，Intel 发布了第一款企业级的持久化内存 —— Intel Optane DC Persistent Memory（下面简称 Optane DIMMs）。 由于模拟器没法百分之百模拟硬件，之前通过模拟器仿真出来的研究结果和真实硬件下的测试结果还是有一些差别的。在 FAST’20 上，有人发表了一篇论文，介绍 Intel Optane DC Persistent Memory 的使用特点 —— An Empirical Guide to the Behavior and Use of Scalable Persistent Memory。 Intel Optane DC Persistent Memory 是目前唯一一款量产的持久化内存，同时目前也只有 Intel 的 Cascade Lake 处理器支持这款持久化内存。 Intel Optane DC Persistent Memory 如上图所示，Optane DIMMs 采用和 DRAM 一样的 DIMM 接口。这意味着，Optane DIMMs 可以直接插在内存插槽上，通过内存总线和 CPU 通信，而 CPU 也可以通过指令直接操作 Optane DIMMs。 Optane DIMMs 的持久化 Optane DIMM 有两种工作模式：Memory Mode 和 App Direct Mode。 Memory Mode 简单说就是把 Optane DIMMs 当成易失性内存使用，把 DRAM 当作 CPU 和 Optane DIMMs 之间的 cache，并且 DRAM 对外不可见（就像 CPU 的多级 cache 对外也不可见）。基于 Memory Mode 的工作模式，可以通过应用无感知的方式，解决一些内存数据库（比如 Redis、Memcached）单机 DRAM 容量不足或成本过高的问题。 App Direct Mode 将 Optane DIMMs 当成一个持久化设备来使用，直接通过 CPU 指令读写 Optane DIMMs，不需要经过 DRAM。应用可以使用能够感知持久化内存的文件系统（比如 EXT4-DAX、XFS-DAX、NOVA）或其他组件（比如 PMDK）来管理、操作持久化内存设备。 Memory Mode 由于不考虑持久化问题，一般情况下将其当做一块更大的 DRAM 使用即可。 在 App Direct Mode 工作模式下，尽管 Optane DIMMs 设备本身是非易失的，但是由于有 CPU Cache 的存在，当设备掉电时，“还没写入” Optane DIMMs 的数据还是会丢失。 为了数据的持久化，Intel 提出了 Asynchronous DRAM Refresh（ADR）机制。ADR 机制保证，一旦写请求达到 ADR 中的 WPQ（Write Pending Queue），就能保证数据的持久性。除了 WPQ，Optane DIMMs 上也有缓存数据，ADR 机制同样会保证这部分数据的持久化。 但是，ADR 机制无法保证 CPU Cache 中的数据的持久化。为了保证 CPU Cache 上的数据持久化，可以调用 CLFLUSHOPT 或 CLWB 指令，将 CPU Cache Line Flush 到 Optane DIMMs 中： CLFLUSHOPT 指令执行完成后，CPU Cache 中的相关数据被逐出。 CLWB 指令执行完成后，CPU Cache 中的相关数据依然有效。 由于，CLFLUSHOPT 和 CLWB 指令都是异步执行的，所以一般需要跟随一个 SFENCE 指令，以保证 Flush 执行完成。 CPU 还提供了 NTSTORE（Non-temporal stores）指令可以做到数据写入的时候 bypass CPU Cache，这样就不需要额外的 Flush 操作了。 Optane DIMMs 的读写延迟 从论文中的测试数据看，Optane DIMMs 的读延迟是 DRAM 的 2~3 倍。另外，Optane DIMMs 顺序读的速度是随机读的 1.8 倍，相比之下，DRAM 顺序读的速度只有随机读的 1.2 倍。 由于写入 Optane DIMMs 的数据只需要到达 ADR 的 WPQ 即可，DRAM 和 Optane DIMMs 的写入延迟接近。 图正上方的三个数字的含义是：load 线程数 &#x2F; ntstore 线程数 &#x2F; store + clwb 线程数 DRAM 的读写带宽几乎不受数据大小和并发线程数的影响，速度很快并且非常稳定。对 DRAM 来说，读带宽大约是写带宽的 1.3 倍，但是 Optane DIMMs 读带宽是写带宽的 2.9 倍。 Optane DIMMs 的读写带宽在读写数据大小为 256B 时达到最大值。这是因为 Optane DIMMs 虽然支持字节寻址，但是每次读写的最小粒度是 256B。当一次读操作小于 256B 时，会浪费一些带宽。当一次写操作小于 256B 时，就会被转换成一次 read-modify-write，造成写放大（这点和 SSD 很像，只不过粒度更小，SSD 一般是大于等于 4KB）。 最后，根据上图的最右所示，Optane DIMMs 在并发线程数较多且访问数据为 4KB 时，带宽掉了个大坑 —— 这和 Optane DIMMs 内部结构有关。主要原因有两个： 对内部 buffer&#x2F;cache 和内存控制器（iMC） 的争用。 由于多条 Optane DIMMs 采用 4KB 交叉的方式组织成一个完整的持久化内存地址空间。每次访问对齐的 4 KB，请求都只能落在一条 Optane DIMMs 上，无法发挥多条 Optane DIMMs 通道并行执行的能力。 论文的最后总结了 4 条 Optane DIMMs 的最佳实践： Avoid random accesses smaller than &lt; 256 B. 避免小于 256 字节的随机读写。 Use non-temporal stores when possible for large transfers, and control of cache evictions. 大内存操作时，使用 ntstore 指令绕过 CPU Cache。 Limit the number of concurrent threads accessing a 3D XPoint DIMM. 限制一个 Optane DIMMs 通道的并发数。 Avoid NUMA accesses (especially read-modify-write sequences). 避免 NUMA 访问。其实内存也一样，远端内存比本地内存要慢不少，这个问题在 Optane DIMMs 表现更突出，需要特别注意。 更具体的内容，建议大家去看论文。 Basic Performance Measurements of the Intel Optane DC Persistent Memory Module 这一篇也比较有代表性，数据更详细。 PMDK 简介 前面说了，为了保证数据的持久化，需要在合适的地方用一些底层的 CPU 指令来保证。这样做有两个明显的缺点： 太过于底层，代码写起来麻烦。 可移植性差，不同 CPU 的指令是不一样的。 为了简化基于持久化内存的应用开发，Intel 开发和维护了 Persistent Memory Development Kit 这个开源组件。虽然这个组件目前由 Intel 开发和维护，但是理论上 PMDK 是与具体的硬件平台无关的——虽然现在依然只有 Intel 的一款持久化内存量产了。 PMDK 中的库可以分成两大类： Volatile libraries。如果不关心数据的持久化，只想通过 persistent memory 扩展内存，可以使用这一类库。 Persistent libraries。如果想要保证数据的 fail-safe，需要使用这一类库。 Volatile libraries libmemkind 提供 malloc 风格的接口，可以将持久化内存当成 DRAM 使用。 libvmemcache 是一个针对持久化内存的特点优化的易失性 LRU 缓存。 Persistent libraries libpmem 提供比较底层的操作持久化内存的接口，比如 pmem_map 类似 mmap、pmem_memcpy 类似 memcpy，具体可以参考官方文档。 libpmemobj 提供基于持久化内存的对象存储能力。 libpmemkv 是一个基于持久化内存的嵌入式 Key-Value 引擎，基于 B+ 树实现，针对读优化（libpmemkv 的内部实现）。 libpmemlog 提供 append-only 的日志文件接口。 libpmemblk 提供块存储接口，简单说就是将持久化内存抽象成一个数组。 除此之外，PMDK 还提供了一些工具和命令用于辅助开发和部署基于持久化内存的应用，具体参考 PMDK 官方文档吧。 1. Optane Memory Figure 1 Optane DIMM 位于内存总线上，并连接着处理器的 iMC (integrated memory controller)。每个 CPU 包含 1 或 2 个处理器芯片，其中包含单独的 NUMA 节点。每个 CPU 芯片都有 2 个 iMCs，每个 iMC 都支持 3 个通道。因此一个 CPU 芯片可在其 2 个 iMCs 上支持 6 个 Optane DIMMs。 为了保证持久化，iMC 位于 ADR (asynchronous DRAM refresh) 区域，确保能在电源故障时 (&lt;100us) 刷新到 ADR domain。 Optane DIMM 支持两种模式： Memory：相当于直接作为非易失性内存使用 APP Direct：提供持久性但不使用 DRAM cache 因为 Optane DIMM 既是【字节寻址】又提供【持久化】，所以可以作为主存设备，也可以作为持久化设备。本文聚焦于持久化使用，在 Section 6 会讨论如何将 Optane DIMM 作为易失性内存使用。 Figure 2 iMC 使用 DDR-T 接口以 Cacheline（64 bytes）粒度与 Optane DIMM 进行通信，该接口与 DDR4 共享机械和电气接口，但使用允许异步命令和数据时序的不同协议。 对 NVDIMM 的内存访问首先到达 on-DIMM controller（称为 XPController），用来协调对 Optane 介质的访问。 与 SSD 相同，Optane DIMM 也会执行内部地址转换以实现磨损均衡和坏块管理，并且维护了 AIT (address indirection table) 用于转换。 因为 3D-XPoint 物理介质的访问粒度为 256 bytes（称为 XPLine），XPController 将较小的请求转为较大的 256-bytes 访问，read-modify-write 操作会导致写放大问题。 XPController 有一个小 write-combining buffer（称为 XPBuffer）用于合并相邻写入。 2. LATTester | Performance Characterization The program and dataset are available at https://github.com/NVSL/OptaneStudy. 描述 Optane 内存具有挑战性，原因有二。 首先，底层技术与 DRAM 有很大不同，但公开的文档很少。 其次，现有工具主要根据局部性和访问大小来衡量内存性能，但我们发现 Optane 性能也在很大程度上取决于内存交错和并发性。持久性为性能测量增加了额外的复杂性。 为了充分了解 Optane 内存的行为，我们构建了一个名为 LATTester 的微基准测试工具包。为了准确测量 CPU 周期数并最大限度地减少虚拟内存系统的影响，LATTester 在内核中作为虚拟文件系统运行，并访问 Optane DIMM 的预填充（即无页面错误）内核虚拟地址。LATTester 还将内核线程固定到固定的 CPU 内核并禁用 IRQ 和缓存预取器。除了简单的延迟和带宽测量外，LATTester 还在 CPU 和 NVDIMM 上收集大量硬件计数器。 2.1 Typical Latency对于 DRAM 来说，随机与顺序的差距为 20%，但对于 Optane 内存来说，这一差距为 80%，而这一差距是 XPBuffer 造成的。 总体而言，Optane 的延迟差异非常小，除了极少数“异常值”，我们将在下一节中进行研究。Optane DIMM 的顺序读取延迟差异较大，因为第一个缓存行访问将整个 XPLine 加载到 XPBuffer 中，而接下来的三个访问读取缓冲区中的数据。 Cacheline: 64 bytes XPLine: 256 bytes 2.2 Tail Latency这些峰值很少见（占访问的 0.006%），但它们的延迟比常见的 Optane 访问高出 2 个数量级。我们怀疑这种影响是由于出于磨损均衡或热问题而进行的重新映射，但我们不能确定。 2.3 Bandwidth 3. Comparison to Emulation 下面，我们使用微基准测试将这些 NVM 模拟技术与真实的 Optane 进行比较，然后提供一个案例研究，说明这些差异如何影响研究结果。 图 6（左）显示了 NVM 仿真机制（例如 PMEP、DRAM-Remote、DRAM）与真实 Optane 内存的写入延迟&#x2F;带宽曲线。图 6（右）显示了与读取器&#x2F;写入器线程数相关的带宽（所有实验都使用固定数量的线程来提供最大带宽）。 请注意，PMEP 是一个专用的硬件平台，因此其性能数字不能直接与我们在其他实验中使用的系统进行比较。这些图中的数据表明，没有任何一种仿真机制能够捕捉 Optane 行为的细节——所有方法都与真实的 Optane 内存大相径庭。他们未能捕捉 Optane 内存对顺序访问和读&#x2F;写不对称的偏好，并对设备延迟和带宽给出了非常不准确的猜测。 4. Best Practices for Optane DIMMs (Guidelines)提炼出四个指导基于 Optane 系统的原则： （1）避免小于 256 B 的随机访问 （2）对于大容量传输，尽可能使用非临时存储，并控制缓存驱逐 （3）限制同时访问Optane DIMM的线程数量 （4）避免跨NUMA节点的混合或多线程访问（尤其是读取-修改-写入序列） 4.1 Avoid small random accesses在内部，Optane DIMM 以 256 B 的粒度更新 Optane 内容。这种粒度加上较大的内部存储延迟意味着较小的更新效率低下，因为它们需要 DIMM 执行内部读取-修改-写入操作，从而导致写入放大。访问表现出的局部性越少，对性能的影响就越严重。 通过实验发现，XPBuffer 大小为 16KB（64 个 XPLines） 案例研究： RocksDB： 在RocksDB中，使用持久性内存表导致了许多小存储操作，这些操作的局部性较差，导致有效写入率（EWR）较低。而基于FLEX的WAL优化使用顺序（且更大的）存储操作，得到了更高的EWR。 NOVA文件系统： NOVA通过增加日志条目的大小和避免一些写时复制操作来提高性能。NOVA-datalog将数据嵌入到日志中，将随机写入转换为顺序写入。 实践建议：这些结果共同为最大化 Optane 存储效率提供了具体指导：避免使用小型存储，但如果不可能，则将每个 Optane DIMM 工作集限制为 16 kB。 4.2 Use non-temporal stores for large writes写入持久内存时，程序员可以选择使用 clflush、clflushopt 或 clwb 指令来确保数据持久化。非临时存储（ntstore）指令可以直接写入持久内存，绕过缓存层次结构。 Non-temporal store（非临时存储）是一种CPU指令，它允许数据直接写入内存，同时绕过CPU缓存（cache）层次结构。这种指令特别适用于优化内存密集型应用的性能，尤其是在处理大量数据传输时。 实践建议： 对于大于 64B 的访问，使用 clflush 或 clwb 刷新缓存行，以提高带宽。 对于大于 512B 的访问，使用非临时存储（ntstore）以降低延迟并提高带宽。 案例研究： PMDK 的微缓冲区技术：通过结合使用非临时存储和常规存储，可以根据对象大小优化性能。 4.3 Limit the number of concurrent threads accessing a Optane DIMMOptane DIMM 的存储性能和 iMC 上的缓冲能力有限，难以同时处理多个线程的访问。 实践建议： 避免多个线程竞争同一 XPBuffer 空间，以减少驱逐和回写操作。 通过线程绑定到非交错的 Optane DIMMs，确保线程和 NVDIMMs 之间的均匀匹配，从而最大化每个 NVDIMM 的带宽。 案例研究： 多NVDIMM感知的NOVA：通过确保线程均匀地访问 DIMMs，优化后的NOVA在FIO基准测试中带宽提升了3%到34%。 4.4 Avoid mixed or multi-threaded accesses to remote NUMA nodesOptane DIMM 的 NUMA 效应比 DRAM 更大，应尽量避免跨 socket 内存流量，特别是涉及多个线程的读写混合访问。 实践建议： 尽量在本地 Optane DIMM 上进行操作，以避免 NUMA 性能下降。 案例研究： PMemKV： 在PMemKV中，使用远程Optane DIMM会显著降低应用性能，尤其是在多线程环境下。 5. Related Work 关于 NVM 的数据一致性，可以参考：《面向非易失内存的数据一致性研究综述》 持久性内存编程的现有技术已经涵盖了系统堆栈，但直到最近，这些结果才在真正的 Optane 内存上进行了测试。大量的工作已经探索了事务内存类型抽象，以强制执行一致的持久状态 $[5,9,12,25,26,28,33,49]$。各种作者已经构建了复杂的 NVM 数据结构，用于日志记录、数据存储和事务处理 $[3,4,10,11,17,23,24, 27, 30, 35, 38, 39, 41, 45, 46, 50, 57]$。自定义 NVM 文件系统也已被探索 [13, 21, 34, 48, 52, 54–56, 62]","tags":["FAST"],"categories":["科研"]},{"title":"[FAST'24] TeRM","path":"/post/科研/fast-24-term/","content":"Paper: TeRM: Extending RDMA-Attached Memory with SSD Slide: View the slides RDMA远程直接内存访问（RDMA）作为一种高性能网络技术，在数据中心中应用广泛。RDMA 允许服务器将其内存区域暴露给客户端，客户端可以通过一边请求（one-sided requests）直接访问这些内存区域。RNIC（RDMA Network Interface Card）是处理请求的关键组件，RNIC 的主要功能是允许计算机在不需要 CPU 干预的情况下直接通过网络访问远程内存。以下是 RNIC 处理请求的一般流程： RNIC 处理请求的流程1. 初始化资源在使用 RDMA 进行通信之前，需要初始化两个重要资源：队列对（Queue Pair, QP）和内存区域（Memory Region, MR）。 队列对（QP）：QP 是与另一个节点通信的端点。QP 包含发送队列（Send Queue）和接收队列（Receive Queue），用于管理发送和接收操作。 内存区域（MR）：MR 暴露应用程序虚拟内存中的一个区域，RNIC 可以访问这个区域。初始化 MR 时，驱动程序会将所有页面固定在物理内存中，并将虚拟地址到物理地址的映射存储在 RNIC 页表中。 2. RDMA 请求类型RDMA 支持两种类型的请求：一边请求（One-sided Requests）和两边请求（Two-sided Requests）。 one-sided request：包括 READ 和 WRITE 操作。这些请求不涉及远程 CPU，客户端可以直接访问远程 MR。 two-sided request：包括 SEND 和 RECV（接收）操作。这些请求提供消息传递抽象，通常用于构建远程过程调用（RPC）。 3. RNIC 处理请求的流程以下是 RNIC 处理一边 RDMA 请求（例如 READ 操作）的详细流程： 提交请求： 客户端通过 QP 提交 RDMA READ 请求，该请求包含源地址、目标地址和数据长度等信息。 请求传输： 客户端的 RNIC 将请求通过 RDMA 网络发送到服务器的 RNIC。 地址解析： 服务器的 RNIC 接收到请求后，从 RNIC 页表中查找目标虚拟地址对应的物理地址。 如果目标虚拟地址在 RNIC 页表中有效，RNIC 直接访问物理内存中的数据。 数据传输： RNIC 使用直接内存访问（DMA）引擎将数据从物理内存中传输到客户端指定的内存区域。 传输完成后，RNIC 发送完成通知（Completion Notification）给客户端，表示请求已完成。 4. RNIC 页错误处理当 RDMA 请求访问的虚拟地址在 RNIC 页表中无效（例如数据在 SSD 上而不在物理内存中）时，会触发 RNIC 页错误。RNIC 页错误的处理流程如下： 触发页错误： RNIC 发现虚拟地址无效时，暂停 QP 并触发 RNIC 页错误中断。 CPU 处理页错误： 驱动程序向操作系统内核请求虚拟到物理地址的映射。操作系统内核触发 CPU 页错误，将数据从 SSD 提升到物理内存，并更新 CPU 页表。 更新 RNIC 页表： 驱动程序更新 RNIC 页表中的映射，并恢复 QP，继续处理请求。 完成请求： 数据传输完成后，RNIC 发送完成通知给客户端。 RDMA READ&#x2F;WRITE 与 RPC READ&#x2F;WRITE 的区别RDMA READ&#x2F;WRITE 是 one-sided 操作，这意味着这些操作可以直接在远程内存区域上执行，而无需远程服务器的 CPU 参与。 RDMA READ 客户端通过QP（Queue Pair）提交READ请求，指定源地址、目标地址和读取长度。 客户端的RNIC（RDMA Network Interface Card）将请求发送到服务器的RNIC。 服务器的RNIC根据内部页表解析目标地址，从物理内存中读取数据并通过DMA传输回客户端。 请求完成后，客户端的RNIC通知客户端请求完成。 RDMA WRITE 客户端通过QP提交WRITE请求，指定源地址、目标地址和写入数据。 客户端的RNIC将数据通过DMA传输到服务器的RNIC。 服务器的RNIC根据内部页表解析目标地址，将数据写入服务器的物理内存。 请求完成后，客户端的RNIC通知客户端请求完成。 RPC (Remote Procedure Call) 是 two-sided 操作，需要客户端和服务端双方参与，RPC通常用于执行需要远程服务器逻辑处理的操作。 RPC READ 客户端发起一个RPC请求，包含要读取的数据地址和长度。 请求通过网络发送到服务器，服务器的CPU接收到请求并进行处理。 服务器的CPU根据请求读取内存数据，并将数据打包成响应消息。 服务器通过网络将响应消息发送回客户端。 客户端接收到响应消息，提取数据。 RPC WRITE： 客户端发起一个RPC请求，包含要写入的数据和目标地址。 请求通过网络发送到服务器，服务器的CPU接收到请求并进行处理。 服务器的CPU将数据写入指定的内存地址。 服务器通过网络发送确认消息回客户端。 客户端接收到确认消息，确认写入操作完成。 RDMA 实现较为复杂，需要在内存管理和地址映射上进行更多配置，而 RPC 实现较为简单，通常基于现有的网络通信库。前者适合分布式存储系统、高性能计算、内存数据库等需要快速访问远程内存的应用，后者适用于分布式系统中的远程服务调用，如微服务架构、远程文件系统操作等。 ODP MR | 按需分页内存区域 ODP MR：On-Demand Paging Memory-Region 前置知识：Demand PagingDemand Paging 是一种虚拟内存管理技术，它允许程序的一部分或全部被加载到物理内存中，而不是一次性将所有内容都加载进来。 当程序访问未加载到内存的页面时，操作系统会根据需要将相应的页面加载到内存中，从而满足程序的执行需求。 Workflow：更多细节详见标题链接 ODP MR Design RNIC Page Table 允许 RNIC 在执行 RDMA 操作时绕过 CPU，直接访问物理内存。 为了扩展RDMA连接的内存空间，ODP MR被提出。ODP MR允许应用程序在物理内存之上初始化一个更大的虚拟内存区域，并通过RDMA访问这些区域。 RNIC 页表将一些虚拟页面映射到物理页面（我们称之为有效虚拟页面），其余页面则保持未映射状态，即无效虚拟页面。由于页面不再固定（Pinned），因此操作系统内核可以交换和迁移页面。应用程序能够公开大于物理内存的 MR。由于虚拟到物理的映射可能会发生变化，CPU 和 RNIC 页表通过图 2 中所示的三个流程进行同步。 （1）Faulting 当 RDMA 请求访问无效虚拟页上的数据时，RNIC 暂停 QP（为了保持数据的一致性）并触发 RNIC 页面故障中断。 驱动程序通过 hmm_range_fault 向操作系统内核请求虚拟到物理页的映射，操作系统内核在这些虚拟页上触发 CPU 页面故障，并在必要时填充页表。 驱动程序更新 RNIC 页表上的映射，并恢复 QP 的运行。 （2）Invalidation 当操作系统内核尝试在换页或页面迁移等场景中解除虚拟页的映射时，它会通过 mmu_interval_notifier 通知 RNIC 驱动程序使虚拟页失效。 RNIC 驱动程序从 RNIC 页表中删除虚拟到物理的映射。 驱动程序通知操作系统内核，物理页不再被 RNIC 使用。然后，操作系统内核修改页表并重新使用这些物理页。 （3）Advising Flow 应用程序可以主动请求 RNIC 驱动程序在 RNIC 页表中填充一个范围。RNIC 驱动程序通过与失效处理类似的步骤来完成建议流程。 但是当RDMA请求访问到不在物理内存中的数据时，会触发一个RNIC页面错误，中断并通过CPU从SSD中加载数据到物理内存，并更新RNIC页表。实验数据显示，在处理一个ODP MR的RDMA读取请求时，当数据在内存中时，延迟仅为 3.66us，但当数据在SSD上时，延迟激增至 570.74 us。这个高延迟主要来源于RNIC页面错误处理的低效机制和CPU页面错误处理的高开销。 本文的动机RNIC 在处理页面错误时会暂停QP，并通过CPU进行地址映射更新，这一过程耗时较长，导致高延迟。 CPU在处理页面错误时，需要从SSD中加载数据到物理内存，并更新RNIC页表，这一过程也同样耗时且难以扩展。 为了应对上述挑战，TeRM提出了一种高效的扩展RDMA连接内存的新方法，旨在通过将异常处理从硬件转移到软件中来优化性能，并引入了一系列技术以减少网络流量和CPU开销。 基于以上分析，TeRM 的设计基于以下两个主要原则： 原则一：将异常处理从硬件转移到软件： 由于RNIC硬件资源有限且处理异常路径的效率低，TeRM建议将RNIC页面错误的处理从硬件转移到软件中，利用软件的灵活性和高效性来处理异常情况。 原则二：消除关键路径中的CPU页面错误： CPU页面错误处理开销高且难以扩展，TeRM通过避免在关键路径中触发CPU页面错误，提升整体性能。 TeRM DesignArchitecture｜Workflow集群基础设施：集群由多台服务器和客户端机器组成，配备 RNIC 并通过 RDMA 网络连接。服务器通过 mmap 将 SSD 扩展为虚拟内存区域，并注册为 TeRM MR（内存区域），TeRM 利用 Linux 内核进行物理内存和 SSD 之间的按需分页管理。 tLib用户空间库：TeRM 包括两个用户空间库实例： tLib-S [服务器端]：管理 RNIC 页表并处里 RPC 请求 tLib-C [客户端]：处理客户端发起的 RDMA 读取和写入 拥有多个 clinet 和 server 主要技术： 消除 RNIC 页面错误 TeRM 通过预留一个物理页并用魔术模式填充，使得所有无效虚拟页都映射到该物理页，从而避免了 RNIC 页面错误。 比如，当碰到 invalid virtual page (比如 v2 v4 v6) 就将它们映射到一个 magic physical page (M)，这样 RDMA READ 就不会触发 RNIC page fault. 自动预取机制 TeRM 通过无锁读取协议和 dry run 模式，提前计算事务的读写集，并在锁争用期间预取所需数据，减少从慢速存储读取数据的时间。 在计算机术语中，dry run 表示：显示运行的结果，但实际上并没有做出任何变更。 分层 I&#x2F;O：使用文件 I&#x2F;O 接口 (buffer I&#x2F;O 和 direct I&#x2F;O) 访问 SSD 扩展的虚拟内存，避免了 CPU 页面错误的高开销。 buffer I&#x2F;O：访问缓存数据 direct I&#x2F;O：直接访问 SSD 数据 热点数据提升：通过客户端跟踪和服务器累积访问频率，确定并动态提升热点数据，将其从 SSD 提升到物理内存，从而提高整体性能。","tags":["FAST"],"categories":["科研"]},{"title":"[FAST-25] GOGETAFS","path":"/post/科研/fast-25-gogetafs/","content":"Paper: Don’t Maintain Twice, It’s Alright: Merged Metadata Management in Deduplication File System with GOGETAFS Slide: View the slides 论文提出了一种新的去重文件系统 GoGetaFS，它通过合并去重元数据和文件系统元数据，减少了维护去重元数据所需的额外I&#x2F;O操作和排序开销。作者通过一系列技术来管理数据和元数据，使得 GoGetaFS 在保持兼容性的同时，实现了高效和1️⃣节省内存的去重功能。实验表明，GoGetaFS 在各种工作负载下都优于现有的去重文件系统，并且能够2️⃣显著减少元数据维护开销。 Background 重删有两类系统： 独立去重系统（Stand alone Deduplication System）：通常作为文件系统之上的独立层运行，管理指纹索引来检测冗余数据 去重文件系统（Deduplication File System, DedupFS）：将数据去重直接集成到文件系统的方案，旨在消除独立去重系统的冗余元数据维护问题。 独立去重系统独立去重系统 是目前最常见的去重存储解决方案。 它有两个关键数据映射表： L2P（Logical-to-Physical） FP2P（Fingerprint-to-Physical） 流程： 数据写入：计算数据块的加密指纹。在 FP2P 表中查找该指纹： 若 已存在，则 更新引用计数，避免写入新数据。 若 不存在，则 插入新的 FP2P 记录 并写入数据块。 数据读取：通过 L2P 表找到 PBN，并返回对应数据。 数据删除 先删除 L2P 记录，然后减少 FP2P 表中的引用计数。 如果引用计数变为 0，则释放物理块。 元数据管理： 由于去重会将多个逻辑块映射到同一个物理块，系统必须保证 FP2P 映射的崩溃一致性（Crash Consistency） 现有方法： 日志记录（Write-ahead Logging）：先将 FP2P 变更记录写入日志区（但不立刻生效），当 L2P 也持久化后，才将 FP2P 变更正式写入元数据。 写时复制（Copy-on-Write） 软更新（Soft Updates）：在元数据写入前，记录 FP2P 依赖关系，并确保 FP2P 先更新，L2P 后更新。 独立去重系统的问题 额外的元数据维护 独立去重系统需要 单独维护 L2P 和 FP2P，增加了 额外的 I&#x2F;O 负担。 写入路径涉及两次 I&#x2F;O（一次 L2P，一次 FP2P），影响性能。 数据一致性问题 FP2P 映射需要独立存储，如果 崩溃发生在 FP2P 和 L2P 更新之间，会导致数据不一致。 需要额外的恢复机制 来修复 FP2P 记录和 L2P 记录的不一致情况。 高计算开销：传统去重使用加密指纹（如 SHA-1）计算成本高，影响写入性能。 去重文件系统代表性方案： DeNOVA（离线去重） NV-Dedup（混合去重） Light-Dedup（基于 PM 的去重） 传统 DedupFS 特点： 采用单一数据路径，直接在文件系统中执行去重操作：L2P、FP2P 不需要独立的 FP2P 维护，但仍然存在额外的 FP2P 记录更新 Observation and Motivation 其中几个观察对于我的论文十分有帮助！记得引用。 Observation 1：当前 DedupFS 性能低于预期论文使用 FIO 工具对三种不同的 DedupFS 进行测试： DeNOVA NV-Dedup Light-Dedup Ideal-Dedup（一个理想模型，用作基准） 研究模拟了不同去重比率（0%、25%、50%、75%）下的 4KiB 顺序写入负载。 在 0% 去重比率下，所有 DedupFS 的性能都低于 Ideal-Dedup。 原因：DedupFS 在每次写入时都需要计算指纹（FP）并查询 FP2P 表，而 Ideal-Dedup 仅执行基本的文件系统操作。 随着去重比率的增加，理论上 DedupFS 性能应该逐步接近 Ideal-Dedup，但 实验结果显示，性能差距并未明显缩小。 疑问：既然 FP 计算和去重减少了数据写入，为什么吞吐量没有提升？ Observation 2：重复数据删除元数据维护是主要瓶颈论文分析了 DedupFS 开销的五个主要组成部分（Breakdown）： Dup Identify（去重识别）：计算指纹、查找 FP2P 表、内容比对 Dedup Metadata（去重元数据维护）：记录&#x2F;更新 FP2P 映射 Data Write（数据写入）：将数据块写入存储 FS Metadata（文件系统元数据维护）：更新 L2P（逻辑到物理）映射 Others（其他开销）：VFS、垃圾回收、块分配等 去重元数据维护开销占 I&#x2F;O 时间的 18% - 38%，成为影响 DedupFS 性能的主要瓶颈。 原因： 额外的崩溃一致性（crash consistency）开销：传统 DedupFS 需要在 写入 L2P 之前 确保 FP2P 表的持久化，以保证一致性。 I&#x2F;O 放大和并行性受限：由于 FP2P 需要独立写入，导致两次元数据写入，并减少了 I&#x2F;O 并行性。 所以论文自然而然提出了「合并元数据」这一重要设计（优势如下）： 重复使用成熟的文件系统 I&#x2F;O 路径和崩溃一致性机制。DedupFS 利用文件系统通过使用与文件系统 L2P 条目相同的 I&#x2F;O 路径来保证 LFP 条目的持久性和崩溃一致性，从而减少实施工作量并提高稳健性。 减少元数据 I&#x2F;O 放大和排序点。LFP (Logical-Fingerprint-Physical) 条目避免在存储中维护 FP2P 表，从而减少 I&#x2F;O 放大和排序点。 消除重复数据删除和文件系统之间的不一致。由于 FP2P 映射始终在容错 LFP 条目中可用，因此无需修复不一致，这可以进一步加快故障恢复。 Design在解决去重文件系统（DedupFS）中的元数据维护开销问题后，GOGETAFS 采用了一种创新的 逻辑-指纹-物理（LFP）映射，将去重元数据合并到文件系统元数据中，从而消除了额外的 FP2P 维护操作，提高了系统的性能和一致性。GOGETAFS 的设计主要围绕四个目标展开：通用性（Generic）、高效性（Effective）、内存高效性（Memory-efficient）以及可配置性（Configurable）。为了满足这些目标，GOGETAFS 采用了一系列关键技术，包括： LFP 映射 全局 LFP 表（GLT） 溢出 FP 表（OFT） 不同的元数据管理策略 GOGETAFS 在数据管理方面解决了传统 DedupFS 与文件系统在数据组织上的不兼容问题。DedupFS 传统上以块为单位进行去重，而文件系统通常以 extent（连续块）方式管理数据。为此，GOGETAFS 采用了两种策略： 一种是利用超指纹（Super-Fingerprint, SFP）对整个 extent 进行指纹计算，但这种方式降低了去重比率，并增加了串行化计算带来的并行性问题。因此，GOGETAFS 选择了更优的方案，即使用溢出 FP 表（OFT），将连续块的指纹存储到一个额外的存储区域，从而避免 LFP 记录的可变长度问题，同时保持了指纹计算的并行性。OFT 的设计基于存储分配的空间局部性，使其能够高效地管理指纹数据，并且在文件删除时不需要额外的清理操作，因为未被 LFP 记录引用的 OFT 条目可以被安全覆盖。 在元数据管理方面，GOGETAFS 采用了全局 LFP 表（GLT），以加速指纹查询和数据去重过程。GLT 通过动态哈希表（Dynamic Hash Table, DHT）组织 LFP 记录，以指纹作为键，实现快速的指纹查找和数据重定向。相比于传统 DedupFS 需要在存储中维护 FP2P 表，GLT 作为一个内存结构，可以通过并行化哈希查询显著提升指纹匹配的速度。此外，GLT 还采用了乐观并发控制（Optimistic Concurrency Control）机制来处理多线程环境下的去重操作，确保多个线程在插入相同指纹时不会导致数据不一致。 为了适应不同的系统环境，GOGETAFS 设计了多种 GLT 变体，以优化内存使用。在内存受限的环境（如 PC）中，GOGETAFS 采用了混合存储策略（Hybrid），将指纹索引存储在内存，而将值（物理块地址和引用计数）存储在存储设备中。这种方式减少了对内存的占用，同时仍然可以通过快速的内存查询提高去重效率。在极端内存受限的环境（如移动设备）中，GOGETAFS 采用了静态哈希表（Static Hash Table, SHT）结构，将 GLT 直接存储在设备上，以避免内存消耗过大，同时优化存储访问路径，以减少 I&#x2F;O 放大效应。 在崩溃一致性和恢复方面，GOGETAFS 充分利用了文件系统的事务和日志机制，使 LFP 记录的持久化与文件系统元数据的持久化同步进行。这意味着，即使发生崩溃，GLT 也可以通过遍历 LFP 记录来恢复，而不需要额外的 FP2P 重建步骤。这种方法不仅提高了恢复速度，还减少了额外的存储写入开销。此外，GOGETAFS 采用了存储友好的恢复策略，在正常关闭系统时，会将 GLT 缓存到一个特殊的文件，以便在下次启动时快速恢复，而在崩溃恢复时，则采用并行扫描 LFP 记录的方式，以提高恢复效率。 GOGETAFS 的实现基于 NOVA 文件系统（in PM）和 F2FS（in SSD），并通过修改其写入条目（write entry）结构来存储 LFP 记录。通过替换原有的 4 字节校验和字段和 4 字节填充字段，GOGETAFS 无需额外的存储空间即可存储 8 字节的非加密指纹。OFT 被设计为一个无锁（lock-free）的数据结构，利用文件系统的事务机制来确保数据一致性，同时避免了传统 DedupFS 需要的额外排序点。在移植性方面，GOGETAFS 也可以扩展到其他文件系统，如 F2FS 以及 BtrFS，只需要对它们的 L2P 记录进行相应的扩展，以存储指纹信息。 Evaluation GOGETAFS 的评估基于多个真实世界的工作负载和合成基准测试，涵盖了不同的存储场景，如服务器、PC 和移动设备。实验环境包括 Intel Xeon 服务器，配置有 512GB Optane DCPMM 和 128GB DRAM，并运行 CentOS Stream 5.1 内核。此外，还在 Z-SSD 模拟环境下对 GOGETAFS 进行了额外测试，以验证其在超低延迟 SSD（ULL SSD）上的表现。 在基本 I&#x2F;O 性能测试中，GOGETAFS 在所有去重比率（0%-100%）的情况下都优于现有 DedupFS，如 NV-Dedup 和 Light-Dedup。特别是在 2MB 块大小的 I&#x2F;O 负载下，GOGETAFS 不仅超越了 Light-Dedup，还比 NOVA 文件系统本身更快。这一现象的原因是 GOGETAFS 采用了更优化的 FP 计算和 I&#x2F;O 并行策略，使得指纹计算能够与数据写入并行进行，从而减少了存储内部缓冲区的争用。此外，在 WebVMs 和 Mails 这样的真实世界工作负载中，GOGETAFS 在 2MB 块大小时的吞吐量比 Light-Dedup 高出 23% - 32%，表明在混合负载情况下，GOGETAFS 仍然具有明显的性能优势。 在元数据维护开销分析中，实验结果显示 GOGETAFS 的元数据 I&#x2F;O 开销比 Light-Dedup 低 75.4% - 92.8%。这一优化主要来源于 LFP 记录的合并，使得 FP2P 记录不再需要独立写入，而是与文件系统元数据一同持久化。此外，实验还分析了去重带来的 I&#x2F;O 放大效应。结果表明，在 4KB 块 I&#x2F;O 的情况下，GOGETAFS 的额外读写开销几乎为零，而 Light-Dedup 需要额外执行 132.2 字节的读操作和 115.6 字节的写操作，导致更高的存储开销。 在不同内存条件下的评估中，GOGETAFS 设计的多个 GLT 变体展现了出色的适应能力。在内存受限环境中（如 PC），GOGETAHYBRID 通过在存储设备中存储指纹值（PBN 和引用计数），而仅在内存中存储指纹键（FP），在减少内存占用的同时，保持了较高的查找效率。而在极端受限的移动环境下，GOGETASHT 采用存储中的静态哈希表，以换取更低的内存消耗，同时优化存储访问路径，使得 I&#x2F;O 性能仍然优于传统 DedupFS。 在崩溃恢复测试中，GOGETAFS 展示了显著的恢复加速效果。相比于传统 DedupFS 需要遍历所有 L2P 记录来重建 FP2P 表，GOGETAFS 只需扫描 LFP 记录，恢复时间缩短了 50% - 67%。此外，在超低延迟 SSD 上，GOGETAFS 仍然能够保持高吞吐量，并比现有 DedupFS 方案减少 15% - 30% 的元数据维护延迟。 综合来看，GOGETAFS 在吞吐量、元数据管理、内存优化和崩溃恢复方面都比现有 DedupFS 方案有显著优势，使其成为更高效、更可靠的去重文件系统方案。","tags":["FAST"],"categories":["科研"]},{"title":"[OSDI'23] SMART","path":"/post/科研/osdi-23-smart/","content":"Paper: SMART: A High-Performance Adaptive Radix Tree for Disaggregated Memory Slide: View the slides Background随着计算和存储资源需求的不断增长，分离式内存（Disaggregated Memory, DM）架构逐渐成为高效资源管理的解决方案。DM 将计算资源和存储资源分离到独立的资源池中，并通过高速 RDMA 网络进行互连。该架构能够提高资源利用率，并为分布式计算提供更高的可扩展性。然而，由于计算节点（CN）和内存节点（MN）之间的远程访问开销，DM 面临新的挑战，其中之一就是 索引结构的优化。 RDMA Architecture 现有的 DM 范围索引通常基于 B+ 树，这种传统的树索引结构在 DM 环境下存在严重的读放大（Read Amplification）和写放大（Write Amplification）问题。当在 B+ 树中查找或插入键值对时，需要遍历多个内部节点，每个节点中包含许多无关的键和指针，从而增加了不必要的网络带宽消耗。由于 DM 的主要瓶颈是网络带宽，B+ 树的读写放大会迅速耗尽 RDMA 网络带宽，导致索引查询的吞吐量降低和访问延迟升高。例如，最先进的 DM B+ 树索引 Sherman 由于这些问题，其吞吐量比 RNIC（远程网络接口卡）的理论上限低 10.8 倍。 Sherman is the state-of-the-art B+ tree on DM 针对这一问题，自适应基数树（Adaptive Radix Tree, ART） 作为替代方案进入研究视野。与 B+ 树相比，ART 在内部节点中不存储完整的键，而是使用部分键（partial keys）进行索引，从而减少了读放大和写放大。然而，ART 直接应用于 DM 仍然存在多个挑战，包括昂贵的锁机制、冗余的 I&#x2F;O 操作，以及复杂的计算侧缓存一致性验证。 MotivationB+ 树在 DM 环境下的主要性能瓶颈在于高读放大和写放大，这些放大会加重 RDMA 网络的负担，降低索引的整体性能。 相比之下，ART 由于其更紧凑的数据结构，本质上具有更低的读写放大，因此在 DM 中具有潜在的优势。通过理论分析和实验结果，我们得出以下观察结论： B+ 树在 DM 中的读写放大严重影响吞吐量 B+ 树在内部节点存储完整的键，并且叶子节点存储多个键值对。在每次索引操作时，都需要读取整个叶子节点，从而导致严重的带宽消耗。 例如，在 Sherman 方案中，每次读取单个键值对需要额外读取 33 倍的数据，而 ART 仅需 1.1 倍。 B+ 树的吞吐量受限于网络带宽 DM 的瓶颈通常是 RDMA 网络带宽，而 B+ 树的读写放大使得其带宽消耗远超 ART，从而导致吞吐量受限。 例如，在 YCSB C（100% 读）负载下【如图】，Sherman 受限于网络带宽的峰值吞吐量为 4.17 Mops&#x2F;s，而 ART 的吞吐量可达 45 Mops&#x2F;s，完全利用了 RNIC 的 IOPS 上限。 B+ 树的锁竞争和远程锁操作增加了写入延迟 由于 DM 的远程内存访问开销较大，传统的基于锁的并发控制会导致频繁的 RDMA 重试，增加网络延迟。 在 YCSB A（50% 读 + 50% 更新）负载下，Sherman 由于锁冲突导致吞吐量下降 7.4 倍，而 ART 由于采用读优化写排除（ROWEX）协议，性能更优。 ART 仍然面临多项挑战： 锁机制开销高：ART 采用的 ROWEX 并发控制仍然包含许多远程锁操作，导致写入性能下降。 冗余 I&#x2F;O 操作降低 IOPS：在多个计算节点上运行的客户端会产生重复的 RDMA 读写操作，浪费有限的 IOPS 资源。 计算侧缓存一致性验证复杂：ART 的路径压缩（Path Compression）和自适应节点设计导致频繁的地址变更，使得计算节点的缓存无效化问题更加复杂。 基于这些挑战，本文提出了一种高性能的分离式内存自适应基数树（SMART），它通过以下几种机制优化 ART 在 DM 上的表现。 混合并发控制 读代理与写合并（RDWC） 反向检查机制 Design SMART 主要通过三种关键技术来提升 ART 在 DM 环境下的性能。 混合并发控制（Hybrid Concurrency Control） internal node &amp; leaf node insert worflow —— SMART 针对 ART 锁机制昂贵 的问题，SMART 采用锁自由（lock-free）内部节点和细粒度锁（fine-grained locks）叶子节点的设计。 内部节点使用 无锁结构，避免频繁的 RDMA 比较和交换（CAS）操作，同时提升并发性能。 叶子节点仍然使用锁，但采用嵌入式锁（embedded locks），减少锁释放的开销，使得锁操作与数据写入同时完成，提高吞吐量。 读代理与写合并（Read Delegation and Write Combining, RDWC） RDWC 针对冗余 I&#x2F;O 操作降低 IOPS 的问题，SMART 采用 RDWC 技术： 读代理（Read Delegation）：多个客户端在同一计算节点访问相同键时，仅有一个客户端执行 RDMA 读取，并将结果共享给其他客户端，从而减少重复的 RDMA 读取操作。 写合并（Write Combining）：多个客户端写入相同键时，先在计算节点合并写入请求，然后一次性将合并后的数据写入远程内存，减少 RDMA 写入次数，提高写吞吐量。 反向检查机制（Reverse Check Mechanism） 针对缓存一致性验证复杂的问题，SMART 设计了一种反向检查机制： 在每个 ART 节点中存储反向指针（Reverse Pointer），指向其父节点，使得计算节点可以验证缓存数据是否过期。 在每个节点头部存储类型字段（Typenode Field），如果节点类型发生变化（如路径压缩导致的节点类型变化），计算节点可以通过该字段检查缓存是否需要刷新。 EvaluationSMART 通过实验对比了现有的 B+ 树索引 Sherman 和传统 ART 在 DM 上的性能。实验环境包括 16 个计算节点和 2 个内存节点，采用 100Gbps RDMA 网络，并运行 YCSB 负载。 实验结果表明： 在写密集型负载（YCSB A）下，SMART 的吞吐量比 Sherman 高 6.1 倍，比 ART 高 3.4 倍，同时 P99 延迟分别降低 1.4 倍和 1.3 倍。 在只读负载（YCSB C）下，SMART 吞吐量比 Sherman 高 2.8 倍，比 ART 高 1.2 倍，同时保持相似的 P99 延迟。 在混合负载（YCSB B）下，SMART 吞吐量比 Sherman 高 2.4 倍，比 ART 高 1.8 倍，同时 P99 延迟降低 1.1 倍和 1.7 倍。 在高并发环境下（&gt;800 clients），ART 由于缓存失效和锁冲突，性能下降明显，而 SMART 保持优异的可扩展性。","tags":["OSDI"],"categories":["科研"]},{"title":"[OSDI'23] Chardonnay","path":"/post/科研/osdi-23-chardonnay/","content":"分布式系统 · 数据库领域的论文 Paper: Chardonnay: Fast and General Datacenter Transactions for On-Disk Databases 传统的分布式磁盘数据库系统通常需要使用昂贵的提交协议，如两阶段提交（2PC），以保证原子性，从而导致分布式事务的速度较慢。或者不使用 2PC，从而牺牲了语义、限制了编程模型或缩小了系统的可扩展性，导致系统的通用性降低。作者认为，在现代数据中心内，这种折衷不再是必要的。利用低延迟的存储和快速的远程过程调用（RPC）以及精心设计的协议，可以实现低延迟的2PC（例如在 Azure 上约 150us 的 2PC over Paxos）。随着快速 2PC 的实现，数据争用瓶颈从2PC转移到了在持有事务锁期间从相对较慢的存储读取数据的过程。 2PC (Two phase commit)2PC 是一种分布式算法，用于协调参与分布式原子事务的所有进程，确定是否提交或中止（回滚）事务。 二阶段提交协议（Two-phase Commit，即2PC）是常用的分布式事务解决方案，它可以保证在分布式事务中，要么所有参与进程都提交事务，要么都取消事务，即实现 ACID 的原子性（A）。在数据一致性中，它的含义是：要么所有副本（备份数据）同时修改某个数值，要么都不更改，以此来保证数据的强一致性。 2PC 要解决的问题可以简单总结为：在分布式系统中，每个节点虽然可以知道自己的操作是成功还是失败，却是无法知道其他节点的操作状态。当一个事务需要跨越多个节点时，为了保持事务的 ACID 特性，需要引入一个作为协调者的组件来统一掌控所有节点（参与者）的操作结果并最终指示这些节点是否要把操作结果进行真正的提交（比如将更新后的数据写入磁盘等等）。因此，二阶段提交的算法思路可以概括为： 参与者将操作结果通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。 顾名思义，2PC 分为两个过程： 表决阶段：此时 Coordinator （协调者）向所有的参与者发送一个 vote request，参与者在收到这请求后，如果准备好了就会向 Coordinator 发送一个 VOTE_COMMIT 消息作为回应，告知 Coordinator 自己已经做好了准备，否则会返回一个 VOTE_ABORT 消息； 提交阶段：Coordinator 收到所有参与者的表决信息，如果所有参与者一致认为可以提交事务，那么 Coordinator 就会发送 GLOBAL_COMMIT 消息，否则发送 GLOBAL_ABORT 消息；对于参与者而言，如果收到 GLOBAL_COMMIT 消息，就会提交本地事务，否则就会取消本地事务。 2PC 的一个众所周知的问题是阻塞，即协调者在不合时宜的时刻发生故障，从而阻止参与者取得进展。这可以通过复制协调者状态来实现可用性。 CAP 理论在分布式系统领域，有一个理论，对于分布式系统的设计影响非常大，那就是 CAP 理论，即对于一个分布式系统而言，它是无法同时满足 Consistency（强一致性）、Availability（可用性）和 Partition tolerance（分区容忍性）这三个条件的，最多只能满足其中两个。但在实际中，由于网络环境是不可信的，所以分区容忍性几乎是必不可选的，设计者基本就是在一致性和可用性之间做选择，当然大部分情况下，大家都会选择牺牲一部分的一致性来保证可用性（可用性较差的系统非常影响用户体验的，但是对另一些场景，比如支付场景，强一致性是必须要满足）。但是分布式系统又无法彻底放弃一致性（Consistency），如果真的放弃一致性，那么就说明这个系统中的数据根本不可信，数据也就没有意义，那么这个系统也就没有任何价值可言。 CAP 理论三个特性的详细含义如下： 一致性（Consistency）：每次读取要么是最新的数据，要么是一个错误； 可用性（Availability）：client 在任何时刻的读写操作都能在限定的延迟内完成的，即每次请求都能获得一个响应（非错误），但不保证是最新的数据； 分区容忍性（Partition tolerance）：在大规模分布式系统中，网络分区现象，即分区间的机器无法进行网络通信的情况是必然会发生的，系统应该能保证在这种情况下可以正常工作。 分区容忍性 | Partition tolerance很多人可能对分区容忍性不太理解，知乎有一个回答对这个解释的比较清楚（CAP理论中的P到底是个什么意思？），这里引用一下： 一个分布式系统里面，节点组成的网络本来应该是连通的。然而可能因为一些故障，使得有些节点之间不连通了，整个网络就分成了几块区域。数据就散布在了这些不连通的区域中。这就叫分区。 当你一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了。这时分区就是无法容忍的。 提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，这一数据项就可能分布到各个区里，容忍性就提高了。 然而，要把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的。 要保证一致，每次写操作就都要等待全部节点写成功，而这等待又会带来可用性的问题。 总的来说就是，数据存在的节点越多，分区容忍性越高，但要复制更新的数据就越多，一致性就越难保证。为了保证一致性，更新所有节点数据所需要的时间就越长，可用性就会降低。 CAP 理论原理 CAP 定理表明，在存在网络分区的情况下，一致性和可用性必须二选一。而在没有发生网络故障时，即分布式系统正常运行时，一致性和可用性是可以同时被满足的。但是，对于大多数互联网应用来说，因为规模比较大，部署节点分散，网络故障是常态，可用性是必须要保证的，所以只有舍弃一致性来保证服务的 AP。但是对于一些金融相关行业，它有很多场景需要确保一致性，这种情况通常会权衡 CA 和 CP 模型，CA 模型网络故障时完全不可用，CP 模型具备部分可用性。 在一个分布式系统中，对于这三个特性，我们只能三选二，无法同时满足这三个特性，三选二的组合以及这样系统的特点总结如下（来自左耳朵耗子推荐：分布式系统架构经典资料）： CA (Consistency + Availability)：关注一致性和可用性，它需要非常严格的全体一致的协议，比如“两阶段提交”（2PC）。CA 系统不能容忍网络错误或节点错误，一旦出现这样的问题，整个系统就会拒绝写请求，因为它并不知道对面的那个结点是否挂掉了，还是只是网络问题。唯一安全的做法就是把自己变成只读的。 CP (consistency + partition tolerance)：关注一致性和分区容忍性。它关注的是系统里大多数人的一致性协议，比如：Paxos 算法 (Quorum 类的算法)。这样的系统只需要保证大多数结点数据一致，而少数的结点会在没有同步到最新版本的数据时变成不可用的状态。这样能够提供一部分的可用性。 AP (availability + partition tolerance)：这样的系统关心可用性和分区容忍性。因此，这样的系统不能达成一致性，需要给出数据冲突，给出数据冲突就需要维护数据版本。Dynamo 就是这样的系统。 对于分布式系统分区容忍性是天然具备的要求，否则一旦出现网络分区，系统就拒绝所有写入只允许可读，这对大部分的场景是不可接收的。因此，在设计分布式系统时，更多的情况下是选举 CP 还是 AP，要么选择强一致性弱可用性，要么选择高可用性容忍弱一致性。 分布式一致性协议为了解决分布式系统的一致性问题，在长期的研究探索过程中，业内涌现出了一大批经典的一致性协议和算法，其中比较著名的有二阶段提交协议（2PC），三阶段提交协议（3PC）和 Paxos 算法。 Google 2009年 在 Transaction Across DataCenter 的分享中，对一致性协议在业内的实践做了一简单的总结，如下图所示，这是 CAP 理论在工业界应用的实践经验。 CAP 理论在工业界的实践 其中，第一行表头代表了分布式系统中通用的一致性方案，包括冷备、Master&#x2F;Slave、Master&#x2F;Master、两阶段提交以及基于 Paxos 算法的解决方案，第一列表头代表了分布式系统大家所关心的各项指标，包括一致性、事务支持程度、数据延迟、系统吞吐量、数据丢失可能性、故障自动恢复方式。 Paxos 算法 Paxos：半数以上同意 2PC：全部同意 基于消息传递且具有高度容错性的一致性算法。Paxos 算法要解决的问题就是如何在可能发生几起宕机或网络异常的分布式系统中，快速且正确地在集群内部对某个数据的值达成一致，并且保证不论发生以上任何异常，都不会破坏整个系统的一致性。 拜占庭问题：消息不完整或者被篡改。Paxos 在维持领导者选举或者变量修改一致性上，采取一种类似议会投票的过半同意机制，比如设定一个领导者，需要将此看做一个议案，征求过半同意，每个节点通过一个议案会有编号记录，再次收到此领导者的不同人选，发现已经有编号记录便驳回，最后以多数通过的结果为准。 Paxos 有点类似分布式二阶段提交方式，但是又不同，2PC 不能是多数节点同意，必须是全部同意。为了遵守过半节点同意的约束，Paxos 算法往往要求节点总数为奇数。 第一阶段：Prepare 阶段A 把申请修改的请求 Prepare Request 发给所有的结点 A，B，C。注意，Paxos 算法会有一个 Sequence Number（你可以认为是一个提案号，这个数不断递增，而且是唯一的，也就是说 A 和 B 不可能有相同的提案号），这个提案号会和修改请求一同发出，任何结点在“Prepare 阶段”时都会拒绝其值小于当前提案号的请求。所以，结点 A 在向所有结点申请修改请求的时候，需要带一个提案号，越新的提案，这个提案号就越是是最大的。 如果接收结点收到的提案号 n 大于其它结点发过来的提案号，这个结点会回应 Yes（本结点上最新的被批准提案号），并保证不接收其它 &lt;n 的提案。这样一来，结点上在 Prepare 阶段里总是会对最新的提案做承诺。 优化：在上述 prepare 过程中，如果任何一个结点发现存在一个更高编号的提案，则需要通知提案人，提醒其中断这次提案。 第二阶段：Accept 阶段如果提案者 A 收到了超过半数的结点返回的 Yes，然后他就会向所有的结点发布 Accept Request（同样，需要带上提案号 n），如果没有超过半数的话，那就返回失败。 当结点们收到了 Accept Request 后，如果对于接收的结点来说，n 是最大的了，那么，它就会通过 request（修改这个值），如果发现自己有一个更大的提案号，那么，结点就会拒绝 request（拒绝修改）。 我们可以看以，这似乎就是一个“两段提交”的优化。其实，2PC&#x2F;3PC 都是分布式一致性算法的残次版本，Google Chubby 的作者 Mike Burrows 说过这个世界上只有一种一致性算法，那就是 Paxos，其它的算法都是残次品。 我们还可以看到：对于同一个值的在不同结点的修改提案就算是在接收方被乱序收到也是没有问题的。 Raft 算法（解决 Paxos 实现难度）Paxos 相比 Raft 比较复杂和难以理解。角色扮演和流程比 Raft 都要啰嗦。比如 Agreement 这个流程，在 Paxos 里边：Client 发起请求举荐 Proposer 成为 Leader，Proposer 然后向全局 Acceptors 寻求确认，Acceptors 全部同意 Proposer 后，Proposer 的 Leader 地位得已承认，Acceptors 还得再向 Learners 进行全局广播来同步。而在 Raft 里边，只有 Follower&#x2F;Candidate&#x2F;Leader 三种角色，角色本身代表状态，角色之间进行状态转移是一件非常自由民主的事情。 Raft 虽然有角色之分但是是全民参与进行选举的模式；但是在 Paxos 里边，感觉更像议员参政模式。 三个角色follower、candidate、leader。 最开始大家都是 follower，当 follower 监听不到 leader，就可以自己成为 candidate，发起投票 leader 选举：timeout 限制 选举的 timeout follower 成为 candidate 的超时时间，每个 follower 都在 150ms and 300ms 之间随机，之后看谁先 timeout，谁就先成为 candidate，然后它会先投自己一票，再向其他节点发起投票邀请。如果其他节点在这轮选举还没有投过票，那么就给 candidate 投票，然后重置自己的选举 timeout。如果得到大多数的投票就成为 leader，之后定期开始向 follower 发送心跳。 如果两个 follower 同时成为 candidate 的话，如果最后得到的票数相同，则等待其他 follower 的选择 timeout 之后成为 candidate，继续开始新一轮的选举。 log 复制leader 把变动的 log 借助心跳同步给 follower，过半回复之后才成功提交，之后再下一次心跳之后，follower 也 commit 变动，在自己的 node 上生效。 分裂之后，另一个分区的 follower 接受不到 leader 的 timeout，然后会有一个先 timeout，成为 candidate，最后成为 leader。于是两个分区就有了两个 leader。 当客户端有变动时，其中的 leader 由于无法收到过半的提交，则保持未提交状态。有的 leader 的修改，可以得到过半的提交，则可以修改生效。 当分裂恢复之后，leader 开始对比选举的 term，发现有更高的 term 存在时，他们会撤销未提交的修改，然后以最新的为准。 Chardonnay Design强一致性快照读取协议Chardonnay 利用快速的 RPC 来支持严格可序列化的无锁快照读取。其核心机制如下： Epoch 服务：维护一个单调递增的计数器，称为 epoch。Epoch 服务通过 Multi-Paxos 协议进行复制，确保每次读取的 epoch 值都保持全局一致。 快照读取协议：在每个事务提交时，读取最新的 epoch 值作为全局序列化点。系统通过该协议确定查询的读写集，从而在执行事务和获取锁之前预取所需的数据。 自动预取机制为了减少在持有锁期间从慢速存储读取数据的时间，Chardonnay 设计了自动预取机制： 干运行模式（Dry Run）：事务在执行正式的读写操作之前，先在干运行模式下运行一次查询，以加载并固定事务需要的所有键值。 预取缓存：每个范围领导者维护一个预取缓存，用于存储事务读取集中的记录。预取缓存作为写通一致性缓存（write-through consistent cache），确保所有事务都能从缓存中读取已预取的键值，而无需访问底层数据库。 轻量级死锁避免为了避免死锁，Chardonnay 提前计算事务的读写集，并按照确定的顺序获取锁： 锁顺序获取：通过干运行模式计算事务的读写集，并按照键值的升序顺序获取锁，避免死锁的发生。 RPC 链式调用：客户端发送一个 RPC 请求到第一个需要键值的范围。该范围获取所有本地锁，执行必要的本地读取操作，然后将请求转发到下一个范围。最后一个范围完成本地操作后，将所有读取结果返回给客户端，从而减少获取锁的开销。 架构 Chardonnay 的系统架构主要包括以下四个组件： Epoch 服务：负责维护和更新单调递增的计数器 epoch，为所有提交的事务提供全局序列化点。 KV 服务：核心服务，存储用户的键值数据，使用共享无结构的范围分片架构，并通过 Paxos 实现 WAL。 事务状态存储：以容错、复制的方式存储活动事务的状态，防止 2PC 阻塞。 客户端库：为用户提供访问数据库的接口，并在 Chardonnay 中充当 2PC 协调器。 Chardonnay 通过利用快速 RPC和无锁快照读取协议，实现了高效的分布式事务处理，并在高争用工作负载下保持了出色的性能。通过自动预取和轻量级死锁避免机制，Chardonnay 在保持严格可序列化语义的同时，显著减少了事务锁的争用，从而实现了高吞吐量和低延迟的分布式数据库系统。","tags":["OSDI"],"categories":["科研"]},{"title":"[OSDI'24] A Tale of Two Paths","path":"/post/科研/osdi-24-atlas/","content":"Paper: A Tale of Two Paths: Toward a Hybrid Data Plane for Efficient Far-Memory Applications Slide: View the slides Background随着网络硬件的快速发展，远程内存（Far Memory）技术因其能够突破本地内存容量限制而受到广泛关注。当前的远程内存系统大致分为两种数据路径： 基于内核分页系统的页粒度访问路径和绕过内核（Kernel-based page-level profiling） 基于对象粒度的访问路径（object fetching） 对象粒度访问通常性能更优，但对计算资源的需求显著更高。 Object fetching is motivated by two observations on the inefficiencies of paging. First, fetching data at the page granularity often leads to I&#x2F;O amplification. Second, managing data in the kernel space is agnostic to program semantics, resulting in missed optimization opportunities. 分页系统（Paging）：一种使用内核的虚拟内存分页机制来透明地访问远程内存的方法。例如，InfiniSwap、Fastswap 和 Canvas 等技术使用内核的分页系统，通过交换远程和本地内存的页面来提高应用程序的内存容量。分页适用于数据访问模式较为规则（如顺序访问）的工作负载。 优点：对于顺序或有规律的内存访问模式，分页能够减少 I&#x2F;O 放大，提升性能。 缺点：当应用程序的访问模式不规则时，分页会导致大量不必要的数据交换，进而产生I&#x2F;O放大（I&#x2F;O Amplification），即加载的大部分页面都包含无用数据，浪费了大量的内存带宽和计算资源。 对象粒度访问（Object Fetching）：与页粒度的方式相比，对象粒度访问使用应用程序的抽象（即对象）来管理远程内存。这种方式可以更精确地获取所需数据，减少 I&#x2F;O 放大。 优点：通过对象粒度交换数据，能够避免加载不相关的内存数据，从而显著减少 I&#x2F;O 开销，提升效率。 缺点：对象粒度的管理需要更多的计算资源，例如，运行对象粒度的最近最少使用（LRU）算法和逐出（Eviction）操作需要大量的计算能力。 ChallengesMajor insight：我们能否为应用程序启用始终在线的分析来识别其访问模式，并在分页和对象获取之间动态切换以适应观察到的模式？如果有效实施，这种方法与最先进的技术相比有两个优势。 首先，即使程序输入不断变化，它的连续分析也可以动态识别不同计算阶段或访问不同数据结构的并行线程的模式。因此，它可以快速更改访问路径以使用更高效的获取机制。 其次，对于具有不规则模式的程序，对象获取会将访问时间接近的对象移动到连续的内存空间中，从而在程序执行时动态改善局部性。这使得执行越来越适合分页，从而具有更高的资源效率 Although promising, realizing this insight requires overcoming three major challenges, as elaborated below: 1. 挑战：如何在低开销下持续精确地对应用进行剖析 传统的内核级分页系统无法提供足够细粒度的数据局部性信息。例如，如果一个页面上的单个对象被频繁访问，而其他对象没有被访问，内核分页系统仍然会将整个页面视为“热点页面”，这导致对不必要的数据进行交换，从而产生 I&#x2F;O 放大。 使用卡片访问表（CAT）：Atlas 通过将每个页面划分为多个卡片，每个卡片代表页面上的 16 字节数据，以便精确测量数据局部性。每当一个页面被访问时，Atlas 会更新对应卡片的访问标记，从而能够更细粒度地分析页面访问的局部性。 页面的卡片访问率（CAR）：通过卡片访问表计算页面的卡片访问率（CAR），如果页面的 CAR 值较高，说明该页面有较好的局部性，可以通过分页机制进行访问；如果 CAR 值较低，则使用对象访问路径来减少 I&#x2F;O 放大。 2. 挑战：如何动态切换访问机制 对于不同的工作负载，局部性会发生变化，因此需要动态切换访问机制。例如，在工作负载初期可能是随机访问模式，稍后可能转为顺序访问，最优的访问路径可能发生变化。 使用页面选择标志（PSF）：Atlas 为每个页面维护一个 1-bit 的标志（PSF），用于指示该页面是通过 “runtime” 还是 “paging” 访问。当页面被交换时，PSF 的值会根据页面的局部性（由 CAR 值决定）动态更新。如果页面的 CAR 值较低，则选择 runtime（对象粒度访问）；如果较高，则选择 paging（页粒度访问）。 动态切换：通过分析程序的访问模式，Atlas 能够在执行过程中实时选择合适的访问路径。这种动态切换确保了系统能够在不同的计算阶段或并行线程之间优化内存访问模式。 为了减少死对象造成的碎片，Atlas 会运行并发撤离任务，定期将活动对象移至连续的内存空间。每次撤离期间，Atlas 都会将最近访问的对象分组到连续的页面中，以进一步改善数据局部性。 3. 挑战：如何协调两条访问路径的同步 由于 kernel 和 runtime 系统是独立的，它们之间没有直接的协调机制，因此可能会发生并发的访问冲突。例如，一个页面可能正在进行分页操作，而同时另一个线程可能在运行时路径中对同一页面进行对象访问，这样会产生数据一致性问题。 同步协议：为了解决这种同步问题，Atlas 设计了一种同步协议，确保内核分页和运行时对象访问之间的一致性。具体来说，Atlas 保证： 对象-页面冲突：禁止同一页面在不同的访问路径下同时被访问。只有当页面的 PSF 值被更新时，才会切换访问路径。 页面交换与对象交换冲突：如果一个页面包含某个正在使用的对象（例如，在一个活跃的解引用范围内），该页面不能被交换出去。 对象迁移与垃圾回收冲突：在执行对象迁移时，必须确保对象不会在迁移过程中被其他线程的解引用操作访问。 使用智能指针与解引用范围：Atlas 使用类似 C++ 智能指针的机制（例如 AtlasUniquePtr），通过为每个对象定义解引用范围，确保在对象迁移或交换期间，其指针不会被错误地更新或访问。这样可以确保数据一致性。 Motivation🔥 多样化的内存访问模式：许多真实的云应用展示了复杂的内存访问模式，这些模式可能是顺序的、随机的、或是其他混合类型。随着应用的执行，这些访问模式可能会发生变化。例如，某些程序的访问模式可能在某个计算阶段表现出规律性，而在另一个阶段则可能变得不规则。在应用 Metis（一个优化的 MapReduce 框架）中，Page View Count (PVC) 程序在 “Map” 阶段会呈现出部分顺序的访问模式（由于数据的偏斜），而在 “Reduce” 阶段则呈现出清晰的顺序访问模式。 现有的解决方案（如 AIFM）采用对象粒度访问来减少I&#x2F;O放大，但它的高计算开销使得它在某些场景下不适用。而传统的分页方法则因为局部性差导致的I&#x2F;O放大问题而变得低效。 问题的核心：究竟如何在不同的工作负载和计算阶段之间选择合适的内存访问路径，以便在减少I&#x2F;O放大的同时不增加不必要的计算开销？ 动态路径切换的需求：由于程序的内存访问模式在执行过程中是不断变化的，无法仅仅依靠静态的编译时分析（如 Mira 等技术）来选择访问路径。因此，需要一种能够在程序执行过程中持续监测其内存访问模式，并根据实际访问模式动态切换访问路径的方法。 混合数据平面（Hybrid Data Plane）：根据应用的内存访问模式，动态选择使用分页（对于具有良好局部性的应用）或对象粒度访问（对于具有不规则访问模式的应用）。这种方式的优势在于能够在不同的计算阶段和并行线程之间自动调整内存访问机制，从而提高远程内存的效率。 离线分析技术（如 Mira）：尽管有一些编译器技术（如 Mira）尝试通过离线分析来优化内存访问路径，但它们依赖于程序的输入数据和执行阶段的静态分析。对于交互式应用（如 Memcached 和 WebService），其输入数据和工作负载不断变化，离线分析无法适应这些变化。 DesignAtlas leaverage the runtime to compute a card access table (CAT) for each page, which is a bitmap where each bit corresponds to a card (i.e., consecutive 16 bytes) 利用 card access rate (CAR) 作为评判 page 的良好&#x2F;较差局部性，方便后续的转换 A page with a high card access rate (CAR, measured as the percentage of the set bits in its CAT) is deemed to possess good locality and should be accessed with paging, while a page with a low CAR has poor locality and should be accessed with object fetching. 主要机制： 引入卡片（card）作为页面内的局部性度量单位，通过对页面访问的细粒度分析进行动态优化。 使用页面选择标志（Path Selector Flag, PSF）动态决定每个页面的访问路径。 数据的迁出和迁入在页面粒度完成，避免高计算开销的对象逐出操作。 运行时与内核的同步： 提出了一个同步协议，确保分页路径和对象路径之间的访问一致性。 Evaluation1️⃣ 硬件和软件环境 硬件 计算服务器和内存服务器：每个服务器使用 2 个 Intel Xeon Gold 6342 CPUs（每个CPU 24个物理核心），每台服务器有 256GB 内存，以及 100Gbps 的 Mellanox ConnectX-5 InfiniBand 网络适配器。 两台服务器通过 200 Gbps InfiniBand 交换机连接。 操作系统：Ubuntu 18.04，内核版本为 5.14-rc5。 配置 禁用 Turbo Boost、CPU频率调节 和 透明大页，以减少硬件特性对结果的影响。 实验框架 Atlas：包括对运行时库和 Linux 内核进行修改，添加页面管理任务（例如路径同步）等。 使用 AIFM 和 Fastswap 作为对比基准。 2️⃣ 基准应用程序 为了评估 Atlas 在不同场景下的性能，作者选择了 8 个应用程序，覆盖了不同的内存访问模式和计算需求： Memcached：一个内存键值存储系统，使用了两种不同的工作负载（MCD-CL 来自 Meta 的 CacheLib，和 MCD-U 来自 YCSB）。 GraphOne：一个实时图分析数据库，支持图的增量更新。 Aspen：一个纯函数式树形图处理框架，处理动态变化的图。 Metis：一个数据处理框架，支持不同的 MapReduce 类型操作（MWC 和 MPVC）。 DataFrame：一个表格数据结构，类似 Pandas 用于内存数据处理。 WebService：一个用于模拟分布式负载的交互式服务。 这些应用程序的内存访问模式涵盖了顺序访问、随机访问、混合访问等不同模式，能够全面展示 Atlas 在各种场景下的表现。 3️⃣ 本地内存比例：为了评估 Atlas 在不同远程内存配置下的表现，实验使用了五种不同的本地内存配置，分别为： 13%、25%、50%、75%、100% 本地内存比例。 其中，100% 本地内存的配置用于评估 Atlas 和其他系统的运行时开销（如智能指针解引用、预取记录和垃圾回收等）。 4️⃣ 计算资源配置：所有实验使用多线程并行执行，确保可以评估在高并发下 Atlas 的性能。 5️⃣ 评估指标 论文使用以下几个核心指标来评估 Atlas 的性能： 吞吐量：表示单位时间内处理的数据量，通常使用每秒完成的操作数（MOPS, Million Operations Per Second）来衡量。 延迟：评估请求的响应时间，特别关注尾延迟（tail latency），即高负载下的响应时间。 内存利用率：评估系统如何有效利用本地内存和远程内存，包括 I&#x2F;O 放大的情况。 CPU 利用率：衡量系统在进行内存管理和计算时的 CPU 使用情况，尤其是在高负载下的资源占用。 如图为 throughput Thoughts典型的 A + B 技术优化的论文，可以借鉴 A + B 的思路融合 fixed-size 和 variable-size 分块策略（我觉得这个可以作为另一个研究点）： no one fits all motivation1（先说说二者策略的优劣，通过实验分析，只用 fixed-size 和只用 variable-size 的方法测试） motivation2（负载存在大文件和小文件，有些文件长期不变，有些文件经常变化） IOPS 高的时候可以选择定长分块（速度快） 系统空闲可以选择变长分块（压缩率高）","tags":["OSDI"],"categories":["科研"]},{"title":"LLM 黄金时代下的 AI Infra","path":"/post/AI-Infra/ai-infra-in-the-era-of-llm/","content":"类比计算机系统的基础软件层以及云计算三层架构的 PaaS 层级，我们认为，AI 产业链中也有层级相似，定位于算力与应用之间的“桥梁”角色的基础软件设施层即 AI Infra。新一轮生成式 AI 浪潮，对于上层应用而言机遇与挑战并存，而 AI Infra 作为必要的基础设施，我们认为其技术及商业发展前景的确定性或更强。本文我们聚焦 AI Infra，揭示其内涵并总结目前国内外项目的商业化进展，再从工作流视角详细梳理各环节及代表厂商。我们认为，AI Infra 是 AI 产业必不可少的基础软件堆栈，“掘金卖铲”逻辑强、商业潜质高，建议投资者持续关注 AI Infra 相关投资机会。 摘要在预训练大模型时代，我们可以从应用落地过程里提炼出标准化的工作流，AI Infra 的投资机会得以演绎。传统 ML 时代 AI 模型通用性较低，项目落地停留在“手工作坊”阶段，流程难以统一规范。而大规模预训练模型统一了“从 0 到 1”的技术路径，具备解决问题的泛化能力，能够赋能“从 1 到 100”的各类应用，并存在相对标准化的工作流，由此衍生出 AI Infra 投资机会。GPT-4 的开发经验也体现专业分工的必要性：根据 OpenAI 的披露，在 GPT-4 的开发过程中，其对 249 人研发团队进行了明确分工，并使用了数据标注、分布式计算框架、实验管理等点工具。 我们认为这也说明了在大模型时代应用基础软件的必要性。目前，AI Infra 产业处于高速增长的发展早期，我们预计未来几年内各细分赛道空间或保持 30%+ 的高速增长，且各方向均有变现实践与养成独角兽企业的潜力。 “AI &#x3D; Data + Code”，组织 AI 所需的养料即数据，管理 AI 模型的训练部署过程，以及支持从模型到应用的整合是 AI Infra 工具的关键能力。 数据准备：无论是支持经典的机器学习模型还是大规模预训练模型，数据准备都是耗时较久、较为关键的一环。我们认为，LLM 浪潮下高质量的标注数据和特征库需求将持续增长，未来海量训练数据的需求或由合成数据满足。此外，我们强调 Data + AI 平台厂商的关键卡位。 模型训练：预训练模型的获取使得模型库更加流行，LLM 大规模训练需求也驱动底层分布式计算引擎和训练框架的迭代。此外，我们认为实验管理工具重要性较高。 模型部署：LLM 模型端的突破释放出大规模应用落地的潜能，更多模型从实验走向生产环境，我们认为有望整体提振模型部署和监控的需求。 应用整合：LLM 赋能应用催生对向量数据库和应用编排工具等的新需求。我们观察到经典的机器学习时代与大模型时代工具栈需求侧重点有所不同，同时，部分点工具正在拓宽产品功能边界，LLMOps 平台型产品的可及市场空间天花板或更高。 AI Infra 是连接算力和应用的 AI 中间层基础设施 资料来源：Grand View Research，Foresight News，Gartner，MarketsandMarkets，拾象科技，Firstmark，a16z，各公司官网，中金公司研究部 一图详解大模型时代的基础软件堆栈 —— AI Infra 本章主要讨论： AI Infra 在 AI 时代 IT 生态中的定位 为什么大模型浪潮下需要格外关注 AI Infra 投资机会 AI Infra 基础软件工具栈涵盖内容 AI Infra 商业化初探 AI Infra 是 AI 时代的中间层基础设施从类比的角度理解 AI Infra：AI 时代连接硬件和上层应用的中间层基础设施。 ✅ 传统本地部署时代：三大基础软件（数据库、操作系统、中间件）实现控制硬件交互、存储管理数据、网络通信调度等共性功能，抽象并隔绝底层硬件系统的复杂性，让上层应用开发者能够专注于业务逻辑和应用功能本身的创新实现。 ☁️ 云时代同理，形成了 IaaS、PaaS、SaaS 三层架构，其中 PaaS 层提供应用开发环境和基础的数据分析管理服务。 🤖 所以类比来看，我认为，进入 AI 时代也有承担类似功能的、连接算力和应用的基础设施中间层即 AI Infra，提供基础模型服务、赋能模型微调和应用开发。 AI Infra 是人工智能时代连接硬件和上层应用的中间层基础设施 LLM 催生 AI Infra 投资机会LLM 流行前，AI 模型通用性较低，项目落地停留在“手工作坊”阶段，流程难以统一规范。人工智能已有数十年的发展历史，尤其是 2006 年以来以深度学习为代表的训练方法的成熟推动第三波发展浪潮。然而，由于传统的机器学习模型没有泛化能力，大部分 AI 应用落地以定制化项目的形式，包括需求、数据、算法设计、训练评估、部署和运维等阶段，其中，数据和训练评估阶段往往需要多次循环，较难形成一套标准化的端到端的流程和解决方案，也由此造成了边际成本高、重复造轮子等问题。 大规模预训练模型完成了“从 0 到 1”的技术统一，泛化能力和通用性释放出“从 1 到 100”的落地需求，且存在相对标准化的流程，衍生出 AI Infra 投资机会。基于 Transformer 算法、超大参数量的预训练模型拥有泛化能力，一定程度上解决了原先需要按项目定制训练的问题，过去正因为 ML 模型的非标和项目制，下游需求并未被完全激发出来，LLM 模型端的突破释放出更大规模的应用落地潜能。而后续的应用过程中主要涉及：高质量样本数据的准备、基础模型获取、模型微调及部署监控、应用编排开发上线等环节，工作流较为标准化，我们建议投资者持续关注 AI Infra 投资机会。 具有泛化能力的通用大规模预训练模型赋能下，后续工作流较为标准化，衍生出 AI Infra 投资机会 AI Infra 基础软件工具栈参考海外 OpenAI 的率先尝试，工作流分工、点工具加持助力成功。一方面，OpenAI 在《GPT-4 Technical Report》论文中披露了参与 GPT-4 开发的人员分工，共 249 人，角色分工明确，预训练、强化学习和对齐、部署等 6 个大方向下又拆分成不同小组，其中数据集&#x2F;数据基础设施、分布式训练基础设施、推理基础设施等分别对应工作流中的数据准备、模型训练、部署应用等环节；另一方面，OpenAI 使用了 Scale 数据标注服务、Ray 分布式计算框架和 Weights and Biases（W&amp;B）实验管理工具，且 W&amp;B 的创立灵感就来自于其创始人之一在 OpenAI 的实习经历。我们认为，OpenAI 的率先尝试经验一定程度上说明专业分工和 AI Infra 基础软件堆栈在大模型时代的必要性。 Open AI《GPT-4 Technical Report》中披露的人员分工明确 AI Infra 广义上包含了基础模型和基础软件栈两层，本篇报告核心关注其中和工作流相关的基础软件工具栈。工作流的视角下，LLM 的开发应用主要涉及数据准备、模型训练、模型部署、产品整合四个主要环节，每个环节都有对应的点工具，亦有集大成的 LLMOps 平台型产品，我们将在下一章详细解读。 AI Infra 全景图 AI Infra 商业化 商业化起步中，已有变现实践，细分赛道或均有长出独角兽的潜力 商业化起步阶段，有望在未来几年快速成长为百亿美元量级的产业。我们认为，AI Infra 整体处于高速增长的发展早期，根据第三方数据，目前大部分细分赛道规模在几亿至几十亿美元量级，我们预计在未来几年内或将保持 30+% 的高速增长。同时，Data + AI、MLOps&#x2F;LLMOps 等平台型产品的市场空间天花板可能更高，我们也观察到点工具厂商正在积极拓展产品边界。我们认为，AI Infra 是 AI 时代不可或缺的基础设施中间层，“掘金卖铲”逻辑的确定性高，有望持续受益于 LLM、AI 应用的繁荣。 AI Infra 细分赛道市场规模 海外厂商积极探索变现，细分赛道或均有长出独角兽的潜力。从微观的视角，我们整理了 AI Infra 各细分赛道海外代表公司的商业模式，基本遵循按使用量付费的定价模式。大多数创业公司成立时间较短，目前收入体量在数千万至小几亿美元量级，其中数据相关的、平台型的厂商起步较早、已初具规模，我们认为这也符合数据需要前置于 AI 模型投入、平台型厂商收入天花板更高的逻辑。此外，我们认为 LLM 模型端突破将释放出更大规模应用落地的潜能，有望带动模型部署、应用整合等后续环节的逐步起量。 AI Infra 各赛道代表公司的商业模式一览 从工作流视角梳理 AI Infra 投资机会大模型时代和传统机器学习时代工具栈侧重点有所不同本章从企业训练模型、构建 AI 赋能应用的工作流视角出发，详解涉及的主要环节，并关注 LLMOps 和 MLOps 在流程上的侧重点差异。我们认为 AI &#x3D; Data + Code，历经数据准备、模型训练、模型部署、产品整合，分环节看： ► 数据准备：高质量标注数据、特征库需求持续，合成数据或成未来趋势。数据准备无论在传统的 MLOps 还是 LLMOps 中都是耗时较久、较为重要的一环。无监督学习降低对标注数据的需求，但 RLHF 机制体现了高质量标注数据的重要性，我们认为未来超大参数量模型对海量训练数据的需求或由合成数据满足。此外，Data + AI 平台厂商卡位关键。 ► 模型训练：模型库更加刚需，训练框架持续迭代，软件工具协助实验管理。基于通用的 LLM 大模型微调、蒸馏出小模型成为高性价比的落地方式，因此需要能够高效便捷地获取预训练模型的模型库；也催生更适应 LLM 大规模训练需求的底层分布式计算引擎和训练框架。此外，我们认为实验管理工具的重要性或始终较高。 ► 模型部署：更多模型从实验走向真实业务环境，部署和监控需求提升。我们认为，LLM 模型端的突破释放出大规模应用落地的潜能，更多的模型从实验环境走向生产环境，有望整体提振模型部署和监控的需求。 ► 应用整合：催生向量数据库和应用编排框架新需求。LLM 赋能应用催生出对应用产品整合相关工具产品的需求，其中较为关键的是向量数据库和应用编排工具。 从工作流视角梳理，大模型时代和传统 ML 时代工具栈侧重点有所不同 数据准备：高质量标注数据、特征库需求持续，合成数据或成未来趋势数据是模型的起点，一定程度上决定了模型的效果和质量，数据准备无论在传统的 MLOps 还是 LLMOps 中都是耗时较久、较为重要的一环。LLM 带来的新变化主要包括： 虽然 LLM 的无监督学习机制降低了对标注数据的需求，但 OpenAI 的 RLHF 体现了高质量标注数据重要性； 模型规模大幅提升，带来日益增长的训练数据需求，长期看可能无法仅通过真实世界数据满足，合成数据提供一种 AIGC 反哺 AI 的解法。此外，数据基础管理软件平台的卡位始终关键，Data + AI 平台化趋势持续演进。 数据标注 GPT 的成功说明了高质量标注数据对提升模型效果的重要性 数据标注位于模型开发的最上游，对图像、视频、文本、音频等非结构化原始数据添加标签，为 AI 提供人类先验知识的输入。近年，无监督学习、强化学习等不需要标注数据的机器学习分支方法论的出现引发市场对于数据标注必要性的讨论与担忧。 不过，OpenAI 通过 RLHF 即基于人类反馈的强化学习来优化模型，且从 OpenAI 披露的分工中能看到有很多负责预训练、强化学习等的 AI 科学家也参与到数据准备中；开源的 LLAMA 2 的论文中也有一段强调高质量数据对模型训练结果影响的表述，Meta 与第三方供应商合作收集了近 3 万个高质量标注，又向市场证明了高质量数据标注工作的重要性。 高质量标注数据在 GPT 模型训练中起重要作用 数据标注厂商正在寻求智能化转型、减少对人力的依赖。在数据标注助力 AI 快速发展的同时，AI 也将反哺数据标注更加自动化、智能化，如利用模型进行数据预处理再人工审核等。Meta AI 发布的 Segment Anything Model 的训练数据集 SA-1B，就是通过智能数据引擎来辅助自动化生成的，该数据引擎经历了辅助手动标注-半自动标注-自动化标注的训练过程。 特征库 特征库（Feature Store）：高质量特征库持续受益 特征是预测模型的输入信号，可以简单理解为模型中的自变量 X，需要经过特征工程从原始数据中筛选得到。而特征库则是生产、管理、运营 ML 过程中所需数据及特征的系统，主要实现： 运行各类数据管道（Pipeline）将原始数据转换为特征值； 存储和管理特征和数据； 为训练和推理提供一致的特征服务 目前该领域的代表性产品包括：开源项目如 Feast，独立商业化公司如 Tecton，大型科技厂商的 ML 平台如 Databricks、SageMaker 等中亦有相应模块。数据和特征的质量决定了机器学习的上限，我们认为高质量特征库有望持续受益，同时国内数据要素市场的蓬勃发展长期看有望为 AI 模型供应更多高质量的数据燃料。 特征库是生产、管理、运营 ML 过程中所需数据及特征的系统 合成数据 合成数据：做真实数据的“平替”，用 AIGC 反哺 AI 一项来自 Epoch AI Research 团队的研究预测存量的高质量语言数据将在 2026 年耗尽，低质量的语言和图像数据存量也将在未来的数十年间枯竭。面对潜在的数据瓶颈，合成数据即运用计算机模拟生成的人造数据，提供了一种成本低、具有多样性、规避了潜在隐私安全风险的解决方法，生成式 AI 的逐渐成熟进一步提供技术支撑。比如，自然语言修改图片的 Instruct-Pix2Pix 模型在训练的时候就用到 GPT-3 和 Stable Diffusion 来合成需要的提示词和图像的配对数据集；Amazon 也利用合成数据来训练智能助手 Alexa，以避免用户隐私问题。合成数据市场参与者较多，独立公司&#x2F;项目如 gretel、MOSTLY AI、datagen、hazy 等，数据标注厂商如 Scale 亦推出相关产品，此外主流科技公司英伟达、微软、亚马逊等均有不同场景的尝试。 Instruct-Pix2Pix 借助 GPT-3、Stable Diffusion 生成指令-图像训练数据集 Data + AI 是行业趋势 数据科学基础平台：数据卡位始终关键，Data + AI 是行业趋势 广义的数据科学涵盖利用各类工具、算法理解数据蕴藏含义的全过程，机器学习可以视为其中的一种方式和手段；狭义的数据科学也可以仅指代机器学习的前置步骤，包括准备、预处理数据并进行探索性分析等。 正如我们从报告《人工智能十年展望（八）：探索 ChatGPT 根基——数据与人工智能如何相互成就？》开始一直强调的观点，数据和 AI 一体两翼，数据是模型的起点、且一定程度上决定了模型的最终效果和质量，数据基础设施厂商卡位关键，从 Data 向 AI 布局是技术能力和业务逻辑的自然延伸。LLM 等大模型的渗透发展不仅额外增加了数据平台上 AI 相关的工作流负载，还可以带动底层 Data 基础设施的需求。 模型训练：模型库更加刚需，训练框架持续迭代，软件工具协助实验管理大模型具有一定通用性，开发者们可以“站在巨人的肩膀上”，在预训练模型的基础上通过少量增量训练蒸馏出专精的小模型以解决垂类场景的需求。 LLM 带来的新变化主要包括： 要想高效便捷地获取模型，则需要一个集成托管各类模型的社区也即模型库； 催生更适应 LLM 大规模训练需求的底层分布式计算引擎和训练框架。 此外，模型训练过程涉及多次往复的修改迭代，无论是 ML 还是 LLM 都需要借助实验管理工具进行版本控制和协作管理。 模型库 模型库（Model Hub）：把握从数据到模型的工作流入口 模型库顾名思义是一个托管、共享了大量开源模型的平台社区，供开发者下载各类预训练模型，除模型外，主流的 Model Hub 平台上还同时提供各类共享的数据集、应用程序 Demo 等，是 AI、ML 细分领域的“GitHub”。 典型代表厂商包括： 海外的 Hugging Face、Replicate 国内关注 Gitee（开源中国推出的代码托管平台）和 ModelScope（阿里达摩院推出的 AI 开源模型社区）等项目 在商业模型上，Model Hub 厂商一般选择切入下游的 AutoTrain（自动创建、优化、评估模型）或模型推理服务，也在尝试就 Model Hub 功能收取订阅制会员费用。 Hugging Face 上托管了 NLP、机器视觉等各类模型 分布式计算和深度学习框架 分布式计算和深度学习框架：大模型“炼丹炉” 分布式计算引擎方面，LLM 的训练过程需要大规模的 GPU 分布式计算集群，过去大数据已带动了以 MapReduce、Spark 为代表的分布式计算引擎的发展，但以 Ray 为代表的近年在 AI 大潮下兴起的分布式计算框架则更贴合 AI 需求（Ray 的首篇论文名为《Ray: A Distributed Framework for Emerging AI Applications》），其核心模块 Ray Tune、Ray Rllib、Ray Train 分别对应机器学习调参、强化、深度学习调参的流程。Ray 在官网的用户案例中表示“Ray 是使 OpenAI 能够增强其训练 ChatGPT 和类似模型能力的关键”。此外，Ray 作为更底层的分布式计算引擎，和 TensorFlow、PyTorch 等深度学习框架兼容，而 DeepSpeed、ColossalAI 等则是在 PyTorch 等基础框架之上针对 LLM 的优化训练设计的新一代框架。 实验管理 实验管理：记录实验元数据，辅助版本控制，保障结果可复现 模型训练是一种实验科学，需要反复的修改与迭代，同时由于无法提前预知实验结果往往还涉及版本回溯、多次往复，因此模型的版本控制和管理就较为必要，实验管理软件可以辅助技术人员和团队追踪模型版本、检验模型性能。该领域代表厂商为 Weights and Biases（W&amp;B）和 Neptune，跟踪机器学习实验，记录实验元数据，包括训练使用数据集、框架、进度、结果等，支持以可视化的形式展现结果、多实验结果对比、团队协作共享等。此外，实验管理也是 LLMOps&#x2F;MLOps 平台型产品如星环科技 Sophon、Google Vertex AI 等产品中的重要模块之一。 以 Neptune 为例，记录每次实验的元数据，支持多实验结果对比 模型部署：更多模型从实验走向真实业务环境，部署和监控需求提升模型部署是让模型从实验环境走向真实生产环境的重要环节，借助模型部署工具能够解决模型框架兼容性差的问题并提升模型运行速度。 模型监控通过对模型输出结果和性能指标的追踪，保障模型上线后的可用性。 我们认为，过去由于 ML 模型的非标和项目制，大规模、持续性的模型部署和监控需求未被完全激发出来，LLM 模型端的突破释放出大规模应用落地的潜能，更多的模型从实验环境走向生产环境，我们认为有望整体提振模型部署和监控的需求。 模型部署 模型部署：从实验走向生产的重要环节 模型部署指把训练好的模型在特定环境中运行，需要尽量最大化资源利用效率，保证用户使用端的高性能。模型部署领域参与者较多，比如 Ray、Tensorflow、PyTorch 等训练框架都提供配套的模型部署功能，模型库厂商如 Hugging Face、实验管理厂商如 W&amp;B 也有相关产品，此外还有如 Seldon、BentoML、OctoML 等独立项目&#x2F;产品。和训练框架自带的部署模块相比，三方的综合性产品能够为不同框架下训练出来的模型提供一套相对统一的部署方式。以 Seldon 为例，在复杂的多模型推理场景下，Seldon 通过模型可解释性、异常值检测等模块，最终选出表现最好的模型进行结果反馈。 Seldon 支持的单一模型、复杂多模型的推理过程示意 模型监控 模型监控：模型可观测性保障可靠可用 可观测性在传统 IT 系统运维中就是重要的数智化手段之一，通过监控各类机器、系统的运行数据对故障和异常值提前告警。模型监控同理，监测模型上线后的数据流质量以及表现性能，关注模型可解释性，对故障进行根因分析，预防数据漂移、模型幻觉等问题。 模型可观测性领域有较多创业公司，包括 Fiddler、WhyLabs、Evidently AI 等，实验管理厂商如 W&amp;B、模型部署厂商如 Seldon 也有所涉及，此外，传统的 IT 运维可观测性厂商也有机会切入 AI 模型监控领域，海外如 Datadog 已经尝试将 Open AI 的模型服务加入纳管范畴，我们也建议关注国内相关厂商的后续进展。 应用整合：催生向量数据库和应用编排框架新需求正如前文提及，LLM 模型端的突破释放出更多应用落地的潜能，由此催生出对应用产品整合相关工具产品的需求，其中较为关键的是向量数据库和 LLM 应用编排工具。 向量数据库 向量数据库：LLM 的外部知识库 让通用大模型具备专业知识主要有两种途径，一是通过微调将专有知识内化到 LLM 中；另一种则是利用向量数据库给 LLM 增加外部知识库，后者成本更低。 向量数据库和 LLM 的具体交互过程为：用户首先将企业知识库的全量信息通过嵌入模型转化为向量后储存在向量数据库中，用户输入 prompt 时，先将其同样向量化，并在向量数据库中检索最为相关的内容，再将检索到的相关信息和初始 prompt 一起输入给 LLM 模型，以得到最终返回结果。 向量数据库和 LLM 的具体交互过程 向量化技术本身已较为成熟，海外模型如 Word2Vec、FastText 等，国内中文 Embedding 模型有 MokaAI 开源的 M3E、IDEA CCNL 开源的二郎神系列。向量数据库厂商&#x2F;产品主要包括 Pinecone、Zilliz、星环科技 Hippo 等，另外也有传统数据库、大数据平台厂商如 PGSQL、Databricks 通过增加向量查询引擎插件来实现支持。我们认为，向量数据库是 AI Answers 类应用落地的刚需，同时本土厂商在中文 Embedding 方面可能更具优势。 商业向量数据库产品 应用编排框架 应用编排框架：LLM 应用“粘合剂” LLM 应用编排框架是一个封装了各种大语言模型应用开发所需逻辑和工具的代码库，LangChain 是当下最流行的框架之一，还有 Anarchy、Dust、AutoGPT、LlamaIndex 等。初始化的大模型存在无法联网、无法调用其他 API、无法访问本地文件、对 Prompt 要求高、生成能力强但内容准确度无法保证等问题，应用编排框架提供了相应功能模块，帮助实现从 LLM 到最终应用的跨越。 以 LangChain 为例，它主要包含以下几个模块： Prompt 实现指令的补全和优化； Chain 调用外部数据源、工具链； Agent 优化模块间的调用顺序和流程； Memory 增加上下文记忆。 集成开发环境 集成开发环境：交互式 Notebook 逐渐流行 在上述 AI 建模流程中，开发者需要处理大量代码编写、分析、编译、调试等工作，可以直接在对应环节或平台型产品的内置环境中进行，也可以使用专门的集成开发环境并调取所需功能。其中，Notebook 是一种交互式的开发环境，和传统的非交互式开发环境相比，Notebook 可以逐单元格（Cell）编写和运行程序，出现错误时，仅需调整并运行出现错误的单元格，大大提升开发效率，因此近年逐渐流行、深受数据科学家和算法工程师的喜爱，被广泛应用于 AI 算法开发训练领域。 LLMOps 一站式解决方案或更适应国内市场前文我们详细介绍了模型训练、构建应用工作流涉及的主要环节及各环节点工具厂商，事实上，这些厂商在强项环节之外亦不断拓宽产品能力边界，比如： 数据标注厂商 Scale AI 拓展合成数据业务并正在投入 LLMOps 领域的 Scale Spellbook（做一个基于大语言模型的开发者工具平台）； 模型库厂商 Hugging face 切入 AutoTrain 和模型部署； 实验管理厂商 W&amp;B 切入模型部署和模型监控等。 MLOps&#x2F;LLMOps 提供一站式平台解决方案，可及市场空间更大，多采取 Data + AI 一体化战略。除此之外还有平台型的 MLOps&#x2F;LLMOps 产品，基本涵盖了上述流程的主要环节，大型科技企业、数据基础软件厂商均参与其中。 我们认为，基于整体数字化进程和软件付费意愿习惯判断，海外企业客户可能倾向于选取各环节点工具自组工具栈，而国内客户可能倾向于一站式的解决方案。此外，从目前 AI Infra 领域独角兽的估值水平来看，平台型厂商多采取 Data + AI 一体化战略，起步较早、规模天花板更高。 AI Infra 领域独角兽企业一览","tags":["LLM","AI Infra","Iaas","Paas","Saas"],"categories":["AI-Infra"]},{"title":"一文详解 26 届各大厂人才计划","path":"/post/秋招指南/26-top-talent/","content":"一、大厂人才项目认知：卷上天的技术圈入场券大厂越来越卷战略级人才项目了，这类项目我个人觉得，本质上是企业技术护城河的人才储备计划。 根据我的发现，在互联网大厂的人才争夺战中，核心技术人才项目应该是已经成为战略储备： 腾讯青云计划聚焦 AI 算法与云计算，侧重基础研究能力； 字节筋斗云人才计划覆盖大模型应用等前沿领域，强调快速迭代创新； 阿里星计划通过滚动招聘锁定多模态大模型与自动驾驶人才，注重技术落地效率； 今年的京东 TGT 主要研究方向包括多模态大模型与应用、机器学习、搜索推荐广告、空间与具身智能等，比较聚焦技术突破和有社会价值的前沿课题。 「腾讯青云计划」高门槛的技术理想主义项目定位：升级后聚焦 AI 大模型、基础设施等十大领域，要求候选人有技术执着且能穿透技术本质。 适合人群：适合铁心走技术专家路线、能扛高压的学术派，双非学生基本没戏。 年薪范围：70-200w 招聘规模：每年约 80人 「字节筋斗云计划」创新压力下的极限挑战课题设置：2025 年开放 42 个前沿课题，涵盖大模型应用、AI Coding 等方向，要求博士在顶会发表过论文。 适合人群：之前听过牛客社区大佬提到，项目考核还挺严苛的严苛，适合抗压能力强且追求快速产出的实战派。 年薪范围：100-150w 招聘规模：每年约 20 人 「阿里星计划」学术派的终极战场选拔标准：仅招顶尖博士生，要求在 AI、云计算等领域有突破性成果，入职即参与达摩院核心项目。 适合人群：学术顶会、工程实践高手、技术大神，压力是比较大的，需要长期闭关搞科研。 年薪范围：120-140w 招聘规模：每年约 40 人 「京东 TGT 计划」技术与应用的实战主义选拔标准：招聘范围本硕博，近百个课题可选择，技术专家带教，直接参与智能仓储系统优化、物流机器人路径规划等落地项目。 适合人群：薪资不设上限是今年京东 TGT 的亮点之一，与其他大厂项目侧重实验室研发不同，TGT 学员从入职起即深度参与京东核心业务场景，目前项目也在进行中，上车时机比较不错。 年薪范围：不设上限 招聘规模：今年第一年尚未明确，不过看了一下京东 TGT 有近百个课题，我觉得招聘量级应该不小 二、选择大厂人才项目的考量因素作为学生党，选大厂项目就像选赛道，没有绝对的好坏，只有适配与否。通过整理了牛客社区内一些大佬的帖子以及我的对大厂项目的了解，在选择大厂人才项目上可以关注的因素。 1. 项目定位与职业规划的匹配度商业融合类（如腾讯青云）：适合技术与管理结合的复合人才，需平衡技术深度与商业化落地能力 业务融合类（如京东 TGT）：适合学术背景强、技术应用于业务的学生，以及关注新兴领域（如零售技术）、希望技术快速落地，需适应业务场景驱动的研发节奏。 2. 上车门槛与自身履历的匹配度学历与成果要求： 阿里星侧重顶尖学术成果（如顶会论文、专利），双非学生几乎无机会 京东 TGT 对学历包容性更高，本硕博学生均可以申请 另外从招聘规模来看，普遍是低于秋招，但京东 TGT 在几个大厂项目中招聘规模最大，竞争压力会低于其他项目。 3. 资源支持与未来规划的匹配度导师配置： 腾讯青云提供 “岗位导师 + 发展导师 + 项目顾问” 三轨制，导师多为首席科学家 京东 TGT 首创 “技术 + 业务 + 成长” 三导师制 薪酬方面：盘点了一下，基本上所有大厂都能给到年薪百万的水平，但今年京东 TGT 提出的薪酬不设上限还是挺值得期待一波的。","tags":["大厂","秋招","腾讯青云计划","字节筋斗云计划","阿里星计划","京东TGT计划"],"categories":["秋招指南"]},{"title":"2025.07.08","path":"/post/小吳日寄/2025-07-08/","content":"感觉我们的世界对慢节奏的人很不友好，再怎么想求知，如果要我以高强度、高精神压力的状态去做的话，我自己觉得没有什么知识值得我放弃悠闲平和的生活。有一句话说得很对，哲学是从闲暇中诞生的。既然如此，找不到故乡的孩子也是相当的可怜。 那种田园牧歌的时代早就一去不复返了。我曾经对科研的憧憬完全来自于牛顿与苹果树，康德漫步于小径，梭罗隐居瓦尔登湖，而不是坐在电脑面前，脊柱侧弯、屁股久坐、眼睛散光，和计算机打交道，未来只有吃不完的苦。我曾经觉得我是会喜欢科研的，在我做出老师也不会做的题目的时候，压轴题答案对出来一样的时候，在每个新学期，发下的课本还弥散着油墨香和新知识香味的时候。 也许我确实是，但是我连打游戏都没法一天八小时持续一个月，看书不行，跑步不行，吉他也不行，唯一成功做到过的只有读书，读高中的时候。但也得考虑到咱们学六门课呢，而且真是差点就死了。 人擅长什么领域，就会在心中的价值天平上给它加码，以确保自己的价值在自己心中过得去。我想高考之于我几乎所有的意义就在于此了。我确认自己的才能、价值、潜力，我知道我的头脑不会背叛我。我所适应的这条路，它的走向大概就是科研吧？我也曾经这样想过。 但好像不是的。 严谨的逻辑，科学的思维方法，阴云之下的大厦，真理海边的贝壳，我现在也仍然憧憬着。可我不想走那条路。它也许确实延伸到美丽的景色边，可是车票呢？或者是昂贵到大部分人支付不起，或者是以其他的美景代为支付。后者是否值当，我不好说，这只能是个人的判断。 那么，我要走到哪条路上去呢？ 走到无论怎样人烟稀少、终究是广袤的那片原野上。独属于我的这一条小径或是平原，独属于我的这一片湖海。我是离群的鸟，冒着饥饿受冻的风险，也要看一看规划以外的人生。生活节奏越来越快、越来越机械化、科技化、去诗意化是无法避免的现实，我无法接受这样的生活，也是无法避免的现实。我需要自己的空间和时间，而且必须以此为最高优先级。 其实我潜意识里始终在以此为标准做选择。小到必须要看闲书、熬大夜、睡大觉，大到咱们学个理科玩玩就可以了。以前很喜欢 ilem 的白鸟过河滩，白鸟白鸟不要回头望，你要替我飞去那地方。现在一想，为什么呢？我又不是被笼子束缚的鸟，更不应该是被笼子束缚的人。 或多或少早就明白这些，最早可追溯至我十一二岁对着王尔德童话，想象自己去森林里砍树盖小木屋的时候。花了八年向自己证明了自己的能力，又花了四年试探这个世界的底线。结果是这个世界根本没有底线。 我时而惊叹于我朋友的文笔，也惊叹于我朋友与我价值观的一致。 从小到大我见过的成绩好的人太多了，然而天下英雄如过江之鲫，即使你万里挑一，在这里也有 14 万个，更何况世界不止中国。 然而幸福是一种独立于客观存在的能力，就像物债二分法，所有权的变动无效并不意味着买卖合同无效：你看到什么，听到什么，感受到什么，才是最重要的，跟客观世界是什么样的、跟别人怎么看你无关。 所以幸福不是那种一下被人流推到癫狂的短暂欢乐，而是一种长期平和的满足。就按一线城市人均寿命 80 岁来算，再扣除最后几年没有质量的生命、扣除已经过去的 18 年，4 年本科、3 年硕士占据现有生命的份额不少。 既然人生永远没有岸，你的体验不重要吗？","categories":["小吳日寄"]},{"title":"C++ 性能优化","path":"/post/C++/when-nanoseconds-matter-ultrafas-trading-systems-in-C++/","content":"Preface最近看了 CppCon24 的一个分享 “When Nanoseconds Matter: Ultrafast Trading Systems in C++“，是顶级量化交易公司 Optiver 的工程师 David Gross 分享了构建低延时交易系统的一些思考与做法，列出了一些性能优化的指导原则。看完之后感觉干货满满，学到了很多 C++ 优化技巧，于是加入自己的理解，整理记录一下。 Principle #1: “Most of the time, you don’t want node containers”作者首先以一个订单簿 (Order Book) 的实现为例。订单簿由不同价格档位 (&lt;price, volume&gt;) 组成，需按 price 排序，并支持高频的插入、修改和删除。正常第一反应就是使用 std::map 数据结构来实现。 Ok，先用 std::map 实现一个基准版本。这里学到的一点是，跑基准要尽量模拟生产环境的情况。在生产环境中，分配给 std::map 节点的内存往往是分散的，因此在基准实现时要加入一些内存分配的扰动。 在得到基准后，可以想想，这些 node containers 的数据结构如 std::map、std::set、std::unordered_map 等，数据节点在内存中是离散存储的，数据缓存局部性比较差的。追求高性能应优先选择连续内存的 std::vector + std::lower_bound 实现。测试发现在该场景下，使用 std::vector 性能更好，但是一样有较大的长尾延迟。 Principle #2: “Understanding your problem (by looking at data)”长尾的原因很简单，使用 std::vector 在插入和删除数据会移动数据。作者分析了业务数据特征，发现频繁操作的数据集中在 std::vector 的头部，导致移动数据成本较高。所以只需简单将反转数据存储顺序，就能减少数据移动成本，长尾延迟显著降低。 Principle #3: “Hand tailored (specialized) algorithms are key to achieve performance”对上述实现运行 perf 看看有什么瓶颈。 这里又学到了一个技巧，使用 fork + execlp 在基准测试主要逻辑运行前启动 perf，能避免初始化等无关函数干扰测试。又是一个 fork 的骚操作！ 通过 perf 发现该版本在调用 std::lower_bound 时有不少分支预测错误，为此，作者实现了一个无分支的二分查找，核心是使用算术运算和条件移动指令 (CMOV) 替代条件跳转。性能得到进一步提升！ 这里也学习到一个 libpapi C++ 库的使用，可在代码中直接读取 CPU 硬件性能计数器，如指令数、周期数、缓存缺失、分支误预测等，方便量化优化效果。 Principle #4: “Simplicity is the ultimate sophistication”Principle #5: “Mechanical sympathy”二分查找会随机访问内存，如果直接简单使用顺序查找会如何？作者测试发现性能更好。所以有时最简单的算法在特定数据和规模下可能是最优的。 数据缓存优化得差不多了，接着看看指令缓存。 使用 [[likely]] 属性提示编译器将高频分支的代码放在主执行路径附近，优化指令缓存局部性。 使用 [[unlikely]],noinline,cold 这些属性标记低频分支的代码。这些代码不会被内联到热点路径中，放得远远滴，避免它们污染指令缓存。真细啊！ 优先使用 lambda，比 std::function 性能更优，后者可能有类型擦除和间接调用开销。 原则里的 Mechanical sympathy 翻译叫“机械共情”。我的理解就是编写高性能代码必须站在机器的角度思考，深刻理解机器的运行方式，如各级缓存，流水性指令、分支预测等，充分利用好其特性。 Principle #6: “True efficiency is found not in the layers of complexity we add, but in the unnecessary layers we remove”作者接着开了另一个话题，主要讲网络和并发。 网络通信上，尽量绕过内核，减少数据拷贝和用户态内核态的切换。这里介绍了一些工具。 如果多进程在同一机器通信，那就没必要使用 Socket，直接使用共享内存。使用共享内存的话，一般需要有个高并发的消息队列。消息队列种类很多，设计前需明确需求边界。 Principle #7: “Choose the right tool for the right task”基于需求，作者设计了一个名为 FastQueue 的单生产者多消费者共享内存无锁队列，主要通过两个原子变量 mReadCounter 和 mWriteCounter 来实现无锁。 整体实现值得好好学习下 这里值得学习是，这些变量都做了 CACHE_LINE_SIZE 内存对齐，避免 False Sharing。 Writer 具体实现 Reader 的具体实现 第一版实现的性能比不上一些开源的库。于是作者又做了几个优化。 第一：缓存写计数器 mCachedWriteCounter，只有写入累积超过阈值，才更新 mWriteCounter，避免频繁访问 mWriteCounter 原子变量。注意这里也做了内存对齐，可以学学如何使用位运算进行高效的对齐计算。 第二：对每条消息做内存对齐。 第三：缓存读计数器 mCachedReadCounter，避免频繁访问 mReadCounter原子变量。 优化后，FastQueue 实现性能优于一些著名开源实现。为什么作者一开始不直接使用开源库呢？因为作者贯彻“Simplicity is the ultimate sophistication”，觉得简单才是高效的额，开源的都太“重”了。 最后作者还提出了 api 设计的零拷贝优化，重新设计接口，允许调用者直接在队列的内部缓冲区进行序列化，能避免了一次内存拷贝。 Principle #8: “Being fast is good – staying fast is better”性能优化非一劳永逸，需持续监控。这里又学到一种新的统计函数信息的方式，就是 Clang Xray Instrumentation。 这是一种低开销的函数级追踪工具，可以动态地给函数入口和出口打桩。作者提到程序只需编译一次，在运行时选择是否开始追踪。如果不开启，打桩的代码只会运行空指令，开销极低。 Principle #9: “Thinking about the system as a whole”Principle #10: “The performance of your code depends on your colleagues’ code as much as yours”作者通过一个随机访问内存的基准测试程序，展示了 CPU 多级缓存的容量效应和缓存竞争的问题： 当数据集能完全放入 L1/L2 Cache (私有) 时，单核与多核 (6 核) 的吞吐量几乎线性扩展。 当数据集增长到 L3 Cache (共享) 大小时，6 核并行时的总吞吐量显著下降，接近单核吞吐量。因为多个核在激烈争抢共享的 L3 Cache。 所以如果在同一台机器里，即使你的程序优化到极致，但是其他程序对 L3 Cache 滥用，也会拖慢你的程序。 总结整个分享下来，学到不少东西，ns 级延迟优化真的很细！作者贯彻的原则就是尽量简单！less is more ! 结合演讲和个人理解，提炼以下优化原则： 基准测试尽量符合生产环境情况。 在性能优化前，分析好业务特性，数据分布。 在性能优化前，分析性能瓶颈，定位关键路径。 多考虑缓存的重要性，如数据缓存，指令缓存。做好数据结构的选择、数据内存对齐，原子变量的 Cache Line 对齐。 尝试在业务中减少使用 node containers，做好性能对比。 标准库和通用算法虽好，但在热点路径上，针对数据和场景尝试自己实现一些算法。 一些著名开源库功能丰富但可能臃肿。在明确边界的需求下，自研简洁高效的组件。 根据实际需求来明确设计边界。 简单设计和实现通常更易维护且性能更好。 移除非必要的抽象层和复杂性。 建立持续性能监控。 考虑整个系统乃至整机的资源共享和竞争。","tags":["C++","并发","perf","网络","量化","vector","map","queue","cache"],"categories":["C++"]},{"title":"选择互联网大厂还是央国企？","path":"/post/秋招指南/internet-companies-or-state-owned-enterprises/","content":"近些年互联网发展站在 2025 年的今天，我真实感受到了通缩所带来的压力。从我短暂的学生时代所看见的： 2018-2020 互联网大厂的疯狂。BAT 大厂非常乐意接受本科生，并且当时就算是没有经验的只要会一些基本算法中小厂都是可以进入的。签完三方还有 2-4 万的签字费； 2020-2022 笛子和华子的时代，这时候的比亚迪、华为、tplink、海康、大华都是应届毕业生保底的 offer。互联网在逐渐收缩，但是还没有开始大面积裁员，更多的是业务调整，出来的人也可以很快找到工作； 2022-2023 这时候的华子、笛子难度逐渐增加但是还处于毕业生保底的 offer，互联网大厂开始裁员，减去没有增量的业务，仅保留营收正常、具有未来前景的业务； 2023-2025 这时候互联网大厂大面积裁员已经成为常态，包括不限于海康威视解散多处研发基地；tplink 解散张江 wifi 芯片团队；美团砍掉优选业务；中电成都某所子公司裁员； 2026+ 最近看到很多 26 届的同学拿到了大厂实习的 offer，我原本是感到开心的，第一反应是互联网回暖，但是回头想来，这并不是一个好兆头，因为当前互联网大厂主攻的 AI 大模型并没有真正盈利没有实际增量，结合 2024 全年阿里的财报显示出来的在职人数，我得到了一个可怕的结论：互联网大厂正在加速内部末位淘汰和部门裁撤，通过快速循环的方式接收和裁撤应届毕业生，可能不到一个合同期就会裁走大部分人 最近也看到很多，从芯片行业、自动化电气行业、新能源行业、工业软件行业和互联网行业，越来越萧条。当我还抱有侥幸心理，认为已经到底了，但是种种迹象表明远没有结束。 华为部分产品线将大量 24 届研发人员输送一线，说明市场在收缩，只能相互之间进行存量竞争 IC 设计今年也是遇冷，岗位急剧减少 比亚迪也传出裁撤智驾部门的消息 58 同城大量裁员 就程序员可选的行业来说，包括半导体、新能源和互联网都在萎缩，而且速度超乎我们的想象。 大厂 or 央国企当然这不是本次讨论的核心，今天讨论的核心是软件开发还值得进入吗？ 个人答案是：不值得，除非能够起薪一线年入 45W，并且每三年涨薪 30%。因为只有这样才能够在 35 岁之前攒够 500W，够以后养老的需要。否则二线 20W 的半垄断型央国企将会是更好的选择。 进一步讨论如何实现应届起薪 45W 现在单纯做开发只能够实现一线收入在 30-40W，是无法达到一线 45W 年薪的。只有算法岗，包括大模型、nlp、cv 等才能够达到这样的薪资。并且这样的薪资多数只能由大厂开具，因此需要一至两篇的相关领域 B 以上论文➕一至两家大厂实习，这样的机会更大。 从长远来看，半垄断型央国企更具有性价比 稳定的细水长流，将提升生活的幸福感，有时候人生追求的不是钱越多越好，而是不受金钱窘迫的束缚，细水长流在没有增量的当下何尝不是一种选择。当然这里所说的更多是央国企当中的二级单位也就是省分&#x2F;区域分公司。 从另一个角度看，十年前 2015 入行的程序员现在 35 岁要离开行业了，经历过行业的上行与下降，才有了现在的积累，你又如何能保证在只有下行的当下，能够坚持到他们的年龄，得到相同的财富积累？现在选择程序员在我看来是一个十分不明智的行为，缩量竞争将会像光伏产业一样，竞争越来越激烈，收益越来越微薄。 半垄断型央国企有哪些？ 包括： 石油（中石油、中石化、中海油） 发电（五大六小） 供电（南网、国网） 烟草（烟草局、卷烟厂） 通信（联通、移动、电信不包括三产） 国有行（中、农、工、建、交、邮） 中证登、中债登、中国结算、北交所、资源性央国企二线研究院、四大资产管理公司 还有地方性的交通、港口等等 半垄断型央国企适合哪些人？ 适合小镇做题家，可以将普通人维持在中产位置不滑落，等经济好转可以为自己的下一代提供稳定富足的基本生活，完成阶级跃迁。一代人有一代人的使命，绝不能一口吃成胖子。完成阶级跃迁从来都是从农民到城市中产再到富裕阶层，稳定的中产才是小镇做题家的最优选择。","tags":["大厂","国企"],"categories":["秋招指南"]},{"title":"国考｜福建生选调｜省考 —— 备战计划","path":"/post/公务员/civil-servant-examination-preparation-plan/","content":"福建选调须知这里插一句话，不同于一般省份的“定向选调生“和”普通选调生”分类，福建并没有严格意义上的定向选调生，只有“选调生”和“引进生”两种分类。 其中讲述了「选调生」和「引进生」的细节 还不太清楚的同学可以先看看这篇文章补课：最偏爱本地人的省份？2022 年福建选调生全方位解读！ 备战计划与资料行测（资料）花生十三笔记总结 粉笔 980 系统课 行测 5000 福建选调生招录考试专用教材 粉笔 APP： 智能组卷 题库 每周模考 申论（资料）申论背诵规范词 人民时评 45 篇 2025 人民日报时评 12 个月｜电子版（每月更新） 人民日报·精读 计划 参考 PPT 和两位选调学长&#x2F;学姐的建议，找优公老师&#x2F;观澜公考咨询（福建选调） 🥕第一阶段：打基础（5-7 月） 每天：言语 30、判断 30、数资 25、常识 15 1、FB980 跟系统课程至少过一遍，对各个模块内容、重难点、出题逻辑有清晰的认知 2、晨读背诵：《实词辦析 1500 个》、《常识 4600 问》 3、错题不同颜色笔做好标记，方便后期复盘 4、申论同时进行，每天 2h 🥕第二阶段：转项拔高（8-10月） 根据自己的薄弱模块去找固定的老师听课 每天：言语 30 题＋判断 30 题＋数资 30 题＋常识 15 题 1、判断：花生十三判断刷题、龙飞图推刷题 2、言语：郭熙 100 题、欣说、阿里木江刷题 3、数量：花生十三数量 1200 题、齐麟刷题 4、资料：高照超大杯、齐麟、花生十三 5、常识：FB（分模块刷） 6、申论：李梦圆、站长申论刷题（每天一套，每周一篇大作文） 🥕第三阶段：考前冲刺（11月-考试前） 1、严格按照考试时间，早上一套行测，下午一套申论，晚上复盘，状态保持到考前 2、错题集完完整整的再过至少 3 遍，不同颜色重新标记难点和知识模糊点，对于变型较多&#x2F;复杂的题型，重点关注各模块用时及正确率 行测 推荐 UP： 网友红领巾：每期粉笔模考解析 拥抱昔日温度：第一视角做题 行测刷题建议 最初期，可以随便写一套，不用计时，做完就好，熟悉一下题型的同时也看下自己的水平在哪里。 刷的卷子可以用粉笔 app 的“智能组卷”功能来生成。 每次做，都要把手机开飞行，对各部分计时。 做题时打印出来做纸质版。 尽量每天都拿出两小时，完整刷一套套题，保持手感。 粉笔每周模考，有空的话也可以参加一下。岗位排名做个参考，不用太放在心上，以免被搞心态。 要形成自己最舒服的做题顺序 常错的题，要善于积累。 （一）常识性价比最低的部分。但福建选调常识有 30 题，整体难度不难，但还是值得一点点的重视。 当年度的大事一定要熟悉，例如我们去年的二十大。网络上有些常识蒙题法，我觉得还是值得一看。一是能够知道在出常识题时，最容易在什么地方设置考点、挖坑；二是在犹豫不决时可以交给蒙题。(刚刚已经说过了，犹豫不决是大忌)。 最后，一些机构针对福建选调整理的福建相关的常识，在其它部分读累了的时候，也是可以看看的。 （二）言语很重要的部分。多刷题，多积累。 【逻辑填空】 善于积累，遇到了就记录，形成自己的记录本 难题偏题不过多纠结，有时候机构之间答案都不一样 个人比较推荐的老师：阿里木江（B站）。但找到适合自己的老师才是最重要的。 “中心理解”这个东西一定要尽可能弄懂，懂了之后做言语会豁然开朗。 （三）判断推理很重要的部分。敢于放弃，回头再看。一定不要纠结!!!! 【图推】 要听课也要刷题，知晓命题点。 个人比较推荐「花生十三」和「刘文超」。花生十三的六面体方法让我印象很深刻。 【定义】 听课知晓命题点。 善用排除法。 【类比】 听课熟悉命题点。 积累。如果选项都看不懂那肯定很难做出来， 【逻辑推理】 个人推荐花生十三的加强削弱 *福建选调在这部分的题可能会非常恶心，一定要果断跳。 判断推理总结：再强调一下，判断推理，不管是哪类题型最重要的是做到这两点! 看课，熟悉题型与命题点 不纠结!不纠结!不纠结!可以圈起来有空回头再看但一定不要纠结。 （四）资料分析非常非常重要。言语和判断是保底，资料是拉开差距的 最好每次做套题都计时。资料对时间的把控特别重要。 技巧性强。因此做得快与慢，准确与否，就差得非常多 掌握技巧，尽量熟悉；刷题做题，保持手感。 资料这部分可以多看一些老师，因为不同老师有不同老师的技巧。个人认为多学一些是没坏处的（但是还是要形成自己的体系，避免技巧太多不知道用哪个） 推荐老师: 刘文超、齐麟、高照、花生十三 小红书 @拥抱昔日温度：第一视角做题，非常强，看厉害的人是怎么做题的，然后尽可能去模仿，对自己的提升会非常大。 （五）数量关系“内幕”：不同于国考，福建选调的数量非常简单，至少 2023。年是这样。 因此，定要留时间给数量，把分拿下。 因此，做其它部分更要尽可能快。 申论推荐：人民日报申论精读（小红书） 仅针对福建选调 标点不占格 分点作答 多写对策 注意时间，尽量写快点 … 福建选调生申论考试时间为 90 分钟，总分为 100 分，近几年题量均为 2 题，而且更注重结合基层问题、民生问题、福建省省情的相关材料进行考察。 内容与普通公考申论类似，考查综合分析题、归纳概括题、写作题（议论文），其中乡村振兴是常考题。 注 （1）篇幅：选调笔试中申论材料一般为 6~9 则，字数在 7000 左右，这就意味着材料字数相对较多，对于考生在材料的阅读理解能力的要求更高，同时提醒各位报考选调的考生需要合理安排时间，在思考全面的同时提高作答效率，做到事半功倍。 （2）题材：申论题材常与选调生到基层工作的内容联系密切，与福建本地的实际情况密切联系，具有较强的实际意义，所以大家可以关注一些本地的新闻时事。 面试考察人选从最低合格分数线以上的人员中确定。本、硕选调生考察人选按报考地区计划数 1 : 2，从高分到低分依次确定。 1. 面试方式选调生面试为半结构化面试，即面对面交谈模式，面试时长不固定，有点像企业面试。省委组织部会到各高校进行考察，考察分为两轮。每轮时间一般为 5-10 分钟不等，也有学员出现面谈达 30 分钟的情况。 2. 考察对象选调考察会安排分管学生工作的领导、班级辅导员、班干部 (1-2 名) 以及同学舍友 (1-2 名) 进行谈话。一般谈话结束后进行考生面谈，根据高校的不同，会出现顺序调换的情况。 3. 面试真题","tags":["选调","国考","省考","行测","申论"],"categories":["公务员"]},{"title":"2025.06.28","path":"/post/小吳日寄/2025-06-28/","content":"前阵子暑期实习挺不顺利的，人很丧，没自信，没目标，也错过了很多机会… 唯一有希望的华子也泡死在池子里了 想回到暑期前重新开始，但没办法，回不去了，这就是生活 就好像我这辈子也回不到大一&#x2F;大二的学习状态一样 或者说，人这一生，都不能走回头路 很多年来，我一直持续在问自己一个问题，怎么就变成这样了呢？ 最近，这个问题变成了，害，那又能有什么办法呢 😮‍💨 看到一个北大的哥们，比我晚入池，前几天就开奖了 hr 和我说，或许这就是北大的魅力吧 颓废在宿舍刷视频的时候，经常刷到蜡笔小新和海绵宝宝，不得不说在那个年代，做的是真好 小学的时候是最应该看蜡笔小新的时候 高中的时候是最应该看斗破苍穹的时候 但我研究生的时候才开始沉迷这俩玩意 不过仔细一想，我现在和高中时候确实有点不一样了，比如高中时候我玩 LOL 宁死不投，现在我看打不过了 15 分钟就上票了，不能让对面虐菜爽 能打过我的人，我不给他们打 人总应该是有点变化的，但我最近又有些新的理解了，成长是一件很难的事，它甚至意味着从头去修改你的一部分人生意义 打个比方：你连体重都控制不了，怎么能控制自己的人生呢？ 朋友说没办法，现在大伙都找着了工作，体重确实不好减 真不好减，最近东子、团子和阿里打外卖价格战，快给哥们喝出糖尿病了 哈哈哈 有个好朋友跑北京实习了，还有一个去了杭州，在厦门读书时哥几个总是经常打哈哈，不过一到上班，感受又不一样了 出发前几天，我说了一句“今日一别，小半年又见不到了，不过咱们的学生生涯好像也就一年多了”，他们没说话，也许是我们经历这寻常的分别太多了，本来早就习惯了，这时候突然来了个人对你说： 嘿，你已经和这么多人走散了呀 大多数人分开后就不会再见了，大多数人或许还有再见的机会 聚散离合，此乃常态，你要习惯 我一直以为，我已经放下过去了，直到最近有一天我梦见她 我忘了她长什么样子，但我知道是她，我和她在高中的桌子上背靠着背坐着 我忘了是为什么，忘了和她说了什么，也忘了结局是什么，在醒来后，我只记得这个场景 但有种说不出的感受，没有多么伤感，也没有多欣喜，像记忆里被砍去了一块，好比放满书的书架，突然有一天你发现有个地方少了一本书，你忘记了少的是什么书，也或许这本书早就丢了，或许你早就不看这本书了，书里的内容早就没用了，但那个缺口却永远留在了哪里，你永远能发现这里确实少了一本书 回忆会陪你一生，即使再模糊，你还是忘不掉 有些事并不是一件需要被解决的事情，而是一件需要被接受的事情，或者说，绝大多数的事情，都只是需要接受的事情，你解决不了 比如在地球 online 度过的这二十来年来看，目前我就这样一人，改变的话起码要拿年来衡量，或者十年来衡量 最近大模型发展的太快了，还记得 22 年刚出 GPT-3.5 的时候，有人感慨涌现就像宇宙给的礼物一样神奇，现在已经没有人再发出这种感慨了，默认大模型就存在和人类差不多甚至更强的智力了，没有上古时期 NLP 用 BERT 胡言乱语的折磨 想起个很好笑的事，以前研究生方向不是 CV 就是 NLP，现在 CV 还有点，感觉 NLP 已经绝迹了，虽然大模型也算是一种 NLP 吧，但已经没有哪个老师招生的时候会给你说：同学，我的研究方向是 NLP 🤣 也不知道为什么，这些年，身边的人总会有种觉得我很厉害的错觉，拜托，我要是真厉害，我还用发愁这些毕业、就业的事么，这样鼠鼠就不用吃生活的苦了，本就不好的胃也可以吃软饭度日了 有时候就觉得自己活得很荒谬，明明近来也没谈恋爱，三天两头垂头丧气跟失恋似的 朋友问我怎么情绪不对，我总不能告诉他最近暑期挂麻了，看不到未来吧 很久以前看 anlin 老师的文章，记得评论区有句话说，说是如果有一天 anlin 老师不再更新文章了，说不定不是一件坏事，因为这说明 anlin 老师在努力生活，或者过得不错，所以不再写日寄了 可我不是 我想把这句话改改，我的日寄大多数时候都很丧，其中虽然有我个人的原因在，但也有深夜写文章的 buff 加成，我希望有一天，大家都能过得不错，这样就不用看我的文章来找一些什么精神共鸣了，但我还是希望提供一些其他东西在，比如我的失败经历、我的踩坑经验，也希望对你有些帮助 It is still summer, but mine is over 没记错的话，是某一年高考的完形填空","categories":["小吳日寄"]},{"title":"如何利用「人民日报」提升申论？","path":"/post/公务员/how-to-improve-essay-writing/","content":"Link: https://www.zhihu.com/question/288739522 已购资料： 电子版｜2025 年人民日报时评（2025.01 ~ 2025.12） 纸质版｜人民日报时评 45 篇（2024.05 ~ 2025.04） 纸质版｜申论背诵规范词 总有公考大神和培训老师跟你说，学写申论就看人民日报。但实际上，如果你不懂看人民日报的技巧，你去刷人民日报 app 纯粹是浪费时间！ 今天就专门讲讲人民日报 app 应该怎么用。 看人民日报 APP 什么内容？ 我们只需要点击“人民日报”四个字，就会有电子版的人民日报。 只看第五版的《评论》 只看第五版的《评论》 只看第五版的《评论》 评论版块里的文章还可以点击，然后变成更加方便阅读的网页格式。 重点选看对象评论这个版块涉及的话题范围比较广，不是每一种话题都要重点研究。 🔥重点看：民生、教育、医疗、养老、住房、食品药品安全、生态环保、文化、放管服改革、精准扶贫和乡村振兴等。 这些话题都有可能成为申论考试内容，一定要条分缕析地去研究。 🥚粗略看：政治建设、司法改革，还有特别专业的比如金融。 这些话题一般不会成为申论素材，只要大概看看文章结构、论证方式就行了。 在评论这个版块里面，大家要特别留意“人民时评”类文章，就是下文箭头所指的。 人民时评文章主要针对社会热点，作及时、准确、深刻的评论，其观点鲜明正统，文风清新流畅，是我们学习的主要对象。 要想跟人民日报学习申论，其实最有效的方法不是通过 app 来看，而是应该把人民日报评论文章都收集起来，当成申论教材，系统研究。 下文会继续讲解如何系统研究，从而临摹人民时评，形成自己的高分申论文章。 怎么看才有用时评文章与今日头条、新浪新闻那些庸脂俗粉不一样，不能一看而过，而是要再三品尝。 每篇时评文章要从粗到细看 4 遍，就像拍电影，先远镜头拍个轮廓，再慢慢拉近，拍细节。 阅读前，要准备好本子和笔，边看边写。 第 1 次：看大概，从头到尾浏览，了解文章基本内容； 第 2 次：看结构，提炼思维导图，写在本子上； 第 3 次：看段落，分析独特、可借鉴的论据和论证方法，标注在思维导图上； 第 4 次：看语句，摘抄万能句和文采句。 空说无益，我们举个栗子。 第 1 次：看大概，了解基本内容读完第一遍，我们知道：这篇文章主要讲了青少年网络沉迷的相关问题。 准备看第二遍，记得边看边画思维导图。 第 2 次：看结构，画思维导图 思维导图不用非常精确，更不用讲究是否美观，只要能让你回忆起整篇文章就好。 第 3 次：看段落，分析论据和论证方法现在我们准备进行第三遍。细看每一段，具体用了哪些论据和论证方式？哪些值得我们写申论文章时候照抄？ 为了方便阅读，大家可以把每段值得借鉴和模仿的地方标注在段落的后面。 大家在做自己的读书笔记时，可以把这些内容，用不同颜色的笔迹，简要标注在你的思维导图上。 遇到特别典型、特别适合搬到申论试卷上的时评文章，还可以把文章打印出来，贴在读书笔记旁边，并把你对优秀段落、语句的分析标注在文章上。 第 4 次：看语句，摘抄万能句和文采句现在准备开始第四遍阅读。 这一遍要找万能句——那种换个主题词，就能直接搬到我们申论文章里的句子。 不但要找出万能句，还要弄明白这种万能句要怎么用。 按照上图的要求，把万能句分类摘抄到本子上。 阅读一定数量的时评文章后，各类万能句也会越积越多。 到时，你可以把相同作用的句子汇总起来： 比如引出总论点的句子，全部汇总到一个文档里； 引出原因的，全部汇总到一个文档，如下图 ↓ ↓ 最后一步：感悟分析上了考场，随便从你这个积累文档中挑出几个句子，就能写出一篇行云流水般的申论。 四遍读下来，你的本子上已经有了思维导图、论证标注和语句摘抄。 此时你还有最后一个任务 —— 写“感悟分析”。 “感悟分析”没有字数要求。有话则长，无话则短。 既可以分析文章的亮点和值得借鉴学习的地方，比如第三遍阅读，你收获的论证方式和论据，也可以是你对文章话题的思考。 很多人都有这种感觉，看过的书或者文章，不管看的时候多认真，隔几天或者几小时，就全忘了。 时评文章不是普通的故事或小说！ 你一定要想方设法让自己记住。 通过写感悟分析，一方面加深你对文章的理解，防止看过就忘，另一方面倒逼你勤动脑多动笔，慢慢提升文字水平和思想深度。 综上，阅读人民时评的方法， 今天唯一的知识点：“3个一”！！！ 一个思维导图、一些摘抄和一段感悟分析。 比如例文最后完成的“3个一”，如下图 ↓ ↓ 时评文章不是每一篇都结构清晰，建议大家实践“3个一”时，从易到难。","tags":["选调","国考","省考","申论"],"categories":["公务员"]},{"title":"2025.06.18","path":"/post/小吳日寄/2025-06-18/","content":"离开学校越久越感觉到，努力和运气，好像运气更重要 在学校里不管是找工作还是上课大多都是单线程的赛跑，努力大多数是能得到反馈 但工作后才慢慢意识到，努力和实现目标并不是 causal relationship，更像是 multivariate regression 努力并不能解释一切，但现实是还有一大堆变量和你控制不了的 noise 你拼了命优化自己的 loss function，结果人家模型早就加了一个隐藏变量叫「时机」或「运气」","categories":["小吳日寄"]},{"title":"2025.06.17","path":"/post/小吳日寄/2025-06-17/","content":"从小到大，没穿过什么名牌衣服，没去过什么名胜场所，没学过任何才艺，也没坐飞机出过国。 中学后，我的成绩就一直不好，高考发挥不尽人意，去了家乡附近一所普通大学。四年里，也没意识到学习的重要性，成绩平淡，目光短浅。 几岁的时候，我以为，我将来会是一个很厉害的人。比如在水里泡了几天，自己就轻而易举地学会了浮水。后来，才发现我不是。走在河山林间里，就像是一块鹅卵石置于潮海之中，并没有什么不同。 十几岁的时候，我以为喜欢一个姑娘，就会和她在一起。但是我没有自信，也不够勇敢。每每听见别人说起青春，我总会想起那个阳光扑面的夏天，一个虎牙马尾，爱笑脸红的女孩。眼见她笑容荡漾，步履渐远，我却无动于衷，阳光日头，遗憾满怀。 二十几岁的时候，我以为生活锤得我满是伤痕，我也会开朗乐观地面对。但是更多时候，我胆怯，我拘谨，我犹豫。我害怕认识陌生人，混在人群中讲不出一句话来，上了讲台，就会莫名地紧张。敞不开心情，也不会有女孩子喜欢。难过的时候，一个人难过，开心的时候，一个人开心。心情低落的时候，写些蹩脚的文字。 比起一事无成，我还体味过很多糟糕的感觉，比如： 努力了好久的考试轻易挂掉 非常期待的计划却突然落了空 喜欢着的女孩向他人表了白 曾经亲密的好友不再联系 至亲离别时的泪水 … 太多太多了，就像是一只低着头行走的鹌鹑。 庆幸的是，这些年来，我也读了很多书，去了很多地方，结交了几个挚友，写下了一些见闻，从波澜壮阔的星空，到至今馋味的寿喜烧。我还有着一些渺小的心愿，并一直在为它偷偷努力着。即使遥遥无期。我希望我的坚持，可以弥补运气和先天的不足。我也知道在这个世界上，有很多我穷尽一生都难以望其项背的人。但是我希望自己再普通，也要活出一点点不一样的光芒。我讨厌以前的自己，我想要变得有趣，变得特别，变得开朗。变成王小波说的那样，有好多奢望，一瞬间天上忽明忽暗的云。在这个一生的黄金时代，年轻人如果你感到现在很辛苦，就快要坚持不下去了，请为未来感同深受的自己，再坚持一下吧。 一事无成并不要紧，重要的是：拜托别像以前的我那样，每天丧气满怀、无精打采的，这个世界也是亮晶晶的。 太阳明亮，水波温柔，街道车如流水马如龙，每个人都在为了更好地自己奔波着。 树木蓬郁，微风和煦，这个少年，你也可以有着不一样的梦想。","categories":["小吳日寄"]},{"title":"2025.06.14","path":"/post/小吳日寄/2025-06-14/","content":"前几天，有个好久不联系的朋友问我，“这些年，你过得还好吗？” 哈哈哈，当然过得很好呀。 因为在绝大多数情况下，我过得不好，也没有勇气说出来。 有时候晚上一个人漫步在晚风里，月光落在身前，夜幕下的路灯和飞虫都显得落寞。 今年过了生日，我就二十五岁了。 这个年纪，身边的人好像都在往前走。毕业工作，买车买房，甚至是结婚生子，似乎只有自己留在了原地。 我以为二十五岁的我，会像个大人一样，在风里雨里奔跑，却没想到喜怒哀乐仍在脸上。 走在路上被小朋友叫叔叔了，会不开心。 常常在路边和偶遇的猫咪对叫，看见漂亮妹子就想回头，望着天空漂浮的云朵，发呆、思考，想着一些不切实际的事情。 只是有时候，想找人出去散散步时，却发现好像已经没了，可以约出来的朋友了。 恍惚间发现，原来自己真的不是个孩子了。尤其是看着身边的同学、朋友陆续结婚生子，会莫名地感到心慌。 爸妈，好像也已没了当初的活力，自己却还不能好好地照顾自己。时间只是让我成长了年岁，却还没让我成为一个合格的大人。 以前，我不能理解年轻人的丧。在我的认知里，从小到大的教育就在告诉我，要用自己热爱的方式过这一生。 后来，我才明白，这只是一个理想的状态。 我们绝大多数的人，最终都会回到世俗的生活里，为家长里短，为柴米油盐烦恼着。 不知从哪一天开始，只是简单熬一下夜，第二天起来做事，就会浑身没劲。我知道那个曾经炙热的少年，就已经与我渐行渐远了。 可能成长，就是在不断地放下着东西。 后来，我渐渐学会了收起自己的锋芒，把委屈藏在心中，说话做事都有所顾虑。在处理问题时，早没了当初初生牛犊不怕虎的干劲…… 隐忍妥协，但有时候又会庆幸自己，依旧有着世俗无法改变的东西。比如说学不会抽烟喝酒，学不会逢迎欺骗，也有着自己的清高与小傲娇，还是那样喜欢沉浸在自己的世界里。 还是会有孩子的心性，比如说贪玩懒惰。 看着别人事业有成的时候，又会陷入焦虑，觉得自己这个样子不思进取，但却没了耐心和心思去学习。 其实，自己并不是个不喜欢分享的人。只是在大多数情况下，没人愿意聆听我的琐碎。 所以，我很沉默，一直都沉默。 朋友圈已经慢慢没了生活的痕迹。 身边的绝大多数人，好像都选择了三天可见。 我觉得挺好的，因为现实里很少有人会真正关心你。大部分的人，根本不会多看一眼你的动态。 我们这一生，注定会被很多人路过，也会路过很多人。 可能只有等到哪天，真正遇见同频共振的那个人，才会像只刺猬样敞开心扉，让彼此看看内心深处，不为人知的优雅。 或许相遇的那天，我会因为历经孤独，而格外懂得珍惜。 以前我总以为，人生最美好的是相遇。后来才明白，其实最美好的可能是重逢。 因为人生里的很多告别，都是毫无征兆的。那些悄无声息的离开，或许是永久的沉默和不回头。 后来的我们，不再去追问心知肚明的答案，也不再轻易地将自己的情绪表露出来，开始尝试去做一个不动声色的人。 那些曾以为生命之不能承受的事，就像是散落在风中的银杏叶，随着成长亦被岁月带走。 那些曾以为刻骨铭心的经历，或是痛苦难捱的日子。后来提及，两个字就足以概括。 从前，从前。 其实，自己这些年来，也并不是过得一点都不快乐。 比如说在路上遇见的快乐小狗，久违的文章动态还有人给我点赞，这些就足够让我快乐。 但又好像不算是真的快乐，只是在一阵短暂的欢愉后，就没了动静。再也没了那种小时候，可以为一件事期待好久好久，就算是得到了还会一直回味的感觉。 小时候的我无忧无虑，却总想着长大。长大后，却又开始怀恋小时候，或许是我还未做好准备，接纳成年人这个身份罢了。 我记得小时候，姥姥家的院子里，种着一颗大银杏树。每年春夏，枝头总是挂着一片绿意。等秋天一到，金灿灿的叶子就在风中招摇。 风将落叶带去远方，天空飘着的云很是明亮。 我只是安静地看着，邻居家那只爱趴在我家屋檐上，呼呼大睡的肥猫，就能虚度一下午的时光。 不知那时候，我们在树下一起追逐玩闹的孩子们。现在，你们怎么样了？这些年来，过得还好吗？ 当我在写这篇日寄时，正在为学习和生活上的一地鸡毛而烦恼着。不知你们会不会也像我一样，在过去或未来的某个时刻，也在怀念着那个无忧的年代。 落叶随着风一阵摆动，家乡的银杏树一直都在，可是我已经回不去了。 老友记 @Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu","categories":["小吳日寄"]},{"title":"福建·福州","path":"/post/摄影日志/fuzhou_2025-06-14/","content":"老友记 @Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu","tags":["摄影","福州"],"categories":["摄影日志"]},{"title":"2025.06.11","path":"/post/小吳日寄/2025-06-11/","content":"我一直觉得，我以前和现在，本质上并没有太大的变化，直到我看到曾经自己写的日寄 我需要承认，我和以前不一样了 我不再敢打敢拼，不再义无反顾，我会犹豫，会权衡利弊，会害怕未来，会怀疑自己 厦门今天的天气很不错，夜晚有风，但一点不冷，白天 30 度的余热还没散去，风吹来只觉得凉爽 很像大三刚保研完在湖边吹风的那个夜晚，意气风发 哎，这一路走来，给过去的我丢人了 我在想，人总会告别这个世界，如果是生病的话，应该会有一个时间周期，如果真有这么一天，我不希望你遇到我时，和我说你有多舍不得我，什么没我不行，什么明明知道没有希望还鼓励我的话，什么没有你日子怎么过，你有什么事情还没有做，等你好了我们一起去xxx怎样 我更想听的是，你有多么怀念我，我这辈子已经完成了什么，告诉我接下来的日子没有我你们仍然会好好过 这就足够了","categories":["小吳日寄"]},{"title":"📷 相机与摄影的知识科普","path":"/post/摄影日志/camera-and-photography/","content":"2024 最佳相机关于相机，可以先看看影视飓风 2024 相机颁奖频道。 影响相机成像质量的因素大体来讲，相机拍照只需要两个部件：镜头和传感器。其他部分都只是起到辅助功能，而这两个部件几乎决定了画质水平。 镜头判断镜头的标准有很多，总的来说，定焦镜头的画质比变焦镜头好，小变焦镜头画质比大变焦镜头好。但镜头变焦能力越强，使用场景就越丰富，能拍摄到更多画面，所以变焦和定焦并没有绝对的好坏标准。 镜头的最大光圈则是越大越好，大光圈镜头一次可接受更多光线，暗光拍摄效果好，最重要的是大光圈能带来更好的背景虚化效果，凸显主体，拍摄出梦幻的画面。定焦镜头通常体积也更小，光圈也容易做到更大。 传感器 · CMOS首先我得科普一下传感器也就是 CMOS 相关的知识，摄影圈经常有一句话：底大一级压死人（底，一般指 CMOS 传感器）。 传感器方面，像素数量决定了清晰度，但最重要的还是传感器尺寸，这也是一台相机最容易直观比较的部分。同技术条件下，大尺寸传感器相比小尺寸传感器拥有更大的单像素尺寸和更高的像素数量，暗光下拍摄噪点更少，画面更清晰。 常见的相机传感器尺寸由小到大依次为： 1&#x2F;2.3 英寸 1 英寸 M4&#x2F;3 画幅 APS-C 画幅 全画幅 中画幅 1&#x2F;2.3 英寸传感器相当于手机传感器的尺寸，如今我们并不太推荐购买 1&#x2F;2.3 英寸的相机，他们的画质水平已经赶不上拥有先进双摄算法的手机了。 提升传感器尺寸能非常直观地提升画质，画质出众的相机，无不采用大传感器。但传感器也不能无限制地做大，镜头的体积和传感器尺寸是三次方的关系，需要在画质和便携性上作出取舍。大多数采用大型传感器的相机都采用体积小巧的定焦镜头，牺牲了变焦能力，这也是为了体积和画质作出的妥协。 单反相机中全画幅与中画幅的区别，如何选择合适的画幅？画幅指的就是感光原件的大小（胶片就是指胶卷的尺寸，数码就是指传感器的尺寸）。对于画幅我们可以用 135 全画幅（或者称 35mm 全画幅）作为标准。 比 135 全画幅更大的，就是中画幅和大画幅了。如果是数码的中画幅，非常贵，只有职业的风光或者商业摄影师才会选择。至于大画幅，数码的简直就是天价，一般都是特殊定制。玩中画幅和大画幅胶片也不会太便宜。所以几乎没有从这入门的。建议你拍到一定程度再考虑。 135 全画幅（35mm 全画幅）又是怎么回事呢？话说很久很久以前，有个叫奥斯卡巴纳克的人做了一台叫徕卡的相机，后来这相机一直活到今天。这台相机就是用 35mm 宽的打孔电影胶片做底片的。所以这种相机叫 35mm 相机，一张底片的大小就叫 35mm 全画幅。后来柯达看着事儿能挣钱，就搞了一个一次性胶卷盒，于是大家就有了简单方便的胶卷。1 表示一次性，35 表示 35mm，于是这种胶卷就代号为 135 胶卷。使用这种胶卷的相机就叫 35mm 相机或者 135 相机。这种画幅尺寸除了叫 35mm 全画幅，也叫 135 全画幅。 135 全画幅的传感器尺寸大小就是 36mm × 24mm，就是我们曾经用的最常见的胶卷的一张底片的大小。虽然曾经的胶卷叫 35mm（宽）胶卷，但是因为两边有打孔，所以实际成像的宽度就是 24mm。 135 相机在胶片时代可以说是用的最广的。 相机进入数码化之后，理所当然所有的数码相机应该也是 135 全画幅相机。但是因为电子传感器曾经很贵，于是很多厂商向成本妥协，推出了小传感器尺寸的各种版本相机。 主流的就是 APS-C、M43 和 1 英寸。 大家记住一点，不管厂商怎么宣传自己的传感器尺寸更加合理，凡是比 135 全画幅小的都是要么向体积妥协，要么向成本妥协。如果这相机体积没有特别小，一定就是向成本妥协了！ 同时代的数码相机，传感器尺寸越大，成像越好，这是一定的。所以我们尽量选择大尺寸传感器。另一方面，中画幅的数码相机因为其往往针对特殊领域，所以画质特别好，但是机身性能一般。 目前这两年最好的选择就是 135 全画幅数码相机，各个方面比较平衡，一定要选择这样的产品。如果您因为暂时的预算问题，无法购买 135 全画幅相机，那么也要做好未来购买的准备——毕竟相机价格越来越低了。 基于这一点，我们选择相机就不难了。 中画幅其实是比全画幅（35mm 全画幅）更大的传感器尺寸。目前主流中画幅传感器大小是 44mm × 33mm。 更大的传感器，意味着什么呢？一般来说： 1、更加优异的画质 ✅ 2、更加出色的背景虚化能力 ✅ 3、更大更加不便携的体积 ❌ 4、更贵的价格 ❌ 在我看来，如果未来中画幅 645（44mm × 33mm）体积控制下来的话，将是民用神器。不过可见的未来，135 全画幅才是王道。 记住，底大就是正义（底，一般指传感器），底大一级压死人。所以其实选择画幅的话，理论上肯定是越大越好，但是越大的画幅其实意味着相机越大越重，所以目前的话如果是刚入门或者刚学习摄影，我认为全画幅的可玩性还是更强的，价格也是更便宜一些。 如果说你对于画质像素等有更高的追求，那么我觉得你可以选择中画幅。 焦距&#x2F;焦段是什么，如何选择合适的镜头？焦距是镜头上最重要的参数之一。 比如一支镜头：Canon EF 70-200mm f&#x2F;2.8L IS II USM 其中 70-200mm 就是表示了这支镜头的焦距，是从 70mm 开始的，到 200mm 结束 焦距有两个数字表示这是一支变焦镜头，焦距覆盖了从 70mm 到 200mm 的整个焦距段 200÷70≈2.86：所以这是一支 2.86 倍的变焦镜头 再比如：Canon 50mm F1.4 USM。 其中 50mm 就是这支镜头的焦距，只有一个数字表示这是一支定焦镜头 焦距一般是一个以 mm 为单位的数字，这个数字又是干嘛的呢？ 这个数字越小，我们叫焦距越短，我们的视野就越宽，取景范围就越广，画面中容纳的景物也就越多，但是每个景物在画面中占的面积就越小 这个数字越大，我们叫焦距越长，我们的视野就越窄，取景范围就越窄，画面中容纳的景物也就越少，但是每个景物在画面中占得面积就越大 超广角超广角一般指的是 24mm 以下的焦距，因为视角大，所以适合拍摄大场景，建筑，风景，都是可以的。因为往往可以离很近拍摄，所以有很强视觉冲击力，也很适合新闻摄影拍摄 24mm 和 28mm这就是一个标准的广角焦距，主要就是用来拍摄风景。当然拍摄到此一游照也是很好的。如果你非抬杠说也能拍人像，确实也能，但是这个焦距的风光片要远远多于其它题材。24mm 相比 28mm 来说，就是更广一点，所以更好。 35mm有人说这是大师的焦距，也被称为人文眼。简单地说就是拍摄人文最好的焦距。之前有人问我：你之前不是说 85mm 不是拍摄人像最好的嘛？为什么又说 35mm 是拍人文的？恰恰一字之差，有了这个区别。拍摄人像是要突出人，自然要弱化背景——要么裁切出画面，要么背景虚化掉。85mm 擅长的就是这个。而拍摄人文照片的时候需要主体和背景环境的关系，所以小广角的 35mm 既能够将背景囊括进来，又可以保留足够的景深。 50mm（标准镜头）这被称为标准镜头，人文、人像都是很好的，也是大师的焦距。对于 50mm 标头的表述实在太多太多。我只说一点吧，我遇到过的人大多数要么喜欢 35mm（比如我），要么喜欢 50mm（比如布列松），这种差异基本上都是表现在人文拍摄时你习惯的视角。所以我觉得这俩焦距用好一个就不易，挑一个，一直坚持下去吧。 85mm说得很多了，就是拍摄人像的镜头。能有很好的背景虚化效果，很好地画面裁切能力，还能保持和模特之间适当的交流距离。 标准变焦镜头一般就是 24mm 或者 28mm 起跳，70mm、85mm、120mm 左右截止。基本上就是你日常挂机的镜头，适合的题材很广。 100mm这个焦距左右集中了最热门的一些微距镜头，因为拍摄距离适中。 135mm也是拍摄人像的焦距，就是需要离人远一点。 200mm 和 300mm这就是妥妥的长焦了，拍摄鸟类啊，荷花啊，运动啊，那种离得不是很远的就可以打得到了。同时也有不少用这个拍摄人像的，因为大光圈的背景虚化效果超级强烈。 超长焦300mm 以上，野生动物、运动题材等等。也用于狗仔偷拍什么的。拍日出日落，满月弦月什么的也挺好的。初学者别觉得超长焦多牛，基本上不是做这类型题材的，很少用得到。 最后的最后最后说一句，没什么是一定的，所以别和我抬杠非说我就要用广角拍人像，长焦拍风景。其实都可以，只是从出片量来说，某个焦距确实适合某些题材。","tags":["摄影","相机","镜头"],"categories":["摄影日志"]},{"title":"📷 摄影作品集","path":"/post/摄影日志/shot/","content":"@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu","tags":["摄影"],"categories":["摄影日志"]},{"title":"如何评价《悉达多》这本书？","path":"/post/藏书阁/siddhartha/","content":"1919年，赫尔曼·黑塞开始写《悉达多》，当时他40多岁，刚结束了战俘救济的工作，唯一的经济来源是出版社的资助。 当时的环境对黑塞乃至整个世界的作家来说，都是一次巨大的冲击。 与此同时，他的妻子因为精神分裂经常需要住院，在这样的情况下，他不得不把自己的三个孩子寄养到朋友家。 毫无疑问，此时黑塞的人生正在走夜路，人在陷入困境的时候，难免会想：自己为什么来到这世间要受苦，人来到这世间究竟是为了什么？我们来世间走一趟真正重要的是什么？ 带着这样的疑问，黑塞用三年时间写出了《悉达多》，他把自己的人生经历融入到悉达多的经历里，追问世界的真相，探寻人生的意义。 悉达多这一生经历的困惑，年轻时期的叛逆，中年时期的沉沦，晚年与孩子的别离之苦，这也是千千万万普通人会经历的一生。 《悉达多》的译者姜乙曾经这样评价黑塞以及他的作品：他永远能找到他的读者，读者也永远能在100年前写的书里找到我们当代的生活。 普通人和悉达多唯一不同的是，悉达多一直经历着，一直感悟着，最终他证悟涅槃了。 悉达多离开父母，离开家乡，和乔文达跟沙门们出发去修行，他们是很纯正的修行人，每日除了打坐、化斋，听师父们讲经文、讲道义，无它。 修行初期的悉达多认为，这世间一切都是欺骗，一切都是谎言，欲望、幸福、美丽都是虚的，活着就是一种折磨。他觉得只要达到无我的境地，他就能觉醒，继而发现那个更大的秘密。 看起来这样的修行才离涅槃更近，可为什么悉达多最终选择入世呢？ 因为有一天他突然发现事情不对劲，他出世的时候确实学到思考、等待、斋戒、三个本领，但这三个本领真的必须要在沙门队伍中学得吗？ 答案当然是未必。禅定和斋戒都是暂时从“我”中逃离出来，这种逃离通过喝酒也能获得。 悉达多跟乔文达说，他觉得修行和求知欲并没有让他们离解脱更近，他们一直在原地踏步。 每次读到这里我都大为震撼，一语惊醒梦中人啊，现实中也有些修行人，会专门腾出一段时间去寺庙吃斋饭、打坐，可是回到现实，他依然是原来的他。 还有些修行人，他们不用去修行团，每天在家冥想一段时间，剩下的时间就好好经营生活，有问题就处理问题，没问题就去思考关于自身的问题。 其实，真正的修行不在别处，而在生活的每时每刻中。 智慧无法通过学习得来，只有通过自己经历、觉知、感悟，才能真正转化成自己内在的东西。 悉达多和乔文达找到乔达摩后，听了乔达摩的法义后，乔文达决定跟随乔达摩，但悉达多决定开启自己的求道之路，走之前他跟乔达摩说，您的法义让我敬佩，它如此清晰，没有瑕疵，但中间却有断裂之处。 也就说，这些法义并没有能解决悉达多内心的疑惑，他没法证实通过学习这些法义，就能脱离苦海。 我们每个人都是如此，听过很多道理，却过不好这一生，因为这道理是别人从生活里悟出来的，而我们只是道听途说，真正用的时候，要么想不起来，要么根本不会用。 众所周知，人要对家人耐心一点，毕竟他们才是这世间除了自己之外最亲的人。 但现实中很多人总是把和颜悦色留给外人，把最狠最毒的话刺进家人的身体里。 有人吃了亏才能懂得一些道理，有人撞了南墙才能学到智慧，有人被骗过才能人间清醒，所有的道理只有通过检验才能转化成自己的经验，反复练习才能成为自己的行为模式，最终达到知行合一的效果。 每个人的内心都有很多执念，我们渴望家人的爱，想要朋友常伴身边，希望和爱人相守，也渴望跟儿女长久相伴，互不生厌。 随着时光的流逝，父母离开我们，朋友渐渐走散，相爱的人渐渐疏离，孩子们会径直走入自己的世界，所以，有人说，长大就是失去的过程。 但再想想，这些执念不过是我们一厢情愿的臆想，而世间万物有自己的运行规则。 你有你的安排，世界另有安排。 小时候，我们总以为自己是世界的中心，长大后才发现，人这一生都在一个巨大的游乐场里，甚至这个游乐场都不是由时间和空间构成的二维空间，它可能是三维甚至更大的空间在主宰着。 正如《正见》里的一句话：我们的血肉，我们所有的情绪，我们所有的觉受，都是由两个以上的元素组合而成。 也就是所谓的世间万物都是由因缘和合构成的，所以无常才是常态。 我们很容易遗忘它，继而进入一种痛苦的轮回。假如我们时时刻刻带着因缘和合觉知，就会明白自己经历的一切都是合理的。 父母为什么会离我们而去，因为人一旦出生，死亡就是固定的结局。 朋友为什么会渐渐走散，因为当初维系你们之前关系的纽带已经不在，渐行渐远也就不足为奇。 爱人间之所以会渐渐疏离，因为每个人都在变化，关系模式不调，就是会越来越远。 孩子们为什么离我们越来越远，因为他们对世界充满好奇，而我们总是跟他们讲旧故事。 且不说这么人际关系这么复杂的事情，即便是你想在家吃个白水煮蛋，都需要讲究因缘和合。 首先你要有一个鸡蛋，还要确保家里没停水，燃气可以使用，煮蛋的锅是完好无损的，最后你还要确保你有把鸡蛋煮熟的时间，然后才能拿到一个煮熟的鸡蛋。 悉达多跟乔文达曾经因为有共同的目标，所以同行了一段时间，之后悉达多觉醒了，他走向了另外一条路，所以，他告别了朋友。 他遇上了船夫，渡过那条河，继而遇上迦摩罗，学习爱经，遇到商人，学会经商，遇见赌徒，成为赌徒，当他发现自己沦陷到世俗中时，他选择再次出世，这一切都是因缘和合，也都是无常。 普通人的生命也是这样，孤独地从生命的每个角落走过，承受不一样的玷污，承担属于自己的罪过，反反复复地跟自己和解，寻找一条属于自己的出路。 这世界上没有两片相同的叶子，也没有两个相同的人，我们都是由无数人的碎片组成的独一无二的个体，生命里经历的人和事情都是合理的。 史铁生有句话非常完美的印证了这样的观点：其实我们每时每刻都是幸运的，因为任何灾难的前面都可以再加上一个“更”字。 所以，生而为人，一旦体认因缘和合，接纳无常，人就不用费劲去跟事情本身对抗，也就可以少受很多苦。 既然无常是常态，那无论当下处于何种困境，只要你一直有在做些什么，就有极大的概率能从中走出来。 悉达多曾经期待过人生圆满的状态，而乔文达这一生都在等着自己证悟涅槃那一刻。 人类真的很喜欢谈未来，总觉得未来会更好，世界会更美好，人生也会更圆满。 于是，我们从小到大一直在等，小学等到中学，中学等到大学，大学等到工作，工作等到退休…… 或早或晚，我们都会发现：哎，不对啊，万一我们活不到退休，之前的等待不就是在浪费生命吗？ 原来我期待的圆满的人生，不会到来，换句话说，每一个当下就是圆满。 在悉达多生命的最后阶段，他跟乔文达说：一切皆有定数，一切只需要我的赞赏、顺从和爱的默许。 老年时期的悉达多跟船夫一起渡人，有一天他遇见了迦摩罗带着他们的孩子来到河边，去追随乔达摩，但却死在了他的身边。 他本想把孩子留在身边，好好照顾，但孩子想要回到富丽堂皇的家乡，享受佣人的照顾，享用锦衣玉食，他试图挽留孩子，但船夫让他去问问河水，河水只是笑他，颤抖着笑他的愚蠢。 最终，他选择放手，让年轻人归于年轻人。 每当他想要去找回儿子，船夫都让他去听听河水的意见，经过多次重复后，悉达多不再和命运搏斗，也不再和自己的想法作对，他脸上才呈现出真正喜悦。 其实，人生没有所谓的遗憾，一切经历都是最好的安排，生命的每个瞬间都是独特的，美妙的。 失业意味着有时间好好做个总结，梳理自我的得与失，也可以趁机想清楚下个阶段人生究竟要去向哪儿？ 结束一段亲密关系，意味着可以回顾自己在亲密关系里的行为模式究竟被什么控制，找到爱自己的方式，再去思考自己需要什么样的爱人？ 不要只是探求目标，而是要去发现，发现生活的要义，生命的有趣之处，自由、敞开、没有目的地沉浸在当下，发现生活给我们的启示。 我特别喜欢史铁生在《病隙碎笔》中的一句话： 人可以走向天堂，但不可以走到天堂。走向，意味着彼岸的成立。走到，岂非彼岸的消失。彼岸的消失即信仰的终结、拯救的放弃。因为天堂不是一处空间，不是一种物质性存在，而是道路，是精神的恒途。 生命是一个过程，而不是一种结果，抱着凡事发生皆有利于我的态度认真生活，就会发现任何体验都是财富，也都是命运附赠的礼物。 无论世事如何变迁，都要爱生活，爱命运，毕竟我们也只来这世间一次，要好好体验，才不算浪费。 《悉达多》并非佛陀的故事，而是讲述了一个普通人一生的经历。悉达多经历了学习、苦行、聆听教义、 觉醒、堕入世俗、悔恨、修行、学会爱，最终在内心平静中修得圆满。这也是每个人追寻自我生命意义的过程。一个人必须亲身去经历，任何教义和知识都无法让人真正明白道之真意，任何言辞也无法替代自身的体悟。用心去感受一切，不拘于表象， 总有一天，我们都会找到自己。","tags":["读书笔记"],"categories":["藏书阁"]},{"title":"网络编程与 I/O 多路复用","path":"/post/C++/network-programming-and-io-multiplexing/","content":"网络编程Socket如果我们要将数据从电脑 A 的某个进程发到电脑 B 的某个进程，如果需要确保数据能够发送给对方，那就选可靠的 TCP 协议，否则可以采用 UDP 协议。 那这时候就需要用 socket 进行编程，第一步就是创建一个关于 TCP 的 socket。 下文皆以 TCP 为例 123// SOCK_STREAM：TCP 流套接字// SOCK_DGRAM：UDP 数据报套接字int sock_fd = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP); sock_fd 相当于文件句柄，客户端和服务端都需要各自创建 fd： 对于服务端：就可以根据 fd 依次执行 bind()、listen()、accept() 方法，然后坐等客户端的连接请求 对于客户端：根据 fd 来执行 connect() 向服务端发起建立连接的请求，此时就会发生 TCP 三次握手 以下是 TCP 三次握手的示意图： 连接建立完成后，客户端可以执行 send() 发送消息，服务端可以执行 recv() 接收消息；反过来，服务端也可以执行 send()，客户端执行 recv()。 相关函数： 1234567int socket(int __domain, int __type, int __protocol)int bind(int __fd, const struct sockaddr *__addr, socklen_t __len)int listen(int __fd, int __n)int connect(int __fd, const struct sockaddr *__addr, socklen_t __len)int accept(int __fd, struct sockaddr *__restrict__ __addr, socklen_t *__restrict__ __addr_len)ssize_t recv(int __fd, void *__buf, size_t __n, int __flags)ssize_t send(int __fd, const void *__buf, size_t __n, int __flags) 服务端可以使用 socket() 系统调用创建套接字，它在 &lt;sys/socket.h&gt; 中定义。 Definition 1int socket(int __domain, int __type, int __protocol) __domain AF_INET：IPv4 AF_INET6：IPv6 __type SOCK_STREAM：TCP 流套接字 SOCK_DGRAM：UDP 数据报套接字 __protocol：指定协议，当 __protocol 为 0 时，会自动选择 type 类型对应的默认协议。 IPPROTO_TCP IPPTOTO_UDP IPPROTO_SCTP IPPROTO_TIPC Usage 123456int serverSocket = socket(AF_INET, SOCK_STREAM, 0);// 定义服务器地址sockaddr_in serverAddress;serverAddress.sin_family = AF_INET;serverAddress.sin_port = htons(8080);serverAddress.sin_addr.s_addr = INADDR_ANY; sockaddr_in：用于存储套接字地址的数据类型 htons：该函数用于将 unsigned int 从机器字节序转换为网络字节序 INADDR_ANY：当我们不想将套接字绑定到任何特定网卡 IP，而是让它监听所有网卡（所有可用 IP）时使用 1bind(serverSocket, (struct sockaddr*)&amp;serverAddress, sizeof(serverAddress)); 调用 bind() 绑定套接字 1listen(serverSocket, 5); 然后监听 serverSocket 引用的套接字 1int clientSocket = accept(serverSocket, nullptr, nullptr); accept() 调用用于接受应用程序正在监听的套接字上收到的连接请求 123char buffer[1024] = &#123;0&#125;;recv(clientSocket, buffer, sizeof(buffer), 0);cout &lt;&lt; &quot;Message from client: &quot; &lt;&lt; buffer &lt;&lt; endl; 然后开始从客户端接收数据，我们可以指定所需的缓冲区大小，以便有足够的空间接收客户端发送的数据 1close(serverSocket); 最后使用 close() 关闭套接字 server.cpp 完整代码 1234567891011121314151617181920212223242526272829303132333435363738394041// C++ program to show the example of server application in// socket programming#include &lt;cstring&gt;#include &lt;iostream&gt;#include &lt;netinet/in.h&gt;#include &lt;sys/socket.h&gt;#include &lt;unistd.h&gt;using namespace std;int main()&#123; // creating socket int serverSocket = socket(AF_INET, SOCK_STREAM, 0); // specifying the address sockaddr_in serverAddress; serverAddress.sin_family = AF_INET; serverAddress.sin_port = htons(8080); serverAddress.sin_addr.s_addr = INADDR_ANY; // binding socket. bind(serverSocket, (struct sockaddr*)&amp;serverAddress, sizeof(serverAddress)); // listening to the assigned socket listen(serverSocket, 5); // accepting connection request int clientSocket = accept(serverSocket, nullptr, nullptr); // recieving data char buffer[1024] = &#123; 0 &#125;; recv(clientSocket, buffer, sizeof(buffer), 0); cout &lt;&lt; &quot;Message from client: &quot; &lt;&lt; buffer &lt;&lt; endl; // closing the socket close(serverSocket); return 0;&#125; 更完整的写法：server.c 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;errno.h&gt;#include &lt;netinet/in.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/socket.h&gt;#include &lt;unistd.h&gt;int main() &#123; // int socket(int __domain, int __type, int __protocol) int sock_fd = socket(AF_INET, SOCK_STREAM, 0); struct sockaddr_in server_addr; server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = htonl(INADDR_ANY); // 0.0.0.0 server_addr.sin_port = htons(2000); // system used: 0 ~ 1023 if (bind(sock_fd, (struct sockaddr*)&amp;server_addr, sizeof(struct sockaddr)) == -1) &#123; printf(&quot;bind failed: %s &quot;, strerror(errno)); &#125; // int listen(int __fd, int __n): 后者为等待队列的长度 listen(sock_fd, 10); printf(&quot;listen finished: %d &quot;, sock_fd); // 3 system(&quot;netstat -ano | grep 2000&quot;); // getchar(); // 方便查看 netstat -ano | grep 2000: tcp 0 0 0.0.0.0:2000 0.0.0.0:* LISTEN off (0.00/0/0) struct sockaddr_in client_addr; // int accept(int __fd, struct sockaddr *__restrict__ __addr, socklen_t *__restrict__ __addr_len) socklen_t len = sizeof(client_addr); int client_fd = accept(sock_fd, (struct sockaddr*)&amp;client_addr, &amp;len); printf(&quot;accept finished &quot;); system(&quot;netstat -ano | grep 2000&quot;); char buffer[1024] = &#123;0&#125;; // ssize_t recv(int __fd, void *__buf, size_t __n, int __flags) int count = recv(client_fd, buffer, sizeof(buffer), 0); printf(&quot;RECV: %s &quot;, buffer); // ssize_t send(int __fd, const void *__buf, size_t __n, int __flags) count = send(client_fd, buffer, count, 0); printf(&quot;SEND: %d &quot;, count); // getchar(); while (1); return 0;&#125; 客户端与服务器类似，我们也需要创建一个套接字并指定地址。不过，我们不会接受请求，而是在能够使用 connect() 调用发送数据时，发送连接请求。然后我们使用 send() 函数发送数据。所有操作完成后，我们使用 close() 函数关闭连接。 client.cpp 完整代码 1234567891011121314151617181920212223242526272829303132// C++ program to illustrate the client application in the// socket programming#include &lt;cstring&gt;#include &lt;iostream&gt;#include &lt;netinet/in.h&gt;#include &lt;sys/socket.h&gt;#include &lt;unistd.h&gt;int main()&#123; // creating socket int clientSocket = socket(AF_INET, SOCK_STREAM, 0); // specifying address sockaddr_in serverAddress; serverAddress.sin_family = AF_INET; serverAddress.sin_port = htons(8080); serverAddress.sin_addr.s_addr = INADDR_ANY; // sending connection request connect(clientSocket, (struct sockaddr*)&amp;serverAddress, sizeof(serverAddress)); // sending data const char* message = &quot;Hello, server!&quot;; send(clientSocket, message, strlen(message), 0); // closing socket close(clientSocket); return 0;&#125; 更完整的写法：client.c 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;netinet/in.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/socket.h&gt;int main() &#123; unsigned short port = 2000; // char *server_ip = &quot;10.26.57.8&quot;; // 应该发送到对应IP的网卡地址: 10.26.57.3 // char *server_ip = &quot;localhost&quot;; // ✅ 两个程序在同一个服务器上跑就可 char *server_ip = &quot;10.26.57.3&quot;; // ✅ 网卡地址能接收到 int sockfd = socket(AF_INET, SOCK_STREAM, 0); if (sockfd &lt; 0) &#123; perror(&quot;socket error&quot;); exit(-1); &#125; struct sockaddr_in server_addr; // bzero &lt;==&gt; memset(&amp;server_addr, 0, sizeof(server_addr)); bzero(&amp;server_addr, sizeof(server_addr)); // 初始化服务器地址 // AF_INET: IPv4 // AF_INET6: IPv6 server_addr.sin_family = AF_INET; server_addr.sin_port = htons(port); // inet_pton() 是一个通用的地址转换函数，不知道你打算转换成 IPv4 还是 IPv6，必须由你告诉它目标地址族 // AF_INET: IPv4 // AF_INET6: IPv6 // 客户端绑定具体服务端IP必须使用该方法 inet_pton(AF_INET, server_ip, &amp;server_addr.sin_addr.s_addr); system(&quot;netstat -ano | grep 2000&quot;); // int connect(int __fd, const struct sockaddr *__addr, socklen_t __len) if (connect(sockfd, (struct sockaddr *)&amp;server_addr, sizeof(server_addr)) == -1) &#123; perror(&quot;connect error&quot;); close(sockfd); exit(-1); &#125; system(&quot;netstat -ano | grep 2000&quot;); char buffer[1024] = &quot;Client INFO: test...&quot;; // ssize_t send(int __fd, const void *__buf, size_t __n, int __flags) int count = send(sockfd, buffer, sizeof(buffer), 0); printf(&quot;SEND: %d &quot;, count); while (1); return 0;&#125; 源码分析sockaddrsockaddr 在头文件 &lt;sys/socket.h&gt; 中定义，sockaddr 的缺陷是 sa_data 把「目标地址」和「端口信息」混在一起了： 12345struct sockaddr&#123; unsigned short sa_family; // 2 字节，地址族，AF_xxx char sa_data[14]; // 14 字节，包含套接字中的目标地址和端口信息 &#125;; sockaddr_insockaddr_in 在头文件 &lt;netinet/in.h&gt; 或 &lt;arpa/inet.h&gt; 中定义，该结构体解决了 sockaddr 的缺陷，把 port 和 addr 分开存储在两个变量中： 123456struct sockaddr_in &#123; sa_family_t sin_family; // 地址族，一般是 AF_INET（IPv4），也可以是 AF_INET6（IPv6） in_port_t sin_port; // 端口号（使用 htons() 转换为网络字节序） struct in_addr sin_addr; // IP 地址（结构体） char sin_zero[8];// 填充字段，保持结构体大小与 sockaddr 一致&#125;; 123struct in_addr &#123; unsigned long s_addr; // 32 位 IPv4 地址打印的时候可以调用 inet_ntoa() 函数将其转换为 char* 类型&#125;; sockaddr 常用于 bind、connect、recvfrom、sendto 等函数的参数，指明地址信息，是一种通用的套接字地址。 sockaddr_in 是 internet 环境下套接字的地址形式。所以在网络编程中我们会对 sockaddr_in 结构体进行操作，使用 sockaddr_in 来建立所需的信息，最后使用类型转化 (struct sockaddr*) 即可。 一般先把 sockaddr_in 变量赋值后，强制类型转换后传入用 sockaddr 做参数的函数： sockaddr_in 用于 socket 定义和赋值 sockaddr 用于函数参数 Usage：程序员不应该操作 sockaddr，而是使用 sockaddr_in 来表示地址，并强转为 (struct sockaddr *) 传入函数中： 12345// int accept(int __fd, struct sockaddr *__restrict__ __addr, socklen_t *__restrict__ __addr_len)struct sockaddr_in client_addr;socklen_t len = sizeof(client_addr);int client_fd = accept(sock_fd, (struct sockaddr*)&amp;client_addr, &amp;len); 12345678// int connect(int __fd, const struct sockaddr *__addr, socklen_t __len)struct sockaddr_in server_addr;bzero(&amp;server_addr, sizeof(server_addr)); // 初始化服务器地址server_addr.sin_family = AF_INET;server_addr.sin_port = htons(2000);inet_pton(AF_INET, &quot;10.26.57.3&quot;, &amp;server_addr.sin_addr.s_addr);connect(sockfd, (struct sockaddr *)&amp;server_addr, sizeof(server_addr) 讲一讲 I&#x2F;O 多路复用｜select、poll、epoll 的区别是什么？I&#x2F;O 多路复用是一种 I&#x2F;O 的处理方式，指的是复用一个线程处理多个 socket 中的事件。能够复用资源，防止创建过多线程导致的上下文切换的开销。 我们熟悉的 select&#x2F;poll&#x2F;epoll 内核提供给用户态的多路复用系统调用，进程可以通过一个系统调用函数从内核中获取多个事件。 select&#x2F;poll&#x2F;epoll 是如何获取网络事件的呢？在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。 select、poll ✅ select 图解 ✅ poll 图解 select 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。 所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。 select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。 poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。 但是 poll 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 $O(n)$，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。 epollLinux 2.6 版本诞生了 epoll 模型，彻底解决了 select&#x2F;poll 性能不足的问题 ✅ epoll 图解 先复习下 epoll 的用法。如下的代码中，先用 epoll_create 创建一个 epoll 对象 epoll_fd，再通过 epoll_ctl 将需要监视的 socket 添加到 epoll_fd 中，最后调用 epoll_wait 等待数据。 1234567891011121314int s = socket(AF_INET, SOCK_STREAM, 0);bind(s, ...);listen(s, ...);// epoll_fdint epfd = epoll_create(...);epoll_ctl(epfd, ...); // 将所有需要监听的 socket 添加到 epfd 中while(1) &#123; int n = epoll_wait(...); for (接收到数据的 socket) &#123; //处理 &#125;&#125; epoll 通过两个方面，很好解决了 select&#x2F;poll 的问题： 第一点，epoll 在内核里使用「红黑树」来跟踪进程所有待检测的文件描述字，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 $O(logn)$。而 select&#x2F;poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select&#x2F;poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。 第二点，epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，内核通过回调函数将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select&#x2F;poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。 从下图你可以看到 epoll 相关的接口作用： epoll 的方式即使监听的 Socket 数量越多的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了，上限就为系统定义的进程打开的最大文件描述符个数。因而，epoll 被称为解决 C10K 问题（服务器同时处理 10,000个 客户端连接的挑战）的利器。","tags":["C++","Socket","TCP","UDP","select","poll","epoll"],"categories":["C++"]},{"title":"2025.05.21 华为笔试题","path":"/post/秋招指南/20250521-huawei/","content":"题解链接：https://mp.weixin.qq.com/s/DawyjMfoNpKxmRfqqJR9hg 测评链接：https://niumacode.com/training/127 1. 开发一个简单任务调度系统你需要开发一个简单的任务调度系统，该系统按任务优先级调度，优先级范围是 $(0, 99)$，数值越小优先级越高。只有高优先级任务执行完成后，低优先级任务才能执行，同等优先级的任务按照 $FIFO$ 原则，先进入调度系统的任务会优先调度，当优先级任务执行时，如果新增高优先级任务，高优先级任务会抢占低优先级任务。 请你实现一个程序，模拟这个任务调度系统。 添加任务：将一个新任务添加到任务调度系统。任务包含一个唯一ID（task_id）、优先级（priority）$[0,99]$，运行时间（time）$[1,10000]$。 执行任务：任务调度系统按照调度策略，调度任务并执行。调度系统调度任务，并消耗对应时间片，时间片范围 $[1,100000]$。 Input程序需要处理以下类型的输入： 添加任务 add task_id priority time 执行任务 run time 注： 输入命令总行数不超过 10000 行 run 命令可以有多个 空行即命令结束 Output显示任务调度系统当前执行的任务 ID。若无任何任务，则显示 idle。 Sample 1输入： 1234add 101 0 10add 20 1 3add 300 0 1run 11 输出： 120 样例 1 解释： add 101 0 10：添加任务 101，其优先级为 0，运行时间为 0 个时间片 add 20 1 3：添加任务 20，其优先级为 1，运行时间为 3 个时间片 add 300 0 1：添加任务 30，其优先级为 0，运行时间为 1 个时间片 run 11：调度系统调度任务并执行。首先调度任务 101，运行了 10 个时间片，任务完成。接下来调度任务 300（其优先级高于任务 20），运行了 1 个时间片，任务完成。此时消耗完全部运行时间片（即 11）。 此时调度系统要运行的任务 id 即为 20 Sample 2输入： 12add 1 0 10run 11 输出： 1idle 样例 2 解释： add 1 0 10：添加任务 1，优先级 0，运行时间为 10 个时间片 run 11：调度系统调度任务，并运行 11 个时间片。选择任务 1 运行了 10 个时间片，任务 1 完成。无任务待调度。 调度系统无任何任务，因此显示 idle。 Solution (False) 每执行一次 run 则输出一次结果 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#include &lt;bits/stdc++.h&gt;using namespace std;struct Task &#123; int id; int priority; int remain; // 剩余时间片&#125;;// 每个优先级维护一个FIFO队列, 下标0是最高优先级queue&lt;Task&gt; slots[100];// 添加任务void addTask(int id, int priority, int time) &#123; slots[priority].push(&#123;id, priority, time&#125;);&#125;// 获取下一个待执行任务, 如果无任务则返回&#123;-1,-1,-1&#125;Task getNext() &#123; for (int p = 0; p &lt; 100; ++p) &#123; if (!slots[p].empty()) &#123; Task t = slots[p].front(); slots[p].pop(); return t; &#125; &#125; return &#123;-1, -1, -1&#125;;&#125;int getCurrentTaskId() &#123; for (int p = 0; p &lt; 100; ++p) &#123; if (!slots[p].empty()) &#123; return slots[p].front().id; &#125; &#125; return -1;&#125;int main() &#123; ios::sync_with_stdio(false); cin.tie(nullptr); string cmd; while (getline(cin, cmd)) &#123; if (cmd.empty()) break; stringstream ss(cmd); ss &gt;&gt; cmd; if (cmd == &quot;add&quot;) &#123; int id, pr, t; ss &gt;&gt; id &gt;&gt; pr &gt;&gt; t; addTask(id, pr, t); &#125; else if (cmd == &quot;run&quot;) &#123; int time; ss &gt;&gt; time; while (time &gt; 0) &#123; Task cur = getNext(); if (cur.id == -1) break; // 无任务 if (cur.remain &lt;= time) &#123; time -= cur.remain; // 任务完成, 消耗所有剩余时间 &#125; else &#123; cur.remain -= time; // 任务未完成 time = 0; slots[cur.priority].push(cur); // 重新排队 &#125; &#125; int nid = getCurrentTaskId(); if (nid == -1) cout &lt;&lt; &quot;idle&quot;; else cout &lt;&lt; nid; cout &lt;&lt; &quot; &quot;; &#125; &#125; return 0;&#125; Solution (True) 只输出最后一次 run ✅ 参考链接：https://codefun2000.com/p/P2972 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#include &lt;bits/stdc++.h&gt;using namespace std;// 任务结构体struct Task &#123; int id; // 任务ID int prio; // 优先级（越小越先） int rem; // 剩余时间片 int order; // 到达顺序&#125;;// 优先队列比较器struct Cmp &#123; bool operator()(const Task &amp;a, const Task &amp;b) const &#123; if (a.prio != b.prio) return a.prio &gt; b.prio; return a.order &gt; b.order; &#125;&#125;;int main() &#123; ios::sync_with_stdio(false); cin.tie(nullptr); priority_queue&lt;Task, vector&lt;Task&gt;, Cmp&gt; pq; string cmd; int next_order = 0; vector&lt;pair&lt;string, vector&lt;int&gt;&gt;&gt; ops; // 读取所有操作 while (getline(cin, cmd)) &#123; if (cmd.empty()) break; stringstream ss(cmd); string op; ss &gt;&gt; op; if (op == &quot;add&quot;) &#123; int id, p, t; ss &gt;&gt; id &gt;&gt; p &gt;&gt; t; ops.push_back(&#123;op, &#123;id, p, t&#125;&#125;); &#125; else if (op == &quot;run&quot;) &#123; int T; ss &gt;&gt; T; ops.push_back(&#123;op, &#123;T&#125;&#125;); &#125; &#125; // 模拟所有操作，只在最后一次 run 后输出 int last_run_idx = -1; for (int i = 0; i &lt; (int)ops.size(); i++) &#123; if (ops[i].first == &quot;run&quot;) last_run_idx = i; &#125; for (int i = 0; i &lt; (int)ops.size(); i++) &#123; auto &amp;op = ops[i]; if (op.first == &quot;add&quot;) &#123; // 入队一个新任务 pq.push(&#123;op.second[0], op.second[1], op.second[2], next_order++&#125;); &#125; else &#123; int T = op.second[0]; while (T &gt; 0 &amp;&amp; !pq.empty()) &#123; Task t = pq.top(); pq.pop(); if (t.rem &lt;= T) &#123; T -= t.rem; // 任务完成，消耗全部剩余时间 &#125; else &#123; t.rem -= T; // 任务未完成，更新剩余时间 T = 0; pq.push(t); // 重新入队 &#125; &#125; // 如果是最后一次 run，输出结果 if (i == last_run_idx) &#123; if (pq.empty()) cout &lt;&lt; &quot;idle &quot;; else cout &lt;&lt; pq.top().id &lt;&lt; &quot; &quot;; &#125; &#125; &#125; return 0;&#125; 2. 地震救灾路线某市发生地震，为了尽快将救援物质输送到受灾乡镇，需要你设计出从救援物质集结点（有仅有一个）到某一个受灾乡镇的最短线路 应急部门通过无人机助察了受灾地区地形，提供了各乡镇之间以及乡镇到救援物质集结点的距离，请你算出救援物质集结点到受灾多镇的最短路径。 Input第一行，N，受灾乡镇个数，3&lt;&#x3D;N&lt;&#x3D;20 第二行至第 N+2 行，救援物质集结点以及各乡镇之间的距离矩阵（即 N+1 个节点之间的相互距离矩阵），距离取值范围是 $[0,100]$。序号 0 的节点表示救援物质集结点，序号 1 ~ N 的节点表示各个受灾乡镇。0 表示两个节点不相邻。 第 N+3 行，m，要抵达的乡镇序号（范围 1~N） Output从物质集结点（节点 0）到乡镇 m（节点 m）的最短路径长度 Sample 1输入： 1234567850 5 13 0 0 05 0 12 0 75 013 12 0 25 0 00 0 25 0 35 200 75 0 35 0 400 0 0 20 40 03 输出： 138 样例 1 解释： 从 0 到 3 的最短路径为 $0-2-3$，长度为 $13 + 25 &#x3D; 38$ Sample 2输入： 1234567850 5 13 0 0 05 0 12 0 75 013 12 0 25 0 00 0 25 0 35 200 75 0 35 0 400 0 0 20 40 05 输出： 158 样例 2 解释： 从 0 到 5 的最短路径为 $0-2-3-5$，长度为 $13+25+20&#x3D;58$ Solution✅ 参考链接：https://codefun2000.com/p/P2973 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;bits/stdc++.h&gt;using namespace std;int main() &#123; int N; cin &gt;&gt; N; // 受灾乡镇个数 int total = N + 1; vector&lt;vector&lt;int&gt;&gt; d(total, vector&lt;int&gt;(total)); // 读入距离矩阵，节点 0 为物资集结点，1~N 为乡镇 for (int i = 0; i &lt; total; i++) &#123; for (int j = 0; j &lt; total; j++) &#123; cin &gt;&gt; d[i][j]; &#125; &#125; int m; cin &gt;&gt; m; // 目标乡镇编号 const int INF = 1e9; vector&lt;int&gt; dist(total, INF); vector&lt;bool&gt; vis(total, false); dist[0] = 0; // 源点到自己的距离为 0 // Dijkstra 算法主循环 for (int i = 0; i &lt; total; i++) &#123; int u = -1, minDist = INF; // 找到未访问且 dist 最小的节点 u for (int j = 0; j &lt; total; j++) &#123; if (!vis[j] &amp;&amp; dist[j] &lt; minDist) &#123; u = j; minDist = dist[j]; &#125; &#125; if (u == -1) break; // 剩余节点不可达 vis[u] = true; // 松弛以 u 为起点的所有边 for (int v = 0; v &lt; total; v++) &#123; if (!vis[v] &amp;&amp; d[u][v] &gt; 0 &amp;&amp; dist[v] &gt; dist[u] + d[u][v]) &#123; dist[v] = dist[u] + d[u][v]; &#125; &#125; &#125; cout &lt;&lt; dist[m] &lt;&lt; endl; // 输出从 0 到 m 的最短距离 return 0;&#125; 补充｜Dijkstra 算法Dijkstra 算法是一种求解非负权图上单源最短路径的算法。 算法思路‼️将结点分成两个集合：已确定最短路长度的点集（记为 $S$ 集合）的和未确定最短路长度的点集（记为 $T$ 集合）。一开始所有的点都属于 $T$ 集合。 初始化 $dis(s) &#x3D; 0$，其他点的 $dis$ 均为 $+∞$。 然后重复这些操作： 从 $T$ 集合中，选取一个最短路长度最小的结点，移到 $S$ 集合中。 对那些刚刚被加入 $S$ 集合的结点的所有出边执行松弛操作。 直到 $T$ 集合为空，算法结束。 时间复杂度朴素的实现方法为每次「操作 2」执行完毕后，直接在 $T$ 集合中暴力寻找最短路长度最小的节点。「操作 2」总时间复杂度为 $O(m)$，「操作 1」总时间复杂度为 $O(n^2)$，全过程的时间复杂度为 $O(n^2+m)&#x3D;O(n^2)$。 可以用「堆」来优化这一过程：每松弛一条边 $(u,v)$，就将 $v$ 插入堆中（如果 $v$ 已经在堆中，直接执行 Decrease-key），「操作 1」直接取堆顶节点即可。共计 $O(m)$ 次 Decrease-key，$O(n)$ 次 pop，堆优化能做到的最优复杂度为 $O(nlogn+m)$。特别地，可以用优先队列 priority_queue 维护，此时无法执行 Decrease-key 操作，但可以通过每次松弛时重新插入该节点，且弹出时检查该节点是否已被松弛过，若是则跳过，复杂度 $O(mlogn)$，优点是实现比较简单。 这里的堆也可以用线段树实现，复杂度为 $O(mlogn)$，在一些特殊的非递归线段树实现下，该做法常数比堆更小。并且线段树支持的操作更多，在一些特殊图问题上只能用线段树来维护。 ✅ 在稀疏图（邻接矩阵）中，$m&#x3D;O(n)$，堆优化的 Dijkstra 算法具有较大的效率优势； ✅ 而在稠密图（邻接图）中，$m&#x3D;O(n^2)$，这时候使用朴素实现更优。 代码实现 这里同时给出 $O(n^2)$ 的暴力做法实现和 $O(m·logm)$ 的优先队列做法实现。 dijkstra 算法推荐练习题： 743. 网络延迟时间 3341. 到达最后一个房间的最少时间 I 3112. 访问消失节点的最少时间 … 1️⃣ 朴素实现｜稠密图（邻接图） 123456789101112131415161718192021struct edge &#123; int v, w;&#125;;vector&lt;edge&gt; e[MAXN];int dis[MAXN], vis[MAXN];void dijkstra(int n, int s) &#123; memset(dis, 0x3f, (n + 1) * sizeof(int)); dis[s] = 0; for (int i = 1; i &lt;= n; i++) &#123; int u = 0, mind = 0x3f3f3f3f; for (int j = 1; j &lt;= n; j++) if (!vis[j] &amp;&amp; dis[j] &lt; mind) u = j, mind = dis[j]; vis[u] = true; for (auto ed : e[u]) &#123; int v = ed.v, w = ed.w; if (dis[v] &gt; dis[u] + w) dis[v] = dis[u] + w; &#125; &#125;&#125; 2️⃣ 优先队列实现｜稀疏图（邻接矩阵） 123456789101112131415161718192021222324252627282930313233struct edge &#123; int v, w;&#125;;struct node &#123; int dis, u; bool operator&gt;(const node&amp; a) const &#123; return dis &gt; a.dis; &#125;&#125;;vector&lt;edge&gt; e[MAXN];int dis[MAXN], vis[MAXN];priority_queue&lt;node, vector&lt;node&gt;, greater&lt;node&gt;&gt; q;void dijkstra(int n, int s) &#123; memset(dis, 0x3f, (n + 1) * sizeof(int)); memset(vis, 0, (n + 1) * sizeof(int)); dis[s] = 0; q.push(&#123;0, s&#125;); while (!q.empty()) &#123; int u = q.top().u; q.pop(); if (vis[u]) continue; vis[u] = 1; for (auto ed : e[u]) &#123; int v = ed.v, w = ed.w; if (dis[v] &gt; dis[u] + w) &#123; dis[v] = dis[u] + w; q.push(&#123;dis[v], v&#125;); &#125; &#125; &#125;&#125; 3. 云计算服务器 GPU 分配某云计算服务商为客户提供 M 数量 GPU 核数的 GPU 分时租用服务，租用计费规则为：允许客户在每个时间单位按需租用不同的 GPU 核数，每个时间单位每个 GPU 核数的费用为 R。现有 N 个客户，每个客户有多个不重叠时间租用一定数量的 GPU 核数租用需求。对于有需求的客户，服务商可选择签约或不签约，若选择签约则需要满足租用需求中的所有时间段所需的 GPU 核数。 为了实现租金最大化收益，服务商需在确保任意时间单位内分配的 GPU 核数总数不超过 M 的基础上选择与哪些客户签约租用协议。 请输出租金最大化收益下的租金最大值。 Input第一行为 M、N、R 的数值，依次用空格隔开，输入格式为 M N R。 从第二行开始，每行为一个客户的租用需求，共 N 行。每行的第一个数字为该客户端的时间段个数 timeSegmentNum，后续为 timeSegmentNum 个时间段及所需的 GPU 核数，时间段个数 timeSegmentNum 与时间段之间、多个时间段之间均用空格分割，同一个客户多个时间段已按起始时间增序排序给出。同个客户多个时间段不会重叠。同一个客户多个时间段已按起始时间增序排序给出。 每个时间段及所需的 GPU 核数格式为 start 起始时间编号:end 结束时间编号:needcores 该时间段所需的 GPU 核数。 变量取值范围 $1&lt;&#x3D;M&lt;&#x3D;100000$$1&lt;&#x3D;N&lt;&#x3D;10$$1&lt;&#x3D;R&lt;&#x3D;10$$0&lt;&#x3D; start&lt;&#x3D; end&lt;&#x3D; 10^9$$0&lt;&#x3D; start&lt;&#x3D; end&lt;&#x3D; 10^9$$1&lt;&#x3D; needCores&lt;&#x3D; 10000$$1&lt;&#x3D; timeSegmentNum &lt;&#x3D; 100$ 客户的租用需求样例 $2$、$0:0:1$、$3:6:10$ 的含义是共有 2 个时间段，0:0:1 表示在第 0 个时间单位需要 1 个 GPU 核，3:6:10 表示从 3 到 6 的时间单位（包含 3 和 6）每个时间单位均需 10 个 GPU 核。 图例为： Output总租金最大值。如果任意一个客户的需求都无法满足，则输出 0 Sample 1输入： 123410 3 22 0:8:5 9:23:102 0:8:5 9:18:101 0:8:5 输出： 1480 样例 1 解释： 共 3 个客户。 由于第一个客户和第二个客户在 $9:18$ 时间范围段内总核数为 20 超过了 10，所以无法同时接受。 最大日租金方案为：接纳第一个客户和第三个客户的需求。 第一个客户共需要的GPU核数为 $9 * 5 + 15*10&#x3D;195$ 第三个客户共需要的GPU核数为 $9 * 5&#x3D;45$ Sample 2输入： 12310 2 11 0:3:61 3:10:6 输出： 148 样例 2 解释： 最大 GPU 核数为 10，共 2 个客户。 第一客户和第二个客户在3时间点，总核数为 12 超过了 10，所以无法同时接受。 第一个客户共需要的GPU核数为 $4 * 6&#x3D;24$ 第二个客户共需要的GPU核数为 $8 * 6&#x3D;48$ 为满足最大租金，采纳第二个客户，最大租金值为（48）* 1&#x3D;48 Sample 3输入： 1210 1 11 0:5:20 输出： 10 样例 3 解释： 最大 GPU 核数为 10，共 1 个客户。在 $0-5$ 时间段需要 20 个 GPU 核数，无法满足。 Sample 4输入： 1210000 1 101 0:1000000000:10000 输出： 11000000000100000 样例 4 解释： 最大 GPU 核数为 10000，共 1 个客户。 客户在 $0-100000000$ 时间段需要 10000 个GPU核数，可以满足。 租金最大值为 1000000000100000 Solution✅ 参考链接：https://codefun2000.com/p/P2974 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#include &lt;bits/stdc++.h&gt;using namespace std;using ll = long long;int main() &#123; ios::sync_with_stdio(false); cin.tie(NULL); // 读入 M, N, R ll M; int N; ll R; cin &gt;&gt; M &gt;&gt; N &gt;&gt; R; // 存储每个客户的时间段需求 vector&lt;vector&lt;tuple&lt;ll,ll,ll&gt;&gt;&gt; segs(N); for (int i = 0; i &lt; N; i++) &#123; int t; cin &gt;&gt; t; while (t--) &#123; ll s, e, c; char ch; cin &gt;&gt; s &gt;&gt; ch &gt;&gt; e &gt;&gt; ch &gt;&gt; c; // 读入格式 s:e:c segs[i].emplace_back(s, e, c); &#125; &#125; ll ans = 0; // 枚举所有子集 for (int mask = 0; mask &lt; (1&lt;&lt;N); mask++) &#123; vector&lt;ll&gt; xs; ll W = 0; // 收集边界 for (int i = 0; i &lt; N; i++) if (mask &amp; (1&lt;&lt;i)) &#123; for (auto &amp;seg: segs[i]) &#123; ll s,e,c; tie(s,e,c) = seg; xs.push_back(s); xs.push_back(e+1); W += (e - s + 1) * c; &#125; &#125; if (xs.empty()) continue; // 离散化 sort(xs.begin(), xs.end()); xs.erase(unique(xs.begin(), xs.end()), xs.end()); vector&lt;ll&gt; diff(xs.size()+1); // 差分数组构造 for (int i = 0; i &lt; N; i++) if (mask &amp; (1&lt;&lt;i)) &#123; for (auto &amp;seg: segs[i]) &#123; ll s,e,c; tie(s,e,c) = seg; int l = lower_bound(xs.begin(), xs.end(), s) - xs.begin(); int r = lower_bound(xs.begin(), xs.end(), e+1) - xs.begin(); diff[l] += c; diff[r] -= c; &#125; &#125; // 扫描检查容量 ll cur = 0; bool ok = true; for (int i = 0; i+1 &lt; (int)xs.size(); i++) &#123; cur += diff[i]; if (cur &gt; M) &#123; ok = false; break; &#125; &#125; if (ok) ans = max(ans, W * R); &#125; cout &lt;&lt; ans; return 0;&#125;","tags":["笔试","实习","华为"],"categories":["秋招指南"]},{"title":"从 POSIX pthread 到 C++11 thread","path":"/post/C++/from-posix-pthread-to-c++11-thread/","content":"推荐阅读：https://chengxumiaodaren.com/docs/concurrent/ 在 C++ 开发中，原生的线程库主要有两个，一个是 Linux 下的 &lt;pthread.h&gt;，另一个是 C++11 提供的 &lt;thread&gt;。 以前一直用的是 pthread 的 API 写 C++ 的多线程程序，直到听说从 C++11 开始的标准库已经包含了对线程的支持。 pthreadpthread 中的 p 是 POSIX (Portable Operating System Interface) 的缩写，是 IEEE 为了在各种 UNIX 操作系统上运行软件，而定义 API 的一系列互相关联的标准总称。相比于 std::thread 的简便易用，pthread 功能比较强大。 线程的创建和管理创建线程｜pthread_create每个线程都有一个在进程中唯一的线程标识符，用一个数据类型 pthread_t 表示，该数据类型在 Linux 中就是一个无符号长整型数据。 1int pthread_create(pthread_t *thread, pthread_attr_t *attr, void *(*start_routine)(void *), void *arg); 若创建成功，返回 0；若出错，则返回错误编号： thread 是线程标识符，但这个参数不是由用户指定的，而是由 pthread_create 函数在创建时将新线程的标识符放到这个变量中 attr 指定线程的属性，可以用 NULL 表示默认属性 start_routine 指定线程开始运行的函数 arg 是 start_routine 所需的参数，是一个无类型指针 默认地，线程在被创建时要被赋予一定的属性，这个属性存放在数据类型 pthread_attr_t 中，它包含了线程的调度策略，堆栈的相关信息，join or detach 的状态等。 pthread_attr_init 和 pthread_attr_destroy 函数分别用来创建和销毁 pthread_attr_t，具体函数声明可参考 man 手册帮助。 结束线程｜pthread_exit、pthread_cancel当发生以下情形之一时，线程就会结束： 线程运行的函数 return 了，也就是线程的任务已经完成； 线程调用了 pthread_exit()； 其他线程调用 pthread_cancel() 结束了线程； 进程调用 exec() 或 exit() 结束； main() 函数先结束了，而且 main() 自己没有调用 pthread_exit() 来等所有线程完成任务。 更抽象地说，线程结束执行的方式共有 3 种，分别是： 线程将指定函数体中的代码执行完后自行结束； 线程执行过程中，遇到 pthread_exit() 函数结束执行。 线程执行过程中，被同一进程中的其它线程（包括主线程）强制终止； 当然，一个线程结束，并不意味着它的所有信息都已经消失，后面会看到僵尸线程的问题。 下面介绍两个函数： 1void pthread_exit(void *retval); retval 是由用户指定的参数，pthread_exit 完成之后可以通过这个参数获得线程的退出状态&#x2F;信息。 1int pthread_cancel(pthread_t thread); 一个线程可以通过调用 pthread_cancel 函数来请求取消同一进程中的线程，这个线程由 thread 参数指定。 如果操作成功则返回 0，失败则返回对应的错误编码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt; // sleep() 函数// 线程执行的函数void* thread_Fun(void* arg) &#123; printf(&quot;新建线程开始执行 &quot;); sleep(10);&#125;int main() &#123; pthread_t myThread; void* mess; int value; int res; // 创建 myThread 线程 res = pthread_create(&amp;myThread, NULL, thread_Fun, NULL); if (res != 0) &#123; printf(&quot;线程创建失败 &quot;); return 0; &#125; sleep(1); // 向 myThread 线程发送 Cancel 信号 res = pthread_cancel(myThread); if (res != 0) &#123; printf(&quot;终止 myThread 线程失败 &quot;); return 0; &#125; // 获取已终止线程的返回值 res = pthread_join(myThread, &amp;mess); if (res != 0) &#123; printf(&quot;等待线程失败 &quot;); return 0; &#125; // 如果线程被强制终止，其返回值为 PTHREAD_CANCELED if (mess == PTHREAD_CANCELED) &#123; printf(&quot;myThread 线程被强制终止 &quot;); &#125; else &#123; printf(&quot;error &quot;); &#125; return 0;&#125; 123$ ./pthread新建线程开始执行myThread 线程被强制终止 一个简单的多线程实现这是一个非常简单的基于 pthread 的多线程实现： 12345678910111213141516171819202122232425262728#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define NUM_THREADS 5void *printHello(void *thread_id) &#123; long tid; tid = (long)thread_id; printf(&quot;Hello World! It&#x27;s me, thread #%ld! &quot;, tid); pthread_exit(NULL);&#125;int main(int argc, char *argv[]) &#123; pthread_t threads[NUM_THREADS]; int rc; long t; for (t = 0; t &lt; NUM_THREADS; t++) &#123; printf(&quot;In main: creating thread %ld &quot;, t); rc = pthread_create(&amp;threads[t], NULL, printHello, (void *)t); if (rc) &#123; printf(&quot;ERROR; return code frome pthread_create() is %d &quot;, rc); exit(-1); &#125; &#125; // Last thing that main() should do pthread_exit(NULL);&#125; 12gcc -Wall _pthread.c -lpthread -o pthread./pthread 12345678910In main: creating thread 0In main: creating thread 1Hello World! It&#x27;s me, thread #0!In main: creating thread 2Hello World! It&#x27;s me, thread #1!In main: creating thread 3Hello World! It&#x27;s me, thread #2!In main: creating thread 4Hello World! It&#x27;s me, thread #3!Hello World! It&#x27;s me, thread #4! 注意输出的顺序可能不同， 要特别注意的是，main() 显示地调用了 pthread_exit() 来等待其他线程的结束（如果不使用这个函数的话，可能 main() 函数结束了也有线程没有执行完毕） 给线程传入初始化参数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define NUM_THREADS 8char *messages[NUM_THREADS];struct thread_data &#123; int tid; int sum; char *msg;&#125;;struct thread_data _datas[NUM_THREADS];void *printHello(void *thread_arg) &#123; int task_id, sum; char *hello_msg; struct thread_data *my_data; my_data = (struct thread_data *)thread_arg; task_id = my_data-&gt;tid; sum = my_data-&gt;sum; hello_msg = my_data-&gt;msg; // sleep(1); printf(&quot;Thread %d: %s Sum = %d &quot;, task_id, hello_msg, sum); pthread_exit(NULL);&#125;int main(int argc, char *argv[]) &#123; pthread_t threads[NUM_THREADS]; int *task_ids[NUM_THREADS]; int rc, t, sum; sum = 0; messages[0] = &quot;English: Hello World!&quot;; messages[1] = &quot;French: Bonjour, le monde!&quot;; messages[2] = &quot;Spanish: Hola al mundo&quot;; messages[3] = &quot;Klingon: Nuq neH!&quot;; messages[4] = &quot;German: Guten Tag, Welt!&quot;; messages[5] = &quot;Russian: Zdravstvytye, mir!&quot;; messages[6] = &quot;Japan: Sekai e konnichiwa!&quot;; messages[7] = &quot;Latin: Orbis, te saluto!&quot;; for (t = 0; t &lt; NUM_THREADS; t++) &#123; sum = sum + t; _datas[t].tid = t; _datas[t].sum = sum; _datas[t].msg = messages[t]; printf(&quot;Creating thread %d &quot;, t); rc = pthread_create(&amp;threads[t], NULL, printHello, (void *)&amp;_datas[t]); if (rc) &#123; printf(&quot;ERROR; return code from pthread_create() is %d &quot;, rc); exit(-1); &#125; &#125; pthread_exit(NULL);&#125; 12345678910111213141516Creating thread 0Creating thread 1Thread 0: English: Hello World! Sum = 0Creating thread 2Thread 1: French: Bonjour, le monde! Sum = 1Creating thread 3Thread 2: Spanish: Hola al mundo Sum = 3Creating thread 4Thread 3: Klingon: Nuq neH! Sum = 6Creating thread 5Thread 4: German: Guten Tag, Welt! Sum = 10Creating thread 6Thread 5: Russian: Zdravstvytye, mir! Sum = 15Creating thread 7Thread 6: Japan: Sekai e konnichiwa! Sum = 21Thread 7: Latin: Orbis, te saluto! Sum = 28 对线程的阻塞｜pthread_join、pthread_detach阻塞时线程之间「同步」的一种方法。 1int pthread_join(pthread_t thread_id, void **value_ptr); pthread_join 函数会让调用它的线程等待 thread_id 线程运行结束之后再运行（如果是 main() 调用，则阻塞 main 线程，直到 join 的所有线程执行结束 —— 常用于等待 main 中创建的所有线程执行完毕） value_ptr 存放了其他线程的返回值 一个可以被 join 的线程，仅仅可以被另一个线程 join，如果同时有多个线程尝试 join 同一个线程时，最终结果是未知的；另外，线程不能 join 自己。上面提到过，创建一个线程时，要赋予它一定的属性，这其中就包括 joinable or detachable 的属性，只有被声明称 joinable 的线程才可以被其他线程 join。 POSIX 标准的最终版本指出线程应该被设置成 joinable 的，显式设置一个线程为 joinable，需要以下四个步骤： Declare a pthread attribute variable of the pthread_attr_t data type Initialize the attribute variable with pthread_attr_init() Set the attribute detached status with pthread_attr_setdetchstate() When done, free library resources used by the attribute with pthread_attr_destroy() pthread_join() 函数会一直阻塞调用它的线程，直至目标线程执行结束（接收到目标线程的返回值），阻塞状态才会解除。如果 pthread_join() 函数成功等到了目标线程执行结束（成功获取到目标线程的返回值），返回值为数字 0；反之如果执行失败，函数会根据失败原因返回相应的非零值，每个非零值都对应着不同的宏，例如： EDEADLK：检测到线程发生了死锁。 EINVAL：分为两种情况，要么目标线程本身不允许其它线程获取它的返回值，要么事先就已经有线程调用 pthread_join() 函数获取到了目标线程的返回值。 ESRCH：找不到指定的 thread 线程。 再次强调，一个线程执行结束的返回值只能由一个 pthread_join() 函数获取，当有多个线程调用 pthread_join() 函数获取同一个线程的执行结果时，哪个线程最先执行 pthread_join() 函数，执行结果就由那个线程获得，其它线程的 pthread_join() 函数都将执行失败。 对于一个默认属性的线程 A 来说，线程占用的资源并不会因为执行结束而得到释放。而通过在其它线程中执行pthread_join(A,NULL);语句，可以轻松实现“及时释放线程 A 所占资源”的目的。 1234567891011121314151617181920212223242526272829303132#include &lt;errno.h&gt; //使用宏 ESRCH#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;// 线程执行的函数void *ThreadFun(void *arg) &#123; pthread_exit(&quot;test_msg&quot;); &#125;int main() &#123; int res; void *thread_result; pthread_t myThread; // 创建 myThread 线程 res = pthread_create(&amp;myThread, NULL, ThreadFun, NULL); if (res != 0) &#123; printf(&quot;线程创建失败&quot;); return 0; &#125; // 阻塞主线程，等待 myThread 线程执行结束 res = pthread_join(myThread, &amp;thread_result); if (res != 0) &#123; printf(&quot;1：等待线程失败&quot;); &#125; // 输出获取到的 myThread 线程的返回值 printf(&quot;%s &quot;, (char *)thread_result); // 尝试再次获取 myThread 线程的返回值 res = pthread_join(myThread, &amp;thread_result); if (res == ESRCH) &#123; printf(&quot;2：等待线程失败，线程不存在 &quot;); &#125; return 0;&#125; 123$ ./pthreadtest_msg2：等待线程失败，线程不存在 __detachstate 属性值用于指定线程终止执行的时机，该属性的值有两个，分别是： PTHREAD_CREATE_JOINABLE（默认值）：线程执行完函数后不会自行释放资源； PTHREAD_CREATE_DETACHED：线程执行完函数后，会自行终止并释放占用的资源。 还有 pthread_detach() 函数，可以直接将目标线程的 __detachstate 属性改为 PTHREAD_CREATE_DETACHED，语法格式如下： 1int pthread_detach(pthread_t thread); 关于 __detachstate 属性，&lt;pthread.h&gt; 头文件中提供了 2 个与它相关的函数，分别是： 12int pthread_attr_getdetachstate(const pthread_attr_t * attr,int * detachstate);int pthread_attr_setdetachstate(pthread_attr_t *sttr，int detachstate); 可以如下创建 detach 状态的线程： 12345pthread_t tid;pthread_attr_t attr;pthread_attr_init(&amp;attr);pthread_attr_setdetachstate(&amp;attr, PTHREAD_CREATE_DETACHED);pthread_create(&amp;tid, &amp;attr, THREAD_FUNCTION, arg); ⚠️ 值得注意的是：僵尸线程（zombie thread）是一种已经退出了的 joinable 线程，但是等待其他线程调用 pthread_join 来 join 它，以收集它的退出信息。如果没有其他线程调用 pthread_join 来 join 它的话，它占用的一些系统资源不会被释放，比如堆栈。如果 main() 函数需要长时间运行，并且创建大量 joinable 的线程，就有可能出现堆栈不足的 error。 ⚠️ 对于那些不需要 join 的线程，最好利用 pthread_detach，这样它运行结束后，资源就会及时得到释放。注意一个线程被使用 pthread_detach 之后，它就不能再被改成 joinable 的了。 ⚠️ 总而言之，创建的每一个线程都应该使用 pthread_join 或者 pthread_detach 其中一个，以防止僵尸线程的出现。 Linux 线程属性之线程栈大小｜pthread_attr_t线程的属性用 pthread_attr_t 类型的变量表示，使用此变量前，必须调用 pthread_attr_init() 函数进行初始化： 1int pthread_attr_init(pthread_attr_t * attr); pthread_attr_t 是一种结构体类型，内部包含多种线程属性（更多内容请看参考资料）： 123456789101112typedef struct&#123; int __detachstate; // 用于指定线程终止执行的时机 int __schedpolicy; // 指定系统调度该线程所用的算法 struct sched_param __schedparam; // 设置线程的优先级 int __inheritsched; // 默认遵循父线程的属性, 用于自定义线程的调度属性 int __scope; // 用于指定目标线程和哪些线程抢夺 CPU 资源 size_t __guardsize; // 用来设置警戒缓冲区的大小 int __stackaddr_set; void* __stackaddr; size_t __stacksize; // 每个线程都有属于自己的内存空间, 线程执行如果需要较大的栈内存，就需要自定义线程拥有的栈大小&#125; pthread_attr_t; POSIX 标准没有规定一个线程的堆栈大小，安全可移植的程序不会依赖于具体实现默认的堆栈限制，而是显式地调用 pthread_attr_setstacksize 来分配足够的堆栈空间。 关于堆栈大小的一个例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;pthread.h&gt;#define N_THREADS 5#define N 1000#define MEGEXTRA 1000000pthread_attr_t _attr;void* do_work(void* thread_id) &#123; double A[N][N]; int i, j; long tid; size_t my_stack_size; tid = (long)thread_id; pthread_attr_getstacksize(&amp;_attr, &amp;my_stack_size); printf(&quot;Thread %ld: stack size = %ld bytes &quot;, tid, my_stack_size); for (i = 0; i &lt; N; i++) &#123; for (j = 0; j &lt; N; j++) &#123; A[i][j] = ((i * j) / 3.452) + (N - i); &#125; &#125; pthread_exit(NULL);&#125;int main(int argc, char* argv[]) &#123; pthread_t threads[N_THREADS]; size_t stack_size; int rc; long t; pthread_attr_init(&amp;_attr); pthread_attr_getstacksize(&amp;_attr, &amp;stack_size); printf(&quot;Default stack size = %li &quot;, stack_size); // 线程栈大小: 8 MB stack_size = sizeof(double) * N * N + MEGEXTRA; printf(&quot;Amount of stack needed per thread = %li &quot;, stack_size); pthread_attr_setstacksize(&amp;_attr, stack_size); printf(&quot;Creating threads with stack size = %li bytes &quot;, stack_size); for (t = 0; t &lt; N_THREADS; t++) &#123; rc = pthread_create(&amp;threads[t], &amp;_attr, do_work, (void*)t); if (rc) &#123; printf(&quot;ERROR; return code from pthread_create() is %d &quot;, rc); exit(-1); &#125; &#125; printf(&quot;Creating %ld threads. &quot;, t); pthread_exit(NULL);&#125; 12345678910$ ./pthread Default stack size = 8388608Amount of stack needed per thread = 9000000Creating threads with stack size = 9000000 bytesCreating 5 threads.Thread 1: stack size = 9000000 bytes Thread 2: stack size = 9000000 bytes Thread 0: stack size = 9000000 bytes Thread 3: stack size = 9000000 bytes Thread 4: stack size = 9000000 bytes 其他相关函数： 1234// 返回 thread IDpthread_self();// 比较两个线程的 ID, 如果不同则返回 0, 否则返回一个非零值pthread_equal(thread_1, thread_2); 互斥锁 MutexMutex 常常被用来保护那些可以被多个线程访问的共享资源，比如可以防止多个线程同时更新同一个数据时出现混乱。 使用互斥锁的一般步骤是： 创建一个互斥锁，即声明一个 pthread_mutex_t 类型的数据，然后初始化，只有初始化之后才能使用； 多个线程尝试锁定这个互斥锁； 只有一个成功锁定互斥锁，成为互斥锁的拥有者，然后进行一些指令； 拥有者解锁互斥锁； 其他线程尝试锁定这个互斥锁，重复上面的过程； 最后互斥锁被显式地调用 pthread_mutex_destroy 来进行销毁。 有两种方式初始化一个互斥锁： 1️⃣ 第一种，利用已经定义的常量初始化，例如： 1pthread_mutex_t mymutex = PTHREAD_MUTEX_INITIALIZER; 2️⃣ 第二种方式是调用 pthread_mutex_init(mutex, attr) 进行初始化。 当多个线程同时去锁定同一个互斥锁时，失败的那些线程 如果是用 pthread_mutex_lock 函数，那么会被阻塞，直到这个互斥锁被解锁，它们再继续竞争； 如果是用 pthread_mutex_trylock 函数，那么失败者只会返回一个错误。 最后需要指出的是，保护共享数据是程序员的责任。程序员要负责所有可以访问该数据的线程都使用 mutex 这种机制，否则，不使用 mutex 的线程还是有可能对数据造成破坏。 相关函数： 1234567int pthread_mutex_init(pthread_mutex_t *__mutex, const pthread_mutexattr_t *__mutexattr);int pthread_mutex_destroy(pthread_mutex_t *__mutex);int pthread_mutex_lock(pthread_mutex_t *__mutex);int pthread_mutex_unlock(pthread_mutex_t *__mutex);int pthread_mutex_trylock(pthread_mutex_t *__mutex);int pthread_mutexattr_init(pthread_mutexattr_t *__attr);int pthread_mutexattr_destroy(pthread_mutexattr_t *__attr); Example下面是一个利用多线程进行向量点乘的程序，其中需要对 dotstr.sum 这个共同读写的数据进行保护。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;/*The following structure contains the necessary informationto allow the function &quot;dotprod&quot; to access its input data andplace its output into the structure. This structure isunchanged from the sequential version.*/typedef struct &#123; double *a; double *b; double sum; int veclen;&#125; DOTDATA;/* Define globally accessible variables and a mutex */#define NUMTHRDS 4#define VECLEN 100000DOTDATA dotstr;pthread_t callThd[NUMTHRDS];pthread_mutex_t mutexsum;/*The function dotprod is activated when the thread is created.As before, all input to this routine is obtained from a structureof type DOTDATA and all output from this function is written intothis structure. The benefit of this approach is apparent for themulti-threaded program: when a thread is created we pass a singleargument to the activated function - typically this argumentis a thread number. All the other information required by thefunction is accessed from the globally accessible structure.*/void *dotprod(void *arg) &#123; /* Define and use local variables for convenience */ int i, start, end, len; long offset; double mysum, *x, *y; offset = (long)arg; len = dotstr.veclen; start = offset * len; end = start + len; x = dotstr.a; y = dotstr.b; /* Perform the dot product and assign result to the appropriate variable in the structure. */ mysum = 0; for (i = start; i &lt; end; i++) &#123; mysum += (x[i] * y[i]); &#125; /* Lock a mutex prior to updating the value in the shared structure, and unlock it upon updating. */ pthread_mutex_lock(&amp;mutexsum); dotstr.sum += mysum; printf(&quot;Thread %ld did %d to %d: mysum=%f global sum=%f &quot;, offset, start, end, mysum, dotstr.sum); pthread_mutex_unlock(&amp;mutexsum); pthread_exit((void *)0);&#125;/*The main program creates threads which do all the work and then print out resultupon completion. Before creating the threads, The input data is created. Sinceall threads update a shared structure, we need a mutex for mutual exclusion.The main thread needs to wait for all threads to complete, it waits for each oneof the threads. We specify a thread attribute value that allow the main thread tojoin with the threads it creates. Note also that we free up handles when theyare no longer needed.*/int main(int argc, char *argv[]) &#123; long i; double *a, *b; void *status; pthread_attr_t attr; /* Assign storage and initialize values */ a = (double *)malloc(NUMTHRDS * VECLEN * sizeof(double)); b = (double *)malloc(NUMTHRDS * VECLEN * sizeof(double)); for (i = 0; i &lt; VECLEN * NUMTHRDS; i++) &#123; a[i] = 1; b[i] = a[i]; &#125; dotstr.veclen = VECLEN; dotstr.a = a; dotstr.b = b; dotstr.sum = 0; pthread_mutex_init(&amp;mutexsum, NULL); /* Create threads to perform the dotproduct */ pthread_attr_init(&amp;attr); pthread_attr_setdetachstate(&amp;attr, PTHREAD_CREATE_JOINABLE); for (i = 0; i &lt; NUMTHRDS; i++) &#123; /* Each thread works on a different set of data. * The offset is specified by &#x27;i&#x27;. The size of * the data for each thread is indicated by VECLEN. */ pthread_create(&amp;callThd[i], &amp;attr, dotprod, (void *)i); &#125; pthread_attr_destroy(&amp;attr); /* Wait on the other threads */ for (i = 0; i &lt; NUMTHRDS; i++) &#123; pthread_join(callThd[i], &amp;status); &#125; /* After joining, print out the results and cleanup */ printf(&quot;Sum = %f &quot;, dotstr.sum); free(a); free(b); pthread_mutex_destroy(&amp;mutexsum); pthread_exit(NULL);&#125; 123456$ ./pthread Thread 0 did 0 to 100000: mysum=100000.000000 global sum=100000.000000Thread 2 did 200000 to 300000: mysum=100000.000000 global sum=200000.000000Thread 1 did 100000 to 200000: mysum=100000.000000 global sum=300000.000000Thread 3 did 300000 to 400000: mysum=100000.000000 global sum=400000.000000Sum = 400000.000000 条件变量 Condition Variable互斥锁只有两种状态，这限制了它的用途。条件变量允许线程在阻塞的时候等待另一个线程发送的信号，当收到信号后，阻塞的线程就被唤醒并试图锁定与之相关的互斥锁。条件变量要和互斥锁结合使用。 条件变量的声明和初始化通过声明 pthread_cond_t 类型的数据，并且必须先初始化才能使用。 初始化的方法也有两种： 1️⃣ 第一种，利用内部定义的常量，例如： 1pthread_cond_t myconvar = PTHREAD_COND_INITIALIZER; 2️⃣ 第二种，利用函数 pthread_cond_init(cond, attr)，其中 attr 由 pthread_condattr_init() 和 pthread_condattr_destroy() 创建和销毁；可以用 pthread_cond_destroy() 销毁一个条件变量。 相关函数： 123int pthread_cond_wait(pthread_cond_t *__restrict__ __cond, pthread_mutex_t *__restrict__ __mutex);int pthread_cond_signal(pthread_cond_t *__cond);int pthread_cond_broadcast(pthread_cond_t *__cond); pthread_cond_wait() 会阻塞调用它的线程，直到收到某一个信号：这个函数需要在 mutex 已经被锁之后进行调用，并且当线程被阻塞时，会自动解锁 mutex。信号收到后，线程被唤醒，这时 mutex 又会被这个线程锁定。 pthread_cond_signal() 函数结束时，必须解锁 mutex，以供 pthread_cond_wait() 锁定mutex。 当不止一个线程在等待信号时，要用 pthread_cond_broadcast() 代替 pthread_cond_signal() 来告诉所有被该条件变量阻塞的线程结束阻塞状态。 Example下面是一个例子，三个线程共同访问 count 变量，thread 2 和 thread 3 竞争地对其进行加 1 的操作，thread 1 等 count 达到 12 的时候，一次性加 125 。 然后 thread 2 和 thread 3 再去竞争 count 的控制权，直到完成自己的对 count 加 10 次的任务。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define NUM_THREADS 3#define TCOUNT 10#define COUNT_LIMIT 12int count = 0;pthread_mutex_t count_mutex;pthread_cond_t count_threshold_cv;void *inc_count(void *t) &#123; int i; long my_id = (long)t; for (i = 0; i &lt; TCOUNT; i++) &#123; pthread_mutex_lock(&amp;count_mutex); count++; /* Check the value of count and signal waiting thread when condition is reached. Note that this occurs while mutex is locked. */ if (count == COUNT_LIMIT) &#123; printf(&quot;inc_count(): thread %ld, count = %d Threshold reached. &quot;, my_id, count); pthread_cond_signal(&amp;count_threshold_cv); printf(&quot;Just sent signal. &quot;); &#125; printf(&quot;inc_count(): thread %ld, count = %d, unlocking mutex &quot;, my_id, count); pthread_mutex_unlock(&amp;count_mutex); /* Do some work so threads can alternate on mutex lock */ sleep(1); &#125; pthread_exit(NULL);&#125;void *watch_count(void *t) &#123; long my_id = (long)t; printf(&quot;Starting watch_count(): thread %ld &quot;, my_id); /* Lock mutex and wait for signal. Note that the pthread_cond_wait routine will automatically and atomically unlock mutex while it waits. Also, note that if COUNT_LIMIT is reached before this routine is run by the waiting thread, the loop will be skipped to prevent pthread_cond_wait from never returning. */ pthread_mutex_lock(&amp;count_mutex); while (count &lt; COUNT_LIMIT) &#123; printf(&quot;watch_count(): thread %ld Count= %d. Going into wait... &quot;, my_id, count); pthread_cond_wait(&amp;count_threshold_cv, &amp;count_mutex); printf(&quot;watch_count(): thread %ld Condition signal received. Count= %d &quot;, my_id, count); printf(&quot;watch_count(): thread %ld Updating the value of count... &quot;, my_id, count); count += 125; printf(&quot;watch_count(): thread %ld count now = %d. &quot;, my_id, count); &#125; printf(&quot;watch_count(): thread %ld Unlocking mutex. &quot;, my_id); pthread_mutex_unlock(&amp;count_mutex); pthread_exit(NULL);&#125;int main(int argc, char *argv[]) &#123; int i, rc; long t1 = 1, t2 = 2, t3 = 3; pthread_t threads[3]; pthread_attr_t attr; /* Initialize mutex and condition variable objects */ pthread_mutex_init(&amp;count_mutex, NULL); pthread_cond_init(&amp;count_threshold_cv, NULL); /* For portability, explicitly create threads in a joinable state */ pthread_attr_init(&amp;attr); pthread_attr_setdetachstate(&amp;attr, PTHREAD_CREATE_JOINABLE); pthread_create(&amp;threads[0], &amp;attr, watch_count, (void *)t1); pthread_create(&amp;threads[1], &amp;attr, inc_count, (void *)t2); pthread_create(&amp;threads[2], &amp;attr, inc_count, (void *)t3); /* Wait for all threads to complete */ for (i = 0; i &lt; NUM_THREADS; i++) &#123; pthread_join(threads[i], NULL); &#125; printf(&quot;Main(): Waited and joined with %d threads. Final value of count = %d. Done. &quot;, NUM_THREADS, count); /* Clean up and exit */ pthread_attr_destroy(&amp;attr); pthread_mutex_destroy(&amp;count_mutex); pthread_cond_destroy(&amp;count_threshold_cv); pthread_exit(NULL);&#125; 1234567891011121314151617181920212223242526272829$ ./pthread Starting watch_count(): thread 1inc_count(): thread 2, count = 1, unlocking mutexinc_count(): thread 3, count = 2, unlocking mutexwatch_count(): thread 1 Count= 2. Going into wait...inc_count(): thread 2, count = 3, unlocking mutexinc_count(): thread 3, count = 4, unlocking mutexinc_count(): thread 2, count = 5, unlocking mutexinc_count(): thread 3, count = 6, unlocking mutexinc_count(): thread 2, count = 7, unlocking mutexinc_count(): thread 3, count = 8, unlocking mutexinc_count(): thread 2, count = 9, unlocking mutexinc_count(): thread 3, count = 10, unlocking mutexinc_count(): thread 2, count = 11, unlocking mutexinc_count(): thread 3, count = 12 Threshold reached. Just sent signal.inc_count(): thread 3, count = 12, unlocking mutexwatch_count(): thread 1 Condition signal received. Count= 12watch_count(): thread 1 Updating the value of count...watch_count(): thread 1 count now = 137.watch_count(): thread 1 Unlocking mutex.inc_count(): thread 2, count = 138, unlocking mutexinc_count(): thread 3, count = 139, unlocking mutexinc_count(): thread 2, count = 140, unlocking mutexinc_count(): thread 3, count = 141, unlocking mutexinc_count(): thread 2, count = 142, unlocking mutexinc_count(): thread 3, count = 143, unlocking mutexinc_count(): thread 3, count = 144, unlocking mutexinc_count(): thread 2, count = 145, unlocking mutexMain(): Waited and joined with 3 threads. Final value of count = 145. Done. std::thread在 C++11 中引入的线程库 std::thread 实际是基于 pthread 实现的，后续主要介绍： 如何使用 std::thread 创建线程 深入剖析 std::thread 的设计原理 使用 std::thread当你创建了一个（非空的）线程对象时，对应线程就会执行，不需要显式的调用 start 或者 run（pthread 也是）。如果之前你没有用过 pthread，也许不会理解何为“方便得出人意料”： pthread_create 只接受 void *f(void *)，所以如果你想调用现成的函数，还需要包装一下； 而且 pthread_create 其函数接受参数（第四个参数）类型为 void *arg，如果要传多个参数，还需要定义结构体，接着将结构体转为 void * 类型再传递进去； 这还没完，传递进去的参数还需要在其内部函数中，重新转型成（可能是一次性的）某个结构体，最后才能取出其中的变量； 创建线程后，调用 Thread.join 就会阻塞到线程执行结束为止（相当于pthread_join）。你也可以选择 detach 该线程，这时候线程会独立执行，不会随调用者终止而结束。 在如下的 demo 中，主线程中使用 std::thread 创建 3 个子线程，线程入口函数是 do_some_work，在主线程运行结束前等待子线程的结束。 注：在构造线程对象 std::thread&#123;do_some_work, i&#125; 的时候，还是建议使用 &#123;&#125; 而不是 ()，以防止编译器产生错误的决议，具体原因可以参考文章（深入了解 C++：别再徘徊于 {} 与 () 之间了） 12345678910111213141516171819202122232425262728// #include &lt;bits/stdc++.h&gt;#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;vector&gt;const int N_THREADS = 3;void do_some_work(int num) &#123; std::cout &lt;&lt; &quot;thread: &quot; &lt;&lt; num &lt;&lt; std::endl; &#125;int main(int argc, char const* argv[]) &#123; std::vector&lt;std::thread&gt; thread_list; thread_list.reserve(N_THREADS); // start thread for (int i = 0; i &lt; N_THREADS; i++) &#123; // 🆗 thread_list.push_back(std::thread&#123;do_some_work, i&#125;); // 🆗 thread_list.push_back(std::thread(do_some_work, i)); thread_list.emplace_back(do_some_work, i); &#125; std::cout &lt;&lt; &quot;work in main thread&quot; &lt;&lt; std::endl; // main() thread will waiting other threads for (int i = 0; i &lt; N_THREADS; i++) &#123; thread_list[i].join(); &#125; std::cout &lt;&lt; &quot;main thread end&quot; &lt;&lt; std::endl; return 0;&#125; 三个子线程共享输出缓冲区 std::cout，此时没有采取任何机制保护线程间共享数据，因此上面 demo 的输出可能不符合你的预期，即很可能不是按照如下格式输出： 1234$ ./threadthread: 0thread: 1thread: 2 实际输出结果（非常混乱）： 123456$ ./threadthread: work in main threadthread: 02thread: 1main thread end 从输出可以看出： 先创建的线程，未必就先运行； 而且几个线程之间是互相抢 CPU 资源的 线程间数据共享问题及其应对措施，留到后文讲解，下面讲解 std::thread 的设计。 深入剖析 std::thread在 g++ 中，thread 是基于 pthread 实现的。本次主要从以下三个方面分 std::thread： std::thread 对象不可复制，只具有移动属性 每个线程具有唯一的标志，即线程 id 创建子线程（即构造 std::thread） 1. 移动属性有很多书籍说，std::thread 对象的所有权只能传递不能复制。实际上，就 std::thread 对象，只具有移动属性，不具有复制属性。std::thread 的构造函数如下： 1234567891011121314151617181920212223242526272829class thread &#123; private: id _M_id; public: thread() noexcept = default; template &lt;typename _Callable, typename... _Args, typename = _Require&lt;__not_same&lt;_Callable&gt;&gt;&gt; explicit thread(_Callable&amp;&amp; __f, _Args&amp;&amp;... __args) &#123; //... &#125; ~thread() &#123; if (joinable()) std::terminate(); &#125; // 禁止复制（复制构造、复制赋值） thread(const thread&amp;) = delete; thread&amp; operator=(const thread&amp;) = delete; // std::thread 只具有移动属性（移动构造、移动赋值） thread(thread&amp;&amp; __t) noexcept &#123; swap(__t); &#125; thread&amp; operator=(thread&amp;&amp; __t) noexcept &#123; if (joinable()) std::terminate(); swap(__t); return *this; &#125; //...&#125; 可以发现，std::thread 禁止了复制构造函数、复制赋值表达式，只留下了移动构造函数、移动赋值，使得 std::thread 对象只能移动，不能复制。这就是之前 demo 中使用 emplace_back 函数添加 std::thread 对象的原因，防止触发复制构造函数。所以向 thread_list 中添加 std::thread 对象有以下几种方式： 当 push_back 接受的是右值，底层调用的还是 emplace_back 函数，因此 4 和 5 是等价的。 12345678910thread_list.push_back(std::thread&#123;do_some_work, i&#125;); // 1.okthread_list.emplace_back(do_some_work, i); // 2.okthread_list.emplace_back(std::thread&#123;do_some_work, i&#125;); // 2.okstd::thread trd&#123;do_some_work, i&#125;;thread_list.push_back(trd); // 3.error❌thread_list.push_back(std::move(trd)); // 4.okthread_list.emplace_back(std::move(trd)); // 5.ok 第三种办法报错： 12345678910/usr/include/c++/9/ext/new_allocator.h: In instantiation of ‘void __gnu_cxx::new_allocator&lt;_Tp&gt;::construct(_Up*, _Args&amp;&amp; ...) [with _Up = std::thread; _Args = &#123;std::thread&amp;&#125;; _Tp = std::thread]’:/usr/include/c++/9/bits/alloc_traits.h:483:4: required from ‘static void std::allocator_traits&lt;std::allocator&lt;_CharT&gt; &gt;::construct(std::allocator_traits&lt;std::allocator&lt;_CharT&gt; &gt;::allocator_type&amp;, _Up*, _Args&amp;&amp; ...) [with _Up = std::thread; _Args = &#123;std::thread&amp;&#125;; _Tp = std::thread; std::allocator_traits&lt;std::allocator&lt;_CharT&gt; &gt;::allocator_type = std::allocator&lt;std::thread&gt;]’/usr/include/c++/9/bits/vector.tcc:115:30: required from ‘void std::vector&lt;_Tp, _Alloc&gt;::emplace_back(_Args&amp;&amp; ...) [with _Args = &#123;std::thread&amp;&#125;; _Tp = std::thread; _Alloc = std::allocator&lt;std::thread&gt;]’_thread.cpp:22:37: required from here/usr/include/c++/9/ext/new_allocator.h:146:4: error: use of deleted function ‘std::thread::thread(const std::thread&amp;)’ 146 | &#123; ::new((void *)__p) _Up(std::forward&lt;_Args&gt;(__args)...); &#125; | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~In file included from _thread.cpp:3:/usr/include/c++/9/thread:142:5: note: declared here 142 | thread(const thread&amp;) = delete; 2. std::thread::id可以发现，在 std::thread 对象中，只有一个成员变量 _M_id。 这个类 id 全称是 std::thread::id，实现如下： 123456789101112131415161718192021class id &#123; // // _M_thread 即 pthread_t 对象，线程的唯一辨识标志 native_handle_type _M_thread; public: // _M_thread 默认值是 0 id() noexcept : _M_thread() &#123;&#125; explicit id(native_handle_type __id) : _M_thread(__id) &#123;&#125; private: friend class thread; friend class hash&lt;thread::id&gt;; // 为 std::thread::id 对象重载了 == 运算 friend bool operator==(thread::id __x, thread::id __y) noexcept; friend bool operator&lt;(thread::id __x, thread::id __y) noexcept; // 为 std::thread::id 对象重载了 &lt;&lt; 操作 template &lt;class _CharT, class _Traits&gt; friend basic_ostream&lt;_CharT, _Traits&gt;&amp; operator&lt;&lt;(basic_ostream&lt;_CharT, _Traits&gt;&amp; __out, thread::id __id);&#125;; 因此，这个 std::thread::id 实际上就是封装了 pthread_t 对象，用作每个线程的标志。 在构造 std::thread 对象的时候，如果没有设置线程入口函数，则线程 _M_id._M_thread 的值是 0 比如下面的 demo，trd 没有设置线程入口函数，trd 调用默认构造函数时，trd 的 _M_id._M_thread 会被初始化为 0 12345int main(int argc, char const* argv[]) &#123; std::thread trd; std::cout &lt;&lt; trd.get_id() &lt;&lt; std::endl; return 0;&#125; 但是，打印线程标志 trd.get_id()，输出的是却不是0。这仅仅是 std::thread::id 在重载 &lt;&lt; 操作符时的设定，用于提示调用者线程没有启动。 12$ g++ thread_.cc -o thread_ &amp;&amp; ./thread_thread::id of a non-executing thread 可以到 std::thread::id 重载的 &lt;&lt; 操作符的函数中一探究竟： 1234567891011121314template&lt;class _CharT, class _Traits&gt;inline basic_ostream&lt;_CharT, _Traits&gt;&amp; operator&lt;&lt;(basic_ostream&lt;_CharT, _Traits&gt;&amp; __out, thread::id __id) &#123; // 线程未启动 if (__id == thread::id()) return __out &lt;&lt; &quot;thread::id of a non-executing thread&quot;; // 线程成功启动 else return __out &lt;&lt; __id._M_thread;&#125;// id的相等判断 inline bool operator==(thread::id __x, thread::id __y) noexcept &#123; return __x._M_thread == __y._M_thread;&#125; 因此判断一个线程是否启动，可如下检测： 123bool thread_is_active(const std::thread::id&amp; thread_id) &#123; return thread_id != std::thread::id();&#125; 设置了线程入口函数，_M_id._M_thread 才是线程的tid值，由 pthread_create(&amp;tid, NULL, ...) 函数设置： 1234567int main(int argc, char const* argv[]) &#123; std::thread trd&#123;[] &#123; std::cout &lt;&lt; &quot;work in sub-thread &quot;; &#125;&#125;; std::cout &lt;&lt; trd.get_id() &lt;&lt; std::endl; trd.join(); return 0;&#125; 123$ ./thread 140203273147968work in sub-thread by the way 在创建 std::thread 对象 trd 时： 如果设置了线程入口函数，那么就必须使用 trd.join() 或者 trd.detach() 来表达子线程与主线程的运行关系，否则在 std::thread 对象析构时，整个程序会被 std::terminate() 中止。 如果没有设置线程入口函数，trd.joinable() 返回值就是 false，因此不会触发 std::terminate()。 1234~thread() &#123; if (joinable()) std::terminate();&#125; 3. 创建子线程当构造 std::thread 对象时，设置了线程入口函数，会在相匹配的构造函数里调用 pthread_create 函数创建子线程。先看整体实现： 1234567891011121314151617// std::thread 构造函数template&lt;typename _Callable, typename... _Args, typename = _Require&lt;__not_same&lt;_Callable&gt;&gt;&gt;explicit thread(_Callable&amp;&amp; __f, _Args&amp;&amp;... __args)&#123; static_assert( __is_invocable&lt;typename decay&lt;_Callable&gt;::type, typename decay&lt;_Args&gt;::type...&gt;::value, &quot;std::thread arguments must be invocable after conversion to rvalues&quot;); // Create a reference to pthread_create, not just the gthr weak symbol. auto __depend = reinterpret_cast&lt;void(*)()&gt;(&amp;pthread_create); // 启动线程 _M_start_thread(_S_make_state(__make_invoker(std::forward&lt;_Callable&gt;(__f), std::forward&lt;_Args&gt;(__args)...)), __depend);&#125; 再细看构造函数执行流程： 在编译期判断构造 std::thread 对象时设置的线程入口函数 __f 及其参数 __args 能否调用。 比如，下面的 demo 中，线程入口函数 thread_func 有个 int 类型的参数 arg，如果传入的参数 __args 无法隐式转换为 int 类型，或者没有设置 __args，都会触发 std::thread 构造函数中的静态断言 static_assert。 报错：error: static assertion failed: std::thread arguments must be invocable after conversion to rvalues 123456789void thread_func(int arg) &#123; &#125;int main(int argc, char const *argv[]) &#123; std::thread trd_1&#123;thread_func, &quot;str&quot;&#125;; // arg 类型不对 std::thread trd_2&#123;thread_func&#125;; // 缺少 arg // ... return 0;&#125; 将线程入口函数 __f 及其参数 __args 进一步封装起来。 这里是使用 __make_invoker 完成的： 1__make_invoker(std::forward&lt;_Callable&gt;(__f), std::forward&lt;_Args&gt;(__args)...); __make_invoker 的作用是返回一个 _Invoker 对象，_Invoker 是个仿函数，通过 _Invoker() 就可以以指定的参数 __args 直接执行线程入口函数 __f。类似于 std::bind： 12345678910void print_num(int i) &#123; std::cout &lt;&lt; i &lt;&lt; &#x27; &#x27;;&#125;int main(int argc, const char* argv[]) &#123; // wrapper auto invoker = std::bind(print_num, -9); // 直接调用 invoker() 就可以以指定参数 -9 调用 print_num invoker();&#125; 启动子线程 在调用 _M_start_thread 函数启动子线程前，执行过程： 创建 _State_ptr 的对象，来封装 _Invoker 对象，再传递给 _M_start_thread 函数。 传递 _M_start_thread 函数的过程，由 _S_make_state 函数完成，_S_make_state 最终返回 _State_ptr 对象。 12345678910111213141516171819202122232425// 基类struct _State &#123; virtual ~_State(); // 虚析构函数 virtual void _M_run() = 0; // 线程运行函数&#125;;using _State_ptr = unique_ptr&lt;_State&gt;; // 父类指针// 子类template&lt;typename _Callable&gt;struct _State_impl : public _State &#123; _Callable _M_func;\t// 线程入口函数 _State_impl(_Callable&amp;&amp; __f) : _M_func(std::forward&lt;_Callable&gt;(__f)) &#123; &#125; void _M_run() &#123; _M_func(); &#125; // 执行线程入口函数&#125;;// 传入_Invoker对象，返回 _State_ptr 对象template&lt;typename _Callable&gt;static _State_ptr _S_make_state(_Callable&amp;&amp; __f) &#123; using _Impl = _State_impl&lt;_Callable&gt;; // 使用子类对象来初始化父类 return _State_ptr&#123;new _Impl&#123;std::forward&lt;_Callable&gt;(__f)&#125;&#125;;&#125; _S_make_state 函数，将线程入口函数 __f 及其参数 __args 封装到 _State_ptr 对象 _State_ptr_obj 中， 这样最后可以通过 _State_ptr_obj-&gt;_M_run() 来调用 __f。 下面到了 _M_start_thread 函数： 1234567891011121314151617181920212223void thread::_M_start_thread(_State_ptr state, void (*)())&#123; const int err = __gthread_create(&amp;_M_id._M_thread, &amp;execute_native_thread_routine, // 线程执行函数 state.get()); if (err) __throw_system_error(err); state.release();&#125;// 内部调用的是 pthread_create 函数static inline int __gthread_create(pthread_t *__threadid, void *(*__func) (void*), void *__args)&#123; return pthread_create(__threadid, NULL, __func, __args);&#125;// 内部执行线程入口函数static void* execute_native_thread_routine(void* __p)&#123; thread::_State_ptr __t&#123;static_cast&lt;thread::_State*&gt;(__p)&#125;; __t-&gt;_M_run(); // 运行线程入口函数 return nullptr;&#125; 因此，在执行完 _M_start_thread 函数后，才具有 _M_start_thread != 0。 Mutex有时候需要限制多个线程对同一资源的访问，这时候一般会使用 Mutex。Mutex 就是一把锁，只有某些线程可以同时占用它（通过 lock 操作）。当线程不用的时候，就得通过 unlock 操作来释放它。 对于 Mutex，std::thread 和 pthread 差不多，无非是 pthread_mutex_lock(&amp;mutex) 变成了 mutex.lock() 等等。 不过在 std::thread 中，mutex 往往和 lock 系列模板一起使用。这是因为 lock 系列模板包装了 mutex 类，提供了 RAII 风格的加锁解锁。 1234567&#123; // 加锁 std::lock_guard&lt;std::mutex&gt; guard(mutex); ... // 自动解锁&#125; mutex 有四种： std::mutex：独占的互斥量，不能递归使用，不带超时功能 std::recursive_mutex：递归互斥量，可重入，不带超时功能 std::timed_mutex：带超时的互斥量，不能递归 std::recursive_timed_mutex：带超时的互斥量，可以递归使用 加解锁方式有三种： std::lock_guard：可以RAII方式加锁 std::unique_lock：比 lock_guard 多了个手动加解锁的功能 std::scoped_lock：防止多个锁顺序问题导致的死锁问题而出世的一把锁 Condition Variable有时候线程之间需要某种同步：当某些条件不满足时，停止执行直到该条件被满足。 这时候需要引入 condition variable —— 状态变量。 在经典的「生产者消费者模式」下，生产者和消费者就是通过 condition variable 来实现同步的。 当有限的生产力无法满足日益增长的消费需求时，消费者进程就会去睡一觉，直到它想要的东西生产出来才醒来。 12345678std::condition_variable condvar;consumer: std::unique_lock&lt;std::mutex&gt; ulock(mutex); condvar.wait(ulock, []&#123; return msgQueue.size() &gt; 0;&#125;);producer: condvar.notify_all(); condition_variable 需要和 unique_lock 搭配使用 在一个线程调用 wait 之前，它必须持有 unique_lock 锁 当 wait 被调用时，该锁会被释放，线程会陷入沉睡，等待着生产者发过来的唤醒信号 当生产者调用同一个 condition_variable 的 notify_all 方法时，所有沉睡在该变量前的消费者会被唤醒，并尝试重新获取之前释放的 unique_lock，继续执行下去（注意这里发生了锁争用，只有一个消费者能够获得锁，其他消费者得等待该消费者释放锁） 如果只想叫醒一个线程，可以用 notify_one pthread 中也提供了对应的方法，分别是 pthread_cond_wait, pthread_cond_broadcast, pthread_cond_signal wait 可以接受两个参数，此时第二个参数用于判断当前是否要沉睡。 1[]&#123; return msgQueue.size() &gt; 0;&#125;); 相当于 123while (msgQueue.size() &lt;= 0) &#123; condvar.wait()&#125; 为了防止线程无限等待（可能一直没有唤醒），通过 wait_until 和 wait_for，你可以设定线程的等待时间。设置 notify_all_at_thread_exit 也许能帮得上忙。 在 pthread 中，对应的调用是 pthread_cond_timedwait。 MoreC++11 的线程库还提供了其他多线程编程的概念，比如 future 和 atomic。 futurefuture 位于头文件 &lt;future&gt; 下，包装了未来某个计算结果的期诺。 当你对所获得的 future 调用 get 时，程序会一直阻塞直到 future 的值被计算出来（如果 future 的值已经计算出来了，get 调用会立刻获得返回值），而这一切都是在后台执行的。 1234567891011121314151617181920212223#include &lt;chrono&gt;#include &lt;iostream&gt;#include &lt;future&gt;using namespace std;int main()&#123; future&lt;int&gt; f1 = async(launch::async, []()&#123; std::chrono::milliseconds dura(2000); std::this_thread::sleep_for(dura); return 0; &#125;); future&lt;int&gt; f2 = async(launch::async, []()&#123; std::chrono::milliseconds dura(2000); std::this_thread::sleep_for(dura); return 1; &#125;); cout &lt;&lt; &quot;Results are: &quot; &lt;&lt; f1.get() &lt;&lt; &quot; &quot; &lt;&lt; f2.get() &lt;&lt; &quot; &quot;; return 0;&#125; 12345$ g++ -std=c++11 -pthread ./future.cpp$ time ./a.out Results are: 0 1./a.out 0.00s user 0.00s system 0% cpu 2.012 total # 是两秒左右而不是四秒 除了 async， packaged_task 和 promise 也都返回一个 future。 atomicatomic 位于头文件 &lt;atomic&gt; 下，实现了类似于 java.util.concurrent.atomic 的功能。它提供了一组轻量级的、作用在单个变量上的原子操作，是 volatile 的替代品，有些时候你也可以用它来替换掉 lock（假如整个 race condition 中只有单个变量） 下面这个例子解释了什么叫做原子操作： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;atomic&gt;#include &lt;iostream&gt;#include &lt;thread&gt;using namespace std;const int NUM = 100;int target = 0;atomic&lt;int&gt; atomicTarget(0);template&lt;typename T&gt;void atomicPlusOne(int trys)&#123; while (trys &gt; 0) &#123; atomicTarget.fetch_add(1); --trys; &#125;&#125;void plusOne(int trys)&#123; while (trys &gt; 0) &#123; ++target; --trys; &#125;&#125;int main()&#123; thread threads[NUM]; thread atomicThreads[NUM]; for (int i = 0; i &lt; NUM; i++) &#123; atomicThreads[i] = thread(atomicPlusOne&lt;int&gt;, 10000); &#125; for (int i = 0; i &lt; NUM; i++) &#123; threads[i] = thread(plusOne, 10000); &#125; for (int i = 0; i &lt; NUM; i++) &#123; atomicThreads[i].join(); &#125; for (int i = 0; i &lt; NUM; i++) &#123; threads[i].join(); &#125; cout &lt;&lt; &quot;Atomic target&#x27;s value : &quot; &lt;&lt; atomicTarget &lt;&lt; &quot; &quot;; cout &lt;&lt; &quot;Non-atomic target&#x27;s value : &quot; &lt;&lt; target &lt;&lt; &quot; &quot;; return 0;&#125; 1234# atomicTarget 的值总是固定的，而 target 的值每次运行时各不相同$ g++ -std=c++11 -pthread ./atom.cppAtomic target&#x27;s value : 1000000Non-atomic target&#x27;s value : 842480 Pros &amp; Cons最后总结下 std::thread 对比于 pthread 的优缺点： 优点： 简单，易用 跨平台，pthread 只能用在 POSIX 系统上（其他系统有其独立的 thread 实现） 提供了更多高级功能，比如 future 更加 C++（与匿名函数，std::bind，RAII 等 C++ 特性更好的集成） 缺点： 没有 RWlock：有一个类似的 shared_mutex，不过它属于 C++14，你的编译器很有可能不支持 操作线程和 Mutex 等的 API 较少：毕竟为了跨平台，只能选取各原生实现的子集。如果你需要设置某些属性，需要通过 API 调用返回原生平台上的对应对象，再对返回的对象进行操作。 生产者消费者（pthread &amp; thread 版本）附上我自己写的，分别用 std::thread 和 pthread 实现的多生产者多消费者程序。 注意行数上的差距。 pthread 版本1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#include &lt;pthread.h&gt;#include &lt;queue&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;// 注意 pthread_* 函数返回的异常值，为了简单（偷懒），我没有去处理它们pthread_mutex_t mutex;pthread_cond_t condvar;std::queue&lt;int&gt; msgQueue;struct Produce_range &#123; int start; int end;&#125;;void *producer(void *args)&#123; int start = static_cast&lt;Produce_range *&gt;(args)-&gt;start; int end = static_cast&lt;Produce_range *&gt;(args)-&gt;end; for (int x = start; x &lt; end; x++) &#123; usleep(200 * 1000); pthread_mutex_lock(&amp;mutex); msgQueue.push(x); pthread_mutex_unlock(&amp;mutex); pthread_cond_signal(&amp;condvar); printf(&quot;Produce message %d &quot;, x); &#125; pthread_exit((void *)0); return NULL;&#125;void *consumer(void *args)&#123; int demand = *static_cast&lt;int *&gt;(args); while (true) &#123; pthread_mutex_lock(&amp;mutex); if (msgQueue.size() &lt;= 0) &#123; pthread_cond_wait(&amp;condvar, &amp;mutex); &#125; if (msgQueue.size() &gt; 0) &#123; printf(&quot;Consume message %d &quot;, msgQueue.front()); msgQueue.pop(); --demand; &#125; pthread_mutex_unlock(&amp;mutex); if (!demand) break; &#125; pthread_exit((void *)0); return NULL;&#125;int main()&#123; pthread_attr_t attr; pthread_attr_init(&amp;attr); pthread_mutex_init(&amp;mutex, NULL); pthread_cond_init(&amp;condvar, NULL); pthread_t producer1, producer2, producer3, consumer1, consumer2; Produce_range range1 = &#123;0, 10&#125;; pthread_create(&amp;producer1, &amp;attr, producer, static_cast&lt;void *&gt;(&amp;range1)); Produce_range range2 = &#123;range1.end, range1.end + 10&#125;; pthread_create(&amp;producer2, &amp;attr, producer, static_cast&lt;void *&gt;(&amp;range2)); Produce_range range3 = &#123;range2.end, range2.end + 10&#125;; pthread_create(&amp;producer3, &amp;attr, producer, static_cast&lt;void *&gt;(&amp;range3)); int consume_demand1 = 20; int consume_demand2 = 10; pthread_create(&amp;consumer1, &amp;attr, consumer, static_cast&lt;void *&gt;(&amp;consume_demand1)); pthread_create(&amp;consumer2, &amp;attr, consumer, static_cast&lt;void *&gt;(&amp;consume_demand2)); pthread_join(producer1, NULL); pthread_join(producer2, NULL); pthread_join(producer3, NULL); pthread_join(consumer1, NULL); pthread_join(consumer2, NULL);&#125; std::thread 版本1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;chrono&gt;#include &lt;condition_variable&gt;#include &lt;future&gt;#include &lt;mutex&gt;#include &lt;queue&gt;// 注意某些调用可能会抛出std::system_error， 为了简单（偷懒），我没有去捕获std::mutex mutex;std::condition_variable condvar;std::queue&lt;int&gt; msgQueue;void producer(int start, int end)&#123; for (int x = start; x &lt; end; x++) &#123; std::this_thread::sleep_for(std::chrono::milliseconds(200)); &#123; std::lock_guard&lt;std::mutex&gt; guard(mutex); msgQueue.push(x); &#125; printf(&quot;Produce message %d &quot;, x); condvar.notify_all(); &#125;&#125;void consumer(int demand)&#123; while (true) &#123; std::unique_lock&lt;std::mutex&gt; ulock(mutex); condvar.wait(ulock, []&#123; return msgQueue.size() &gt; 0;&#125;); // wait的第二个参数使得显式的double check不再必要 printf(&quot;Consume message %d &quot;, msgQueue.front()); msgQueue.pop(); --demand; if (!demand) break; &#125;&#125;int main()&#123; std::thread producer1(producer, 0, 10); std::thread producer2(producer, 10, 20); std::thread producer3(producer, 20, 30); std::thread consumer1(consumer, 20); std::thread consumer2(consumer, 10); producer1.join(); producer2.join(); producer3.join(); consumer1.join(); consumer2.join();&#125;","tags":["C++","pthread","thread","mutex","future","atomic","生产者消费者","多线程","并发"],"categories":["C++"]},{"title":"推荐系统架构","path":"/post/AI-Infra/recommendation-system-architecture/","content":"背景需求互联网的一个主要应用就是信息匹配，只有与人发生关系的信息才具有价值，因此人和信息的匹配是互联网应用的核心问题。 信息匹配的方式有多种: 门户&#x2F;订阅&#x2F;搜索&#x2F;推荐。 早期互联网应用以门户展示信息为主，类似专柜陈列的商品，由网站维护人员更新信息，所有人看到的信息都一样。代表就是搜狐&#x2F;网易&#x2F;新浪，互联网的技术发展主要推动因素就是计算广告的技术发展，为了提供更多的广告位，让网站能够展示更多的信息，因此由了订阅模式主流是 SRR &#x2F; 社区等属性，基于社交关注关系，订阅感兴趣的内容主要代表由新浪微博，天涯社区等等，但有很多信息并能通过社交关系获得因此衍生出了搜索需求，用户通过一些 query 来查询到自己想要的信息，这还是信息找人的时代，主要代表就是谷歌&#x2F;百度&#x2F;搜狗。 再后来，随着互联网上的信息越来越多，人们陷入了选择困难，人们在阅读信息之前，可能对信息一无所知，只有看到时才知道是否喜欢，人们越来越懒，这就催生出了推荐系统：基于用户广泛的历史行为，预测用户可能感兴趣的信息主动推送，从而达到用户与信息的匹配，由于用户在推荐之前并不知道内容是什么，这扩大了信息的候选范围，进一步提高了潜在的广告位数量，这成为互联网应用的核心竞争力，这是技术与业务的完美结合。 约束条件 业务目标: 互联网技术本质上是为了用户需求服务的，推荐系统的目标就是增加留存，使用时长等。 低延迟：推荐系统作为核心的在线系统，必须要尽可能的降低延迟，因为每降低 20ms 就可以上线一个策略，来优化业务目标，同时刷首页信息流的延迟感会直接影响用户体验。 稳定性: 推荐系统是跟业务目标直接相关的，如果出现问题会直接降低用户留存，使用时长等指标直接影响公司收入，因为通常广告业务需要依赖留存与使用时长进行变现。 迭代效率 &amp; 质量：必须做的足够快，推荐系统的迭代速度直接影响公司的竞争能力，同时要对复杂系统保持高迭代效率，势必会导致问题频发，如何保证服务质量将是长久的拉锯战。 成本：推荐系统需要大量的存储&#x2F;计算&#x2F;网络成本，如何优化庞大的机器资源成本，这将直接创造收入。 技术方案如果你要给一个朋友推荐一本书你需要怎么做？ 第一步: 你要自己读过很多书，这样朋友问你的时候你才能及时的推荐给朋友 第二步: 你应该尽可能的了解这个朋友（你对他的印象&#x2F;他现在的状态&#x2F;他想看什么书） 第三步: 基于你对这个朋友的了解以及对你读过的书的了解，潜意识快速筛选出来几十本可以推荐的书 第四步: 然后快速的对这几十本书进行猜测，你这位朋友喜欢这几本书的概率有多大？然后按概率排个序 第五步: 取 topK 结果推荐，基于朋友的反馈，你修正了对朋友兴趣的理解，你的猜测将变得更加准确 第六步: 如果你觉得朋友适合看你刚写的书，那么你会在推荐中夹带私货，强烈安利自己的书（广告） 第七步: 再次推荐书籍时可能会重复推荐，当你发现脑子想到了之前推荐过的书时，你要把他忽略 这个信息匹配的本质就是推荐的基本原理。将人的兴趣量化，再将要推荐的物品特征进行量化，将两个量化值进行计算得到一个分值，然后对所有的计算结果取 topK，返回 topK 的结果，这一过程就是推荐的基本原理。为了实现这一基本步骤，我们发明了多种推荐算法，关于推荐算法的介绍可以参考: 推荐系统公开课，接下来的内容将假设你已经对基本的推荐算法有所了解。 根据对推荐算法的分类以及基本原理的理解，我们可以对推荐系统按数据流的构建过程划分为多个模块：候选构建&#x2F;特征工程&#x2F;召回系统&#x2F;排序系统&#x2F;模型训练&#x2F;混排系统&#x2F;消重系统。 基本概念 推荐阅读：推荐系统的基础概念 item：代表信息的容器，可以是一个视频&#x2F;文章&#x2F;商品&#x2F;广告等等 消费：用户浏览 item 所承载的信息，然后发生一系列行为，播放&#x2F;点赞&#x2F;收藏&#x2F;关注&#x2F;转发&#x2F;购买等等 分发：决定将哪些 item 与用户匹配，展示给用户进行消费的过程就是分发过程 打包：推荐系统决定分发哪些 item 给到用户，但是推荐系统不关注 item 承载哪些信息，他只关注 item 具有的特征，因此打包就是将用户能够浏览的信息拼接封装到 item 的这个容器中展示给用户的过程。 user：消费或者生产 item 的用户 候选：准备推荐给用户消费的 item 数据集合 预估：深度学习模型的前向传播 召回：信息检索的一个过程，通过一个 key 获得一堆相关的 id 排序：对召回的 id，按照某种分值进行排序 数据流：数据整个生命周期的处理过程 特征：物理上客观事物所蕴含信息的数学表达 样本：用于机器学习模型训练的数据特征 候选构建当文章&#x2F;视频 (item) 内容发布后，经过一些审核与处理后需要将 item 存储为易于推荐系统查询的格式，通常就是正排+倒排，正排就是以 itemID 为 key，然后一些 item 相关的结构化属性进行序列化后，存储好的 kv 数据项，而倒排就是以某个属性或者计算的 tag 为 key，value 是一个 timeID 的 list，这两种数据结构覆盖了基本的查询需求，用来为推荐引擎的候选构建提供基础的数据支撑。 所以候选集合本质上就是一个易于推荐引擎查询数据的索引结构，是为推荐提供数据的模块。 特征工程内容候选实在太多，将所有的 item 送入模型进行预估计算量非常大，不可能在秒级返回计算结果，这就要求必须在所有的内容候选中选择最有可能排序在前面的 item，返回一个 top k 的结果，这种大规模的筛选与搜索引擎非常相似，但搜索引擎基于 pagerank 计算的相关性，而推荐召回则基于用户的兴趣与 item 特征之间的相关性，通常通过向量检索，余弦相似度计算两个向量之间的距离来衡量二者的相似程度（分布式向量检索引擎），但真实的召回系统通常要有十几种召回策略，这些召回策略会并行使用，然后将召回结果统一合并。 排序系统训练好的模型，要在线被服务所请求对外提供服务，用户每次主动请求首页的信息流，将携带这个用户的特征信息与返回的一堆 item 的特征，将这些特征信息组成模型的输入，然后经过计算图的计算，输入的特征值与权重参数计算得到一个分值，该分值表示用户如果观看了这个内容将使得损失函数最小化，损失函数被表示为距离业务目标的偏差（使用时长），反过来说就是使得使用时长得到增长。 分布式机器学习系统: Parameter Server 设计 为了增强效果，一次召回通常会返回上千条内容，如果直接放在模型中进行预估，同样延迟会超过 1s，不可接受，为此将排序阶段分为粗排和精排两部分，利用一些简单的策略进行快速打分，将上千条内容过滤掉为几百条，粗排的目标是选择最有可能在排序中排在前面的内容，排序部分通常被称之为精排，为了与粗排进行区分，几百条内容通常在过精排的复杂模型时能够保障在毫秒时间内返回，从而在工程实现与业务目标之间取得权衡。 模型训练机器学习模型本质上就是一堆参数 + 计算图所组成的数据结构，所谓训练就是先给这些参数一个初始化的值，然后通过输入训练样本，反向传播来更新这些参数值，使其通过计算图可以得到一个使得损失函数最小化的结果。 重排（混排）系统推荐系统需要考虑多样化需求且要满足一定的运营能力，即同一个作者的内容不能集中推荐，这需要一套复杂的规则系统，对推荐系统返回的 item list 整体负责，对于多样性问题，需要考虑一刷内 item 之间的相互影响，相同作者&#x2F;相似内容等等，为了降低推荐 item 的相似性，需要有一定的打散模型，能够在精排选出的几百条内容中，考虑一次请求整体列表的特征得到整体收益最大的一个排列组合，以便于提高业务目标。 具体的做法，就是使用 dfs 对 300 条内容进行检索，组合的多种排列形式当作候选，通过规则系统和精排打分作为剪枝依据，加速计算过程，最终整体作为输入，过重排模型，得到对排序 list 的打分，选择打分最高的一组 list，进行返回。 当精排返回 top500 条内容后，根据客户端请求的条数进行截断，返回 8-16 条 top 内容，然后在其中插入广告，请求广告系统获取 N 个广告，广告展示在哪个位置上能够使得 ecpm 和用户体验达到最佳状态? 即: 让用户看到最贵的广告，同时要保证用户不那么反感。这是一个高价值的竞拍问题，将广告和 item 使用 dfs 深度遍历组合每一种情况，将这些情况交给算法模型进行评估，打分，选择整体分值最高的排序方式，最终将其放出这一过程就是混排。 消重系统用户在一段时间内不能看到相同的内容，这是没有意义的是影响用户体验的，为此我们需要避免同一用户在一段时间内，多次请求到相同内容，之前的召回系统每次召回的内容在一段时间内有可能是相同的，因为向量检索的更新难以做到实时性。这是不符合预期的，所以需要有一个系统记录当前用户历史上浏览过了哪些内容，并在召回后将其过滤掉，这样就能保障送入排序阶段的内容都是用户没有流量过的新内容，消重系统应该尽量在接近用户侧写入，接近召回侧过滤。 整合架构 场景信息包括: 设备信息&#x2F;当前时间&#x2F;用户上一刷点赞的 item&#x2F;用户最近下载了啥 app 等等信息 从第二步开始真正的进入推荐引擎，重排 server 将作为信息流广告和推荐业务的入口服务 广告是另一个复杂的系统，基于用户的特征，预测对哪些广告更加感兴趣，能够促进转化，此阶段也将真正开始请求推荐系统 向量召回输入的是 user 的 embedding 信息，该 embedding 是 user feature server 实时计算的，其返回的是 item id 以及 embedding, 是一个双塔模型，除了主要的向量召回，也会有一些策略召回作为对向量召回的补充，输入的是聚类 id 输出的是 id list 通过 item id 获取正排信息，这里会大量查询本地缓存，这些 item 的属性信息用于后续的过滤打散 多个召回通道返回的内容需要合并在一起，通常采用蛇形 merge 的方式合并，然后执行一些过滤规则，例如摄政类&#x2F;曾经刷过的内容&#x2F;关键词屏蔽&#x2F;作者屏蔽&#x2F;版权屏蔽等扽过滤规则，确保放出的 id 有效性较高 粗排阶段，通过 uid embedding 和 几千个 item 的 embedding，进行快速的排序预测，通常是一个简单的 ctr 模型，主要是计算快速，在几十毫秒内能够计算出几千个 item 的得分，粗排的目标是尽可能的将高价值的 item 排在前面。 精排阶段，主要对推荐效果负责，将以复杂的算法模型作出准确的预估，通常消耗几百毫秒，是推荐最耗时消耗计算资源最多的地方，输入进去的关于 user 和 item 的 embedding 信息，作为模型的输入参数，精排的模型是多目标模型，会有很多输出，每个输出代表一个预测分数，例如转发的概率，点赞的概率，完播的概率等等，每个输出分数对应一个模型，都会讲输入参数入图计算，进入 tf 的 serving 中，根据图计算的 DAG 配置，从配置中确定权重的 id，通常叫做 feature id，根据这个 id 去 ps 中查询具体的 embedding 数值，然后在 worker server 中进行权重的计算，完成前向传播过程，完成计算过程，得到分数，然后精排服务还会对所有的分数过一个融合公式得到一个最终分，该融合公式是认为确定的，通常就是加权平均，根据业务目标调整分数权重即可，最终该融合公式的得分即位排序分 精排返回结果后，执行控制流回到重排服务，将 item id 和 ad id 输入规则系统，进行 dfs 检索，选择符合规则策略并取得分最高的一列组合返回，此时决定了最终呈现给用户的 item id 的顺序以及内容 此阶段会异步的返回 ack 请求回调精排服务，告诉精排服务哪些 item id 被正式选中进行曝光，此时精排服务会真正的发送 stream feature 用于进行实时的进行训练样本的拼接 此时 item id + ad id 的 list 返回到了 feed server，feed server 将 id list 记录到历史消重服务中，该服务是为了记录用户已经看过哪些内容，用于在召回之后将其过滤的操作，同时作为曝光日志（用户看了哪些内容），也会作为训练样本拼接的数据流之一，通常为了覆盖足够的业务逻辑与场景，越接近客户侧的写消重操作效果越好，因为这样将约接近客户真实的曝光行为，越在接近召回的地方做过滤效果越好，因为这样将节约计算资源，确保之后执行的操作都是对可放出的 id 进行的。但过于接近客户侧的写消重，例如由客户端上报写消重，将会因为客户端跨公网传输数据，延迟较高无法实时记录历史数据而不得不放弃 feed server 主要的作用就是根据 id 以及 id 的类型进行业务打包，也就是根据 id 点查该 id 所对应的内容数据，比如 id 的类型是小视频，则就通过 id 去查询小视频服务返回小视频的播放地址，点赞数&#x2F;评论数&#x2F;作者头像等等用于 feed 流展示的数据，如果 id 类型是一个商品，则就去商品服务打包商品的封面图，价格，销量等数据信息，如果是一个广告，则去广告的打包服务查询，总之这一步将根据 id 查询具体体裁内容的展示信息 用户真正的看到了 feed 信息，然后根据自己的喜好表达一些消费行为，转发&#x2F;点赞&#x2F;评论&#x2F;停留播放等行为，这些行为会被客户端上报给服务端 服务端会对数据进行检查，然后对错误的数据进行剔除，加工转换后用于拼接训练样本，训练样本会进入 joiner server，该 server 将 精排服务上报的 关于 item 的特征信息 (embedding)，以及服务端上报的曝光 item id 信息缓存在一个大的 cache 中，缓存 1 小时，客户端上报数据代表着用户对 item 的行为，该数据如果在 1 小时内被回传则说明是正例，将拼接出一个正例样本，如果 1 小时内没有被回传则被认为是负例，为保证正负例一样多，才能保证训练模型不会过拟合，通常会对负例进行采样，丢弃一部分负例，这样保证正负例一样多，进行模型的实时训练，这部分数据就会进入 MLOPS 平台，训练模型参数","tags":["AI Infra","推荐系统"],"categories":["AI-Infra"]},{"title":"根据（前中后序）构造二叉树系列","path":"/post/数据结构与算法/constructing-binary-tree/","content":"✅ 构造二叉树系列相关例题： 889. 根据前序和后序遍历构造二叉树（不唯一） 105. 从前序与中序遍历序列构造二叉树（唯一） 106. 从中序与后序遍历序列构造二叉树（唯一） 1008. 前序遍历构造二叉搜索树 1008. 前序遍历构造二叉搜索树题意：根据前序遍历结果构造二叉搜索树 12输入：preorder = [8,5,1,7,10,12]输出：[8,5,10,1,7,null,12] 1️⃣ buildTree · 递归12345678910111213141516171819202122class Solution &#123;public: TreeNode* buildTree(vector&lt;int&gt;&amp; preorder, int left, int right) &#123; if (left &gt; right) &#123; return nullptr; &#125; int i; for (i = left + 1; i &lt;= right; i++) &#123; if (preorder[i] &gt; preorder[left]) break; &#125; TreeNode* _left = buildTree(preorder, left + 1, i - 1); TreeNode* _right = buildTree(preorder, i, right); return new TreeNode(preorder[left], _left, _right); &#125; TreeNode* bstFromPreorder(vector&lt;int&gt;&amp; preorder) &#123; if (preorder.empty()) return nullptr; return buildTree(preorder, 0, preorder.size() - 1); &#125;&#125;; 12345678910111213class Solution &#123;public: TreeNode* bstFromPreorder(vector&lt;int&gt;&amp; preorder) &#123; if (preorder.empty()) return nullptr; int i = upper_bound(preorder.begin() + 1, preorder.end(), preorder[0]) - preorder.begin(); vector&lt;int&gt; preleft(preorder.begin() + 1, preorder.begin() + i); vector&lt;int&gt; preright(preorder.begin() + i, preorder.end()); TreeNode* left = bstFromPreorder(preleft); TreeNode* right = bstFromPreorder(preright); return new TreeNode(preorder[0], left, right); &#125;&#125;; 106. 从中序与后序遍历序列构造二叉树 12输入：inorder = [9,3,15,20,7], postorder = [9,15,7,20,3]输出：[3,9,20,null,null,15,7] 1️⃣ 递归 123456789101112131415class Solution &#123;public: TreeNode* buildTree(vector&lt;int&gt;&amp; inorder, vector&lt;int&gt;&amp; postorder) &#123; if (inorder.empty()) return nullptr; int i = ranges::find(inorder, postorder.back()) - inorder.begin(); vector&lt;int&gt; in1(inorder.begin(), inorder.begin() + i); vector&lt;int&gt; in2(inorder.begin() + i + 1, inorder.end()); vector&lt;int&gt; post1(postorder.begin(), postorder.begin() + i); vector&lt;int&gt; post2(postorder.begin() + i, postorder.end() - 1); TreeNode* left = buildTree(in1, post1); TreeNode* right = buildTree(in2, post2); return new TreeNode(postorder.back(), left, right); &#125;&#125;; 105. 从前序与中序遍历序列构造二叉树 123输入: preorder = [3,9,20,15,7], inorder = [9,3,15,20,7]输出: [3,9,20,null,null,15,7] 1️⃣ 递归 123456789101112131415class Solution &#123;public: TreeNode* buildTree(vector&lt;int&gt;&amp; preorder, vector&lt;int&gt;&amp; inorder) &#123; if (preorder.empty()) return nullptr; int i = ranges::find(inorder, preorder[0]) - inorder.begin(); vector&lt;int&gt; pre1(preorder.begin() + 1, preorder.begin() + i + 1); vector&lt;int&gt; pre2(preorder.begin() + i + 1, preorder.end()); vector&lt;int&gt; in1(inorder.begin(), inorder.begin() + i); vector&lt;int&gt; in2(inorder.begin() + i + 1, inorder.end()); TreeNode* left = buildTree(pre1, in1); TreeNode* right = buildTree(pre2, in2); return new TreeNode(preorder[0], left, right); &#125;&#125;; 889. 根据前序和后序遍历构造二叉树 如果存在多个答案，您可以返回其中 任何 一个。 12输入：preorder = [1,2,4,5,3,6,7], postorder = [4,5,2,6,7,3,1]输出：[1,2,3,4,5,6,7] 1️⃣ 递归首先说明，如果只知道前序遍历和后序遍历，这棵二叉树不一定是唯一的，如下图。 题目说，如果存在多个答案，我们可以返回其中任何一个。那么不妨规定：无论什么情况，在前序遍历中，preorder[1] 都是左子树的根节点值。 递归边界： 如果 preorder 的长度是 0，对应着空节点，返回空。 如果 preorder 的长度是 1，对应着二叉树的叶子，创建一个叶子节点并返回。 1234567891011121314151617181920class Solution &#123;public: TreeNode* constructFromPrePost(vector&lt;int&gt;&amp; preorder, vector&lt;int&gt;&amp; postorder) &#123; if (preorder.empty()) &#123; return nullptr; &#125; if (preorder.size() == 1) &#123; return new TreeNode(preorder[0]); &#125; int left_size = find(postorder.begin(), postorder.end(), preorder[1]) - postorder.begin() + 1; vector&lt;int&gt; pre1(preorder.begin() + 1, preorder.begin() + left_size + 1); vector&lt;int&gt; pre2(preorder.begin() + left_size + 1, preorder.end()); vector&lt;int&gt; post1(postorder.begin(), postorder.begin() + left_size); vector&lt;int&gt; post2(postorder.begin() + left_size, postorder.end() - 1); TreeNode* root = new TreeNode(preorder[0]); root-&gt;left = constructFromPrePost(pre1, post1); root-&gt;right = constructFromPrePost(pre2, post2); return root; &#125;&#125;;","tags":["LeetCode","数据结构"],"categories":["数据结构与算法"]},{"title":"二叉树匹配问题｜子树匹配？子结构匹配？","path":"/post/数据结构与算法/binary-tree-matching/","content":"✅ 二叉树匹配类题目总结匹配类二叉树可以使用一种套路相对固定的递归函数，这类题目与字符串匹配有些神似，求解过程大致分为两步： 先将根节点匹配； 根节点匹配后，对子树进行匹配。 相关例题： 100. 相同的树（即 check 函数本身） 101. 对称二叉树 1367. 二叉树中的链表 572. 另一棵树的子树 &amp; 面试题 04.10. 检查子树（匹配子树） LCR 143. 子结构判断（匹配子结构） 100. 相同的树 12345678class Solution &#123;public: bool isSameTree(TreeNode* p, TreeNode* q) &#123; if (!p || !q) return p == q; return p-&gt;val == q-&gt;val &amp;&amp; isSameTree(p-&gt;left, q-&gt;left) &amp;&amp; isSameTree(p-&gt;right, q-&gt;right); &#125;&#125;; 101. 对称二叉树 1234567891011121314class Solution &#123;public: bool check(TreeNode* a, TreeNode* b) &#123; if (a == nullptr &amp;&amp; b == nullptr) return true; if (a == nullptr || b == nullptr) return false; return a-&gt;val == b-&gt;val &amp;&amp; check(a-&gt;left, b-&gt;right) &amp;&amp; check(a-&gt;right, b-&gt;left); &#125; bool isSymmetric(TreeNode* root) &#123; return check(root-&gt;left, root-&gt;right); &#125;&#125;; 1367. 二叉树中的链表 题意：「链表」在「二叉树」中的匹配 123输入：head = [4,2,8], root = [1,4,4,null,2,2,null,1,null,6,8,null,null,null,null,1,3]输出：true解释：树中蓝色的节点构成了与链表对应的子路径。 12345678910111213141516class Solution &#123;public: bool check(ListNode* head, TreeNode* root) &#123; if (head == nullptr) return true; if (root == nullptr) return false; return head-&gt;val == root-&gt;val &amp;&amp; (check(head-&gt;next, root-&gt;left) || check(head-&gt;next, root-&gt;right)); &#125; bool isSubPath(ListNode* head, TreeNode* root) &#123; if (root == nullptr) return false; return check(head, root) || isSubPath(head, root-&gt;left) || isSubPath(head, root-&gt;right); &#125;&#125;; 572. 另一棵树的子树 &amp; 面试题 04.10. 检查子树（匹配子树）这道题的题意是这样的：输入两棵二叉树 A 和 B，判断 B 是不是 A 的子结构，且约定空树不是任意一个树的子结构。 比如上面这个例子，我们发现 B 是 A 的子结构，因为它们的结构相同，且节点值相等。 求解思路可以分解为以下两步： 匹配根节点：首先在 A 中找到与 B 的根节点匹配的节点 C； 匹配其他节点：验证 C 的子树与 B 的子树是否匹配。 1234567891011121314151617class Solution &#123;public: bool check(TreeNode* a, TreeNode* b) &#123; // 以下四行代码也可以改成: if (a == nullptr || b == nullptr) &#123; return a == b; &#125; if (a == nullptr &amp;&amp; b == nullptr) return true; if (a == nullptr || b == nullptr) return false; return a-&gt;val == b-&gt;val &amp;&amp; check(a-&gt;left, b-&gt;left) &amp;&amp; check(a-&gt;right, b-&gt;right); &#125; bool checkSubTree(TreeNode* t1, TreeNode* t2) &#123; if (t1 == nullptr || t2 == nullptr) return false; return check(t1, t2) || checkSubTree(t1-&gt;left, t2) || checkSubTree(t1-&gt;right, t2); &#125;&#125;; LCR 143. 子结构判断（匹配子结构） 123输入：tree1 = [3,6,7,1,8], tree2 = [6,1]输出：true解释：tree2 与 tree1 的一个子树拥有相同的结构和节点值。即 6 - &gt; 1。 对于本题来讲，与「面试题 04.10. 检查子树」很像，不同的是 B 属于 A 的一部分也可以，没必要一直匹配到叶子节点，因此只需对 check 函树的基本条件进行修改即可。 12345678910111213141516class Solution &#123;public: bool check(TreeNode* a, TreeNode* b) &#123; if (b == nullptr) return true; if (a == nullptr) return false; return a-&gt;val == b-&gt;val &amp;&amp; check(a-&gt;left, b-&gt;left) &amp;&amp; check(a-&gt;right, b-&gt;right); &#125; bool isSubStructure(TreeNode* t1, TreeNode* t2) &#123; if (t1 == nullptr || t2 == nullptr) return false; return check(t1, t2) || isSubStructure(t1-&gt;left, t2) || isSubStructure(t1-&gt;right, t2); &#125;&#125;;","tags":["LeetCode","算法"],"categories":["数据结构与算法"]},{"title":"高频「链表」面试题","path":"/post/数据结构与算法/interview-linked-list/","content":"✅ 高频链表面试题相关例题： 141. 环形链表 142. 环形链表 II 160. 相交链表 206. 反转链表 92. 反转链表 II 876. 链表的中间结点 234. 回文链表 21. 合并两个有序链表 2. 两数相加 445. 两数相加 II 19. 删除链表的倒数第 N 个结点 24. 两两交换链表中的节点 25. K 个一组翻转链表 23. 合并 K 个升序链表 146. LRU 缓存 138. 随机链表的复制 … 82. 删除排序链表中的重复元素 II 61. 旋转链表 86. 分隔链表 148. 排序链表 141. 环形链表 123输入：head = [3,2,0,-4], pos = 1输出：true解释：链表中有一个环，其尾部连接到第二个节点。 1️⃣ 快慢指针12345678910111213class Solution &#123;public: bool hasCycle(ListNode* head) &#123; ListNode *slow = head, *fast = head; while (fast &amp;&amp; fast-&gt;next) &#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; if (slow == fast) return true; &#125; return false; &#125;&#125;; 142. 环形链表 II给定一个链表的头节点 head ，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。 如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，评测系统内部使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。如果 pos 是 -1，则在该链表中没有环。注意：pos 不作为参数进行传递，仅仅是为了标识链表的实际情况。 不允许修改 链表。 示例 1： 123输入：head = [3,2,0,-4], pos = 1输出：返回索引为 1 的链表节点解释：链表中有一个环，其尾部连接到第二个节点。 1️⃣ 快慢指针 1234567891011121314151617181920class Solution &#123;public: ListNode* detectCycle(ListNode* head) &#123; ListNode *slow = head, *fast = head; while (fast &amp;&amp; fast-&gt;next) &#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; if (slow == fast) &#123; // a = k(b + c) + c ListNode* node = head; while (node != slow) &#123; node = node-&gt;next; slow = slow-&gt;next; &#125; return slow; &#125; &#125; return nullptr; &#125;&#125;; 160. 相交链表 1234567891011class Solution &#123;public: ListNode* getIntersectionNode(ListNode* headA, ListNode* headB) &#123; ListNode *p = headA, *q = headB; while (p != q) &#123; p = p ? p-&gt;next : headB; q = q ? q-&gt;next : headA; &#125; return p; &#125;&#125;; 206. 反转链表 1️⃣ 迭代｜三指针1234567891011121314class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; ListNode* pre = nullptr; ListNode* cur = head; while (cur) &#123; ListNode* nxt = cur-&gt;next; cur-&gt;next = pre; pre = cur; cur = nxt; &#125; return pre; &#125;&#125;; 2️⃣ 递归1234567891011class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; if (!head || !head-&gt;next) return head; ListNode* new_head = reverseList(head-&gt;next); head-&gt;next-&gt;next = head; head-&gt;next = nullptr; // 为了反转后的末节点 return new_head; &#125;&#125;; 92. 反转链表 II 反转链表进阶：反转部分区间，找到区间 leftNode 与 rightNode，以及 leftNode 左节点 pre 与 rightNode 右节点 nxt，独立区间（断开连接）后反转再接回。 123456789101112131415161718192021222324252627282930313233343536373839class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; ListNode* pre = nullptr; ListNode* cur = head; while (cur) &#123; ListNode* nxt = cur-&gt;next; cur-&gt;next = pre; pre = cur; cur = nxt; &#125; return pre; &#125; ListNode* reverseBetween(ListNode* head, int left, int right) &#123; ListNode dummy(0, head); ListNode* pre = &amp;dummy; int t = left; while (--t) &#123; pre = pre-&gt;next; &#125; ListNode* leftNode = pre-&gt;next; ListNode* rightNode = leftNode; t = right - left; while (t--) &#123; rightNode = rightNode-&gt;next; &#125; ListNode* nxt = rightNode-&gt;next; // 断开链接 pre-&gt;next = nullptr; rightNode-&gt;next = nullptr; // 反转链表 ListNode* node = reverseList(leftNode); // 重新链接 pre-&gt;next = node; leftNode-&gt;next = nxt; return dummy.next; &#125;&#125;; 876. 链表的中间结点 123输入：head = [1,2,3,4,5]输出：[3,4,5]解释：链表只有一个中间结点，值为 3 。 123输入：head = [1,2,3,4,5,6]输出：[4,5,6]解释：该链表有两个中间结点，值分别为 3 和 4 ，返回第二个结点。 1️⃣ 快慢指针1234567891011class Solution &#123;public: ListNode* middleNode(ListNode* head) &#123; ListNode *slow = head, *fast = head; while (fast &amp;&amp; fast-&gt;next) &#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; &#125; return slow; &#125;&#125;; 234. 回文链表 1️⃣ 回文链表判断 &#x3D; 寻找中间节点 + 反转链表前置题目： 876. 链表的中间结点 206. 反转链表 1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: ListNode* middleNode(ListNode* head) &#123; ListNode *slow = head, *fast = head; while (fast &amp;&amp; fast-&gt;next) &#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; &#125; return slow; &#125; ListNode* reverseList(ListNode* head) &#123; ListNode *pre = nullptr, *cur = head; while (cur) &#123; ListNode* nxt = cur-&gt;next; cur-&gt;next = pre; pre = cur; cur = nxt; &#125; return pre; &#125; bool isPalindrome(ListNode* head) &#123; ListNode* mid = middleNode(head); ListNode* head2 = reverseList(mid); while (head2) &#123; if (head-&gt;val != head2-&gt;val) &#123; return false; &#125; head = head-&gt;next; head2 = head2-&gt;next; &#125; return true; &#125;&#125;; 21. 合并两个有序链表 12输入：l1 = [1,2,4], l2 = [1,3,4]输出：[1,1,2,3,4,4] 1️⃣ 迭代（常用）12345678910111213141516171819class Solution &#123;public: ListNode* mergeTwoLists(ListNode* list1, ListNode* list2) &#123; ListNode dummy&#123;&#125;; ListNode* cur = &amp;dummy; while (list1 &amp;&amp; list2) &#123; if (list1-&gt;val &lt; list2-&gt;val) &#123; cur-&gt;next = list1; list1 = list1-&gt;next; &#125; else &#123; cur-&gt;next = list2; list2 = list2-&gt;next; &#125; cur = cur-&gt;next; &#125; cur-&gt;next = list1 ? list1 : list2; return dummy.next; &#125;&#125;; 2️⃣ 递归12345678910111213class Solution &#123;public: ListNode* mergeTwoLists(ListNode* list1, ListNode* list2) &#123; if (list1 == nullptr) return list2; // 注：如果都为空则返回空 if (list2 == nullptr) return list1; if (list1-&gt;val &lt; list2-&gt;val) &#123; list1-&gt;next = mergeTwoLists(list1-&gt;next, list2); return list1; &#125; list2-&gt;next = mergeTwoLists(list1, list2-&gt;next); return list2; &#125;&#125;; 2. 两数相加｜从头开始相加 1️⃣ 迭代123456789101112131415161718192021class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; ListNode dummy; ListNode* cur = &amp;dummy; int carry = 0; while (l1 || l2 || carry) &#123; if (l1) &#123; carry += l1-&gt;val; l1 = l1-&gt;next; &#125; if (l2) &#123; carry += l2-&gt;val; l2 = l2-&gt;next; &#125; cur = cur-&gt;next = new ListNode(carry % 10); carry /= 10; &#125; return dummy.next; &#125;&#125;; 2️⃣ 递归12345678910111213141516class Solution &#123;public: // l1 和 l2 为当前遍历的节点，carry 为进位 ListNode* addTwoNumbers(ListNode* l1, ListNode* l2, int carry = 0) &#123; if (l1 == nullptr &amp;&amp; l2 == nullptr) &#123; // 递归边界：l1 和 l2 都是空节点 return carry ? new ListNode(carry) : nullptr; // 如果进位了，就额外创建一个节点 &#125; if (l1 == nullptr) &#123; // 如果 l1 是空的，那么此时 l2 一定不是空节点 swap(l1, l2); // 交换 l1 与 l2，保证 l1 非空，从而简化代码 &#125; int sum = carry + l1-&gt;val + (l2 ? l2-&gt;val : 0); // 节点值和进位加在一起 l1-&gt;val = sum % 10; // 每个节点保存一个数位（直接修改原链表） l1-&gt;next = addTwoNumbers(l1-&gt;next, (l2 ? l2-&gt;next : nullptr), sum / 10); // 进位 return l1; &#125;&#125;; 445. 两数相加 II｜从尾开始相加 1️⃣ 迭代｜反转链表 + 两数相加1234567891011121314151617181920212223242526272829303132333435class Solution &#123; ListNode* reverseList(ListNode* head) &#123; ListNode* pre = nullptr, *cur = head; while (cur) &#123; ListNode* nxt = cur-&gt;next; cur-&gt;next = pre; pre = cur; cur = nxt; &#125; return pre; &#125; ListNode* addTwo(ListNode* l1, ListNode* l2) &#123; ListNode dummy; // 哨兵节点 auto cur = &amp;dummy; int carry = 0; // 进位 while (l1 || l2 || carry) &#123; // 有一个不是空节点，或者还有进位，就继续迭代 if (l1) carry += l1-&gt;val; // 节点值和进位加在一起 if (l2) carry += l2-&gt;val; // 节点值和进位加在一起 cur = cur-&gt;next = new ListNode(carry % 10); // 每个节点保存一个数位 carry /= 10; // 新的进位 if (l1) l1 = l1-&gt;next; // 下一个节点 if (l2) l2 = l2-&gt;next; // 下一个节点 &#125; return dummy.next; // 哨兵节点的下一个节点就是头节点 &#125;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; l1 = reverseList(l1); l2 = reverseList(l2); auto l3 = addTwo(l1, l2); return reverseList(l3); &#125;&#125;; 2️⃣ 递归｜反转链表 + 两数相加123456789101112131415161718192021222324252627282930313233class Solution &#123; ListNode* reverseList(ListNode* head) &#123; if (head == nullptr || head-&gt;next == nullptr) &#123; return head; &#125; auto new_head = reverseList(head-&gt;next); head-&gt;next-&gt;next = head; // 把下一个节点指向自己 head-&gt;next = nullptr; // 断开指向下一个节点的连接，保证最终链表的末尾节点的 next 是空节点 return new_head; &#125; // l1 和 l2 为当前遍历的节点，carry 为进位 ListNode* addTwo(ListNode* l1, ListNode* l2, int carry = 0) &#123; if (l1 == nullptr &amp;&amp; l2 == nullptr) &#123; // 递归边界：l1 和 l2 都是空节点 return carry ? new ListNode(carry) : nullptr; // 如果进位了，就额外创建一个节点 &#125; if (l1 == nullptr) &#123; // 如果 l1 是空的，那么此时 l2 一定不是空节点 swap(l1, l2); // 交换 l1 与 l2，保证 l1 非空，从而简化代码 &#125; carry += l1-&gt;val + (l2 ? l2-&gt;val : 0); // 节点值和进位加在一起 l1-&gt;val = carry % 10; // 每个节点保存一个数位 l1-&gt;next = addTwo(l1-&gt;next, (l2 ? l2-&gt;next : nullptr), carry / 10); // 进位 return l1; &#125;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; l1 = reverseList(l1); l2 = reverseList(l2); // l1 和 l2 反转后，就变成【2. 两数相加】了 auto l3 = addTwo(l1, l2); return reverseList(l3); &#125;&#125;; 19. 删除链表的倒数第 N 个结点 1️⃣ 快慢指针123456789101112131415161718class Solution &#123;public: ListNode* removeNthFromEnd(ListNode* head, int n) &#123; ListNode dummy(0, head); ListNode *fast = &amp;dummy, *slow = &amp;dummy; while (n--) &#123; fast = fast-&gt;next; &#125; while (fast-&gt;next) &#123; slow = slow-&gt;next; fast = fast-&gt;next; &#125; ListNode* d = slow-&gt;next; slow-&gt;next = d-&gt;next; delete d; return dummy.next; &#125;&#125;; 24. 两两交换链表中的节点 1️⃣ 迭代｜四指针 1234567891011121314151617181920class Solution &#123;public: ListNode* swapPairs(ListNode* head) &#123; ListNode dummy(0, head); // 用哨兵节点简化代码逻辑 ListNode* node0 = &amp;dummy; ListNode* node1 = head; while (node1 &amp;&amp; node1-&gt;next) &#123; // 至少有两个节点 ListNode* node2 = node1-&gt;next; ListNode* node3 = node2-&gt;next; node0-&gt;next = node2; // 0 -&gt; 2 node2-&gt;next = node1; // 2 -&gt; 1 node1-&gt;next = node3; // 1 -&gt; 3 node0 = node1; // 下一轮交换，0 是 1 node1 = node3; // 下一轮交换，1 是 3 &#125; return dummy.next; // 返回新链表的头节点 &#125;&#125;; 2️⃣ 递归1234567891011121314151617class Solution &#123;public: ListNode* swapPairs(ListNode* head) &#123; if (head == nullptr || head-&gt;next == nullptr) &#123; return head; &#125; ListNode* node1 = head; ListNode* node2 = head-&gt;next; ListNode* node3 = node2-&gt;next; node1-&gt;next = swapPairs(node3); // 1 指向递归返回的链表头 node2-&gt;next = node1; // 2 指向 1 return node2; // 返回交换后的链表头节点 &#125;&#125;; 25. K 个一组翻转链表 1️⃣ 从「反转链表 · 迭代版」到「K 个一组翻转链表」1234567891011121314151617181920212223242526class Solution &#123;public: ListNode* reverseKGroup(ListNode* head, int k) &#123; int n = 0; for (ListNode* cur = head; cur; cur = cur-&gt;next) &#123; n++; &#125; ListNode dummy(0, head); ListNode* p0 = &amp;dummy; ListNode* prev = nullptr; ListNode* cur = head; for (; n &gt;= k; n -= k) &#123; for (int i = 0; i &lt; k; i++) &#123; ListNode* nxt = cur-&gt;next; cur-&gt;next = prev; prev = cur; cur = nxt; &#125; ListNode* last = p0-&gt;next; p0-&gt;next = prev; last-&gt;next = cur; p0 = last; &#125; return dummy.next; &#125;&#125;; 2️⃣「206. 反转链表」+「92. 反转链表 II」1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Solution &#123;public: // 206. 反转链表 ListNode* reverseList(ListNode* head) &#123; ListNode* pre = nullptr; ListNode* cur = head; while (cur) &#123; ListNode* nxt = cur-&gt;next; cur-&gt;next = pre; pre = cur; cur = nxt; &#125; return pre; &#125; // 92. 反转链表 II ListNode* reverseBetween(ListNode* head, int left, int right) &#123; ListNode dummy(0, head); ListNode* pre = &amp;dummy; for (int i = 0; i &lt; left - 1; i++) &#123; pre = pre-&gt;next; &#125; ListNode* leftNode = pre-&gt;next; ListNode* rightNode = leftNode; for (int i = left; i &lt; right; i++) &#123; rightNode = rightNode-&gt;next; &#125; ListNode* nxt = rightNode-&gt;next; rightNode-&gt;next = nullptr; reverseList(leftNode); pre-&gt;next = rightNode; leftNode-&gt;next = nxt; return dummy.next; &#125; ListNode* reverseKGroup(ListNode* head, int k) &#123; int n = 0; ListNode* cur = head; while (cur) &#123; n++; cur = cur-&gt;next; &#125; if (n &lt; k) &#123; return head; &#125; ListNode* new_head = head; int times = n / k; for (int i = 0; times--; i += k) &#123; ListNode* node = reverseBetween(new_head, i + 1, i + k); if (i == 0) &#123; new_head = node; &#125; &#125; return new_head; &#125;&#125;; 23. 合并 K 个升序链表12345678910输入：lists = [[1,4,5],[1,3,4],[2,6]]输出：[1,1,2,3,4,4,5,6]解释：链表数组如下：[ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6]将它们合并到一个有序链表中得到。1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6 ✅ 快手一面，面试官来一题简单题😊，最后还问了时间复杂度：假设 k 个链表，共 n 个节点，那时间复杂度为 $O(k·logk+n·logk)$ 即 $O(n·logk)$。 1️⃣ 最小堆时间复杂度分析：假设 $k$ 个链表, 共 $n$ 个节点, 最小堆单次操作 $O(log k)$, 初始化堆需要 $O(k·logk)$, 那时间复杂度为 $O(k·logk + n·logk)$，即 $O(n·logk)$。 1234567891011121314151617181920212223242526272829303132333435/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; auto cmp = [](const ListNode* a, const ListNode* b) &#123; return a-&gt;val &gt; b-&gt;val; &#125;; priority_queue&lt;ListNode*, vector&lt;ListNode*&gt;, decltype(cmp)&gt; pq; for (auto&amp; head : lists) &#123; if (head) &#123; pq.push(head); &#125; &#125; ListNode dummy&#123;&#125;; ListNode* head = &amp;dummy; while (!pq.empty()) &#123; ListNode* node = pq.top(); pq.pop(); head-&gt;next = node; head = head-&gt;next; if (node-&gt;next) pq.push(node-&gt;next); &#125; return dummy.next; &#125;&#125;; 2️⃣ 分治法前置题目：21. 合并两个有序链表 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeTwoLists(ListNode* list1, ListNode* list2) &#123; ListNode dummy&#123;&#125;; ListNode* cur = &amp;dummy; while (list1 &amp;&amp; list2) &#123; if (list1-&gt;val &lt; list2-&gt;val) &#123; cur-&gt;next = list1; list1 = list1-&gt;next; &#125; else &#123; cur-&gt;next = list2; list2 = list2-&gt;next; &#125; cur = cur-&gt;next; &#125; cur-&gt;next = list1 ? list1 : list2; return dummy.next; &#125; ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists, int l, int r) &#123; if (l == r) return lists[l]; if (l &gt; r) return nullptr; int m = (l + r) &gt;&gt; 1; auto left = mergeKLists(lists, l, m); auto right = mergeKLists(lists, m + 1, r); return mergeTwoLists(left, right); &#125; ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; return mergeKLists(lists, 0, lists.size() - 1); &#125;&#125;; 146. LRU 缓存 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364struct Node &#123; int key; int value; Node* prev; Node* next; Node(int k = 0, int v = 0) : key(k), value(v) &#123;&#125;&#125;;class LRUCache &#123;private: Node* dummy; int capacity; unordered_map&lt;int, Node*&gt; key_to_node; void remove(Node* node) &#123; node-&gt;prev-&gt;next = node-&gt;next; node-&gt;next-&gt;prev = node-&gt;prev; &#125; void push_front(Node* node) &#123; node-&gt;next = dummy-&gt;next; node-&gt;prev = dummy; dummy-&gt;next-&gt;prev = node; dummy-&gt;next = node; &#125; Node* get_node(int key) &#123; if (!key_to_node.count(key)) &#123; return nullptr; &#125; Node* node = key_to_node[key]; remove(node); push_front(node); return node; &#125;public: LRUCache(int capacity) : capacity(capacity), dummy(new Node()) &#123; dummy-&gt;next = dummy; dummy-&gt;prev = dummy; &#125; int get(int key) &#123; Node* node = get_node(key); return node == nullptr ? -1 : node-&gt;value; &#125; void put(int key, int value) &#123; Node* node = get_node(key); if (node != nullptr) &#123; node-&gt;value = value; return; &#125; node = new Node(key, value); if (key_to_node.size() == capacity) &#123; Node* last = dummy-&gt;prev; remove(last); key_to_node.erase(last-&gt;key); delete last; &#125; key_to_node[key] = node; push_front(node); &#125;&#125;; 138. 随机链表的复制 12输入：head = [[7,null],[13,0],[11,4],[10,2],[1,0]]输出：[[7,null],[13,0],[11,4],[10,2],[1,0]] 1234567891011121314151617181920212223242526272829303132/*// Definition for a Node.class Node &#123;public: int val; Node* next; Node* random; Node(int _val) &#123; val = _val; next = NULL; random = NULL; &#125;&#125;;*/class Solution &#123;public: unordered_map&lt;Node*, Node*&gt; cacheNode; Node* copyRandomList(Node* head) &#123; if (head == nullptr) return nullptr; if (!cacheNode.count(head)) &#123; Node* newHead = new Node(head-&gt;val); cacheNode[head] = newHead; newHead-&gt;next = copyRandomList(head-&gt;next); newHead-&gt;random = copyRandomList(head-&gt;random); &#125; return cacheNode[head]; &#125;&#125;; 82. 删除排序链表中的重复元素 II给定一个已排序的链表的头 head ， 删除原始链表中所有重复数字的节点，只留下不同的数字 。返回 已排序的链表 。 123456789101112131415161718class Solution &#123;public: ListNode* deleteDuplicates(ListNode* head) &#123; ListNode dummy(0, head); auto cur = &amp;dummy; while (cur-&gt;next &amp;&amp; cur-&gt;next-&gt;next) &#123; int val = cur-&gt;next-&gt;val; if (cur-&gt;next-&gt;next-&gt;val == val) &#123; while (cur-&gt;next &amp;&amp; cur-&gt;next-&gt;val == val) &#123; cur-&gt;next = cur-&gt;next-&gt;next; &#125; &#125; else &#123; cur = cur-&gt;next; &#125; &#125; return dummy.next; &#125;&#125;; 61. 旋转链表给你一个链表的头节点 head ，旋转链表，将链表每个节点向右移动 k 个位置。 12输入：head = [1,2,3,4,5], k = 2输出：[4,5,1,2,3] 思路：我们可以先将给定的链表连接成环，然后将指定位置断开。 123456789101112131415161718192021222324class Solution &#123;public: ListNode* rotateRight(ListNode* head, int k) &#123; if (k == 0 || !head || !head-&gt;next) &#123; return head; &#125; int n = 1; ListNode* iter = head; while (iter-&gt;next) &#123; iter = iter-&gt;next; n++; &#125; int t = n - k % n; if (t == n) return head; iter-&gt;next = head; // 连成环 while (t--) &#123; iter = iter-&gt;next; &#125; ListNode* ret = iter-&gt;next; iter-&gt;next = nullptr; return ret; &#125;&#125;; 86. 分隔链表给你一个链表的头节点 head 和一个特定值 x ，请你对链表进行分隔，使得所有 小于 x 的节点都出现在 大于或等于 x 的节点之前。 你应当 保留 两个分区中每个节点的初始相对位置。 12输入：head = [1,4,3,2,5,2], x = 3输出：[1,2,2,4,3,5] 1️⃣ 模拟12345678910111213141516171819202122class Solution &#123;public: ListNode* partition(ListNode* head, int x) &#123; ListNode largeDummy(0); ListNode* large = &amp;largeDummy; ListNode smallDummy(0); ListNode* small = &amp;smallDummy; while (head) &#123; if (head-&gt;val &lt; x) &#123; small-&gt;next = head; small = small-&gt;next; &#125; else &#123; large-&gt;next = head; large = large-&gt;next; &#125; head = head-&gt;next; &#125; small-&gt;next = largeDummy.next; large-&gt;next = nullptr; return smallDummy.next; &#125;&#125;; 148. 排序链表 1️⃣ 归并排序（分治法）｜链表的中间结点 + 合并两个有序链表12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123;public: // 876. 链表的中间结点（快慢指针） ListNode* middleNode(ListNode* head) &#123; ListNode* pre = head; ListNode* slow = head; ListNode* fast = head; while (fast &amp;&amp; fast-&gt;next) &#123; pre = slow; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; &#125; pre-&gt;next = nullptr; // 断开 slow 与前一个节点的连接 return slow; &#125; // 21. 合并两个有序链表 (双指针) ListNode* mergeTwoLists(ListNode* list1, ListNode* list2) &#123; ListNode dummy; ListNode* cur = &amp;dummy; while (list1 &amp;&amp; list2) &#123; if (list1-&gt;val &lt; list2-&gt;val) &#123; cur-&gt;next = list1; list1 = list1-&gt;next; &#125; else &#123; cur-&gt;next = list2; list2 = list2-&gt;next; &#125; cur = cur-&gt;next; &#125; cur-&gt;next = list1 ? list1 : list2; return dummy.next; &#125; ListNode* sortList(ListNode* head) &#123; if (!head || !head-&gt;next) return head; ListNode* mid = middleNode(head); ListNode* head1 = sortList(head); ListNode* head2 = sortList(mid); return mergeTwoLists(head1, head2); &#125;&#125;;","tags":["LeetCode","数据结构"],"categories":["数据结构与算法"]},{"title":"差分数组","path":"/post/数据结构与算法/difference-array/","content":"✅ 差分数组相关例题： 2848. 与车相交的点 1094. 拼车 1109. 航班预订统计 2406. 将区间分为最少组数 2381. 字母移位 II 2772. 使数组中的所有元素都等于零 2528. 最大化城市的最小电量 难点：如何快速地「把区间内的数都加一」呢？ 2848. 与车相交的点（一维差分数组）给你一个下标从 0 开始的二维整数数组 nums 表示汽车停放在数轴上的坐标。对于任意下标 i，nums[i] = [starti, endi] ，其中 starti 是第 i 辆车的起点，endi 是第 i 辆车的终点。 返回数轴上被车 任意部分 覆盖的整数点的数目。 示例 1： 123输入：nums = [[3,6],[1,5],[4,7]]输出：7解释：从 1 到 7 的所有点都至少与一辆车相交，因此答案为 7 。 示例 2： 123输入：nums = [[1,3],[5,8]]输出：7解释：1、2、3、5、6、7、8 共计 7 个点满足至少与一辆车相交，因此答案为 7 。 1️⃣ 差分数组核心思路：计算每个点被覆盖了多少次。统计覆盖次数大于 0 的点，即为答案。 假设一开始有一个全为 0 的数组 a，用来保存每个点被覆盖了多少次。 对于示例 1，我们可以把 a 中下标在 [3,6] 的元素都加一，下标在 [1,5] 的元素都加一，下标在 [4,7] 的元素都加一。 然后，统计 a[i] &gt; 0 的个数，即为答案。 如何快速地「把区间内的数都加一」呢？ 这可以用差分数组实现。 12345678910111213141516171819class Solution &#123;public: int numberOfPoints(vector&lt;vector&lt;int&gt;&gt;&amp; nums) &#123; int max_end = ranges::max(nums, &#123;&#125;, [](const auto&amp; a) &#123; return a[1]; &#125;)[1]; vector&lt;int&gt; diff(max_end + 2); // 首尾两点做标记 for (auto&amp; interval : nums) &#123; diff[interval[0]]++; diff[interval[1] + 1]--; &#125; // s += d int s = 0, ans = 0; for (int d : diff) &#123; s += d; ans += s &gt; 0; &#125; return ans; &#125;&#125;; 1094. 拼车车上最初有 capacity 个空座位。车 只能 向一个方向行驶（也就是说，不允许掉头或改变方向） 给定整数 capacity 和一个数组 trips , trip[i] = [numPassengersi, fromi, toi] 表示第 i 次旅行有 numPassengersi 乘客，接他们和放他们的位置分别是 fromi 和 toi 。这些位置是从汽车的初始位置向东的公里数。 当且仅当你可以在所有给定的行程中接送所有乘客时，返回 true，否则请返回 false。 示例 1： 12输入：trips = [[2,1,5],[3,3,7]], capacity = 4输出：false 示例 2： 12输入：trips = [[2,1,5],[3,3,7]], capacity = 5输出：true 1️⃣ 差分数组123456789101112131415161718192021class Solution &#123;public: bool carPooling(vector&lt;vector&lt;int&gt;&gt;&amp; trips, int capacity) &#123; // ranges::max(list, comp, proj) int max_end = ranges::max(trips, &#123;&#125;, [](const auto&amp; a) &#123; return a[2]; &#125;)[2]; vector&lt;int&gt; diff(max_end + 1); for (auto&amp; trip : trips) &#123; int num = trip[0], from = trip[1], to = trip[2]; diff[from] += num; // 不一定要 +1，根据题目情况而变 diff[to] -= num; &#125; int s = 0; for (int d : diff) &#123; s += d; if (s &gt; capacity) return false; &#125; return true; &#125;&#125;;","tags":["LeetCode","算法"],"categories":["数据结构与算法"]},{"title":"快手一面｜合并 K 个升序链表","path":"/post/数据结构与算法/kuaishou-merge-k-ascending-linked-lists/","content":"快手一面 &amp; 时间复杂度快手一面，面试官说来一题简单题😊，最后还问了时间复杂度：假设 k 个链表，共 n 个节点，那时间复杂度为 $O(k·logk+n·logk)$ 即 $O(n·logk)$。 23. 合并 K 个升序链表给你一个链表数组，每个链表都已经按升序排列。 请你将所有链表合并到一个升序链表中，返回合并后的链表。 示例 1： 12345678910输入：lists = [[1,4,5],[1,3,4],[2,6]]输出：[1,1,2,3,4,4,5,6]解释：链表数组如下：[ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6]将它们合并到一个有序链表中得到。1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6 1️⃣ 最小堆时间复杂度分析：假设 $k$ 个链表, 共 $n$ 个节点, 最小堆单次操作 $O(log k)$, 初始化堆需要 $O(k·logk)$, 那时间复杂度为 $O(k·logk + n·logk)$，即 $O(n·logk)$。 1234567891011121314151617181920212223242526272829303132333435/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; auto cmp = [](const ListNode* a, const ListNode* b) &#123; return a-&gt;val &gt; b-&gt;val; &#125;; priority_queue&lt;ListNode*, vector&lt;ListNode*&gt;, decltype(cmp)&gt; pq; for (auto&amp; head : lists) &#123; if (head) &#123; pq.push(head); &#125; &#125; ListNode dummy&#123;&#125;; ListNode* head = &amp;dummy; while (!pq.empty()) &#123; ListNode* node = pq.top(); pq.pop(); head-&gt;next = node; head = head-&gt;next; if (node-&gt;next) pq.push(node-&gt;next); &#125; return dummy.next; &#125;&#125;; 2️⃣ 分治法前置题目：21. 合并两个有序链表 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeTwoLists(ListNode* list1, ListNode* list2) &#123; ListNode dummy&#123;&#125;; ListNode* cur = &amp;dummy; while (list1 &amp;&amp; list2) &#123; if (list1-&gt;val &lt; list2-&gt;val) &#123; cur-&gt;next = list1; list1 = list1-&gt;next; &#125; else &#123; cur-&gt;next = list2; list2 = list2-&gt;next; &#125; cur = cur-&gt;next; &#125; cur-&gt;next = list1 ? list1 : list2; return dummy.next; &#125; ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists, int l, int r) &#123; if (l == r) return lists[l]; if (l &gt; r) return nullptr; int m = (l + r) &gt;&gt; 1; auto left = mergeKLists(lists, l, m); auto right = mergeKLists(lists, m + 1, r); return mergeTwoLists(left, right); &#125; ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; return mergeKLists(lists, 0, lists.size() - 1); &#125;&#125;; 复习「堆排序」123456789101112131415161718192021222324252627282930313233343536class Solution &#123;public: // 向下调整 void heapify(vector&lt;int&gt;&amp; nums, int i, int n) &#123; int largest = i; int left = i * 2 + 1; int right = i * 2 + 2; if (left &lt; n &amp;&amp; nums[left] &gt; nums[largest]) largest = left; if (right &lt; n &amp;&amp; nums[right] &gt; nums[largest]) largest = right; if (largest != i) &#123; swap(nums[largest], nums[i]); heapify(nums, largest, n); &#125; &#125; void heapsort(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); // i = n / 2 也可, 多判断一次而已 // 向上初始化构建, 获取数组最大值 for (int i = n / 2 - 1; i &gt;= 0; i--) &#123; heapify(nums, i, n); &#125; // 最大值不断调整到末尾, 并对新元素 nums[0] 向下进行调整 for (int i = n - 1; i &gt;= 0; i--) &#123; swap(nums[i], nums[0]); heapify(nums, 0, i); // 每次都从 0 开始调整 &#125; &#125; vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) &#123; heapsort(nums); return nums; &#125;&#125;;","tags":["LeetCode","算法"],"categories":["数据结构与算法"]},{"title":"高频「大数相加」面试题","path":"/post/数据结构与算法/interview-add-two/","content":"这是一种经常考察的思维：大数相加。一般有以下几种数据结构类型的考察方式： 数组：66. 加一 字符串：415. 字符串相加 链表： 2. 两数相加｜顺序➕ 445. 两数相加 II｜逆序➕（腾讯 CDG 一面） 二进制：67. 二进制求和 大数相乘：43. 字符串相乘 66. 加一｜数组版给定一个由 整数 组成的 非空 数组所表示的非负整数，在该数的基础上加一。 最高位数字存放在数组的首位， 数组中每个元素只存储单个数字。 你可以假设除了整数 0 之外，这个整数不会以零开头。 123输入：digits = [1,2,3]输出：[1,2,4]解释：输入数组表示数字 123。 123456789101112131415class Solution &#123;public: vector&lt;int&gt; plusOne(vector&lt;int&gt;&amp; digits) &#123; int n = digits.size(), add = 1; for (int i = n - 1; i &gt;= 0 &amp;&amp; add; i--) &#123; int res = digits[i] + 1; digits[i] = res % 10; add = res / 10; &#125; if (add) &#123; digits.insert(digits.begin(), 1); &#125; return digits; &#125;&#125;; 415. 字符串相加｜字符串版给定两个字符串形式的非负整数 num1 和num2 ，计算它们的和并同样以字符串形式返回。 你不能使用任何內建的用于处理大整数的库（比如 BigInteger）， 也不能直接将输入的字符串转换为整数形式。 示例 1： 12输入：num1 = &quot;11&quot;, num2 = &quot;123&quot;输出：&quot;134&quot; 123456789101112131415161718class Solution &#123;public: string addStrings(string num1, string num2) &#123; int i = num1.length() - 1, j = num2.length() - 1, add = 0; string ans = &quot;&quot;; while (i &gt;= 0 || j &gt;= 0 || add) &#123; int x = i &gt;= 0 ? num1[i] - &#x27;0&#x27; : 0; int y = j &gt;= 0 ? num2[j] - &#x27;0&#x27; : 0; int result = x + y + add; ans.push_back(&#x27;0&#x27; + result % 10); add = result / 10; i--; j--; &#125; reverse(ans.begin(), ans.end()); return ans; &#125;&#125;; 2. 两数相加｜链表版 · 从头开始➕ 123输入：l1 = [2,4,3], l2 = [5,6,4]输出：[7,0,8]解释：342 + 465 = 807. 12输入：l1 = [9,9,9,9,9,9,9], l2 = [9,9,9,9]输出：[8,9,9,9,0,0,0,1] 1️⃣ 迭代123456789101112131415161718192021222324252627282930313233/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; ListNode dummy; ListNode* cur = &amp;dummy; int carry = 0; while (l1 || l2 || carry) &#123; int res = 0; if (l1) &#123; res += l1-&gt;val; l1 = l1-&gt;next; &#125; if (l2) &#123; res += l2-&gt;val; l2 = l2-&gt;next; &#125; res += carry; carry = res / 10; cur = cur-&gt;next = new ListNode(res % 10); &#125; return dummy.next; &#125;&#125;; 2️⃣ 递归12345678910111213141516171819202122232425/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2, int carry = 0) &#123; if (!l1 &amp;&amp; !l2) &#123; return carry ? new ListNode(carry) : nullptr; &#125; if (!l1) &#123; swap(l1, l2); &#125; int sum = carry + l1-&gt;val + (l2 ? l2-&gt;val : 0); l1-&gt;val = sum % 10; l1-&gt;next = addTwoNumbers(l1-&gt;next, (l2 ? l2-&gt;next : nullptr), sum / 10); return l1; &#125;&#125;; 445. 两数相加 II｜链表版 · 从尾开始➕ 12输入：l1 = [7,2,4,3], l2 = [5,6,4]输出：[7,8,0,7] ✅ 两数相加 II &#x3D; 两数相加 + 反转链表 1️⃣ 迭代｜206. 反转链表（迭代）+ 2. 两数相加（迭代）123456789101112131415161718192021222324252627282930313233343536class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; ListNode* pre = nullptr; ListNode* cur = head; while (cur) &#123; ListNode* nxt = cur-&gt;next; cur-&gt;next = pre; pre = cur; cur = nxt; &#125; return pre; &#125; ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; l1 = reverseList(l1); l2 = reverseList(l2); ListNode dummy; ListNode* cur = &amp;dummy; int carry = 0; while (l1 || l2 || carry) &#123; int res = carry; if (l1) &#123; res += l1-&gt;val; l1 = l1-&gt;next; &#125; if (l2) &#123; res += l2-&gt;val; l2 = l2-&gt;next; &#125; carry = res / 10; cur = cur-&gt;next = new ListNode(res % 10); &#125; return reverseList(dummy.next); &#125;&#125;; 2️⃣ 递归｜206. 反转链表（递归）+ 2. 两数相加（递归）1234567891011121314151617181920212223242526272829303132class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; if (!head || !head-&gt;next) &#123; return head; &#125; ListNode* new_head = reverseList(head-&gt;next); head-&gt;next-&gt;next = head; head-&gt;next = nullptr; return new_head; &#125; ListNode* addTwo(ListNode* l1, ListNode* l2, int carry = 0) &#123; if (!l1 &amp;&amp; !l2) &#123; return carry ? new ListNode(carry) : nullptr; &#125; if (!l1) &#123; swap(l1, l2); &#125; int sum = carry + l1-&gt;val + (l2 ? l2-&gt;val : 0); l1-&gt;val = sum % 10; l1-&gt;next = addTwo(l1-&gt;next, (l2 ? l2-&gt;next : nullptr), sum / 10); return l1; &#125; ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; l1 = reverseList(l1); l2 = reverseList(l2); ListNode* head = addTwo(l1, l2, 0); return reverseList(head); &#125;&#125;; 67. 二进制求和｜二进制版给你两个二进制字符串 a 和 b ，以二进制字符串的形式返回它们的和。 示例 1： 12输入:a = &quot;11&quot;, b = &quot;1&quot;输出：&quot;100&quot; 示例 2： 12输入：a = &quot;1010&quot;, b = &quot;1011&quot;输出：&quot;10101&quot; 1234567891011121314151617class Solution &#123;public: string addBinary(string a, string b) &#123; int carry = 0; int i = a.length() - 1, j = b.length() - 1; string ans; while (i &gt;= 0 || j &gt;= 0 || carry) &#123; int x = i &gt;= 0 ? a[i--] - &#x27;0&#x27; : 0; int y = j &gt;= 0 ? b[j--] - &#x27;0&#x27; : 0; int s = x + y + carry; carry = s / 2; ans.push_back(s % 2 + &#x27;0&#x27;); &#125; reverse(ans.begin(), ans.end()); return ans; &#125;&#125;; 43. 字符串相乘｜大数相乘✖️给定两个以字符串形式表示的非负整数 num1 和 num2，返回 num1 和 num2 的乘积，它们的乘积也表示为字符串形式。 **注意：**不能使用任何内置的 Big Integer 库或直接将输入转换为整数。 示例 1: 12输入: num1 = &quot;2&quot;, num2 = &quot;3&quot;输出: &quot;6&quot; 示例 2: 12输入: num1 = &quot;123&quot;, num2 = &quot;456&quot;输出: &quot;56088&quot; 1️⃣ 竖式相加思路：建立在「大数相加」的基础上，因为多个数之间需要累加（容易理解） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Solution &#123;public: // 大数相加 string addStrings(string num1, string num2) &#123; int i = num1.length() - 1, j = num2.length() - 1, add = 0; string ans = &quot;&quot;; while (i &gt;= 0 || j &gt;= 0 || add) &#123; int x = i &gt;= 0 ? num1[i] - &#x27;0&#x27; : 0; int y = j &gt;= 0 ? num2[j] - &#x27;0&#x27; : 0; int result = x + y + add; add = result / 10; ans.push_back(&#x27;0&#x27; + result % 10); i--; j--; &#125; reverse(ans.begin(), ans.end()); return ans; &#125; // 大数相乘 string multiply(string num1, string num2) &#123; if (num1 == &quot;0&quot; || num2 == &quot;0&quot;) return &quot;0&quot;; int multiply = 0; int m = num1.length(), n = num2.length(); string ans = &quot;0&quot;; for (int i = m - 1; i &gt;= 0; i--) &#123; int x = num1[i] - &#x27;0&#x27;; string num; int add = 0; for (int j = n - 1; j &gt;= 0 || add; j--) &#123; if (x == 0) &#123; num = &quot;0&quot;; break; &#125; if (j &lt; 0) &#123; num.push_back(&#x27;0&#x27; + add); break; &#125; int y = num2[j] - &#x27;0&#x27;; int result = x * y + add; add = result / 10; num.push_back(&#x27;0&#x27; + result % 10); &#125; reverse(num.begin(), num.end()); if (num != &quot;0&quot;) ans = addStrings(ans, num + string(multiply, &#x27;0&#x27;)); multiply++; &#125; return ans; &#125;&#125;; 2️⃣ 相乘 思路：直接做乘法，长度分别为 m 和 n 的数字相乘，值长度不超过 m + n，vector&lt;int&gt; ansArr(m + n) 12345678910111213141516171819202122232425262728class Solution &#123;public: string multiply(string num1, string num2) &#123; if (num1 == &quot;0&quot; || num2 == &quot;0&quot;) &#123; return &quot;0&quot;; &#125; int m = num1.length(), n = num2.length(); vector&lt;int&gt; ansArr(m + n); for (int i = m - 1; i &gt;= 0; i--) &#123; int x = num1[i] - &#x27;0&#x27;; for (int j = n - 1; j &gt;= 0; j--) &#123; int y = num2[j] - &#x27;0&#x27;; ansArr[i + j + 1] += x * y; &#125; &#125; for (int i = m + n - 1; i &gt; 0; i--) &#123; ansArr[i - 1] += ansArr[i] / 10; ansArr[i] %= 10; &#125; int idx = ansArr[0] == 0 ? 1 : 0; string ans; while (idx &lt; m + n) &#123; ans.push_back(&#x27;0&#x27; + ansArr[idx]); idx++; &#125; return ans; &#125;&#125;;","tags":["LeetCode","算法"],"categories":["数据结构与算法"]},{"title":"单调栈","path":"/post/数据结构与算法/monotonic-stack/","content":"✅ 单调栈相关例题 739. 每日温度 496. 下一个更大元素 I 503. 下一个更大元素 II 84. 柱状图中最大的矩形｜Hard 42. 接雨水｜Hard 407. 接雨水 II｜Hard 907. 子数组的最小值之和｜Medium 1793. 好子数组的最大分数｜Hard 84. 柱状图中最大的矩形给定 n 个非负整数，用来表示柱状图中各个柱子的高度。每个柱子彼此相邻，且宽度为 1 。 求在该柱状图中，能够勾勒出来的矩形的最大面积。 示例 1: 123输入：heights = [2,1,5,6,2,3]输出：10解释：最大的矩形为图中红色区域，面积为 10 1️⃣ 单调栈1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: int largestRectangleArea(vector&lt;int&gt; &amp;heights) &#123; int n = heights.size(); vector&lt;int&gt; left(n, -1); stack&lt;int&gt; st; for (int i = 0; i &lt; n; i++) &#123; while (!st.empty() &amp;&amp; heights[i] &lt;= heights[st.top()]) &#123; st.pop(); &#125; if (!st.empty()) &#123; left[i] = st.top(); &#125; st.push(i); &#125; vector&lt;int&gt; right(n, n); st = stack&lt;int&gt;(); for (int i = n - 1; i &gt;= 0; i--) &#123; while (!st.empty() &amp;&amp; heights[i] &lt;= heights[st.top()]) &#123; st.pop(); &#125; if (!st.empty()) &#123; right[i] = st.top(); &#125; st.push(i); &#125; int ans = 0; for (int i = 0; i &lt; n; i++) &#123; ans = max(ans, heights[i] * (right[i] - left[i] - 1)); &#125; return ans; &#125;&#125;; 42. 接雨水（常用「相向双指针」方法）给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。 示例 1： 123输入：height = [0,1,0,2,1,0,1,3,2,1,2,1]输出：6解释：上面是由数组 [0,1,0,2,1,0,1,3,2,1,2,1] 表示的高度图，在这种情况下，可以接 6 个单位的雨水（蓝色部分表示雨水）。 1️⃣ 前后缀分离1234567891011121314151617181920212223class Solution &#123;public: int trap(vector&lt;int&gt;&amp; height) &#123; int n = height.size(); vector&lt;int&gt; pre_max(n); // pre_max[i] 表示从 height[0] 到 height[i] 的最大值 pre_max[0] = height[0]; for (int i = 1; i &lt; n; i++) &#123; pre_max[i] = max(pre_max[i - 1], height[i]); &#125; vector&lt;int&gt; suf_max(n); // suf_max[i] 表示从 height[i] 到 height[n-1] 的最大值 suf_max[n - 1] = height[n - 1]; for (int i = n - 2; i &gt;= 0; i--) &#123; suf_max[i] = max(suf_max[i + 1], height[i]); &#125; int ans = 0; for (int i = 0; i &lt; n; i++) &#123; ans += min(pre_max[i], suf_max[i]) - height[i]; // 累加每个水桶能接多少水 &#125; return ans; &#125;&#125;; 2️⃣ 相向双指针（谁小谁移动） 利用这个思路可以完成「3D 接雨水」 注意 while 循环可以不加等号，因为在「谁小移动谁」的规则下，相遇的位置一定是最高的柱子，这个柱子是无法接水的。 123456789101112class Solution &#123;public: int trap(vector&lt;int&gt;&amp; height) &#123; int ans = 0, left = 0, right = height.size() - 1, pre_max = 0, suf_max = 0; while (left &lt; right) &#123; pre_max = max(pre_max, height[left]); suf_max = max(suf_max, height[right]); ans += pre_max &lt; suf_max ? pre_max - height[left++] : suf_max - height[right--]; &#125; return ans; &#125;&#125;; 3️⃣ 单调栈上面的方法相当于「竖着」计算面积，单调栈的做法相当于「横着」计算面积。 这个方法可以总结成 16 个字：找上一个更大元素，在找的过程中填坑。 注意 while 中加了等号，这可以让栈中没有重复元素，从而在有很多重复元素的情况下，使用更少的空间。 123456789101112131415161718192021class Solution &#123;public: int trap(vector&lt;int&gt;&amp; height) &#123; int ans = 0; stack&lt;int&gt; st; for (int i = 0; i &lt; height.size(); i++) &#123; while (!st.empty() &amp;&amp; height[i] &gt;= height[st.top()]) &#123; int bottom_h = height[st.top()]; st.pop(); if (st.empty()) &#123; break; &#125; int left = st.top(); int dh = min(height[left], height[i]) - bottom_h; // 面积的高 ans += dh * (i - left - 1); &#125; st.push(i); &#125; return ans; &#125;&#125;; 407. 接雨水 II（短板效应）给你一个 m x n 的矩阵，其中的值均为非负整数，代表二维高度图每个单元的高度，请计算图中形状最多能接多少体积的雨水。 示例 1: 123输入: heightMap = [[1,4,3,1,3,2],[3,2,1,3,2,4],[2,3,3,2,3,1]]输出: 4解释: 下雨后，雨水将会被上图蓝色的方块中。总的接雨水量为1+2+1=4。 示例 2: 12输入: heightMap = [[3,3,3,3,3],[3,2,2,2,3],[3,2,1,2,3],[3,2,2,2,3],[3,3,3,3,3]]输出: 10 1️⃣ 优先队列 priority_queue 维护短板哪个格子的接水量，在一开始就能确定？ 最外面一圈的格子是无法接水的。 假设 (0,1) 的高度是最外面一圈的格子中最小的，且高度等于 5，那么和它相邻的 (1,1)，我们能知道： (1,1) 的水位不能超过 5，否则水会从 (0,1) 流出去。 (1,1) 的水位一定可以等于 5，这是因为 (0,1) 的高度是最外面一圈的格子中最小的，(1,1) 的水不可能从其他地方流出去。 我们从最外面一圈的格子开始。想象成一个木桶，最外面一圈格子的高度视作木板的高度。 接着上面的讨论： 如果 (1,1) 的高度 ≥5，那么 (0,1) 这块木板就没用了，我们去掉 (0,1) 这块木板，改用 (1,1) 这块木板。 如果 (1,1) 的高度 &lt;5，假设我们接的不是水，是水泥。那么把 (1,1) 的高度填充为 5，仍然可以去掉 (0,1) 这块木板，改用 (1,1) 这块（填充水泥后）高为 5 的木板水泥板。 继续，从当前木板中，找到一根最短的木板。假设 (1,1) 是当前所有木板中最短的，那么其邻居 (1,2) 和 (2,1) 的水位就是 (1,1) 的高度，因为超过 (1,1) 高度的水会流出去。然后，去掉 (1,1) 这块木板，改用 (1,2) 和 (2,1) 这两块木板。依此类推。 由于每次都要找最短的木板，所以用一个最小堆维护木板的高度。按照上述做法，不断循环，直到堆为空。 为方便实现，代码在初始化堆的时候，直接遍历了整个矩阵。 「42. 接雨水」那题需要维护左右两个指针，本题相当于维护了“一圈”指针。42 那题每次取左右最小的指针，然后移动到相邻位置上；本题也是取最小的指针（出堆），往周围的邻居移动（入堆）。 1234567891011121314151617181920212223242526272829303132class Solution &#123; static constexpr int DIRS[4][2] = &#123;&#123;0, 1&#125;, &#123;0, -1&#125;, &#123;1, 0&#125;, &#123;-1, 0&#125;&#125;;public: int trapRainWater(vector&lt;vector&lt;int&gt;&gt;&amp; heightMap) &#123; int m = heightMap.size(), n = heightMap[0].size(); priority_queue&lt;tuple&lt;int, int, int&gt;, vector&lt;tuple&lt;int, int, int&gt;&gt;, greater&lt;&gt;&gt; pq; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if (i == 0 || i == m - 1 || j == 0 || j == n - 1) &#123; pq.push(&#123;heightMap[i][j], i, j&#125;); heightMap[i][j] = -1; &#125; &#125; &#125; int ans = 0; while (!pq.empty()) &#123; auto [min_height, i, j] = pq.top(); pq.pop(); for (auto&amp; [dx, dy] : DIRS) &#123; int x = i + dx; int y = j + dy; if (x &gt;= 0 &amp;&amp; y &gt;= 0 &amp;&amp; x &lt; m &amp;&amp; y &lt; n &amp;&amp; heightMap[x][y] != -1) &#123; ans += max(min_height - heightMap[x][y], 0); pq.push(&#123;max(min_height, heightMap[x][y]), x, y&#125;); heightMap[x][y] = -1; &#125; &#125; &#125; return ans; &#125;&#125;; 907. 子数组的最小值之和给定一个整数数组 arr，找到 min(b) 的总和，其中 b 的范围为 arr 的每个（连续）子数组。 由于答案可能很大，因此 返回答案模 10^9 + 7 。 示例 1： 12345输入：arr = [3,1,2,4]输出：17解释：子数组为 [3]，[1]，[2]，[4]，[3,1]，[1,2]，[2,4]，[3,1,2]，[1,2,4]，[3,1,2,4]。 最小值为 3，1，2，4，1，1，2，1，1，1，和为 17。 1️⃣ 单调栈解法等价于「84. 柱状图中最大的矩形」，本题计算以 arr[i] 为最小值的子数组的个数： 123456789101112131415161718192021222324252627282930313233343536class Solution &#123; const int MOD = 1e9 + 7;public: // 类似题目: 84. 柱状图中最大的矩形 int sumSubarrayMins(vector&lt;int&gt;&amp; arr) &#123; int n = arr.size(); // 左边界 left[i] 为左侧严格小于 arr[i] 的最近元素位置（不存在时为 -1） vector&lt;int&gt; left(n, -1); stack&lt;int&gt; st; for (int i = 0; i &lt; n; i++) &#123; while (!st.empty() &amp;&amp; arr[st.top()] &gt;= arr[i]) st.pop(); if (!st.empty()) left[i] = st.top(); st.push(i); &#125; st = stack&lt;int&gt;(); // 右侧找 &lt;= 是为了避免重复统计 // 右边界 right[i] 为右侧小于等于 arr[i] 的最近元素位置（不存在时为 n） vector&lt;int&gt; right(n, n); for (int i = n - 1; i &gt;= 0; i--) &#123; while (!st.empty() &amp;&amp; arr[st.top()] &gt; arr[i]) st.pop(); if (!st.empty()) right[i] = st.top(); st.push(i); &#125; long ans = 0l; for (int i = 0; i &lt; n; i++) &#123; ans += (long)arr[i] * (i - left[i]) * (right[i] - i); &#125; return ans % MOD; &#125;&#125;; 1793. 好子数组的最大分数给你一个整数数组 nums **（下标从 0 开始）**和一个整数 k 。 一个子数组 (i, j) 的 分数 定义为 min(nums[i], nums[i+1], ..., nums[j]) * (j - i + 1) 。一个 好 子数组的两个端点下标需要满足 i &lt;= k &lt;= j 。 请你返回 好 子数组的最大可能 分数 。 示例 1： 123输入：nums = [1,4,3,7,4,5], k = 3输出：15解释：最优子数组的左右端点下标是 (1, 5) ，分数为 min(4,3,7,4,5) * (5-1+1) = 3 * 5 = 15 。 1️⃣ 背向双指针我们尝试从 $i&#x3D;k, j&#x3D;k$ 出发，通过不断移动指针来找到最大矩形。比较 nums[i−1] 和 nums[j+1] 的大小，谁大就移动谁（一样大移动哪个都可以）。 12345678910111213141516class Solution &#123;public: int maximumScore(vector&lt;int&gt;&amp; nums, int k) &#123; int max_score = nums[k], n = nums.size(), mn = nums[k]; int l = k, r = k; for (int t = 1; t &lt; n; t++) &#123; if (r == n - 1 || (l &amp;&amp; nums[l - 1] &gt; nums[r + 1])) &#123; mn = min(mn, nums[--l]); &#125; else &#123; mn = min(mn, nums[++r]); &#125; max_score = max(max_score, mn * (r - l + 1)); &#125; return max_score; &#125;&#125;; 2️⃣ 单调栈本题要计算的分数，和「84. 柱状图中最大的矩形」是一样的，计算的是最大矩形面积，只不过多了一个约束：矩形必须包含下标 k。 1234567891011121314151617181920212223242526272829303132class Solution &#123;public: int maximumScore(vector&lt;int&gt;&amp; nums, int k) &#123; int n = nums.size(); vector&lt;int&gt; left(n), right(n); stack&lt;int&gt; st; for (int i = 0; i &lt; n; i++) &#123; while (!st.empty() &amp;&amp; nums[st.top()] &gt;= nums[i]) &#123; st.pop(); &#125; left[i] = st.empty() ? -1 : st.top(); st.push(i); &#125; st = stack&lt;int&gt;(); for (int i = n - 1; i &gt;= 0; i--) &#123; while (!st.empty() &amp;&amp; nums[st.top()] &gt;= nums[i]) &#123; st.pop(); &#125; right[i] = st.empty() ? n : st.top(); st.push(i); &#125; int ans = 0; for (int i = 0; i &lt; n; i++) &#123; // 分数的定义其实就是矩形面积: 同「84. 柱状图中最大的矩形」 int score = nums[i] * (right[i] - left[i] - 1); // 仅仅加一个判断条件即可 if (left[i] &lt; k &amp;&amp; right[i] &gt; k) ans = max(ans, score); &#125; return ans; &#125;&#125;;","tags":["LeetCode","数据结构"],"categories":["数据结构与算法"]},{"title":"模运算","path":"/post/数据结构与算法/modulo/","content":"✅ 模运算✅ 更多细节：0x3f 分享丨模运算的世界：当加减乘除遇上取模（模运算恒等式&#x2F;费马小定理） 代码实现时，加减乘除如下： 12345678910111213141516171819MOD = 1_000_000_007// 加‼️(a + b) % MOD = ((a % MOD) + (b % MOD)) % MOD// 减(a - b + MOD) % MOD// 把任意整数 a 取模到 [0,MOD-1] 中，无论 a 是正是负(a % MOD + MOD) % MOD// 乘（注意使用 64 位整数）‼️a * b % MOD = ((a % MOD) * (b % MOD)) % MOD// 多个数相乘，要步步取模，防止溢出a * b % MOD * c % MOD// 除（MOD 是质数且 b 不是 MOD 的倍数）a * qpow(b, MOD - 2, MOD) % MOD 其中 qpow 为快速幂，具体请看【图解】一张图秒懂快速幂。 注：Python 内置快速幂函数 pow(x, y, m) 用于计算 $x^y\\ mod\\ m$。特别地，除法也可以写成 a * pow(b, -1, MOD) % MOD 总之，如果发现解答错误，可以检查下代码，看看是不是哪里漏掉取模了。 取模练习题｜3379. 转换数组给你一个整数数组 nums，它表示一个循环数组。请你遵循以下规则创建一个大小 相同 的新数组 result ： 对于每个下标 i（其中 0 &lt;= i &lt; nums.length），独立执行以下操作： 如果 nums[i] &gt; 0：从下标 i 开始，向 右 移动 nums[i] 步，在循环数组中落脚的下标对应的值赋给 result[i]。 如果 nums[i] &lt; 0：从下标 i 开始，向 左 移动 abs(nums[i]) 步，在循环数组中落脚的下标对应的值赋给 result[i]。 如果 nums[i] == 0：将 nums[i] 的值赋给 result[i]。 返回新数组 result。 **注意：**由于 nums 是循环数组，向右移动超过最后一个元素时将回到开头，向左移动超过第一个元素时将回到末尾。 示例 1： 输入： nums &#x3D; [3,-2,1,1] 输出： [1,1,1,3] 解释： 对于 nums[0] 等于 3，向右移动 3 步到 nums[3]，因此 result[0] 为 1。 对于 nums[1] 等于 -2，向左移动 2 步到 nums[3]，因此 result[1] 为 1。 对于 nums[2] 等于 1，向右移动 1 步到 nums[3]，因此 result[2] 为 1。 对于 nums[3] 等于 1，向右移动 1 步到 nums[0]，因此 result[3] 为 3。 123456789101112class Solution &#123;public: vector&lt;int&gt; constructTransformedArray(vector&lt;int&gt;&amp; nums) &#123; // 由于数组是循环数组，把下标对 n 取模 int n = nums.size(); vector&lt;int&gt; result(n); for (int i = 0; i &lt; n; i++) &#123; result[i] = nums[((i + nums[i]) % n + n) % n]; &#125; return result; &#125;&#125;;","tags":["LeetCode","算法"],"categories":["数据结构与算法"]},{"title":"动态规划｜子数组或子序列的乘积最大值","path":"/post/数据结构与算法/maximum-product-of-subarray-or-subsequence/","content":"字节面试原题⁉️ 「子数组」乘积最大值：152. 乘积最大子数组 「子序列」乘积最大值：2708. 一个小组的最大实力值 「三维子数组」乘积最大值：1594. 矩阵的最大非负积（本题为「鹅厂」与「字节」面试算法题，也是「152. 乘积最大子数组」的升维算法题） 「子数组」乘积最大值：152. 乘积最大子数组给你一个整数数组 nums ，请你找出数组中乘积最大的非空连续 子数组（该子数组中至少包含一个数字），并返回该子数组所对应的乘积。 123输入: nums = [2,3,-2,4]输出: 6解释: 子数组 [2,3] 有最大乘积 6。 123输入: nums = [-2,0,-1]输出: 0解释: 结果不能为 2, 因为 [-2,-1] 不是子数组。 123456789101112class Solution &#123;public: int maxProduct(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); vector&lt;long&gt; mx(nums.begin(), nums.end()), mn(nums.begin(), nums.end()); for (int i = 1; i &lt; n; i++) &#123; mx[i] = max(&#123;mx[i - 1] * nums[i], (long)nums[i], mn[i - 1] * nums[i]&#125;); mn[i] = min(&#123;mn[i - 1] * nums[i], (long)nums[i], mx[i - 1] * nums[i]&#125;); &#125; return *max_element(mx.begin(), mx.end()); &#125;&#125;; 「子序列」乘积最大值：2708. 一个小组的最大实力值给你一个下标从 0 开始的整数数组 nums ，它表示一个班级中所有学生在一次考试中的成绩。老师想选出一部分同学组成一个 非空 小组，且这个小组的 实力值 最大，如果这个小组里的学生下标为 i0, i1, i2, … , ik ，那么这个小组的实力值定义为 nums[i0] * nums[i1] * nums[i2] * ... * nums[ik] 。 请你返回老师创建的小组能得到的最大实力值为多少。 123输入：nums = [3,-1,-5,2,5,-9]输出：1350解释：一种构成最大实力值小组的方案是选择下标为 [0,2,3,4,5] 的学生。实力值为 3 * (-5) * 2 * 5 * (-9) = 1350 ，这是可以得到的最大实力值。 123输入：nums = [-4,-5,-4]输出：20解释：选择下标为 [0, 1] 的学生。得到的实力值为 20 。我们没法得到更大的实力值。 12345678910111213class Solution &#123;public: long long maxStrength(vector&lt;int&gt;&amp; nums) &#123; long long mn = nums[0], mx = mn; for (int i = 1; i &lt; nums.size(); i++) &#123; long long x = nums[i]; long long tmp = mn; mn = min(&#123;mn, x, mn * x, mx * x&#125;); mx = max(&#123;mx, x, tmp * x, mx * x&#125;); &#125; return mx; &#125;&#125;; 「三维子数组」乘积最大值：1594. 矩阵的最大非负积给你一个大小为 m x n 的矩阵 grid 。最初，你位于左上角 (0, 0) ，每一步，你可以在矩阵中 向右 或 向下 移动。 在从左上角 (0, 0) 开始到右下角 (m - 1, n - 1) 结束的所有路径中，找出具有 最大非负积 的路径。路径的积是沿路径访问的单元格中所有整数的乘积。 返回 最大非负积 对 10^9 + 7 取余 的结果。如果最大积为 负数 ，则返回 -1 。 注意：取余是在得到最大积之后执行的。 示例 1： 123输入：grid = [[-1,-2,-3],[-2,-3,-3],[-3,-3,-2]]输出：-1解释：从 (0, 0) 到 (2, 2) 的路径中无法得到非负积，所以返回 -1 。 示例 2： 123输入：grid = [[1,-2,1],[1,-2,1],[3,-4,1]]输出：8解释：最大非负积对应的路径如图所示 (1 * 1 * -2 * -4 * 1 = 8) ✅ 本题为「鹅厂」与「字节」面试算法题，也是「152. 乘积最大子数组」的升维算法题 1️⃣ 三维数组第三维度记录 min 与 max，需要单独初始化第一行和第一列。 由于过程中无法确定最大值的由来，那么需要「左」和「上」的最大最小值来乘于当前值 grid[i][j]，与「乘积最大子数组」思路一致。 12345678910111213141516171819202122232425262728class Solution &#123;public: int maxProductPath(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; const int MOD = 1e9 + 7; int m = grid.size(), n = grid[0].size(); // [0]: min; [1]: max vector f(m, vector(n, vector(2, 0LL))); f[0][0] = &#123;grid[0][0], grid[0][0]&#125;; for (int j = 1; j &lt; n; j++) &#123; f[0][j][0] = f[0][j - 1][0] * grid[0][j]; f[0][j][1] = f[0][j - 1][1] * grid[0][j]; &#125; for (int i = 1; i &lt; m; i++) &#123; f[i][0][0] = f[i - 1][0][0] * grid[i][0]; f[i][0][1] = f[i - 1][0][1] * grid[i][0]; &#125; for (int i = 1; i &lt; m; i++) &#123; for (int j = 1; j &lt; n; j++) &#123; int x = grid[i][j]; f[i][j][0] = min(&#123;f[i - 1][j][0] * x, f[i - 1][j][1] * x, f[i][j - 1][0] * x, f[i][j - 1][1] * x&#125;); f[i][j][1] = max(&#123;f[i - 1][j][0] * x, f[i - 1][j][1] * x, f[i][j - 1][0] * x, f[i][j - 1][1] * x&#125;); &#125; &#125; return f[m - 1][n - 1][1] &gt;= 0 ? f[m - 1][n - 1][1] % MOD : -1; &#125;&#125;; 2️⃣ 两个二维数组相当于将方法一三维数组的第三维度拆分成两个二维数组，与「乘积最大子数组」思路一致。 123456789101112131415161718192021222324class Solution &#123;public: int maxProductPath(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; const int MOD = 1e9 + 7; int m = grid.size(), n = grid[0].size(); vector&lt;vector&lt;long long&gt;&gt; mx(m, vector&lt;long long&gt;(n)); vector&lt;vector&lt;long long&gt;&gt; mn(m, vector&lt;long long&gt;(n)); mx[0][0] = mn[0][0] = grid[0][0]; for (int j = 1; j &lt; n; j++) mx[0][j] = mn[0][j] = mx[0][j - 1] * grid[0][j]; for (int i = 1; i &lt; m; i++) mx[i][0] = mn[i][0] = mx[i - 1][0] * grid[i][0]; for (int i = 1; i &lt; m; i++) &#123; for (int j = 1; j &lt; n; j++) &#123; int x = grid[i][j]; mx[i][j] = max(&#123;mx[i - 1][j] * x, mn[i - 1][j] * x, mx[i][j - 1] * x, mn[i][j - 1] * x&#125;); mn[i][j] = min(&#123;mx[i - 1][j] * x, mn[i - 1][j] * x, mx[i][j - 1] * x, mn[i][j - 1] * x&#125;); &#125; &#125; return mx[m - 1][n - 1] &gt;= 0 ? mx[m - 1][n - 1] % MOD : -1; &#125;&#125;;","tags":["LeetCode","算法"],"categories":["数据结构与算法"]},{"title":"快速幂","path":"/post/数据结构与算法/qpow/","content":"✅ 快速幂快速幂相关题目： 2961. 双模幂运算 [1451] 2550. 猴子碰撞的方法数 [1663] 372. 超级次方 [算术评级 5] 50. Pow(x, n) [算术评级 5] 12# python 自带快速幂库函数用于计算 x^y mod mpow(x, y, m) CPP 手撕「快速幂」库函数 12345678910111213// 本题 mod 很小，即使平方也不会超过 int 范围，所以不需要用 long longint pow(int x, int n, int mod) &#123; // long long res int res = 1; while (n) &#123; if (n &amp; 1) &#123; res = res * x % mod; &#125; x = x * x % mod; n &gt;&gt;= 1; &#125; return res;&#125; 快速幂实现思路（workflow）如下图： 代码实现时，注意 n&#x3D;−$2^{31}$ 的情况，取反后 n&#x3D;$2^{31}$ 超出 int 最大值。可以转成 64 位 int 解决（即 long long） 50. Pow(x, n)（包含负数与浮点数）实现 pow(x, n) ，即计算 x 的整数 n 次幂函数（即，$x^n$ ）。 示例 1： 12输入：x = 2.00000, n = 10输出：1024.00000 示例 2： 12输入：x = 2.10000, n = 3输出：9.26100 1️⃣ 快速幂（模板代码）12345678910111213141516171819class Solution &#123;public: double myPow(double x, int N) &#123; double ans = 1; long long n = N; if (n &lt; 0) &#123; // x^-n = (1/x)^n n = -n; x = 1 / x; &#125; while (n) &#123; // 从低到高枚举 n 的每个比特位 if (n &amp; 1) &#123; // 这个比特位是 1 ans *= x; // 把 x 乘到 ans 中 &#125; x *= x; // x 自身平方 n &gt;&gt;= 1; // 继续枚举下一个比特位 &#125; return ans; &#125;&#125;; 372. 超级次方你的任务是计算 $a^b$ 对 1337 取模，a 是一个正整数，b 是一个非常大的正整数且会以数组形式给出。 示例 1： 12输入：a = 2, b = [3]输出：8 示例 2： 12输入：a = 2, b = [1,0]输出：1024 1️⃣ DFS + 快速幂12345678910111213141516171819202122232425262728class Solution &#123;public: int MOD = 1337; int qpow(int x, int n) &#123; int res = 1; // due to dfs() x %= MOD; while (n) &#123; if (n &amp; 1) &#123; res = res * x % MOD; &#125; x = x * x % MOD; n &gt;&gt;= 1; &#125; return res; &#125; int dfs(int a, vector&lt;int&gt;&amp; b, int idx) &#123; if (idx == -1) return 1; return qpow(a, b[idx]) * qpow(dfs(a, b, idx - 1), 10) % MOD; &#125; int superPow(int a, vector&lt;int&gt;&amp; b) &#123; return dfs(a, b, b.size() - 1); &#125;&#125;; 2550. 猴子碰撞的方法数现在有一个正凸多边形，其上共有 n 个顶点。顶点按顺时针方向从 0 到 n - 1 依次编号。每个顶点上 正好有一只猴子 。下图中是一个 6 个顶点的凸多边形。 每个猴子同时移动到相邻的顶点。顶点 i 的相邻顶点可以是： 顺时针方向的顶点 (i + 1) % n ，或 逆时针方向的顶点 (i - 1 + n) % n 。 如果移动后至少有两只猴子停留在同一个顶点上或者相交在一条边上，则会发生 碰撞 。 返回猴子至少发生 一次碰撞 的移动方法数。由于答案可能非常大，请返回对 109+7 取余后的结果。 注意，每只猴子只能移动一次。 示例 1： 1234567输入：n = 3输出：6解释：共计 8 种移动方式。下面列出两种会发生碰撞的方式：- 猴子 1 顺时针移动；猴子 2 逆时针移动；猴子 3 顺时针移动。猴子 1 和猴子 2 碰撞。- 猴子 1 逆时针移动；猴子 2 逆时针移动；猴子 3 顺时针移动。猴子 1 和猴子 3 碰撞。可以证明，有 6 种让猴子碰撞的方法。 1️⃣ 正难则反｜快速幂只有全部顺时针和全部逆时针这 2 种不会碰撞，所以只需要计算 $2^n-2$，这就需要用到快速幂。 C++：手搓快速幂 Python：使用内置 pow(x, n, mod) 快速幂库函数 123456789101112131415161718192021class Solution &#123;public: int MOD = 1e9 + 7; int qpow(long long x, int n) &#123; int res = 1; while (n) &#123; if (n &amp; 1) &#123; res = ((res % MOD) * (x % MOD)) % MOD; &#125; x = ((x % MOD) * (x % MOD)) % MOD; n &gt;&gt;= 1; &#125; return res; &#125; int monkeyMove(int n) &#123; int ans = qpow(2, n); return (ans - 2 + MOD) % MOD; &#125;&#125;; 1234class Solution: def monkeyMove(self, n: int) -&gt; int: MOD = 1_000_000_007 return (pow(2, n, MOD) - 2) % MOD","tags":["LeetCode","算法"],"categories":["数据结构与算法"]},{"title":"排序数组（堆排、快排、归排）","path":"/post/数据结构与算法/sort-algorithm/","content":"1️⃣ 堆排序123456789101112131415161718192021222324252627282930313233343536class Solution &#123;public: // 向下调整 void heapify(vector&lt;int&gt;&amp; nums, int i, int n) &#123; int largest = i; int left = i * 2 + 1; int right = i * 2 + 2; if (left &lt; n &amp;&amp; nums[left] &gt; nums[largest]) largest = left; if (right &lt; n &amp;&amp; nums[right] &gt; nums[largest]) largest = right; if (largest != i) &#123; swap(nums[largest], nums[i]); heapify(nums, largest, n); &#125; &#125; void heapsort(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); // i = n / 2 也可, 多判断一次而已 // 向上初始化构建, 获取数组最大值 for (int i = n / 2 - 1; i &gt;= 0; i--) &#123; heapify(nums, i, n); &#125; // 最大值不断调整到末尾, 并对新元素 nums[0] 向下进行调整 for (int i = n - 1; i &gt;= 0; i--) &#123; swap(nums[i], nums[0]); heapify(nums, 0, i); // 每次都从 0 开始调整 &#125; &#125; vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) &#123; heapsort(nums); return nums; &#125;&#125;; 2️⃣ 快速排序（朴素版）123456789101112131415161718192021222324252627282930313233class Solution &#123;public: int partition(vector&lt;int&gt;&amp; nums, int l, int r) &#123; int pivot = nums[l]; int i = l, j = r + 1; while (i &lt; j) &#123; // while (i &lt; r &amp;&amp; nums[++i] &lt; pivot) 也可 while (++i &lt; r &amp;&amp; nums[i] &lt; pivot) ; // while (j &gt; l &amp;&amp; nums[--j] &gt; pivot) 也可 while (--j &gt; l &amp;&amp; nums[j] &gt; pivot) ; if (i &lt; j) &#123; swap(nums[i], nums[j]); &#125; &#125; swap(nums[l], nums[j]); return j; &#125; void quicksort(vector&lt;int&gt;&amp; nums, int l, int r) &#123; if (l &lt; r) &#123; int pivot = partition(nums, l, r); quicksort(nums, l, pivot - 1); quicksort(nums, pivot + 1, r); &#125; &#125; vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) &#123; quicksort(nums, 0, nums.size() - 1); return nums; &#125;&#125;; 3️⃣ 快速排序（随机版 · 性能🔝）12345678910111213141516171819202122232425262728293031323334353637class Solution &#123;public: int partition(vector&lt;int&gt;&amp; nums, int l, int r) &#123; int pivot = nums[l]; int i = l, j = r + 1; while (i &lt; j) &#123; while (++i &lt; r &amp;&amp; nums[i] &lt; pivot) ; while (--j &gt; l &amp;&amp; nums[j] &gt; pivot) ; if (i &lt; j) &#123; swap(nums[i], nums[j]); &#125; &#125; swap(nums[l], nums[j]); return j; &#125; int randomized_partition(vector&lt;int&gt;&amp; nums, int l, int r) &#123; int i = l + rand() % (r - l + 1); swap(nums[i], nums[l]); return partition(nums, l, r); &#125; void quicksort(vector&lt;int&gt;&amp; nums, int l, int r) &#123; if (l &lt; r) &#123; int pivot = randomized_partition(nums, l, r); quicksort(nums, l, pivot - 1); quicksort(nums, pivot + 1, r); &#125; &#125; vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) &#123; quicksort(nums, 0, nums.size() - 1); return nums; &#125;&#125;; 4️⃣ 归并排序1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: void merge(vector&lt;int&gt;&amp; nums, int l, int m, int r) &#123; int i = l, j = m + 1, k = 0; vector&lt;int&gt; temp(r - l + 1); while (i &lt;= m || j &lt;= r) &#123; if (i &gt; m) &#123; temp[k++] = nums[j++]; &#125; else if (j &gt; r) &#123; temp[k++] = nums[i++]; &#125; else if (nums[i] &lt; nums[j]) &#123; temp[k++] = nums[i++]; &#125; else &#123; temp[k++] = nums[j++]; &#125; &#125; for (int idx = 0; idx &lt; (r - l + 1); idx++) &#123; nums[l + idx] = temp[idx]; &#125; &#125; void mergesort(vector&lt;int&gt;&amp; nums, int l, int r) &#123; if (l &gt;= r) return; int m = (l + r) / 2; mergesort(nums, l, m); mergesort(nums, m + 1, r); merge(nums, l, m, r); &#125; vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) &#123; mergesort(nums, 0, nums.size() - 1); return nums; &#125;&#125;;","tags":["LeetCode","算法"],"categories":["数据结构与算法"]},{"title":"质数筛法（暴力、埃式筛、欧拉筛）","path":"/post/数据结构与算法/sieve-of-prime-number/","content":"如何判断一个数是不是质数，现在求区间 $[1,1e7]$ 内所有质数，学习「埃式筛法」和「欧拉筛法」之前，先介绍下暴力筛选。 可借此题验证下：204. 计数质数 1. 暴力筛选0 表示质数，1 表示合数。 1234567891011static final int N = 1e7 + 5;int st[N]; // 初始化为0，0表示质数，1表示合数for(int i = 2; i &lt;= n; i++)&#123; for(int j = 2; j * j &lt;= i; j++)&#123; //试除法 if(i % j == 0)&#123; st[i] = 1; // 合数，标记为1 break; &#125; &#125;&#125; 2. 埃式筛法这种方法无疑是最慢的，换一种思路：一个质数的倍数一定是合数。 所以假设 P 是质数，我们可以筛选掉区间 $[1,1e7]$ 中所有 P 的倍数。 为什么这样能筛去所有的合数呢，因为一个合数一定能被分解为几个质数的幂的乘积，并且这个数的质因子一定是小于它本身的，所以当我们从小到大将每个质数的倍数都筛去的话，当遍历到一个合数时，它一定已经被它的质因子给筛去了。 123456789101112131415#include &lt;iostream&gt;#include &lt;vector&gt;const int N = 1e7 + 5;int st[N]; // st[i] == 1 表示 i 是合数；0 表示 i 是素数void E_sieve(int n) &#123; for (int i = 2; i &lt;= n; i++) &#123; if (st[i] == 0) &#123; for (int j = 2 * i; j &lt;= n; j += i) &#123; st[j] = 1; // j 是 i 的倍数，是合数，标记为 1 &#125; &#125; &#125;&#125; 我们还可以对其进行优化： 我们会先筛 2 的所有倍数，然后筛 3 的所有倍数，但筛除3的倍数时，我们还是从 3 的 2 倍开始筛，其实 $3 * 2$ ，已经被 $2 * 3$ 时筛过了。又比如说筛 5 的倍数时，我们从 5 的 2 倍开始筛，但是 $5 * 2$ 会先被 $2 * 5$ 筛去，$5 * 3$ 会先被 $3 * 5$ 筛去，$5 * 4$ 会先被 $2 * 10$ 筛去，所以我们每一次只需要从 $i * i$ 开始筛，因为 $(2，3,…,i - 1)$ 倍已经被筛过了。 另外，判断一个数 n 是不是质数，我们只需要判断 $[2,\\sqrt{n}]$ 内有没有它的因子，在筛选合数时，我们也可以这样做，因为一个合数的最小质因子一定小于等于 $\\sqrt{n}$。 优化后的埃式筛法： 1234567891011121314#include &lt;iostream&gt;const int N = 1e7 + 5;int st[N]; // st[i] == 1 表示 i 是合数，0 表示 i 是素数void E_sieve(int n) &#123; for (int i = 2; i &lt;= n / i; i++) &#123; if (st[i] == 0) &#123; for (int j = i * i; j &lt;= n; j += i) &#123; st[j] = 1; // j 是 i 的倍数，标记为合数 &#125; &#125; &#125;&#125; 时间复杂度可以近似看成 $O(n)$ 但是我们还可以更快，那就是欧拉筛，又称为线性筛。 3. 欧拉筛法&#x2F;线性筛法欧拉筛的核心思想就是确保每个合数只被最小质因数筛掉，或者说被合数的最大因子筛掉。 比如 $120 &#x3D; 2^3 * 3 * 5$，120 会被 2 筛一次，3 筛一次，5 筛一次。 多做了两次不必要的操作，如何确保 120 只 2 筛选掉。 时间复杂度：$O(n)$ 12345678910111213141516171819#include &lt;iostream&gt;const int N = 1e7 + 5;int st[N]; // st[i] == 1 表示 i 是合数int primes[N]; // 存所有质数int cnt = 0; // 质数的个数void ola(int n) &#123; for (int i = 2; i &lt;= n; i++) &#123; if (st[i] == 0) &#123; primes[cnt++] = i; // i 是质数，加入 primes 数组 &#125; for (int j = 0; j &lt; cnt &amp;&amp; primes[j] &lt;= n / i; j++) &#123; st[primes[j] * i] = 1; // 标记合数 if (i % primes[j] == 0) // 保证每个合数只被它的最小质因子筛一次 break; &#125; &#125;&#125;","tags":["LeetCode","算法"],"categories":["数据结构与算法"]},{"title":"腾讯 wxg 一面｜354. 俄罗斯套娃信封问题","path":"/post/数据结构与算法/tecent-wxg-russian-doll-envelope/","content":"腾讯 WXG 一面｜354. 俄罗斯套娃信封问题给你一个二维整数数组 envelopes ，其中 envelopes[i] = [wi, hi] ，表示第 i 个信封的宽度和高度。 当另一个信封的宽度和高度都比这个信封大的时候，这个信封就可以放进另一个信封里，如同俄罗斯套娃一样。 请计算 最多能有多少个 信封能组成一组“俄罗斯套娃”信封（即可以把一个信封放到另一个信封里面）。 注意：不允许旋转信封。 示例 1： 123输入：envelopes = [[5,4],[6,4],[6,7],[2,3]]输出：3解释：最多信封的个数为 3, 组合为: [2,3] =&gt; [5,4] =&gt; [6,7]。 示例 2： 12输入：envelopes = [[1,1],[1,1],[1,1]]输出：1 提示： 1 &lt;= envelopes.length &lt;= 10^5 envelopes[i].length == 2 1 &lt;= wi, hi &lt;= 10^5 0️⃣ 前置题目✅ 300. 最长递增子序列｜DP &#x2F; 二分 1️⃣ LIS · 动态规划（超时 TLE）时间复杂度 $O(n^2)$ 1234567891011121314151617181920class Solution &#123;public: int maxEnvelopes(vector&lt;vector&lt;int&gt;&gt;&amp; envelopes) &#123; int n = envelopes.size(); vector&lt;pair&lt;int, int&gt;&gt; arr(n); for (int i = 0; i &lt; n; i++) arr[i] = &#123;envelopes[i][0], envelopes[i][1]&#125;; ranges::sort(arr); vector&lt;int&gt; f(n, 1); for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; i; j++) &#123; if (arr[i].first &gt; arr[j].first &amp;&amp; arr[i].second &gt; arr[j].second) &#123; f[i] = max(f[i], f[j] + 1); &#125; &#125; &#125; return ranges::max(f); &#125;&#125;; 2️⃣ 贪心 + 二分查找时间复杂度：$O(n·logn)$ 先排序，再按照 LIS 二分贪心模板求最长递增子序列。因为二者都必须是递增的，所以第二维度需要逆序排序，使得第一维度相同的多个数，最后一个插入的一定是最小值，这样能嵌套的信封最多。 123456789101112131415161718class Solution &#123;public: int maxEnvelopes(vector&lt;vector&lt;int&gt;&gt;&amp; envelopes) &#123; sort(envelopes.begin(), envelopes.end(), [](auto&amp; a, auto&amp; b) &#123; return a[0] &lt; b[0] || (a[0] == b[0] &amp;&amp; a[1] &gt; b[1]); &#125;); vector&lt;int&gt; g; for (auto&amp; e : envelopes) &#123; auto it = lower_bound(g.begin(), g.end(), e[1]); if (it == g.end()) &#123; g.push_back(e[1]); &#125; else &#123; *it = e[1]; &#125; &#125; return g.size(); &#125;&#125;;","tags":["LeetCode","算法"],"categories":["数据结构与算法"]},{"title":"并查集","path":"/post/数据结构与算法/union-search/","content":"✅ 并查集 相关例题： 1971. 寻找图中是否存在路径 684. 冗余连接 685. 冗余连接 II 并查集是一种用于管理元素所属集合的数据结构，实现为一个森林，其中每棵树表示一个集合，树中的节点表示对应集合中的元素。 顾名思义，并查集支持两种操作： 合并（Union）：合并两个元素所属集合（合并对应的树） 查询（Find）：查询某个元素所属集合（查询对应的树的根节点），这可以用于判断两个元素是否属于同一集合 并查集在经过修改后可以支持单个元素的删除、移动；使用动态开点线段树还可以实现可持久化并查集。 模板代码1234567891011121314151617181920vector&lt;int&gt; p(n);iota(p.begin(), p.end(), 0);vector&lt;int&gt; size(n, 1);int find(int x) &#123; if (p[x] != x) &#123; // 路径压缩 p[x] = find(p[x]); &#125; return p[x];&#125;void unite(int a, int b) &#123; int pa = find(a), pb = find(b); if (pa == pb) return; p[pa] = pb; size[pb] += size[pa];&#125; 684. 冗余连接树可以看成是一个连通且 无环 的 无向 图。 给定往一棵 n 个节点 (节点值 1～n) 的树中添加一条边后的图。添加的边的两个顶点包含在 1 到 n 中间，且这条附加的边不属于树中已存在的边。图的信息记录于长度为 n 的二维数组 edges ，edges[i] = [ai, bi] 表示图中在 ai 和 bi 之间存在一条边。 请找出一条可以删去的边，删除后可使得剩余部分是一个有着 n 个节点的树。如果有多个答案，则返回数组 edges 中最后出现的那个。 示例 1： 12输入: edges = [[1,2], [1,3], [2,3]]输出: [2,3] 示例 2： 12输入: edges = [[1,2], [2,3], [3,4], [1,4], [1,5]]输出: [1,4] 1️⃣ 并查集12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123;public: vector&lt;int&gt; p; void init(int n) &#123; p.resize(n + 1); iota(p.begin(), p.end(), 0); &#125; int find(int x) &#123; if (x != p[x]) p[x] = find(p[x]); // 路经压缩 return p[x]; &#125; bool isSame(int u, int v) &#123; int pu = find(u); int pv = find(v); return pu == pv; &#125; void join(int u, int v) &#123; int pu = find(u); int pv = find(v); p[pu] = pv; &#125; vector&lt;int&gt; findRedundantConnection(vector&lt;vector&lt;int&gt;&gt;&amp; edges) &#123; init(edges.size()); for (auto e : edges) &#123; int u = e[0], v = e[1]; if (isSame(u, v)) &#123; return e; &#125; else &#123; join(u, v); &#125; &#125; return &#123;&#125;; &#125;&#125;;","tags":["LeetCode","Union Search"],"categories":["数据结构与算法"]},{"title":"C++ ACM 模式","path":"/post/秋招指南/cpp-acm-input-output/","content":"✅ 华为校招机考备考题单：https://rttxvuqg3f.feishu.cn/docx/PcBHdy3GsoIhxnx1RqucVqRdnAf C++ ACM 模式输入输出1. 输入输出的相关库函数1️⃣ 输出格式化（精度）C++ 提供了多种方式来控制输入输出的格式，常用的包括 std::setw、std::setprecision、std::fixed 等。 123456789101112#include &lt;iostream&gt;#include &lt;iomanip&gt; // 提供格式化工具int main() &#123; double pi = 3.14159265358979; std::cout &lt;&lt; &quot;原始值: &quot; &lt;&lt; pi &lt;&lt; std::endl; // 设置输出精度为 2 位小数 std::cout &lt;&lt; &quot;保留两位小数: &quot; &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; pi &lt;&lt; std::endl; return 0;&#125; 2️⃣ cincin 是标准输入流对象，通常用于从用户那里读取数据。当我们用 while (cin) 来读取输入时，它的工作原理是不断检查输入流是否有效。如果用户输入了数据并且没有遇到错误或者文件结束标志（例如 Ctrl+Z 或 Ctrl+D 表示 EOF），那么 cin 就会继续读取并进入循环。 注意，cin &gt;&gt; val 会一直从 标准输入流 中读取数据，以空白字符为分隔符，包括： 空格 &#39; &#39; 回车 &#39; &#39; 制表符 &#39;\\t&#39; 这些都是分隔符，但 不会终止输入流，只是划分输入的不同部分。 3️⃣ stringstreamstd::stringstream 是 C++ 标准库中的一个类，位于 &lt;sstream&gt; 头文件中。它提供了一个用于在内存中进行输入输出操作的字符串流。std::stringstream 允许你像使用 std::cin 和 std::cout 一样操作字符串，它可以用来从字符串中读取数据，或将数据写入到字符串中。它的主要用途是进行字符串的格式化和数据的转换。 std::stringstream 继承自 std::iostream，因此可以使用 &lt;&lt; 和 &gt;&gt; 运算符来进行数据流的输入输出。如果想清空 stringstream 中的数据，可以使用 str(&quot;&quot;) 方法，将流的内容设置为空字符串，或者使用 clear() 来重置流的状态。 12345678910111213141516171819#include &lt;iostream&gt;#include &lt;sstream&gt;int main() &#123; std::stringstream ss1; int x = 10; double y = 3.14; ss1 &lt;&lt; &quot;Integer: &quot; &lt;&lt; x &lt;&lt; &quot;, Double: &quot; &lt;&lt; y; std::cout &lt;&lt; ss.str() &lt;&lt; std::endl; std::stringstream ss2(&quot;123 456 3.14&quot;); int a, b; double c; ss &gt;&gt; a &gt;&gt; b &gt;&gt; c; std::cout &lt;&lt; &quot;a: &quot; &lt;&lt; a &lt;&lt; &quot;, b: &quot; &lt;&lt; b &lt;&lt; &quot;, c: &quot; &lt;&lt; c &lt;&lt; std::endl; // 清空: ss.str(&quot;&quot;) ss1.str(&quot;&quot;);&#125; 4️⃣ getlinegetline 函数是 C++ 中用于从输入流中读取一行文本的函数，通常用于读取用户输入或文件中的一行数据。它的基本用法是：读取一整行数据，直到遇到换行符（ ）为止。它不会将换行符包含在返回的字符串中。函数原型为： 1istream&amp; getline (istream&amp; is, string&amp; str); 它接受两个参数： is：输入流对象（如 cin 或 ifstream）。 str：存储读取内容的 string 对象。 123456789101112#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main() &#123; // 输入 1 2 3 4 string line; while (getline(cin, line)) &#123; cout &lt;&lt; &quot;输入的行是: &quot; &lt;&lt; line &lt;&lt; endl; &#125; return 0;&#125; 1234567891011121314151617#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main() &#123; std::string input; std::cin &gt;&gt; input; // 输入 1,2,3,4 std::stringstream ss(input); std::vector&lt;int&gt; nums; std::string number; // stringstream, string while (getline(ss, number, &#x27;,&#x27;)) &#123; nums.push_back(std::stoi(number)); &#125; return 0;&#125; 2. A+B+C+…（单行输入版）输入样例： 11 2 3 4 5 输出样例： 115 题解： 123456789101112#include &lt;bits/stdc++.h&gt;using namespace std;int main() &#123; // 数据范围: -10^9 &lt;= x &lt;= 10^9 long long val, s = 0; while (cin &gt;&gt; val) &#123; s += val; &#125; cout &lt;&lt; s &lt;&lt; endl; return 0;&#125; 3. A+B+C+…（多行输入版）输入样例： 1231 2 34 5 6 78 9 输出样例： 12362217 题解： 123456789101112131415161718192021#include &lt;iostream&gt;#include &lt;sstream&gt;using namespace std;int main() &#123; string line; while (getline(cin, line)) &#123; // 持续读取完整一行，一直到 EOF // 使用 stringstream 解析每一行的输入 // 假设读到的是&quot;1 2 3&quot; stringstream ss(line); long long num, sum = 0; while (ss &gt;&gt; num) &#123; // 逐个读取这一行的整数 sum += num; // 将读取的整数累加到 sum 中 // 先是sum += 1 // 再是sum += 2 // 最后是sum += 3 &#125; cout &lt;&lt; sum &lt;&lt; endl; // 输出这一行所有整数的和 : 6 &#125; return 0;&#125; 🔥 4. A+B+C+…（带元素个数的多行输入版）输入： 123455 31 2 2 3 2234 输出： 123310 ⚠️ 本题反而要注意：cin 不是读到 停止，而是 EOF，所以 line 14 不能用 while(cin &gt;&gt; val) 来替代，否则后续元素都会被吸收到 nums 数组中。 12345678910111213141516171819202122#include &lt;algorithm&gt;#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;int main() &#123; ios::sync_with_stdio(false); cin.tie(nullptr); int n, Q; cin &gt;&gt; n &gt;&gt; Q; vector&lt;int&gt; nums(n); for (int i = 0; i &lt; n; i++) &#123; cin &gt;&gt; nums[i]; &#125; vector&lt;int&gt; query(Q); for (int i = 0; i &lt; Q; i++) &#123; cin &gt;&gt; query[i]; &#125; return 0;&#125; 或者可以使用 cin.peek() != &#39; &#39; 搭配 cin &gt;&gt; val 使用（这一刻我才明白 cin.peek() 与 cin.ignore() 的作用）： 记得先处理上一行的末尾（如果需要处理）：cin.ignore() 或 cin.get() 再使用 cin.peek() != &#39; &#39; &amp; cin &gt;&gt; val 来循环读取当前行元素 12345678910111213141516171819202122232425262728293031#include &lt;algorithm&gt;#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;int main() &#123; ios::sync_with_stdio(false); cin.tie(nullptr); int n, Q; cin &gt;&gt; n &gt;&gt; Q; //vector&lt;int&gt; nums(n); //for (int i = 0; i &lt; n; i++) &#123; // cin &gt;&gt; nums[i]; //&#125; // 等价于 // 🔥注意这里需要处理第一行的 &#x27; &#x27;, 因为 cin &gt;&gt; n &gt;&gt; Q 后还没跳到下一行。 cin.ignore(); // 或者 cin.get(); vector&lt;int&gt; nums; int val; while (cin.peek() != &#x27; &#x27; &amp;&amp; cin &gt;&gt; val) &#123; nums.push_back(val); &#125; vector&lt;int&gt; query(Q); for (int i = 0; i &lt; Q; i++) &#123; cin &gt;&gt; query[i]; &#125; return 0;&#125; ⚠️ 拓展延伸 1️⃣ 上述的输入是： 123455 3⏎(换行)1 2 2 3 2⏎(换行)2⏎(换行)3⏎(换行)4⏎(换行) 2️⃣ 假设输入变成以下这种（即第二行换行符前还有一个␣(空格)）： 123455 3⏎(换行)1 2 2 3 2␣(空格)⏎(换行)2⏎(换行)3⏎(换行)4⏎(换行) 那 nums 的个数会有 6 个，即第 3 行的 2 也会当成 nums 的元素，因为 ␣(空格) 不是 ，所以会再触发一次 cin 操作，所以建议使用 for (int i = 0; i &lt; n; i++) &#123; cin &gt;&gt; nums[i]; &#125; 的方式替代 peek() 判断！ OJ 时间复杂度限制与预估在编写程序时，分析其时间复杂度（Time Complexity）是评估程序效率的重要手段。时间复杂度描述了程序运行时间与输入规模之间的关系，通常使用大O符号表示（如O(n)、O(n²)等）。下面将详细解释时间复杂度的概念，并分析这段代码的时间复杂度。 🔥 OJ 一般 C++ 1秒（即1000ms）大概能跑 1e8 量级（很多题目都会限制时间和内存，如下： 时间限制: C&#x2F;C++ 1000ms , 其他语言： 2000ms 内存限制: C&#x2F;C++ 256MB , 其他语言： 512MB 123456789101112#include &lt;iostream&gt;using namespace std;int x;int ans = 0;int main() &#123; cin&gt;&gt;x; for (int i = 1; i &lt;= x; i++) &#123; ans++; &#125; cout&lt;&lt;ans; return 0;&#125; 🔥对于这个简单的代码，x &lt; **1e8** , 运行不会超时 ， x &gt; 1e8 , 运行超时 ✅ 时间复杂度衡量的是算法执行所需的时间增长率，随着输入规模的增加，算法的运行时间如何变化。常见的时间复杂度包括： O(1)：常数时间，无论输入规模多大，执行时间保持不变。 O(log n)：对数时间，随着输入规模增加，执行时间按对数增长。例如二分操作。 O(n)：线性时间，执行时间与输入规模成正比。 O(n log n)：线性对数时间，常见于高效排序算法如快速排序、归并排序。 O(n²)：平方时间，常见于简单的嵌套循环，如冒泡排序。 ✅ 如何计算时间复杂度： 识别基本操作：确定算法中最频繁执行的操作，如循环中的语句、递归调用等。 计算基本操作的执行次数：根据输入规模，计算这些操作随着输入增长的次数。 忽略低阶项和常数系数：在大O表示法中，只保留增长最快的项，忽略常数和低阶项。 🔥 对于一般情况： n&#x3D;$10^5$ 或 n&#x3D;$10^6$ 左右考虑 $O(n log n)$ 以下的做法 n&#x3D;$5 * 10^3$ 左右考虑 $O(n^2)$ 以下的做法 n&#x3D;$10^2$ 左右考虑 $O(n^3)$ 以下的做法 n&#x3D;$20$ 左右考虑 $O(2^n)$ 以下的做法 各数据类型的读入与构造数组1234567891011121314#include &lt;bits/stdc++.h&gt;#include &lt;numeric&gt;using namespace std;int main() &#123; int n; cin &gt;&gt; n; vector&lt;int&gt; nums(n); for (int i = 0; i &lt; n; i++) &#123; cin &gt;&gt; nums[i]; &#125; cout &lt;&lt; accumulate(nums.begin(), nums.end(), 0) &lt;&lt; endl; return 0;&#125; 链表123456789101112131415161718192021222324252627282930313233343536373839#include &lt;bits/stdc++.h&gt;using namespace std;struct ListNode &#123; int val; ListNode *next; ListNode(int x) : val(x), next(nullptr) &#123;&#125;&#125;;ListNode *createLinkedList(vector&lt;int&gt; &amp;nums) &#123; ListNode dummy(0); ListNode *cur = &amp;dummy; for (int x : nums) &#123; cur-&gt;next = new ListNode(x); cur = cur-&gt;next; &#125; return dummy.next;&#125;void printLinkedList(ListNode *head) &#123; for (ListNode *cur = head; cur; cur = cur-&gt;next) &#123; cout &lt;&lt; cur-&gt;val &lt;&lt; endl; &#125;&#125;int main() &#123; int n; cin &gt;&gt; n; // 读取数组长度 vector&lt;int&gt; nums(n); for (int i = 0; i &lt; n; i++) &#123; cin &gt;&gt; nums[i]; // 读取数组元素 &#125; ListNode *head = createLinkedList(nums); // 创建链表 printLinkedList(head); // 遍历链表并输出 return 0;&#125; 二叉树的读入与构建（输入为数组形式） 本题相当于根据「层序遍历」结果来构造二叉树：本质就是根据数组索引来构造 ✅ 推荐阅读（题解）： 889. 根据前序和后序遍历构造二叉树 105. 从前序与中序遍历序列构造二叉树 106. 从中序与后序遍历序列构造二叉树 1008. 前序遍历构造二叉搜索树 输入 11 2 3 4 5 -1 6 树的结构 12345 1 / \\ 2 3 / \\ \\4 5 6 输出 123456123456 题解 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;bits/stdc++.h&gt;using namespace std;struct TreeNode &#123; int val; TreeNode *left; TreeNode *right; TreeNode(int x) : val(x), left(nullptr), right(nullptr) &#123;&#125;&#125;;TreeNode *buildTree(const vector&lt;int&gt; &amp;nums) &#123; if (nums.empty() || nums[0] == -1) return nullptr; vector&lt;TreeNode *&gt; nodes(nums.size(), nullptr); for (size_t i = 0; i &lt; nums.size(); i++) &#123; if (nums[i] != -1) nodes[i] = new TreeNode(nums[i]); &#125; for (size_t i = 0; i &lt; nums.size(); i++) &#123; if (nodes[i]) &#123; if (2 * i + 1 &lt; nums.size()) nodes[i]-&gt;left = nodes[2 * i + 1]; if (2 * i + 2 &lt; nums.size()) nodes[i]-&gt;right = nodes[2 * i + 2]; &#125; &#125; return nodes[0];&#125;void levelOrder(TreeNode *root) &#123; if (!root) return; queue&lt;TreeNode *&gt; q; q.push(root); while (!q.empty()) &#123; TreeNode *curr = q.front(); q.pop(); cout &lt;&lt; curr-&gt;val &lt;&lt; endl; if (curr-&gt;left) q.push(curr-&gt;left); if (curr-&gt;right) q.push(curr-&gt;right); &#125;&#125;int main() &#123; string line; getline(cin, line); stringstream ss(line); vector&lt;int&gt; nums; int val; while (ss &gt;&gt; val) &#123; nums.push_back(val); &#125; TreeNode *root = buildTree(nums); levelOrder(root); return 0;&#125; 普通树的读入与构建（输入为相邻边 &amp; father 数组） 分成两种形式的读入，一起讲解 题目描述给定一棵 n 个节点的树，节点编号为1−n1−n，树的根节点固定为 1。我们有两种方式表示树的结构： 方式一：通过 n-1 条边的形式，每条边 u v 表示节点 u 和节点 v 之间存在一条边。 方式二：通过一个 father 数组，father[i] 表示节点 i+1 的父节点。 请你编写程序，读入树的结构并使用深度优先搜索遍历打印这棵树的节点编号。 为了输出统一，从根节点开始遍历，优先访问序号小的子节点。 输入输入包含三部分： 第一行包含一个整数 n，表示树的节点个数。 第二行包含一个整数 type，表示树的表示方式： 如果 type = 1，表示通过边的形式输入。 如果 type = 2，表示通过 father 数组输入。 如果 type = 1，接下来会有 n-1 行，每行两个整数 u v，表示树中节点 u 和节点 v 之间存在一条边。 如果 type = 2，接下来一行有 n 个整数，father[i] 表示节点 i+1 的父节点，其中 father[0] = 0，表示 1 号节点为根节点,没有父节点。 输出打印遍历这棵树的节点编号。 输入样例 1123456511 21 32 42 5 输出样例 111 2 4 5 3 样例1 图例12345 1 / \\ 2 3 / \\4 5 输入样例 2123520 1 1 2 2 输出样例 211 2 4 5 3 数据范围 $1\\le n \\le 10^5$ 🔥题解1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;algorithm&gt;#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;#define MAX 100005 // 假设最大节点数 10^5vector&lt;int&gt; adjList[MAX]; // 邻接表vector&lt;int&gt; traversalResult; // 存储先序遍历结果void DFS(int node, int parent) &#123; traversalResult.push_back(node); for (auto &amp;child : adjList[node]) &#123; if (child != parent) &#123; DFS(child, node); &#125; &#125;&#125;int main() &#123; int n, type; cin &gt;&gt; n &gt;&gt; type; if (type == 1) &#123; // type 1: 通过边的形式读入 for (int i = 0; i &lt; n - 1; i++) &#123; int u, v; cin &gt;&gt; u &gt;&gt; v; adjList[u].push_back(v); adjList[v].push_back(u); &#125; &#125; else if (type == 2) &#123; // type 2: 通过 father 数组输入 vector&lt;int&gt; father(n + 1); for (int i = 1; i &lt;= n; i++) &#123; cin &gt;&gt; father[i]; if (father[i] != 0) &#123; adjList[father[i]].push_back(i); adjList[i].push_back(father[i]); &#125; &#125; &#125; // 为了保证遍历顺序的一致性，先对每个节点的子节点进行排序 for (int i = 1; i &lt;= n; i++) &#123; sort(adjList[i].begin(), adjList[i].end()); &#125; DFS(1, 0); for (int i = 0; i &lt; (int)traversalResult.size(); i++) &#123; if (i &gt; 0) cout &lt;&lt; &#x27; &#x27;; cout &lt;&lt; traversalResult[i]; &#125; return 0;&#125; 图的构造（邻接矩阵 &amp; 邻接表）题目描述给定两张有向图 A 和 B，其中图 A 以邻接矩阵形式给出，图 B 以邻接表形式给出。请判断这两张图是否完全一样。我们将“完全一样”的定义为：每个节点的邻居集合完全一致。 输入输入的第一行包含两个整数 n，表示图的节点数。 接下来的 n 行，给出图 A 的邻接矩阵。该矩阵的第 i 行第 j 列表示节点 i 和节点 j 之间是否有边。如果存在边，则该位置的值为 1，否则为 0。 接下来的 n 行，给出图 B 的邻接表。每行第一个数 node,后面跟的第一个数 k 表示接下来输入 k 个数 val 表示节点 node 向这些节点 val 连一条边。 输出如果图 A 和图 B 完全一样，则输出 “YES”；否则输出 “NO”。 注意 图 A 和图 B 是有向图，即如果 A[i][j]=1，那么 i 到 j 有条有向边。 节点编号从 1 到 n。 图 A 和图 B 的节点数相同。 数据范围： $1≤n≤10^3$ 图 A 的邻接矩阵大小为 n×n，其中每个元素为 0 或 1。 图 B 的邻接表中每个节点的邻居数量不超过 n−1。 样例输入 1123456730 1 11 0 11 1 01 2 2 32 2 1 33 2 1 2 样例输出 11YES 样例输入 2123456730 1 11 0 11 1 01 2 2 32 2 1 33 1 1 样例输出 21NO 样例 2 提示图 A 的邻接矩阵为： 1230 1 11 0 11 1 0 表示图 A 中，节点 1 与节点 2 和节点 3 相连，节点 2 与节点 1 和节点 3 相连，节点 3 与节点 1 和节点 2 相连。 图 B 的邻接表为： 1231 2 2 32 2 1 33 1 1 表示图 B 中，节点 1 与节点 2 和节点 3 相连，节点 2 与节点 1 和节点 3 相连，节点 3 与节点 1 相连。 对比可以发现，在图 B 中，节点 3 不连向 节点 2。因此，图 A 和图 B 不完全一样，输出 “NO”。 邻接矩阵 邻接表 题解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;algorithm&gt;#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;int main() &#123; int n; // 顶点数 cin &gt;&gt; n; vector&lt;vector&lt;int&gt;&gt; adjA(n + 1), adjB(n + 1); // 读取并转换图 A for (int i = 1; i &lt;= n; i++) &#123; for (int j = 1; j &lt;= n; j++) &#123; int val; cin &gt;&gt; val; if (val == 1) adjA[i].push_back(j); &#125; &#125; // 读取图 B for (int i = 0; i &lt; n; i++) &#123; int node, k; cin &gt;&gt; node &gt;&gt; k; adjB[node].resize(k); for (int j = 0; j &lt; k; j++) &#123; cin &gt;&gt; adjB[node][j]; &#125; &#125; // 对邻接表排序 for (int i = 1; i &lt;= n; i++) &#123; sort(adjA[i].begin(), adjA[i].end()); sort(adjB[i].begin(), adjB[i].end()); &#125; // 比较邻接表 bool same = true; for (int i = 1; i &lt;= n; i++) &#123; if (adjA[i] != adjB[i]) &#123; same = false; break; &#125; &#125; cout &lt;&lt; (same ? &quot;YES&quot; : &quot;NO&quot;) &lt;&lt; endl; return 0;&#125;","tags":["C++","ACM","LeetCode"],"categories":["秋招指南"]},{"title":"2025.04.24 吉比特笔试题","path":"/post/秋招指南/20250424-gbits/","content":"1. 数组查询给定一个数组 a[n]，以及 q 次查询 (l, r)，输出 a[l] - a[l+1] - a[l+2] - ... - a[r-1] - a[r] 的值。 输入描述 第一行包含两个整数 n 和 q，表示数组的长度和查询的次数。 第二行包含 n 个整数，表示数组 a。 接下来的 q 行，每行包含两个整数 l 和 r，表示查询的区间（假设数组下标从 1 开始）。 输出描述 对于每个查询，输出一个整数，表示对应的计算结果。 示例 1 输入： 123455 31 2 3 4 51 52 43 3 输出： 123-13-53 解释： 第一个查询：$1 - 2 - 3 - 4 - 5 &#x3D; -13$ 第二个查询：$2 - 3 - 4 &#x3D; -5$ 第三个查询：$3$ 代码：模拟 &#x2F; 前缀和 直接按照题目要求计算即可。对于每个查询 (l, r)，从 a[l] 开始，依次减去 a[l+1] 到 a[r] 的值。时间复杂度为 $O(q * n)$，在 n 和 q 较小的情况下可以通过。 优化思路：可以预处理前缀和数组 prefix，其中 prefix[i] 表示 a[1] - a[2] - ... - a[i]。然后对于查询 (l, r)，结果为： 如果 l == 1，直接取 prefix[r]。 否则，结果为 a[l] - (prefix[r] - prefix[l])。 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;int main() &#123; int n, q; cin &gt;&gt; n &gt;&gt; q; vector&lt;int&gt; a(n + 1); vector&lt;int&gt; prefix(n + 1, 0); for (int i = 1; i &lt;= n; ++i) &#123; cin &gt;&gt; a[i]; if (i == 1) &#123; prefix[i] = a[i]; &#125; else &#123; prefix[i] = prefix[i - 1] - a[i]; &#125; &#125; while (q--) &#123; int l, r; cin &gt;&gt; l &gt;&gt; r; if (l == 1) &#123; cout &lt;&lt; prefix[r] &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; a[l] - (prefix[r] - prefix[l]) &lt;&lt; endl; &#125; &#125; return 0;&#125; 2. 多米诺骨牌推倒给定一排多米诺骨牌，每个骨牌有一个数值。每次操作可以选择一个位置和一个方向（左或右）进行推倒。推倒的规则是： 如果相邻骨牌（根据方向）的数值比当前骨牌的数值小，则会被推倒，并继续向该方向传播，直到遇到不小于当前骨牌数值的骨牌为止。 问最少需要多少次操作才能将所有骨牌都推倒。 输入描述 第一行包含一个整数 n，表示骨牌的数量。 第二行包含 n 个整数，表示每个骨牌的数值。 输出描述 输出一个整数，表示最少需要的操作次数。 示例 1 输入： 1253 1 2 4 1 输出： 13 解释： 第一次操作：选择 4，向右推倒，可以推倒 1（因为 1 &lt; 4） 第二次操作：选择 3，向右推倒，可以推倒位置 1 第二次操作：选择 2 推倒 代码：转化为区间覆盖问题 后半部分代码参考 LC 45. 跳跃游戏 II 这个问题是一个链式反应模拟 + 贪心优化问题。目标是最小化推动次数，使得所有积木都被推倒。 我们可以对问题进行如下处理： 模拟倒塌过程（从某个位置向左或向右传递）； 预处理每个积木从左或右可以推倒的“影响范围”； 贪心策略：用最少的“倒塌段”覆盖所有积木（区间覆盖）。 步骤详解： Step 1：预处理每个积木向左&#x2F;右能影响多远 对于每个位置 i： 向右倒：不断检查 A[i+1] &lt; A[i], A[i+2] &lt; A[i+1]… 直到不满足，记录影响区间 R[i]； 向左倒：不断检查 A[i-1] &lt; A[i], A[i-2] &lt; A[i-1]… 类似，记录影响区间 L[i]。 Step 2：把每个可能的倒塌行为看作一个“区间”覆盖 从 i 向右能推倒到 j，我们记录一个区间 [i, j] 从 i 向左能推倒到 k，我们记录一个区间 [k, i] 总共会有 2n 个这样的区间。 Step 3：用最少的这些区间覆盖整个 [1, n] 这个就是经典的 区间覆盖问题： 将所有区间按起点排序； 每次选择起点 ≤ 当前覆盖末尾，终点最大的区间； 如果无法延伸则失败； 否则计数操作次数，直到覆盖整个 [1, n] 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;int main() &#123; int n; cin &gt;&gt; n; vector&lt;int&gt; A(n + 2); // 1-based indexing, pad for safety for (int i = 1; i &lt;= n; ++i) &#123; cin &gt;&gt; A[i]; &#125; vector&lt;pair&lt;int, int&gt;&gt; intervals; // 向右推 for (int i = 1; i &lt;= n; ++i) &#123; int j = i; while (j + 1 &lt;= n &amp;&amp; A[j + 1] &lt; A[j]) &#123; ++j; &#125; intervals.emplace_back(i, j); &#125; // 向左推 for (int i = 1; i &lt;= n; ++i) &#123; int j = i; while (j - 1 &gt;= 1 &amp;&amp; A[j - 1] &lt; A[j]) &#123; --j; &#125; intervals.emplace_back(j, i); &#125; // 贪心区间覆盖 [1, n] sort(intervals.begin(), intervals.end()); int res = 0, end = 0, next_end = 0, idx = 0; while (end &lt; n) &#123; while (idx &lt; intervals.size() &amp;&amp; intervals[idx].first &lt;= end + 1) &#123; next_end = max(next_end, intervals[idx].second); ++idx; &#125; if (next_end == end) &#123; cout &lt;&lt; -1 &lt;&lt; endl; // 理论上不会出现 return 0; &#125; end = next_end; ++res; &#125; cout &lt;&lt; res &lt;&lt; endl; return 0;&#125; 3. 绳子分割与多边形面积牛牛小朋友和他的朋友们，一共 $n$ 个人在操场上玩一个圈地盘的游戏。 这个游戏的规则是这样的，将一根的绳子剪成 $n$ 段， 让每个小朋友都能有一小段绳子。 每个小朋友用拿到的一小段绳子分别圈地，要求绳子头尾相接（头尾相接时产生的损耗忽略不计），并且第 $i$ 个小朋友要求他用绳子在地上圈起来的地盘是 $a_i$ 边形的（有些小朋友对他圈起来的地盘是什么形状的并不关心，用 $-1$ 表示）。 小朋友们只能找到一根长度为 $l$ 的绳子，需要把绳子剪开之后，所有小朋友可以圈出地盘的面积的最小值为 $s$。为了让小朋友们尽可能高兴，需牛牛要一种剪绳子的方法，让 $s$ 尽可能大。你能帮助牛牛解决这个问题吗？你只需要精确到小数点后 6 位即可（和标准答案相对误差低于 $1e^{-5}$ 则被判定为正确）。 输入描述 第一行包含两个整数 l 和 n。 第二行包含 n 个整数，表示数组 a。 输出格式 输出一个浮点数，表示面积最小值的最大可能值，保留足够的小数位数。 示例 1 输入： 1210 24 -1 输出： 12.5 代码 这个问题可以转化为 二分答案 + 几何判断 的问题： 核心思想： 目标：将长度为 l 的绳子分成 n 段，使得所有小朋友围成的图形的面积的最小值最大化。 限制条件： 每个小朋友的形状是一个正多边形，边数为 a_i（若为 -1，代表形状不限制，可以视为正圆）。 总绳长为 l。 我们用 二分搜索 来猜测最小的面积 s，然后验证是否可以在绳长为 l 的情况下满足每个人的要求。 面积计算公式： 对于边数为 k 的正多边形，边长为 x / k，周长为 x，面积为： $$A &#x3D; \\frac{k}{4} \\cdot x^2 \\cdot \\cot\\left(\\frac{\\pi}{k}\\right)$$ 如果是圆（a_i == -1），设周长为 x，则半径 r = x / (2π)，面积为： $$A &#x3D; \\pi \\cdot \\left(\\frac{x}{2\\pi}\\right)^2 &#x3D; \\frac{x^2}{4\\pi}$$ 给定一个猜测的最小面积 s，我们尝试为每个小朋友分配一段最短绳长，使得他能围成面积至少为 s，然后计算所有这些最短绳长的和是否不超过 l。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;cmath&gt;#include &lt;iomanip&gt;using namespace std;const double PI = acos(-1.0);const double EPS = 1e-7;int n;double l;vector&lt;int&gt; a;double get_min_len(int k, double s) &#123; if (k == -1) &#123; // Circle return sqrt(4 * PI * s); &#125; else &#123; double tan_val = tan(PI / k); double coeff = k / (4 * tan_val); // cotangent = 1 / tan return sqrt(s / coeff); &#125;&#125;bool check(double s) &#123; double total_len = 0; for (int i = 0; i &lt; n; ++i) &#123; double min_len = get_min_len(a[i], s); total_len += min_len; if (total_len &gt; l) return false; &#125; return true;&#125;int main() &#123; cin &gt;&gt; n &gt;&gt; l; a.resize(n); for (int i = 0; i &lt; n; ++i) &#123; cin &gt;&gt; a[i]; &#125; double left = 0, right = 1e18; // Upper bound high enough// while (right - left &gt; EPS) for (int iter = 0; iter &lt; 100; ++iter) &#123; // binary search double mid = (left + right) / 2; if (check(mid)) &#123; left = mid; &#125; else &#123; right = mid; &#125; &#125; cout &lt;&lt; fixed &lt;&lt; setprecision(6) &lt;&lt; left &lt;&lt; endl; return 0;&#125;","tags":["笔试","实习","吉比特"],"categories":["秋招指南"]},{"title":"Effective C++","path":"/post/C++/effective-c++/","content":"Effective C++ 视 C++ 为一个语言联邦（C、Object-Oriented C++、Template C++、STL） 宁可以编译器替换预处理器（尽量以 const、enum、inline 替换 #define） 尽可能使用 const 确定对象被使用前已先被初始化（构造时赋值（copy 构造函数）比 default 构造后赋值（copy assignment）效率高） 了解 C++ 默默编写并调用哪些函数（编译器暗自为 class 创建 default 构造函数、copy 构造函数、copy assignment 操作符、析构函数） 若不想使用编译器自动生成的函数，就应该明确拒绝（将不想使用的成员函数声明为 private，并且不予实现） 为多态基类声明 virtual 析构函数（如果 class 带有任何 virtual 函数，它就应该拥有一个 virtual 析构函数） 别让异常逃离析构函数（析构函数应该吞下不传播异常，或者结束程序，而不是吐出异常；如果要处理异常应该在非析构的普通函数处理） 绝不在构造和析构过程中调用 virtual 函数（因为这类调用从不下降至 derived class） 令 operator= 返回一个 reference to *this （用于连锁赋值） 在 operator= 中处理 “自我赋值” 赋值对象时应确保复制 “对象内的所有成员变量” 及 “所有 base class 成分”（调用基类复制构造函数） 以对象管理资源（资源在构造函数获得，在析构函数释放，建议使用智能指针，资源取得时机便是初始化时机（Resource Acquisition Is Initialization，RAII）） 在资源管理类中小心 copying 行为（普遍的 RAII class copying 行为是：抑制 copying、引用计数、深度拷贝、转移底部资源拥有权（类似 auto_ptr）） 在资源管理类中提供对原始资源（raw resources）的访问（对原始资源的访问可能经过显式转换或隐式转换，一般而言显示转换比较安全，隐式转换对客户比较方便） 成对使用 new 和 delete 时要采取相同形式（new 中使用 [] 则 delete []，new 中不使用 [] 则 delete） 以独立语句将 newed 对象存储于（置入）智能指针（如果不这样做，可能会因为编译器优化，导致难以察觉的资源泄漏） 让接口容易被正确使用，不易被误用（促进正常使用的办法：接口的一致性、内置类型的行为兼容；阻止误用的办法：建立新类型，限制类型上的操作，约束对象值、消除客户的资源管理责任） 设计 class 犹如设计 type，需要考虑对象创建、销毁、初始化、赋值、值传递、合法值、继承关系、转换、一般化等等。 宁以 pass-by-reference-to-const 替换 pass-by-value （前者通常更高效、避免切割问题（slicing problem），但不适用于内置类型、STL迭代器、函数对象） 必须返回对象时，别妄想返回其 reference（绝不返回 pointer 或 reference 指向一个 local stack 对象，或返回 reference 指向一个 heap-allocated 对象，或返回 pointer 或 reference 指向一个 local static 对象而有可能同时需要多个这样的对象。） 将成员变量声明为 private（为了封装、一致性、对其读写精确控制等） 宁以 non-member、non-friend 替换 member 函数（可增加封装性、包裹弹性（packaging flexibility）、机能扩充性） 若所有参数（包括被this指针所指的那个隐喻参数）皆须要类型转换，请为此采用 non-member 函数 考虑写一个不抛异常的 swap 函数 尽可能延后变量定义式的出现时间（可增加程序清晰度并改善程序效率） 尽量少做转型动作（旧式：(T)expression、T(expression)；新式：const_cast&lt;T&gt;(expression)、dynamic_cast&lt;T&gt;(expression)、reinterpret_cast&lt;T&gt;(expression)、static_cast&lt;T&gt;(expression)、；尽量避免转型、注重效率避免 dynamic_casts、尽量设计成无需转型、可把转型封装成函数、宁可用新式转型） 避免使用 handles（包括 引用、指针、迭代器）指向对象内部（以增加封装性、使 const 成员函数的行为更像 const、降低 “虚吊号码牌”（dangling handles，如悬空指针等）的可能性） 为 “异常安全” 而努力是值得的（异常安全函数（Exception-safe functions）即使发生异常也不会泄露资源或允许任何数据结构败坏，分为三种可能的保证：基本型、强列型、不抛异常型） 透彻了解 inlining 的里里外外（inlining 在大多数 C++ 程序中是编译期的行为；inline 函数是否真正 inline，取决于编译器；大部分编译器拒绝太过复杂（如带有循环或递归）的函数 inlining，而所有对 virtual 函数的调用（除非是最平淡无奇的）也都会使 inlining 落空；inline 造成的代码膨胀可能带来效率损失；inline 函数无法随着程序库的升级而升级） 将文件间的编译依存关系降至最低（如果使用 object references 或 object pointers 可以完成任务，就不要使用 objects；如果能够，尽量以 class 声明式替换 class 定义式；为声明式和定义式提供不同的头文件） 确定你的 public 继承塑模出 is-a（是一种）关系（适用于 base classes 身上的每一件事情一定适用于 derived classes 身上，因为每一个 derived class 对象也都是一个 base class 对象） 避免遮掩继承而来的名字（可使用 using 声明式或转交函数（forwarding functions）来让被遮掩的名字再见天日） 区分接口继承和实现继承（在 public 继承之下，derived classes 总是继承 base class 的接口；pure virtual 函数只具体指定接口继承；非纯 impure virtual 函数具体指定接口继承及缺省实现继承；non-virtual 函数具体指定接口继承以及强制性实现继承） 考虑 virtual 函数以外的其他选择（如 Template Method 设计模式的 non-virtual interface（NVI）手法，将 virtual 函数替换为 “函数指针成员变量”，以 tr1::function 成员变量替换 virtual 函数，将继承体系内的 virtual 函数替换为另一个继承体系内的 virtual 函数） 绝不重新定义继承而来的 non-virtual 函数 绝不重新定义继承而来的缺省参数值，因为缺省参数值是静态绑定（statically bound），而 virtual 函数却是动态绑定（dynamically bound） 通过复合塑模 has-a（有一个）或 “根据某物实现出”（在应用域（application domain），复合意味 has-a（有一个）；在实现域（implementation domain），复合意味着 is-implemented-in-terms-of（根据某物实现出）） 明智而审慎地使用 private 继承（private 继承意味着 is-implemented-in-terms-of（根据某物实现出），尽可能使用复合，当 derived class 需要访问 protected base class 的成员，或需要重新定义继承而来的时候 virtual 函数，或需要 empty base 最优化时，才使用 private 继承） 明智而审慎地使用多重继承（多继承比单一继承复杂，可能导致新的歧义性，以及对 virtual 继承的需要，但确有正当用途，如 “public 继承某个 interface class” 和 “private 继承某个协助实现的 class”；virtual 继承可解决多继承下菱形继承的二义性问题，但会增加大小、速度、初始化及赋值的复杂度等等成本） 了解隐式接口和编译期多态（class 和 templates 都支持接口（interfaces）和多态（polymorphism）；class 的接口是以签名为中心的显式的（explicit），多态则是通过 virtual 函数发生于运行期；template 的接口是奠基于有效表达式的隐式的（implicit），多态则是通过 template 具现化和函数重载解析（function overloading resolution）发生于编译期） 了解 typename 的双重意义（声明 template 类型参数是，前缀关键字 class 和 typename 的意义完全相同；请使用关键字 typename 标识嵌套从属类型名称，但不得在基类列（base class lists）或成员初值列（member initialization list）内以它作为 base class 修饰符） 学习处理模板化基类内的名称（可在 derived class templates 内通过 this-&gt; 指涉 base class templates 内的成员名称，或藉由一个明白写出的 “base class 资格修饰符” 完成） 将与参数无关的代码抽离 templates（因类型模板参数（non-type template parameters）而造成代码膨胀往往可以通过函数参数或 class 成员变量替换 template 参数来消除；因类型参数（type parameters）而造成的代码膨胀往往可以通过让带有完全相同二进制表述（binary representations）的实现类型（instantiation types）共享实现码） 运用成员函数模板接受所有兼容类型（请使用成员函数模板（member function templates）生成 “可接受所有兼容类型” 的函数；声明 member templates 用于 “泛化 copy 构造” 或 “泛化 assignment 操作” 时还需要声明正常的 copy 构造函数和 copy assignment 操作符） 需要类型转换时请为模板定义非成员函数（当我们编写一个 class template，而它所提供之 “与此 template 相关的” 函数支持 “所有参数之隐式类型转换” 时，请将那些函数定义为 “class template 内部的 friend 函数”） 请使用 traits classes 表现类型信息（traits classes 通过 templates 和 “templates 特化” 使得 “类型相关信息” 在编译期可用，通过重载技术（overloading）实现在编译期对类型执行 if…else 测试） 认识 template 元编程（模板元编程（TMP，template metaprogramming）可将工作由运行期移往编译期，因此得以实现早期错误侦测和更高的执行效率；TMP 可被用来生成 “给予政策选择组合”（based on combinations of policy choices）的客户定制代码，也可用来避免生成对某些特殊类型并不适合的代码） 了解 new-handler 的行为（set_new_handler 允许客户指定一个在内存分配无法获得满足时被调用的函数；nothrow new 是一个颇具局限的工具，因为它只适用于内存分配（operator new），后继的构造函数调用还是可能抛出异常） 了解 new 和 delete 的合理替换时机（为了检测运用错误、收集动态分配内存之使用统计信息、增加分配和归还速度、降低缺省内存管理器带来的空间额外开销、弥补缺省分配器中的非最佳齐位、将相关对象成簇集中、获得非传统的行为） 编写 new 和 delete 时需固守常规（operator new 应该内涵一个无穷循环，并在其中尝试分配内存，如果它无法满足内存需求，就应该调用 new-handler，它也应该有能力处理 0 bytes 申请，class 专属版本则还应该处理 “比正确大小更大的（错误）申请”；operator delete 应该在收到 null 指针时不做任何事，class 专属版本则还应该处理 “比正确大小更大的（错误）申请”） 写了 placement new 也要写 placement delete（当你写一个 placement operator new，请确定也写出了对应的 placement operator delete，否则可能会发生隐微而时断时续的内存泄漏；当你声明 placement new 和 placement delete，请确定不要无意识（非故意）地遮掩了它们地正常版本） 不要轻忽编译器的警告 让自己熟悉包括 TR1 在内的标准程序库（TR1，C++ Technical Report 1，C++11 标准的草稿文件） 让自己熟悉 Boost（准标准库） More Effective C++ 仔细区别 pointers 和 references（当你知道你需要指向某个东西，而且绝不会改变指向其他东西，或是当你实现一个操作符而其语法需求无法由 pointers 达成，你就应该选择 references；任何其他时候，请采用 pointers） 最好使用 C++ 转型操作符（static_cast、const_cast、dynamic_cast、reinterpret_cast） 绝不要以多态（polymorphically）方式处理数组（多态（polymorphism）和指针算术不能混用；数组对象几乎总是会涉及指针的算术运算，所以数组和多态不要混用） 非必要不提供 default constructor（避免对象中的字段被无意义地初始化） 对定制的 “类型转换函数” 保持警觉（单自变量 constructors 可通过简易法（explicit 关键字）或代理类（proxy classes）来避免编译器误用；隐式类型转换操作符可改为显式的 member function 来避免非预期行为） 区别 increment&#x2F;decrement 操作符的前置（prefix）和后置（postfix）形式（前置式累加后取出，返回一个 reference；后置式取出后累加，返回一个 const 对象；处理用户定制类型时，应该尽可能使用前置式 increment；后置式的实现应以其前置式兄弟为基础） 千万不要重载 &amp;&amp;，|| 和 , 操作符（&amp;&amp; 与 || 的重载会用 “函数调用语义” 取代 “骤死式语义”；, 的重载导致不能保证左侧表达式一定比右侧表达式更早被评估） 了解各种不同意义的 new 和 delete（new operator、operator new、placement new、operator new[]；delete operator、operator delete、destructor、operator delete[]） 利用 destructors 避免泄漏资源（在 destructors 释放资源可以避免异常时的资源泄漏） 在 constructors 内阻止资源泄漏（由于 C++ 只会析构已构造完成的对象，因此在构造函数可以使用 try…catch 或者 auto_ptr（以及与之相似的 classes） 处理异常时资源泄露问题） 禁止异常流出 destructors 之外（原因：一、避免 terminate 函数在 exception 传播过程的栈展开（stack-unwinding）机制种被调用；二、协助确保 destructors 完成其应该完成的所有事情） 了解 “抛出一个 exception” 与 “传递一个参数” 或 “调用一个虚函数” 之间的差异（第一，exception objects 总是会被复制（by pointer 除外），如果以 by value 方式捕捉甚至被复制两次，而传递给函数参数的对象则不一定得复制；第二，“被抛出成为 exceptions” 的对象，其被允许的类型转换动作比 “被传递到函数去” 的对象少；第三，catch 子句以其 “出现于源代码的顺序” 被编译器检验对比，其中第一个匹配成功者便执行，而调用一个虚函数，被选中执行的是那个 “与对象类型最佳吻合” 的函数） 以 by reference 方式捕获 exceptions（可避免对象删除问题、exception objects 的切割问题，可保留捕捉标准 exceptions 的能力，可约束 exception object 需要复制的次数） 明智运用 exception specifications（exception specifications 对 “函数希望抛出什么样的 exceptions” 提供了卓越的说明；也有一些缺点，包括编译器只对它们做局部性检验而很容易不经意地违反，与可能会妨碍更上层的 exception 处理函数处理未预期的 exceptions） 了解异常处理的成本（粗略估计，如果使用 try 语句块，代码大约整体膨胀 5%-10%，执行速度亦大约下降这个数；因此请将你对 try 语句块和 exception specifications 的使用限制于非用不可的地点，并且在真正异常的情况下才抛出 exceptions） 谨记 80-20 法则（软件的整体性能几乎总是由其构成要素（代码）的一小部分决定的，可使用程序分析器（program profiler）识别出消耗资源的代码） 考虑使用 lazy evaluation（缓式评估）（可应用于：Reference Counting（引用计数）来避免非必要的对象复制、区分 operator[] 的读和写动作来做不同的事情、Lazy Fetching（缓式取出）来避免非必要的数据库读取动作、Lazy Expression Evaluation（表达式缓评估）来避免非必要的数值计算动作） 分期摊还预期的计算成本（当你必须支持某些运算而其结构几乎总是被需要，或其结果常常被多次需要的时候，over-eager evaluation（超急评估）可以改善程序效率）","tags":["C++"],"categories":["C++"]},{"title":"GDB: The GNU Project Debugger","path":"/post/系统与体系结构/debugging-with-gdb/","content":"官方文档：GDB: The GNU Project Debugger 官方提供的 GDB Document 所展示的 gdb 调试全过程示例如下链接【已阅】：https://sourceware.org/gdb/current/onlinedocs/gdb/Sample-Session.html#Sample-Session gdb m4 set width 70 break m4_changequote &#x2F; b m4_changequote run &#x2F; r n &#x2F; next s &#x2F; step backtrace &#x2F; bt p lquote &#x2F; print lquote list &#x2F; l p len_lquote=strlen(lquote) c &#x2F; continue ctrl-d &#x2F; quit 1. gdb 启动 gdb12345# 直接启动 gdb$ gdb# 启动 gdb 的同时加载一个要调试的 [可执行文件]# 该 test 文件在编译的过程中必须要加 -g 选项, 把调试信息加到可执行文件中: gcc -g test.c -o test$ gdb test 2. quit&#x2F;q 退出 gdb12$ quit$ q 3. file 命令加载程序1234$ file [可执行文件](gdb) file testReading symbols from test... 4. list&#x2F;l 命令显示源代码1list` 命令可以列出可执行文件的源代码的一部分，简写为 `l 该命令既可不带参数：list 命令将显示 10 行代码，第一次从首行开始显示，第二次从上次显示的末行的下一行开始显示，以此类推 也可带 1 个参数：list n 命令显示的是第 n 行的前 5 行和后 4 行代码 或者带 2 个参数：list n1, n2 命令显示的是 n1—n2 行之间的源代码内容 还可以显示某函数附近的源代码内容：list funcname 123456789101112131415161718192021222324(gdb) list1 #include &lt;iostream&gt;2 #include &lt;fstream&gt;3 #include &lt;vector&gt;45 using namespace std;67 int main()8 &#123;9 ofstream outfile;10 outfile.open(&quot;./results/MD_trace_results.txt&quot;, ios::out | ios::app);(gdb) l11 if (!outfile.is_open())12 &#123;13 cout &lt;&lt; &quot;failed&quot; &lt;&lt; endl;14 exit(1);15 &#125;1617 cout &lt;&lt; &quot;succeeded&quot; &lt;&lt; endl;1819 return 1;20 &#125;(gdb) lLine number 21 out of range; open_file.cpp has 20 lines. 5. run&#x2F;r 命令运行程序使用 run &#x2F; r 可以在 gdb 中运行调试中的程序，该命令可以跟一个或多个参数，作为运行程序的命令行参数。 12345678910(gdb) run 1 2 3`/home/wyk/straid/code/open_file&#x27; has changed; re-reading symbols.Starting program: /home/wyk/straid/code/open_file 1 2 3argc = 4argv[0]: /home/wyk/straid/code/open_fileargv[1]: 1argv[2]: 2argv[3]: 3succeeded[Inferior 1 (process 145429) exited with code 01] 使用 show args 命令显示传给该程序的参数列表： 12(gdb) show argsArgument list to give program being debugged when it is started is &quot;1 2 3&quot;. 如果重新运行 run 则会将上次的命令行重新参数传给该程序。 如果要改变传递给程序的参数，可使用 set args： 12345678910(gdb) set args 4 5 6(gdb) runStarting program: /home/wyk/straid/code/open_file 4 5 6argc = 4argv[0]: /home/wyk/straid/code/open_fileargv[1]: 4argv[2]: 5argv[3]: 6succeeded[Inferior 1 (process 145554) exited with code 01] 6. break&#x2F;b 命令设置断点程序执行到断点时将被挂起，有以下几种方式设置断点： 1break` 命令也有简写形式 `b (1) 根据行号设置断点 break &lt;linenum&gt; 12(gdb) break 10Breakpoint 1 at 0x5555555552d5: file open_file.cpp, line 10. 设置好断点后启动程序，会停在断点位置： 12345(gdb) runStarting program: /home/wyk/straid/code/open_file 4 5 6Breakpoint 1, main (argc=4, argv=0x7fffffffe178) at open_file.cpp:1010 cout &lt;&lt; &quot;argc = &quot; &lt;&lt; argc &lt;&lt; endl; (2) 根据函数名设置断点 break &lt;funcname&gt; 12(gdb) break mainBreakpoint 2 at 0x5555555552a9: file open_file.cpp, line 8. (3) 执行非当前源文件的某行或某函数时停止执行（为非当前源文件设置断点） 123(gdb) break filename:linenum# or(gdb) break filename:funcname (4) 根据条件停止执行程序 123(gdb) break linenum if expr# or(gdb) break funcname if expr ⭐清除断点： clear &lt;source-line&gt;：清除源文件某一行的所有断点 delete &lt;breakpoint-id&gt;：删除 info b 中对应 ID 的断点 1234567891011121314(gdb) info bNum Type Disp Enb Address What1 breakpoint keep y 0x00005555555553ad in main(int, char**) at open_file.cpp:172 breakpoint keep y 0x00005555555553e3 in main(int, char**) at open_file.cpp:193 breakpoint keep y 0x00005555555552d5 in main(int, char**) at open_file.cpp:10(gdb) clear 17 # 清除源文件 line 17 位置的断点(gdb) info bNum Type Disp Enb Address What2 breakpoint keep y 0x00005555555553e3 in main(int, char**) at open_file.cpp:193 breakpoint keep y 0x00005555555552d5 in main(int, char**) at open_file.cpp:10(gdb) delete 2 # 清除 Num=2 的断点(gdb) info bNum Type Disp Enb Address What3 breakpoint keep y 0x00005555555552d5 in main(int, char**) at open_file.cpp:10 7. 在不退出&#x2F;中断 gdb 的情况下使用 shell 命令：!&lt;command&gt; 或 shell &lt;command&gt;1234567891011121314151617181920212223# don&#x27;t work(gdb) echo $PATH# works(gdb) shell echo $PATH/home/wyk/.vscode-server/bin/8fa188b2b301d36553cbc9ce1b0a146ccb93351f/bin/remote-cli:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin(gdb) !ls -al $PWDtotal 108drwxrwx--- 8 wyk wyk 4096 Dec 17 17:36 .drwxrwxr-x 6 wyk wyk 4096 Dec 7 08:57 ..drwxr-xr-x 2 root root 4096 Dec 7 12:43 bindrwxrwxr-x 7 wyk wyk 4096 Dec 7 12:43 include-rwxrwxrwx 1 wyk wyk 278 Nov 22 03:04 install_depends.sh-rwxrwxr-x 1 wyk wyk 3589 Dec 7 09:12 Makefiledrwxr-xr-x 2 root root 4096 Dec 7 12:43 obj-rwxrwxr-x 1 wyk wyk 41016 Dec 17 17:36 open_file-rw-rw-r-- 1 wyk wyk 535 Dec 17 17:36 open_file.cpp-rw-rw-r-- 1 wyk wyk 5964 Nov 22 03:04 README.mddrwxrwxr-x 2 wyk wyk 4096 Dec 7 10:38 results-rwxrwxrwx 1 wyk wyk 880 Dec 12 15:08 run_bench.sh-rwxrwxrwx 1 wyk wyk 486 Dec 7 10:37 run_tracemd.sh-rwxrwxrwx 1 wyk wyk 397 Dec 7 09:27 run_tracest.shdrwxrwxr-x 2 wyk wyk 4096 Nov 22 03:04 srcdrwxrwxr-x 2 wyk wyk 4096 Nov 22 03:04 Traces 因为在 GDB 中不常使用 shell 命令，所以需要 shell 和 ! 的限制，而经常在开发环境中使用 make 命令，所以无需使用以上符号即可调用 make 命令。 12345678910# make 命令可直接调用(gdb) make -j4# sudo 命令：还是得使用 ! 或者 shell(gdb) !sudo make -j10[sudo] password for wyk: g++ -I. -I./include -I./include/Bitmap -I./include/concurrentqueue -I./src -Wp,-MT,obj/define.o -Wp,-MMD,obj/define.o.d -g -std=c++2a -Wall -Wno-unused-variable -Wno-unused-but-set-variable -Wno-sign-compare -Wno-comment -O3 -c -o obj/define.o ./include/define.ccg++ -I. -I./include -I./include/Bitmap -I./include/concurrentqueue -I./src -Wp,-MT,obj/ecEncoder.o -Wp,-MMD,obj/ecEncoder.o.d -g -std=c++2a -Wall -Wno-unused-variable -Wno-unused-but-set-variable -Wno-sign-compare -Wno-comment -O3 -c -o obj/ecEncoder.o ./include/ecEncoder.ccg++ -I. -I./include -I./include/Bitmap -I./include/concurrentqueue -I./src -Wp,-MT,obj/metadata.o -Wp,-MMD,obj/metadata.o.d -g -std=c++2a -Wall -Wno-unused-variable -Wno-unused-but-set-variable -Wno-sign-compare -Wno-comment -O3 -c -o obj/metadata.o ./include/metadata.cc... @ 管道命令 |, 可用 pipe 将 gdb 中的命令与 shell 命令结合使用 [ | 原本是用于 shell 与 shell 之间的管道命令 ] 1234567891011# 不生效(gdb) show args | wc -lArgument list to give program being debugged when it is started is &quot;1 2 3&quot;.# 使用 pipe 即可打通 gdb 与 shell 之间的传输(gdb) pipe show args | wc -l1(gdb) pipe p argv | wc -l1# | 原本用于 shell 与 shell 之间的命令传输(gdb) !ls -al | wc -l17 8. s 命令 &#x3D;&#x3D; step「单步进入」1234(gdb) help sStep program until it reaches a different source line.Usage: step [N]Argument N means step N times (or till program stops for another reason). 9. finish 命令「单步跳出」1234(gdb) help finishExecute until selected stack frame returns.Usage: finishUpon return, the value returned is printed and put in the value history. 10. n 命令 &#x3D;&#x3D; next「单步跳过」123456(gdb) help nStep program, proceeding through subroutine calls.Usage: next [N]Unlike &quot;step&quot;, if the current source line calls a subroutine,this command does not enter the subroutine, but instead steps overthe call, in effect treating it as a single source line. 11. c 命令 &#x3D;&#x3D; continue「跳到下一个断点」1234567891011(gdb) help cContinue program being debugged, after signal or breakpoint.Usage: continue [N]If proceeding from breakpoint, a number N may be used as an argument,which means to set the ignore count of that breakpoint to N - 1 (so thatthe breakpoint won&#x27;t break until the Nth time it is reached).If non-stop mode is enabled, continue only the current thread,otherwise all the threads in the program are continued. To continue all stopped threads in non-stop mode, use the -a option.Specifying -a and an ignore count simultaneously is an error. 12. return n 命令直接跳过当前函数后面的语句并直接返回 n，该 n 值是自定义的返回值12345678910(gdb) return 6Make main(int, char**) return now? (y or n) y#0 __libc_start_main (main=0x5555555552a9 &lt;main(int, char**)&gt;, argc=4, argv=0x7fffffffe178, init=&lt;optimized out&gt;, fini=&lt;optimized out&gt;, rtld_fini=&lt;optimized out&gt;, stack_end=0x7fffffffe168) at ../csu/libc-start.c:342342 ../csu/libc-start.c: No such file or directory.(gdb) n[Inferior 1 (process 148790) exited with code 06](gdb) nThe program is not being run. 13. print var&#x2F;p var 命令查看 var 值12345678910111213141516(gdb) print argv$1 = (char **) 0x7fffffffe178(gdb) print argc$2 = 4(gdb) print *argv[0]$3 = 47 &#x27;/&#x27;(gdb) print argv[0]$4 = 0x7fffffffe42e &quot;/home/wyk/straid/code/open_file&quot;(gdb) print argv[1]$5 = 0x7fffffffe44e &quot;1&quot;(gdb) print argv[2]$6 = 0x7fffffffe450 &quot;2&quot;(gdb) print argv[3]$7 = 0x7fffffffe452 &quot;3&quot;(gdb) print argv[4]$8 = 0x0 14. backtrace &#x2F; bt 与 frame、up、down、info 搭配食用：查看函数调用栈的最佳命令｜快速定位 bug 位置 立瀚教学 get 到 backtrace，转载链接：gdb调试之函数调用栈——backtrace 更基础的 gdb 内容：GDB调试利器 bt ：bt是 backtrace 指令的缩写，显示所有的函数调用栈的信息，栈中的每个函数都被分配了一个编号，最近被调用的函数在 0 号帧中（栈顶），并且每个帧占用一行。 bt n ：显示函数调用栈从栈顶算起的 n 帧信息（n 表示一个正整数）。 bt -n ：显示函数调用栈从栈底算起的 n 帧信息。 bt full ：显示栈中所有信息如：函数参数，本地变量等。 bt full n ：显示函数调用栈从栈顶算起的 n 帧的所有信息。 bt full -n ：显示函数调用栈从栈底算起的 n 帧的所有信息。 上面的 bt 指令主要是查看栈的信息，而每一帧都会有详细的信息，这些函数调用信息帧包括：调用函数的地方，函数的参数等。如果想查看栈中某一帧的信息，首先要做的是切换当前栈。这时候需用用到 frame 指令（缩写形式为 f）。 f n &#x2F; frame n: 它的功能是切换到编号为 n 的栈帧（n 表示一个正整数），并显示相关信息。 除了使用 frame 指令切换栈帧外，还可以使用 up 和 down 指令。 down n ：表示往栈顶方向下移 n 层（n 表示一个正整数，默认值为 1）。 up n ：表示往栈底方向上移 n 层。 info 指令是一个很强大的指令，使用它可以查看各种变量的值，如果我们希望看到详细的函数调用信息帧的信息，如：函数地址、调用函数的地址、被调用函数的地址、当前函数由哪种编程语言编写、函数参数地址及形参值、局部变量的地址、当前桢中存储的寄存器等，可以使用以下指令： info frame ： 指令的缩写形式为 i f ，查看函数调用帧的所有信息。 info args ：查看函数变量的值。 info locals ：查看本地变量的信息。 15. 了解一下 GDB 的语法规则|注意事项 使用 gdb 调试的前提是在编译命令中添加 -g 参数，因为有些编译器是无法同时处理 -g 和 -O 选项，所以无法调试带有调试信息 (-g) 的优化 (-O) 可执行文件！ gdb 是单行输入，由 &lt;命令&gt; 跟着 &lt;参数&gt;，取决于命令，比如 step 5 表示连续执行 5 次 step 对于缩写无歧义的 gdb 命令，通常可以截断使用；如果有些以相同字母开头可能造成歧义的命令，可以使用 help 命令来判别该缩写命令是属于哪一条具体的命令，比如 help s 直接按下「回车」会重复上一步命令，但是对于某些可能带来麻烦的命令不会生效，比如 run；对于 list 和 x 命令，按下回车会构造新的参数来重复命令，这样方便扫描资源和内存（连续按下 list 会往下不断展示 10 行代码） ，ctrl+o 同 Enter # 表示注释，同 shell 脚本 gdb 使用 Tab 按钮也可「补全命令」 1234567891011121314# 盘点一些 gdb 系统命令 [Useful](gdb) help(gdb) help &lt;command&gt;(gdb) complete &lt;alphabet&gt; # 列出以 alphabet 开头的所有命令, 比如 complete sh: sharedlibrary shell show(gdb) show(gdb) info(gdb) set# Here are several miscellaneous show subcommands, all of which are exceptional in lacking corresponding set commands:(gdb) show version(gdb) show copying(gdb) info copying(gdb) show warranty(gdb) info warranty(gdb) show configuration ⭐更多内容（未完待续）： inferior 可以同时调试多个程序 info inferiors inferior &lt;infno&gt; add-inferior clone-inferior remove-inferiors &lt;infno&gt; kill inferiors &lt;infno&gt; … threads 可以调试多线程 info threads … checkpoint 可以保留快照，搭配 restart &lt;checkpoint-id&gt; 回到快照点，当你接近错误点时，可以保留快照，如果因为走得太远导致错过关键语句，无需重新启动程序，直接跳回上一个快照点 checkpoint 即可 checkpoint: 在此处留下快照点 info checkpoints: 查看所有快照点信息 restart &lt;checkpoint-id&gt;: 回到指定快照点 delete checkpoint &lt;checkpoint-id&gt;: 删除指定快照点 … watchpoint: 当观察的表达式变化时，立刻停下 catchpoint: 当某个事件触发时，立刻停下 breakpoint: 断点——毋庸置疑 b &lt;linenum&gt; b &lt;funcname&gt; info breakpoints save breakpoints &lt;filename&gt; disable breakpoints enable breakpoints clear &lt;source-line&gt;：清除源文件某一行的所有断点 delete &lt;breakpoint-id&gt;：删除 info b 中对应 ID 的断点 step step 是单步程序源代码 stepi 是单步机器指令 next next 是单步程序源代码 nexti 是单步机器指令 finish until …","tags":["C++","gdb"],"categories":["系统与体系结构"]},{"title":"技术人求职指南","path":"/post/秋招指南/job-hunting-guide-for-technical-personnel/","content":"序言：求职市场凛冬已至，技术人该如何杀出重围整个小册内容可分为 求职前、求职中、求职后、入职后 四个阶段，具体如下： 本小册始于求职，却不止步于求职，虽然未曾包罗职场所有的软技能，但是对于技术人职场这个板块，许多方面都有所涉及。同时，尽管整个小册未牵扯任何技术内容，看着学起来难度不大，但其中无一不是实用的技巧分享，重要性远超你去学习某个单一的技术，能得到的回报也绝对会远超你所花费的成本。 整体收益清单如下： 工作多年的技术人，能给自己做好技术总结与定位； 能够掌握平时学习、面试前复盘的技巧与方法论； 能搞懂招聘方的用人需求、HR筛选简历的具体过程； 学会简历优化的技巧，打造一份最适合自己的简历； 理解投递简历的时机、技巧，增多自己的面试机会； 能摸透求职面试过程中的面试官，到底是什么角色； 学会消除面试前的焦虑，及调研要入职的目标公司； 掌握各类面试场景中的引导、控场技巧、忌讳点； 能从容应对HR面中的各类人事问题，以及谈薪技巧； 学会面试之后如何对面试进行总结、复盘与自我优化； 多个Offer在手时，学会自行判断哪个才最适合自己； 作为新人入职时，如何快速融入新环境和安稳转正； 具备做职业规划的能力，合理安排职业的生涯路线； 大龄程序员该怎样避免中年危机，保持核心竞争力； 如果被提拔成技术管理层，如何才能带好自己的团队； 学会如何优雅地向上级领导、公司提出涨薪与离职； 当工作出现意外状况，学会利用法律进行合理维权； 了解如何实现“睡后收入”，避开“副业兼职”的坑。 自我认知篇：作为技术人该如何定位自己在行业内的级别？一、如何理解技术行业内的级别？人分三六九等，技术行业内的潜规则同样如此。 不同行业对于技术工种的等级划分，具体职称上也许会有不同，但殊归同途，凡是涉及到技术性的岗位，都能被分为“初级、中级、高级、资深”这四个级别，简单总结如下： 初级：掌握岗位要求的基本技术，满足日常工作的基本需求（能干活）。 中级：不仅仅只局限于满足基本需求，在广度上也有着丰富认知（能干更多的活）。 高级：对技术不是停留在表面应用，而是在技术的深度上有一定研究（懂原理）。 资深：除开有着广度、深度认知外，能充分了解各个细节并解决问题（懂原理还有实际经验）。 可以看出，越往后级别越高，专业能力也会越强。这里对高级和资深稍作解释：高级更偏向于理论派，懂很多知识但没有太多实战经验；而资深则属于实战派，不仅懂，还具备丰富的经验沉淀，资深既代表了能力，还代表了资历，以及权威性。 作为技术人的我们，了解这些级别划分后，同时也要清楚自己的定位，否则就会出现如下这种尴尬场景： 目前处于初级水平，但偏偏学习时在看底层原理，求职路上发现面试官压根不问。 学习是件好事，但必须掌握科学的方式方法，千万别盲目跟风学习，只有明确了自身的能力定位后，才能带来最大的学习收益。比如，认识到自己目前处于“爬”阶段，那下一阶段则要学习“走”的能力，而跳过“走”直接去学“跑”的方案也并非不可取，只是并没有学“走”给自己带来的收益大罢了。 二、技术人该如何明确自我定位？关于明确自我定位的好处在前面已重点说明，一方面有利于清晰地认识自我水平，另一方面则可以确定提升的方向。 不过自我定位是一个比较虚的概念，针对不同的人、不同的工作年限，实际情况会存在些许差异。为此，下面会先讲明不同年限应该要达到的级别，接着再阐述技术人该如何进行自我总结，最后则会针对一些特殊情况进行讲解。 不同年限的工作者应该达到的级别在技术行业中都有一个潜规则，那就是一位从事N年的人，应该要达到XXX水平，比如今天公司招了一位具有九年经验的新员工，虽然你与他之间素未谋面，但潜意识下，就会觉得来了个大牛，这也是工作年限带来的“附加Buff加成”。 不过虽说年限不一定代表能力，但对于业内的技术人员而言，都可以依据不同年限做出一定判断，在这件事上所有技术人都有一个“共识”，通常来说，不同年限对应的标准如下。 工作0~2年：至少需要达到初级水准。 工作3~5年：至少需要达到中级水准。 工作5~8年：至少需要达到高级水准。 工作8年以上：至少需要达到资深水准。 至少要将能力与工作年限保持正比，否则一方面薪资不如意，另一方面求职机会也会少上许多。 技术人该如何做好自我总结？自我总结依旧是一个比较泛的概念，有工作总结、年度总结、人生总结等各色各样的总结，相信大家也一定写过不少，尤其是入职一家要求写日报、周报、月报的企业时，XXX总结会令人写到麻木。不过我这里提到的并非常规性的自我总结，而是技术人的能力总结，更偏于撰写一份自己的“知识图谱”。 只有总结了自己的技术能力，才能帮助我们更加清晰地认识自我。但往往很多人都缺乏这种“技术总结”的能力，尤其是随着工作年限的增长，工作中会出现如下场景： 新入职的工作要用到这个，我得去学一学。下周接手的项目上会用到XXX技术，我得抽空去看看。新项目中要XXX来做，我得去瞅瞅。……. 相信碰到这种情况的人不在少数，很多时候去学习一项新技术，都会有点身不由己，并不是自己想学，而是工作需要，不得不去掌握！最终就造成了“这也会，那也会，什么都会，但似乎又什么都不会”的尴尬局面出现。 当遇到这种情况，如果长期处于一家企业不动还好，但当你再次踏上求职路时，此前埋下的诸多弊端就会凸显出来，不知道如何写简历、如何准备面试、不清楚自己该找什么级别的工作……彻底迷失了自我，并失去了前进的方向。 这种现象往往在工作年限较长的群体中额外明显，想要走出这个困境，首先得学会对自我的技术进行总结！如何总结呢？最有效的方法是：知识树。 知识树是指通过思维导图之类的软件，例如通过支持在线编辑的 XMind 进行技术归纳，先将自己掌握的诸多技术按属性进行总结，再从知识树中得出反馈，从而确定自己的能力级别，如下所示： 但在做知识树总结时，有三点需要注意。 第一点，整棵知识树应当围绕着一个明确的方向展开（⭐比如 C++ 方向）。因为知识树要具备高强度的专业性，不能将日常生活中懂的方方面面全部写进去，这显然并不合适。开始撰写前必须先挑选自己最擅长的方向作为主体。以开发岗为例，如果你掌握了多门语言，那么一定要先选择一门语言作为主体，其他技能可以归纳到另一个主体分支中： 第二点，知识树不应该无限制延伸。这里主要针对树的深度和分支数量，对于某个具体的技术栈，千万别把每个细节都详细罗列，也不必无限往下深究原理，如下： 上述只是简单示例，重点是要记住不要无限拓展即可，毕竟这是总结，不是写书、写手册，如果不控制树的深度，浪费时间不说，同时还失去了总结的初衷。 就好比写小说，咱们只需要将情节脉络、目录规划写出即可，无需在其中详细写出每一个情节、章节的具体内容。 第三点，首次进行总结，不必追求完美。很多人首次画知识树时，往往都会追求完善性，写一个技术栈时，刻意去搜索还有哪些没写，还有哪些可以补充的。但记住：在首次画知识树时，你记得多少写多少就行，后面可以继续完善。 同时在画知识树时，千万要牢记：列出来的技术点一定是自己熟悉的，不要把只听过或者只简单了解过的技术点罗列在其中！画知识树不是设计技术大纲，实事求是才能得到最准确的答案。 如何根据知识树判断自己的能力？当各位将知识树画好后，首先纵观知识树的二&#x2F;三级分支数量，如果仅有几个，这意味着你很大可能处于“初级水平”，也就是能满足工作的基本需求。反之，如果分支数量较多，整棵树的主干已经涉及了很多主流技术栈，那也就意味着你很大可能达到了“中级水准”。 那如何判断自己是否达到了“高级”水平呢？这点依旧可以靠知识树来给出答案，如果知识树广度足够，挨个去看罗列出的技术栈，询问自己是否理解技术的大体原理。如果你认为对大部分技术，都有一定深度的见解，再加上自己具有不错的经验沉淀，那么恭喜你，你已经达到了“高级”水平。 最后，如果技术广度、深度都有了，如何判断自己是不是资深呢？对于这个问题，知识树和我都给不了你答案，此时的你应该扪心自问，自己是否达到了资深水平？ 因为高级和资深之间，其实并没有明确的边界，更多的是技术见解、经验沉淀上的差异，如果一个已达资深水平的技术人，当你询问内心时，你就一定能够给出自信的答案。 技术能力与工作年限不匹配怎么办？在经过技术总结后，如果你发现能力和年限严重不匹配，好比你有六年经验，结果到头来一看，哦豁！能力就中级怎么办？这时需要做的自然就是学习，但学习的过程无疑是痛苦且难坚持的，尤其是工作并不轻松的小伙伴，代表需要拿出休闲、下班后的时间去学习。 但凡事先苦而后甜，如果连学习的苦都吃不下，那你只能本本分分地当一个“菜鸟”，更高的薪资？更好的发展？不存在的，既然选择在技术行业继续打拼，那就不要停下学习的脚步！当你学不进去想要放弃时，记住一句话：这是未来的你，正在向你发出的求救信号！ 不过学习也并非靠死办法，产生兴趣才是最好的良药，后面会有关于学习方法的分享，但这些是后话了。 如何根据能力定位，确定提升方向？ 事先声明：如果急着找工作，可以先跳过这点，因为学习是长久的事，不能操之过急。 针对前面的多种情况，如果是初级，那下一步的提升计划，应该围绕着技术广度展开，至少要将当前专业内的大部分主流技术掌握后，才能达到“中级水准”。 🎯对于「初级」的小伙伴来说，提升广度的技术要学哪些呢？很简单，去看市场招聘，看招聘中频繁出现的技术栈，对于你不会的，统统记录下来，然后用不同的颜色，加入到知识树中，最后去进行相应学习即可。 🎯而目前已经达到「中级水准」时，下一步的提升应该针对技术深度，也就是对自己掌握的技能，别再停留在表面应用，而是深入内部探寻其原理，使用经验+深度，才能帮你抵达“高级水平”。 那中级水准的小伙伴，加强深度的方向是什么呢？比较快的做法就是找培训机构，也就是那些打着“XXX进阶课程”名号的机构，对于他们课程的含金量先不做评价，重点是参考他们的课程大纲！虽说课程质量不一定能保障，但大纲这块绝对花了心血，毕竟这是招牌，想要吸引“进阶培训”的学员，课程大纲必然要令人满意。 培训机构卖的进阶课程，绝对是技术的风向标，任何一家机构都不会掺杂无用内容在里面，大纲是市场需求提炼后的精华内容。当你拿到课程大纲后，直接和自己的知识树比对，把自己没有掌握的技术，同样用不同颜色标注上去即可。 知识树标出自己要提升的技术点后，接着可以慢慢学习，学习的同时要记得完善知识树，毕竟前面只是简单的罗列，后续学会某个技术栈后，可以将大体梗概补充在知识树中，这也能够帮助你后续快速复习。 ⭐额外说明，不是你把某个技术学了，就代表你一定会了它，牢记：学是一回事，用是另外一回事！千万不要产生一个错觉，也就是看了一套教程就代表学会了它，只有当你能把这项技术灵活运用时，才代表着真正学会了它。 🚫所以大家在学习工作用不到的技术时，请一定要多加思考！很多时候，尤其是看视频学习，人会处于“接受式思维”，别人怎么教，自己就怎么理解，这样带来的弊端就是： 当相同的技术换一个场景，你就不会用了，这显然不能说你会了这项技术，只能说有所了解。 为此，想要真正学会一项新技术，要带有“质疑式思维”去看！学习时多思考，才能真正帮你掌握它。尤其是针对一些还在校的小伙伴来说，因为没有过实际的业务经验，所以学习时更需如此，否则会导致面试中，换个方式问，结果就一问三不知。 三、怎样得到自我画像？前面讲清楚了技术级别、自我定位以及如何制定提升的计划，下面开始接入“求职话题”的正轨。 求职是一场没有硝烟的战争，想要把这场仗打得漂亮，就必须要牢记一点：成功需要缜密的计划和精心的准备！对于冲动之下就提桶跑路的做法，我个人不是很赞成，因为这会让求职变得异常被动，如下： 快速与目前公司交接工作，办理离职的相关手续； 草草地写好简历，开始通过各大招聘渠道投递简历； 简单地刷刷面试题八股文，准备迎接面试开始； 面试发挥不够理想，人事通知：先暂时回家等通知； 反复投简历、去面试、等通知、不断处于焦虑中…… 上面这个找工作的过程，我将其称之为运气流面试法，尤其当能力一般时，会显得异常被动，能否成功上岸找到下家，主动权统统交给了市场。运气好，可能很快就找到了新工作。运气略微背一点，稍微拖上几周的时间，你内心就会慢慢变得焦虑、心态逐渐变差…… 要记住！找工作是你选公司，而并不是公司选你，求职的目标应该是钱多事少离家近，而不是跌跌撞撞碰运气。 那怎么做到你选公司呢？这需要你对自身有全面的了解，在前面认识到自身的技术能力后，接着还要看看自己的综合条件。 古人讲究吾日三省吾身，而作为求职者的我们，也理当如此，但这三省究竟是什么呢？ 自己的学历背景怎么样？ 自己的工作履历怎么样？ 自己的技术能力怎么样？ 在正式踏上求职路之前，一定要想明白这三个问题，因为这三点贯穿咱们整个求职旅途。 学历背景怎么样？学历背景，这将直接决定着你面试机会的多与少，虽说许多人都在高呼：“学历其实并没有那么重要！” 但不可置疑的一点就是：学历是你求职路上的敲门砖，如果学历不行，很多人事会直接用软件过滤掉。 除开少部分公司，如今大部分企业的HR压根不看本科以下的简历，本科以下的会直接过滤，连看都不看，是不是很残忍？但事实就是如此。 连能力都不看就直接pass，有人也许会觉得这未免太不公平了吧！但请记住：95%+的HR并不懂技术，同时也不缺应聘者，工作年限、能力无法三言两语确认，所以学历便成了筛选的第一关，从高学历的群体中挑选人才，会比从所有群体中挑选人才更简单。 工作履历怎么样？工作履历是指自己的工作年限与经历，这其中包含了上家公司的性质、背景等。如果你有大厂背景，例如BATJ企业的工作经验，这无疑将成为你求职路上的闪光点，至少在你出去面试时，许多人都会下意识地为你打上大佬的标签。 不过除开大厂背景外，你目前的工作年限以及上家公司的性质，是外包、自研、外企还是独角兽？（下文有详细介绍） 这些多少会对你后面的求职有些许影响，Why？因为你的工作履历将决定着你下份工作的收入，不同履历的求职者，市场会给予不同的报价，很少有人能打破涨薪30%的限制。例如一位只具备两年外包经验的求职者，市场能否给到30K的薪酬呢？显然并不现实，就算你技术再优秀，也很难打破市场的潜规则。 ✍不过，履历虽然决定求职报价，但 30% 的薪资涨幅（最多 30%，潜规则），也并不是所有人都能拿到，除非你能力十分出色，否则一般涨幅只会处于 10%～20% 这个区间，按如今的环境来看，「平跳」都是很常见的事。 技术能力怎么样？学历决定了面试机会的多与少，履历决定了薪资的高或低，而技术能力则是最后一省，这也是最重要的！ 任何一个技术行业，不存在只靠优秀的学历、出色的履历，就能成功入职的情况，技术行业的根本是以技术作为驱动，你技术能力的强弱，将直接决定着你能否通过面试。 学历虽然决定着面试机会，但在技术能力够强的前提下，也并非绝对，比如Vue的作者尤大（尤雨溪），假设他就算是初中学历，此时去找工作，学历高或低，这对他会有影响吗？答案很显然。 当然，有人或许会觉得举例很极端，技术能达到这个层次的人，才多少呢？ 确实，但我要表达的意思是：只要你能力够强，学历其实没有那么重要！一般社招（三年以上）有本科学历，不管背景、性质如何，相对来说影响就不大了。同时，市场对“高能力的人才”的包容性很强，大家可以去看“六年以上”的社招市场，就算你的学历是专科，依旧存在一大批能达标的招聘。 因此，当你达到某些条件后，就算学历、履历不行，只要技术足够OK，可以忽略前面两条。 三省吾身后得到自我画像在真正准备面试前，作为求职者的我们必然要思考前面三个问题，思考清楚后同样用思维导图的形式进行总结： 学历决定面试数量，履历决定薪资待遇，技术决定能否入职！其中最重要的是第三条，大家都身处在这个行业，对于这条的含义，诸位也许比我更明白。在我的工作生涯中，也见过许多名校毕业、高学历者面试被pass，毕竟能做事才是这个行业最重要的前提。 仔细想明白这三点后，相信大家对于下份工作，该找什么类型、什么薪资范围的下家，心里多多少少有谱了。 不过这并非是让大家“三省吾身”的初衷，做这一步只是为了让诸位更全面地认识自己，尤其对条件较差的小伙伴而言，如学历较低的伙伴，很多时候会下意识逃避这一点，但只有当认识到自身的缺陷后，才能便于后续做出调整。 求职意向篇：怎样定下合理的期望薪资及确定目标公司？现在应该对自己的技术、现状有了新的认知，但也仅仅止步于此。 如何根据自我画像，制定合理的期望薪资呢？如何选择适合自己的公司呢？ 一、如何制定合理的期望薪资？求职者的面试期望，主要包含期望薪资、目标公司这两方面，想要制定合理的求职期望，需要结合自身情况、市场环境来综合考虑。下面一起聊聊吧～ 影响期望薪资的因素先讲明几个影响期望薪资的因素，接着再说如何制定期望薪资，影响薪资的因素有以下四个。 市场氛围：如果大环境整体氛围不行，跳槽时几乎很难找工作，涨薪的可能性也会很小。 技术级别：不同的技术能力，好比初级和高级，两者拿到的薪水待遇自然不同。 所在城市：一线、新一线、省会、非省会城市之间，薪资待遇必然有所差异。 一线城市：北京、上海、广州、深圳。 新一线城市：成都、重庆、杭州、武汉、苏州、西安、南京、长沙、天津、郑州、东莞、青岛、昆明、宁波、合肥。 二线城市：泉州、厦门、福州、… 三线城市：… 四线城市：… 五线城市：… 工作履历：很多人上一份工作履历，将会成为下一份工作的基础，薪资涨幅会受限。 大环境的市场氛围如何判断？很多人在跳槽前，最想知道的就是目前外面的行情怎么样，接着会根据行情来决定是提桶跑路、还是继续窝着。 行情好不好其实可以直观地从招聘软件看出，根据招聘方的活跃度进行判断。如果你所在的城市，发布招聘需求的大部分招聘者活跃度很低，这意味着当前城市的行情并不是很好，很多HR、Boss都停止了招聘。 但这种手段需要一定的数据支持，单纯靠人工手动来进行判断，需要查看大量招聘才能得到具体的反馈，因此这种方式最好结合数据采集手段（爬虫）完成，效率更快的同时，精准性也会更高。 当然，大家也可以通过技术群&#x2F;社区等渠道，直接询问相关城市的同行，以此得到大概行情。 如果目前行情并不佳，最好的选择是骑驴找马，也就是暂时先不辞去当前工作，先出去试试水感受氛围，找到满意的下家后可以选择无缝衔接。但如果目前已经离职，想要在行情较差的市场中找到工作，那这时就需要做好降低期望的心理准备（尤其是在如今这个四处喊着“XXX已死”的时段内，新工作很有可能是平跳，甚至降薪）。 不同城市、技术级别的薪资标准自身技术级别、所在城市，都会影响你的期望薪资。IT行业公认的薪资梯队如下： 这里以一线城市的后端开发岗为例，来说明不同级别的薪资范畴。 初级开发工程师：7K～13K左右。 中级开发工程师：13K～20K左右。 高级开发&#x2F;技术专家：20K～32K左右。 资深开发&#x2F;架构师：32K以上。 上述薪资范畴，在不同的岗位上也许存在差异，例如前端、C/C++、Go……但级别对应的薪资中位数浮动区间不大，因此可以适当参考上述给出的薪资标准。 不过假设你是中级水平，到底拿14K，还是18K呢？这要根据上份履历决定，下面聊聊这点。 上份履历是重要基础前面在强调行情、城市、技术决定期望薪资，但更重要的一点是：你上份工作履历，这将直接决定着下份工作的待遇。通常情况下30%是极限，比如上份工作是10K，但你自认为能力到了高级，直接开价25K，这属于漫天要价，基本不可能拿到。 但如果你目前的薪资较低，能力特别出色的情况下，跳槽薪资翻倍的可能性也有，例如原本是6K，经过跳槽后要到12K，这种现象比较常见。 不过随着工作年限的增长，到手薪资的不断提高，这意味着你越来越接近行业薪资的天花板，所以跳槽时，薪资的涨幅空间会越来越小，一般不会超过前面所说的30%。 有时你的能力明明达到了高级水平，但你在上家公司一待就是三四年，老板也不怎么给你涨薪，所以导致上份工作的薪资并不是很高，此时该如何摆脱上份工作带来的涨薪限制呢？其实这种情况也有解决方案。 实话实说：只要能力足够出色，招聘方也会给到满意的报价。 编织谎言：说自己之前在“非一线”的分公司上班，所以薪资谈的是非一线城市的待遇。 第一个方案比较容易理解，第二个方案的原理则是：享受“非一线转一线”带来的“红利”，这时原本所说的30%限制会被打破（但一个谎言需要更多的谎言来圆，这样做的话要想好说辞）。 制定合理的期望薪资经过前面的内容熏陶后，大家对影响期望薪资的各个因素都已了解，那究竟如何制定合理的期望薪资呢？接下来重点聊聊这个。 很多人在面试前没有想过期望薪资，因此喜欢临时报价，但要牢记：期望薪资并不该是“顺来逆受”！你必须得先自己坚定立场，如果你自己报出的期望薪资都很随便，那很大程度上就与这个薪资无缘了。 当然，适当参考面试情况来选择性报价，这种方案是可取的。坚定立场并非死守立场，如面试前的期望是20K，但面试发挥得一塌糊涂，结果还楞生生喊20K的报价，这合理吗？显然并不合理。 不过选择性报价的前提是：你得有一个自己的最低要价。所以，这里要借助一些招聘平台，从招聘平台得到市场反馈的报价，大家要学会善用招聘网站的“条件筛选”，如下： 先选择好求职城市，然后把上节得到的自我画像信息依次填入，最终就能得到市场给予的报价。 通常情况下，市场对相同条件的求职者，给予的薪资区间大致相同，所以这个报价，也是你期望薪资的参考之一。同时还要结合上份履历、技术能力去进行微调，经过一番调整后，你将得到一个与你最符合的期望薪资。 接着可以优化成范围值，例如期望15K，则可以变为14K~16K，设立最低期望和最高期望，这样方便你根据面试的发挥情况，去进行合理报价。 同时，因为该薪资范围是结合自我画像得来的，所以你几乎是与该薪资最匹配的人选，毕竟该薪酬范围内的招聘要求你完全满足！ 但制定好期望薪资后还不够，找工作、找工作，一定要理解里面的“找”字，这意味着你可以挑公司，而并不是公司挑你。因此，接着我们就来聊聊如何确定自己的目标公司。 二、如何确定最合适的目标公司？大部分小伙伴刚踏入社会时，对第一家任职的公司基本没有要求，想的是有口饭吃就成。不过随着自己的年限、经验、技术不断增长，有了资本之后，开始对下家公司也有了一定要求，好比：“打死不去外包！” 不同类型、规模的企业，所具备的氛围有所不同，入职后的工作内容也存在差异。比如微小创业型公司，你进去之后可能需要干特别多的活；而中大型规模的企业，入职后的分工会很详细，多个岗位各司其职，相互之间配合起来完成工作任务。 接着大致介绍一下企业的分类，大家可以根据不同类型企业的特点，选择一类自己期望入职的企业。 技术人眼中的企业分类这几年由于疫情影响，倒下了一大批公司，但留下来的依旧不少，对于所有招聘IT技术类岗位的企业而言，咱们可以用体量、性质、业务三个维度来进行划分。下面先做大致罗列，后面再列出具体区别。 站在 体量或规模 的维度来看，企业可以划分为四大类。 小型&#x2F;创业型企业：公司规模通常在 100 人以下。 中型&#x2F;成长型企业：规模通常在 200~1000 人左右。 大型&#x2F;成熟型企业：上市企业、国企、独角兽、次级大厂等，规模通常在几千到几万人左右。 互联网顶级大厂：典型的BATJ、美团、拼多多、字节……以纯互联网业务为主的企业。 以 公司性质 的角度来说，企业大致可分为两大类、五小类。 自研型企业 软件产品即核心：软件作为公司主营业务，依靠互联网产品盈利，如阿里、字节、腾讯等。 软件产品非核心：公司主营业务为实体产品，软件系统用于辅助功能，如车企、餐饮等。 国外企业（外企）：国内的外企通常是为了打开亚洲市场，可能是官网、平台、产品等。 外包型企业 人力外包型：对外招聘技术人员，外派到项目方驻场开发。 项目外包型：类似于接单工作室，招聘技术人员开发外部接到的项目。 从业务的划分而言，企业大致可以分为两类。 互联网型企业：主要以卖服务为主，例如直播、金融、电商等类型的业务。 传统型企业：主要依托于实际产品，例如工业、银行、保险等类型的业务。 PS：互联网型和传统型企业的划分，其实有多种解读，有些以技术老旧来区分，这里就以性质来分。 上面分别从三个维度对企业进行了划分，之前也说过不同类型的企业，以IT技术人员的身份入职，工作量、工作内容、福利待遇、内在地位等方面有所差异，下面展开讲一讲。 以体量规模维度划分小型企业： 优势：初级进入后成长速度快。 ①地位不错：由于公司团队人数不多，因此每一个技术成员都是核心。 ②成长最快：因为技术人员配比不全，所以工作承担的责任更大。 ③具备潜力：如果公司后面业务做大，你将成为元老级骨干，待遇也许咔咔涨。 ④氛围很好：由于公司人员较少，每个人之间都很熟悉，同事之间能打成一片。 劣势：工作内容繁杂且风险大。 ①工作繁杂：很大几率成为全干人才，前端、后端、测试、运维一体化。 ②风险较大：公司规模较小，资金链也较短，一点意外因素可能就欠薪倒闭。 ③成长较少：对于初级开发而言收获的成长最多，但中高级以上工作带来的成长很小。 ④隐私性低：人员少、资金小，代表场地不会太大，回头一看会发现老板正盯着你。 ⑤加班较多：由于制度不完善，所以加班、下班后再上线等情况是常事。 中型企业： 优势：业务稳定且潜力很高。 ①业务稳定：能做到这个规模说明至少稳住了一块业务，入职后倒闭风险较低。 ②潜力很高：每一个大型企业都是从这步跨过去的，比小企业的晋升空间大。 ③团队完善：通常至少会配备完善的技术团队，不会出现哪里需要哪里搬的现象。 劣势： ①加班严重：由于公司正在高速成长，所以平时加班会较多。 ②裙带关系：这个规模的企业中，领导层裙带关系最多，公司高层普遍是老板亲朋。 ③福利较差：该规模的企业中还未搭建出完善的福利体系，能享受到的福利随机。 大型企业： 优势：某个领域的独角兽，风险性极低。 ①福利不错：具备完善的福利体系，生日会、下午茶、奖金、年终奖等都有。 ②制度完善：加班有补贴，晋升体系明确，管理制度正规化…… ③加班较少：因为已经打下了一块业务，所以平时工作量也不大，加班较少。 ④风险极低：由于已经啃下了某块业务，抗风险性更高，不用担心跑路。 ⑤影响力好：虽然没有顶级大厂的含金量高，但也具备一定知名度，可以“镀银”。 劣势：官僚主义严重，归属感不高。 ①官僚主义：由于企业不算小，所以高层容易拉帮结派，需要一定情商才好晋升。 ②归属感低：新人进入团队后容易成为螺丝仔，同事之间较为冷漠，归属感不高。 ③结构复杂：内部管理结构比较复杂，各项工作流程也相对复杂，不利于快速发展。 ④发展缓慢：由于已经啃下一大块业务，更多的是求稳，而并非追求激进发展。 ⑤成长较低：内部已经具备完善的技术体系，熟悉后很难从工作中获得技术成长。 顶级大厂： 优势：薪资待遇高，镀金的完美跳板。 ①薪资超高：相同技术对比其他规模的企业，薪资待遇要高出30%以上。 ②福利超好：正常年终奖在3～6个月，有购房低息贷、期权分红等。 ③镀金跳板：业内影响力大且名气高，“毕业后”具备大厂背景加持。 ④流程规范：相较于外部企业，大厂的工作流程更正规，能收获不少知识。 ⑤积累人脉：身边都是社会精英人士，对比外部更容易积累优质的人脉资源。 ⑥晋升明确：新人进入后，能力决定薪资待遇，前期成长的速度较为可观。 劣势：内卷超级严重，个人地位不高。 ①内卷严重：因为绩效末尾淘汰机制的存在，同事之间内卷十分严重。 ②地位不高：如果不是影响力较大的巨佬入职，在团队中的影响力较低。 ③暗斗颇重：大厂一般倡导狼性文化，部门、员工之间竞争相对严重。 ④难晋高岗：普通员工干到一定级别线后，很难“立大功”晋升更高的职位。 ⑤易成螺丝：大厂讲究专而精，入职后通常会分配到某个岗位上打螺丝。 以公司性质维度划分以公司性质来划分，主要可分为自研型、外包型这两类企业。自研型企业中主要分为软件产品为核心、软件产品非核心这两种，但为了全面性，咱们也将外企列入了自研型企业中。反观外包型企业，主要涵盖人力外包与项目外包。 接着简单说明一下各类公司的优劣势。 软件即核心型自研：技术人员的地位很高，并且福利待遇相对不错，负责的产品也会更加追求完善性。但由于是自研型企业，所以能接触到的业务线不多，入职一段时间后，工作能给自己带来的成长不多，并且以普通员工的身份入职，很容易成为打螺丝的那位。 软件非核心型自研：整体与前者相差不大，但技术人员的地位相对没有那么高，毕竟公司主要以实体产品为主。但入职后十分安逸，忙完项目产品的初版研发后，后续的工作特别轻松，不过个人成长会随之受限，后续也很难以技术身份晋升内部高管，比较适合养老。 外企：有机会进的小伙伴都可以尝试，除开少数外企，大部分外企的福利待遇特别好，并且十分强调工作与休息时间的界限，钱多事少的类型。不过想进需要一定的英语能力，并且有些外企所用的技术会跟国内主流技术脱轨，不利于后续发展（研究所、军工类的也大致相同）。 人力型外包：地位特别特别特别低，著名的那句“外包仔别偷吃公司零食”就源自于这类外包公司，一般入职后会被外派到甲方驻场，负责大型项目的边角料业务开发，十分不利于后续发展。至于优势的话似乎没有太多，也许钱会多一点点？如果不是走投无路，不建议选这类Offer。 项目型外包：这类外包比前者要好，地位也没有那么低，主要是负责开发承接的外部项目，特别适合初中级积累业务经验，能够接触到各行各业的项目（我有位老同学堪称外包狂人，巅峰时期一人负责17个外包项目）。但项目更追求开发速度，并不追求质量，讲究“能跑就行、又不是不能用……”，不利于后期成长。 以业务性质维度划分站在业务性质的维度上划分，主要可分为互联网企业和传统型企业。 前者一般技术较新，技术上也更为激进一些，对于技术人来说，工作带来的成长会更大。 后者则技术相对较老，发展较为缓慢，技术上较为保守，求稳为上策。 对于技术人员而言，互联网型企业必然会比传统型企业好上许多，不仅仅是薪资待遇上的差距，更多的是工作上带来的个人成长。 技术人该如何选目标公司？经过一番啰嗦后，相信诸位对各类企业有了一定了解，不同类型的企业多少会有差异，前面给出优劣分析，虽说不一定绝对权威，但大体符合，因此可以作为客观参考项。 了解各类企业的优劣特点后，又该如何选择目标公司呢？ 这得因人而异，每个人的追求不同，所以选择也会有所不同。比如有人要钱，就算加班也能接受；而有人追求轻松，钱少一点也不在乎……为此，大家可以根据自己内心所想，去确定目标公司。 站在我个人的角度给出的建议，初级可以选业务比较丰富或成长价值不错的企业，如项目型外包、小型创业公司等，因为现阶段对个人成长最有益的，是追求业务和工作经验上的积累。 中级则可以选技术成长类的企业，主要关注入职后能给自己带来能力增长的企业。 高级水准左右的小伙伴，则主要追求好的平台，如大厂、大型企业等，这有利于后续个人的发展空间（职位、薪资）。 当然，初级选业务积累，中级选技术成长，高级选后期发展，这也仅是我个人的建议，也不一定要这么选，大家适当参考即可，具体还是要遵从自己的内心想法，如果你内心没有要求，遵守“给钱就干”的原则也不是不行。 自己到底要不要尝试冲击大厂？冲击大厂，这应该是很多技术人的梦想之一，毕竟大厂不仅代表更高的薪资福利，而且也是一种镀金手段。当履历上增添一笔大厂的工作经验后，也能成为以后简历的闪光点，有助于拿到更多的面试。同时从大厂“毕业”之后，薪资报酬也会高上许多。 入职大厂带来的好处毋庸置疑，以大厂作为跳板也的确是很不错的镀金方案，但大厂的招聘往往更严格，除非你的综合条件都不差，并对自身技术有绝对自信，否则我并不建议冲大厂，因为大厂的面试流程比较长，有些能达到好几周。所以目前如果处于待业状态，在没有一定把握的情况下，冲击大厂反而会带来一定的影响（时间开销）。 不过大厂也并非遥不可及，如果你具备以下条件，那我的建议是可以尝试尝试。 远超同龄人的技术，至少对比相同年限的工作经验者，技术能力上有不小优势。 具备不错的学历背景，不要求一定要是985/211名校、硕士等学历，但至少还过得去。 具备不错的项目经历，有参与过核心系统的架构与开发工作，只有简单的项目就不必尝试。 年龄最好是在25岁及以下，最多不能超过28岁，超过该年龄时再尝试，技术要求更高。 上述这四点，是通过「社招」进大厂需满足的四个前提，如果其中某条不曾具备，那你去尝试的结果很有可能会以失败告终。 但还有一类人除外，那就是「应届生」，满足两点即可： 不错的学校背景，如985/211院校的应届生，大厂会去校园招聘； 具备扎实的计算机功底、不错的项目经历，或者不错的实习经验。 学历不错的应届生是最容易进大厂的一批人，因为不仅招聘要求会放低，而且流程也会快很多，并且无需对某个技术有特别深入的研究，大厂招聘应届生更关注“培养价值”，毕竟还未真正出学校的应届生，专业方向还未彻底定性，所以可栽培的价值很高。 如果符合上述两个条件的小伙伴，可以参加校招会尝试看看。错过了校招进大厂的小伙伴，那就只能走社招进入，网申通道投递的简历，通过率比较低，因此社招想要进大厂，最好还是找人内推。 如何挖掘高潜力的企业大家都做过“买彩票中五百万”的美梦，也一定有过“入职的公司突然成为独角兽，从此自身地位水涨船高”的念头。 当自身冲击大厂不够格时，找一家具有“成为独角兽”潜力的企业，这听起来似乎很不错，对吧？但从数不尽的创业公司中，想找到这样的企业，难度无疑堪比大海捞针！ 难道我们只能凭运气来碰“高潜力”公司吗？答案是No，其实找高潜力的“千里马”，也存在一定的技巧与方法！哦？具体怎么做呢？下面来聊一聊。 以个人的视角和认知，想要挑选出“千里马”格外困难，就好比在股市中，普通人买到潜力股的概率也很小，不过股市中我们可以抄作业，抄一些大佬的持仓配置，这个技巧同样可以换到“挑公司”中！那挑选高潜力公司时，究竟要抄谁的作业呀？很简单，抄大厂和资本的。 我们可以借助企业工商信息查询系统，如企查查、天眼查等，直接搜索大厂的名字，接着查看其对外的投资情况，例如： 又或者可以去抄资本机构的作业，如红杉资本、纪源资本、高瓴资本、达晨创投、深创投等投资公司，根据其对外的投资情况，选择心仪的“高潜力”公司： 这背后的原理相信大家都懂，作为专业的投资手，以及行业的龙头，投资的目光自然比咱们看得更远，所以当大家想要真正找一家高潜力的公司时，就可以优先往大厂、资本投资的优质企业投递简历。 三、应届毕业生又该如何抉择？ 事先声明：非应届生身份的小伙伴，可跳过这个阶段。 应届毕业生属于一个比较特殊的群体，目前的处境也有些尴尬，现在整个行业的人才较为饱和，企业招聘时也不缺人来应聘，因此如今留给应届生的空间越来越小，纵观整个行业趋势，涌入这个行业的人每年都在逐步增多，所以应届生将要面临的是“狼超多、肉很少”的情况。 应届毕业生中，如果学历背景较为不错的，那一定要尝试冲击大厂，这将是一个改写以后人生走向的路口，因为第一份工作的薪水、经历，将直接决定你的起点，大厂无疑是起点最高的一个选择。例如普通公司4K的实习生，和大厂15K的实习生，两者在找第二份工作时，薪资待遇将会有着天差地别。 但如果学历、院校背景没有那么好，在有其他更好选择的情况下，我不建议再往这行钻，为什么呢？下面一起来探讨一下。 相较于早些年人才稀缺的那个时代，如2010年左右，只要你说是计算机专业毕业的，一大堆公司会抢着要。而回头再看如今，除开规模不错的企业外，很多公司对应届生的招聘开始减少，这个现象大家应该能够明显感受到。随着时间往后推移，尤其是疫情影响之后，很多企业甚至都不再招聘实习生，这是为什么呢？ 主要有如下四点原因。 人才饱和：略微多花一点钱，就能招聘一个具备实际动手能力的初级开发。 事情很多：因为刚出学校，很多东西不懂，往往许多工作需要老人协助完成。 效率很低：花费了多于老员工的N倍时间，做出来的结果还需要再次改善。 忠诚度低：企业花了几个月的时间培养成型，结果因为薪资不满意很容易跑路。 因此，除开大厂外，很多企业，尤其是中小型公司基本上不会选择招聘实习岗，因为除开少数优秀的实习生外，选择招聘其他实习生反而是一种吃力不讨好的行为。 当然，看到这里我相信有部分小伙伴，可能会感到略微有些难受，觉得这些话有些难听，但这就是现实。 对于应届毕业生而言，这个行业如今没有那么美好，那应届生该如何抉择呢？ 最好的选择是大厂&#x2F;中厂，大厂有足够的魅力留下实习生的心（薪资待遇&#x2F;镀金履历）。 如果学历不够，第二选择是考研，市场对高学历的应届生很友好，考研后选择机会更多。 如果自认考研无法上岸，第三选择是靠亲戚朋友转行，转到一个发展、薪资不错的行业。 如果原生家庭没有人脉资源，最后的选择才是踏入这行死磕，开启一条“异常苦逼之路”。 🌗总之，对于应届生来说，只需认准一条原则即可，那就是尽可能地去提升你的起点！你的第一份工作，很大几率下，将会直接影响着你未来的发展，当有更好的起点可供选择时，那请千万不要犹豫，进大厂、考编、考公、考研都是这个道理，起点不同，未来的人生轨迹也会完全不同！ 技术突击篇：如何根据求职意向进行快速提升与复盘？一、突击与复盘并不是闭眼摸虾如何准备面试才最高效呢？那就是：请围绕着期望薪资准备面试，千万不要闭眼摸虾！ 既然有了一个具体的期望薪资，那你就能确定自己要准备哪些技术，因为同一薪资范围内的招聘要求大致都相同，此时你可以拿着自己的期望薪资，去到一些招聘平台上，多查看一些招聘要求，从中选取出现频率较高的技术栈与要求，然后进行定制化复盘。 为何要这么做呢？因为许多小伙伴在准备面试时，都会显得有些无厘头，这或许是因为环境造成的，如今四处都在喊着面试要造火箭，培训机构天天跟你说：你是个只懂CRUD的螺丝仔……久而久之，这些话也成了业内所有人的共识，大家在准备面试时，也潜意识地会去看原理性的内容，但这有必要吗？也许有一定意义，毕竟前面的那些话，也在一定程度上影响了面试官，但请牢记：千万不要把重心放错了地方！ 比如典型的案例： 高并发，这玩意儿重要吗？重要，但如果你只想找初级的工作，天天研究高并发有意义吗？有人可能会回答：“没办法，面试要问！” 但请记住，初级面试中会不会问高并发呢？显然大部分不会，除开少数个例除外。 从上述案例中要明白一个道理，前面做的技术定位、求职意向并非白用功，你应该要搞清自己需要的、摒弃不需要的，不要去做无意义的技术准备。通过招聘需求得到自己的复习&#x2F;学习重心，再结合目前的现状来制定计划，才能让面试前的技术准备最高效。 一般要准备面试的群体我将其分为如下两类，这两类群体都有各自的面试计划。 时间充裕的骑驴找马者：目前有工作，考虑换个新环境。 焦急万分的自由技术人：目前已辞职，迫切需要新工作。 二、技术突击：时间充裕的骑驴找马者对于目前还未离职的小伙伴而言，时间方面会比较充足，这意味着可以慢慢准备面试，在这种情况之下，去刷面试题反而不是最好的选择，应该要考虑的是做技术突击，逐步将自己的能力提升到符合期望薪资的水准。毕竟刷面试题属于临时抱佛脚、治标不治本的做法，很难真正理解那些自己不懂的知识点。 既然要做技术突击，切入点在哪？到底是追求广度还是深度？对于这点，要因人而异。如若想要找“中级水平”的工作，首先应该追求广度；如果打算尝试“高级水平”的面试，此时应该注重技术深度。但牢记：广度不是涵盖全部，深度不是死钻到底，一定要把握好分寸，追求广度也好，深度也罢，想要做到极致很难，不仅要耗费很多时间，而且还需投入大量精力。 确定了学习方向后，接着再回到之前所画的“知识树”，通过调研招聘需求后，用其他颜色把自己所缺乏的技术标注出来，这是接下来要学习的内容，尤其对技术与年限严重不匹配者来说，这将是你技术追上工作年限的最佳时机。 确定了要完善的技术内容后，接着还需规划学习路线，凡事都有轻重缓急之分，学习也不例外，对于自己缺乏的技术，要先做好优先级排序，首先把那些热度高、通用性强的技术放前面，闲暇之余再考虑那些能用到、但热度不高的技术。这样做的好处在于可以应对突发情况，就算中途被“优化”了，因为重要的技术已经弄懂了，那些优先级不高的内容在面试中也不会影响大局。 最快的与最有质量的学习方法学习的方向、欠缺的知识、学习的路线都确定了后，又该如何去学习不足的技术呢？ 效率最高的学习方法：读经典书籍，看优质专栏。 质量最高的学习方法：看教学视频，跟培训课程。 对于具备不错基础及自学能力的人，个人建议选第一种方式！一方面是因为速度快，另一方面还能顺便加强自学能力。 不过有一点不可否认：通过第二种方式学习，无疑会比前者更加轻松且质量更高，因为任何课程&#x2F;视频的设计者在规划时，绝对已经考虑周全，你想要掌握的技术点，基本都能学到，能录制课程的人绝对比“目前的你”更懂这项技术。但相较前者会更加浪费时间，同时还有一点要注意：通过看视频&#x2F;课程的方式学习，容易让人产生依赖性，丧失一定程度上的自主学习能力！ 这点相信有过长期靠视频学习的小伙伴，应该能感同身受，当你想要研究一个新问题&#x2F;新技术，如果在网上没有找到相关视频时，将会显得有些无从下手，不知道如何开展研究，这就是长期依靠第二种方式学习带来的弊端。 有人会说：“你这意思是一定要靠第一种方式学习咯？”实则不然，要分具体情况来定，如果目前要研究一个从未接触过的新技术，或自己底子不是特别好，那选择第二种方式依旧是最好的方案。 第一种方式更适合一些目前至少达到了中级以上水平，且具备一定自主学习能力的小伙伴！如果不熟悉某项技术，再加上自主学习能力较弱，那么自己去尝试研究时，花费的时间会远超第二种方式。毕竟现在各种资料满天飞，但大多数仅停留在表面阐述，或仅有只言片语，想要找到一套较完整且有深度的资料，也会比较困难。 找到适合自己的优质学习资源选择一种适合自己的学习方式后，如何找到优质的资源呢？ 先来聊聊如何寻找质量不错的视频教程（对应前面第二种学习方式），这里也可以加上一个前缀：免费，但事先声明，我并非引导大家成为白嫖佬，只是希望大家别花冤枉钱。这里提供几种方式，如下： 学习前请先查查自己的网盘，如果平时你爱收集资源，或许能给你一个意料外的惊喜； 网盘没有对应资源时，请先去常用的资源平台看看，如大家比较熟悉的B站； 合理使用搜索引擎，天下没有不透风的墙，搜索引擎玩得溜，想要啥都能找出来； 善用技术交流圈，技术群、社区、论坛，略微花点代价，大部分学习资料都能换到； 学会通过网购渠道低价买入，起步大几千的课程舍不得买，此时你去闲鱼、淘宝能有惊喜。 不过并非所有视频资源都算优质，大家一定也遇到过很多优劣不一的资源，因此找到一份学习资源时，要记住：“客官，你不要那么猴急啊，讨厌~”优不优质全靠同行衬托，最好的办法是找几套出处不同的教程，简单听一下相同知识点的讲解，就能高低立判，选择最好或最适合的那份再学习也不迟。 接着再简单聊聊，如果选择通过第一种方式学习，又该如何寻找优质的资料呢？如下： 如果比较热门且出现时间较长的技术，先去看看有没有对应的经典书籍； 如果是比较新的热门技术，可以直接去参考对应技术栈的官方文档； 通过搜索引擎、技术网站输入具体的关键字，多点开几篇资料，对比后再阅读； 寻找优质的连载资料，例如某些大佬的付费专栏、电子书、掘金的小册子等。 自己研究某项技术时，通常就是依靠这四种方法。 第一种方法无疑最好，至少专业性最高，但大部分书籍的描述会有些拗口，这时需要你具备一定的理解、推导能力。 第二种方法比较适合研究新技术，官网的文档绝对是最准确的，但有时会看到的是英文版手册，所以需要不错的英语阅读能力。 第三种方法绝对是大家最常用的方案，也是较为特殊的一种方法。一项技术对应的文章资料有很多，但资料五花八门，同一个知识点可能会被解读出不同的释义，这时你需要具备一定的辨别能力，千万别听风就是雨，最好多对比不同的资料，再结合自己的理解去推导出你想要的答案。 说实话，这样做会比较耗精力，想要从一堆资料中去研究明白一个知识点，需要不少的时间，毕竟有时找到了满意的、但描述却不全面，有些描述全面、但内容又不满意，所以想要通过这种方法去学习，往往要靠自己去提炼精华，多看多理解，最终形成自己的技术认知。 不难发现，上述一些问题也是我强调第一种学习方式得具备一定底子的原因。如果底子较为薄弱，当你看书、看官方文档时就会很难理解，甚至犯困，当你去看文章时，也很难做到“取其精华，去其糟粕”。 理性看待线下培训与线上网课相信大家对“培训”这个词汇都不陌生，随着国内互联网的发展，再加上近些年疫情影响，培训机构、在线教育的崛起速度异常惊人，但对于培训机构的评价却褒贬不一，尤其是身为程序员的我们，对它们是又爱又恨，爱是因为能从它们身上学到一些知识（大部分视频教程都源自于培训机构），恨是因为它们加速了行业内卷。 这里不对“培训机构”做过多评价，我们重点是要聊一聊它们的核心业务：付费课程。 但凡接触过这些机构的小伙伴，经过一番营销洗脑以及课程推广后，对于它们的付费课程多少有过幻想，对比传统的教学视频，付费课程的最大吸引力在于：课程内容全面，都以面授或直播的形式开展，不懂的可以当场提问，有疑惑的课后随时解答。 这是付费课程的最大优势，也是大家想买课的最大原因。但记住！并不是所有机构都那么负责，很多机构付费前对你无微不至，但加入后需要解答时，你会发现解答的时间很慢、甚至压根没人回（这里有相关经验的小伙伴应该深有体会）。 那我们到底需不需要这些付费课程呢？或者付费课程值不值得入手呢？这同样得因人而异，如果你的自主学习能力差、自律性比较差、底子比较薄弱，那应该会比较合适，毕竟花钱了你会更加珍惜一些。 反观前面对于能选择第一种学习方式的人来说，这个课程的价值就不大了，毕竟课程里面有的东西你都能靠自己研究明白，唯一珍贵的一点是有人能帮你解答疑惑，但对比其昂贵的学费，显然投入和产出不成正比。 但如果你坚决要报课学习，那也没有问题，只不过以我接触过的人来说，大部分人报课后，只是给自己买了个教训（里面坑很多）。因此，在付费前一定要货比三家，请擦亮眼睛仔细分辨，选择一家好的机构，不仅后续能拥有更好的服务，而且也会帮你省去很多麻烦。 综上，我们就可以提炼其主线内容啦，如下图： 三、快速复盘：焦急万分的自由技术人前面针对还在职的小伙伴，提供了一系列的准备方案，那再来到大家比较关心的一种情况，如果我目前已经离职了，现在迫切需要一份新工作怎么办？ 我：我知道这时的你会很急，但你先别急！ 你：！？？！ 你：哥，我是想要你教我一套能快速找工作的秘诀啊，不是听废话的。 怎样才能快速找到新工作呢？记住，等我有条件开公司了，第一时间就给你直接发Offer，哈哈~ 心态调整与制定复盘计划的核心话回正题，在很多人看来“你很急但先别急”这句话是废话，尤其是所投简历如石沉大海、面试回家等通知的小伙伴，听到这句话会更来气：“奶奶个熊的，火都快烧到我屁股上了，你还叫我不要急！” 但要明白一个道理：你的焦虑并不能改变你的处境，急躁只能加速你内心的焦虑，最终反而会影响你的心态，所以离职后首先要做的是调整好自己的心态，做好“长期奋战”的心理准备。 以我的某位朋友为例，他当时就是这种情况，求职碰壁后并未焦虑，而是调节好了心理并放松了心态，您猜这结果怎么着？ 高情商：他硬生生享受了前所未有的一年长假。 低情商：一年没找着工作。 上面这个故事告诉我们，放松心态不是完全摆烂，调节心理不是放弃挣扎，否则最终你也将成为一位享受长假的自由人！调整心态目的是在于减少不必要的焦虑，但自己的面试计划也要如常进行。那待业的小伙伴又该如何快速做技术复盘呢？和前面类似，先定位自身技术能力，接着根据自身所缺，按优先级制定一份复盘计划即可。 但千万要记住一点：复盘计划不是学习计划，相较于前一种的未离职人员，你没有那么多时间去做提升，因此复盘计划是围绕着你自身的技术在做准备，复盘的核心是：我目前会哪些技术？期望薪资的面试中，会问到哪些技术？问到什么程度？针对自身不足去准备即可。 这里额外说明一点：火候欠缺者应该适当降低期望。如果你目前的能力最多只能拿到15K，但你的期望薪资偏偏定在18K，此时距离18K还有好些个未掌握的技术需要学习，但目前已经没了工作，想要去学习还未掌握的技术时，你的时间扛不住这么消耗，所以最好的做法是适当降低期望薪资，最好降低到一个自己有把握的范围内。人要量力而行，千万不要打肿脸充胖子，否则就算接到了面试也很难通过。 如何高效地刷面试八股文接着再说说，当制定好复盘计划后，如何基于复盘计划进行快速复盘呢？ 其实这就没有秘诀了，老老实实去看面试八股文，八股文既然能有这么高的热度，绝不是偶然造成的！它们都是经过精心地整理、认真地撰写，最终才形成的面试题合集，这将是你快速复盘的最大助力。 刷面试题最快的方法不是死记硬背，而是尝试理解。以我的职业生涯为例，从工作以来，我也负责过许多场大大小小的面试，考察的求职者中不乏有很多“八股文选手”，我提出的诸多问题，他们都能给出准确的回答，不过其中至少有70%以上的选手，其回答让我感到异常僵硬，给人一种背书的感觉，回答的说法也比较官方化，缺乏自己的理解，简单来说就是回答不接地气。 所以！看八股文时一定要学会自己去理解，只有当你理解了才能在面试中谈出自己的看法，而不是死板地僵硬回答。毕竟八股文涵盖了诸多面试问题，而热度高的那些问题，绕来绕去就那么些，面试前的很多求职者基本上都看八股文，相同的问题别人这么回答，你也这么回答，最终只会导致你显得平平无奇。 虽说要试图理解面试八股文，但有时会碰到这种情况（举个形象的例子）。 问：为什么 AlCl3 是共价化合物？ 答：金属元素与非金属元素形成的化合物通常是离子化合物，如NaCl、K2S等，但AlCl3是共价化合物。AlCl3的熔点192.4℃（2.5个大气压），沸点为177.8℃（沸点比熔点低是因为测定AlCl3熔点需加压，因而使得熔点升高）。AlCl3在熔融态、气态和非极性溶剂中均以二聚体Al2Cl6的形式存在。 这你能看懂吗？90%的人看了直摇头，看不懂，根本看不懂，其实我也看不懂，因为我是随手复制的。 但这种情况在刷题过程中又会碰到，有些面试题你可能压根不懂，无法理解时怎么办呢？最好的办法是选择跳过，毕竟连看都看不懂了，意味着这个题远超你目前的技术认知，所以不要浪费时间去试图理解它。但你又担心面试会被问到这个题咋办？实在担心的话也可以简单背一下答案，给自己简单留个印象和心理安慰。 同时，不要去试图找到一份十全十美的面试题，因为就算找到了也不一定适用，刷面试题也要多看多比对才行，多用搜索引擎搜索XXX面试题，例如：Spring面试题、Vue面试题……从搜索结果中挑几篇自己认为合适的，然后进行复盘，切记：不要拿着一份相同的八股文反复看！ 相同的技术栈要多找几份面试题来刷，看第一篇的时候带着理解思维，看完第一篇，后面的速度就会比较快，把自己找的几份面试题都看了之后，再选一份自己认为最好的，接着去遮住答案，在心里模拟回答一下，回答后再仔细看一遍原文的答案，以此加深脑海中的印象。 通过这种方式刷题，好处如下。 第一遍以理解思维去看：能让你对相应知识点形成自己的认知。 后续针对相同技术多刷不同面试题：能纠正你前面的错误认知，增强你对知识点的记忆。 最后模拟回答再看解析：能联想面试场景回答，再次加深脑海里的印象。 虽然这样刷题的进度会慢点，但绝对是效果最好的，而且会比反复看同一份面试题要有趣得多，最主要的是能形成自我理解，而并非死记原文的官方回答。 对这一阶段进行简单总结：先放松心态做好心理准备 → 针对自己的已有技术找出不足 → 制定好复盘计划与路线 → 按计划开始有技巧地刷面试题。 四、降维打击才是求职的灵丹妙药如今四处都在喊着XXX寒冬、XXX已死、XXX已凉……当大家听到、看到这些话时，难免内心会产生焦虑。身处技术行业的我们，又该如何摆脱这些困境呢？最后就再来聊一个求职必胜的小妙招，也就是：如何增强自己在面试中的核心竞争力！ 其实具体方法在标题中就给出了，那就是依靠 “降维打击” 来做到鹤立鸡群。 道理很简单，现在很多岗位在招聘时，都处于狼多肉少的情况，如果你不能在众多面试者中脱颖而出，那就很难收到入职邀约，先来看个例子： 假设一个企业发布了招聘需求，总共来了五位应聘者面试，恰巧你也是其中之一，但你们五个候选者的技术水平都差不多，面试中的发挥也差异不大，这时企业会怎么挑选合适的人选呢？ 这个时候就得看眼缘了，比如你因为面试时左脚先进门，所以不合适。另一个人因为嘴角有颗痣，所以也不合适。最终入职的人，也许就是一个面试官、HR看着更顺眼的人！这公平吗？不公平，但现实中有些情况下，的确如此。 所以，面对于上述那种场景，想要做到真正的求职必胜，就必须让自己的面试表现更为突出才行！具体该如何做呢？以我来举例子，场景如下： 现在有一个8K的初级招聘，目前有三位应届毕业生争得焦头烂额，都想自己拿到入职邀约。 此时我去面试后，并且极力表现出想加入这家公司，这时面试官会怎么选？通常情况下会选我，Why？因为对比其他三位候选人，我的经验、能力、面试表现绝对会亮眼一些，招聘和购物都遵循着同样的道理，也就是追求性价比，此时我的性价比更高，所以肯定是招聘方的不二人选。 从上面这则小故事中，希望诸位能明白一个道理：降维打击到底是什么意思？就是以超出对应岗位的能力去面试！ 比如，你目前具备找18K工作的能力，但你偏偏去面15K的招聘，这会显得你额外突出，自然也能在众多候选者中脱颖而出。但反过来，如果目前只具备18K的能力，求职时也往18K的招聘上冲，最终结果也就是显得平平无奇，毕竟和你竞争的人都处于同一个水平。 但能面18K为啥要去拿15K？其实我的意思并非让大家降低自己的期望薪资，而是提高自己的技术水平。比如你目前的期望薪资是18K，那你就把能力提升到20K的水准，然后再去面18K的招聘，这才是我口中所谓的“降维打击”。这也是为什么我推荐大家提前准备面试的原因，充分准备和临时抱佛脚，两者之间相差甚大！ PS：上面所述的15K、18K、20K只是为了将技术能力具体化，实际求职过程中，15K、18K的技术能力可能大致相同，相同技术能力的人，到底是拿15K还是18K，要取决于对应求职者的工作履历，也存在一定的运气成分。 洞悉人事篇：HR 是如何在成百上千份简历中挑选候选者的？前面一节聊了面试前如何技术准备，这节来说说求职路上必遇的角色：HR&#x2F;人事，一次求职面试过程中，通常都会先与这个角色打交道。 人事这个角色分歧很大，有令人厌烦的尖酸刻薄者，有善于交际的亲和派，也有狐假虎威的二五仔，甚至有啥也不懂的毕业生。 在很多公司举行的匿名投票中，票选最让人讨厌的职位时，HR往往都是首当其冲的那个。 相对来说，HR是一个吃力不讨好的职位，需要很高的情商才能做得很好，否则很容易遭人嫌，对外让应聘者讨厌（态度不好），对内让领导嫌弃（招不到人）、让员工厌恶（克扣考勤），所以做好HR其实很难。 不过这里就不对HR的难处做过多描述了，下面重点谈一谈HR对求职途中的影响。 一、重新认识一下 HR任何企业中都会有HR（Human Resource），翻译过来叫人力资源，但也习惯被称为人事。小一些的公司也许只会有1~2个人事专员，具备一定规模的企业则会组建人力资源部&#x2F;人事部。其工作职责分为六大模块。 人力资源规划：根据公司业务发展需求，规划内部各部门岗位需求和人员招聘数量。 执行招聘计划：在各渠道发布招聘信息、负责应聘者的初次筛选、面试接待与HR面等。 组织内部培训：负责内部岗位技能、企业文化、新人入职等培训，督导培训计划的实施。 参与绩效管理：参与制定绩效方案、组织绩效实施、评估、反馈等工作，完善绩效体系。 核对员工考勤：核实员工的打卡、迟到、缺勤、旷工、请假、工牌、卫生等各类考勤情况。 处理劳动关系：处理入职、试用、转正、升职、请假、异动、劝退、裁员等劳动管理工作。 当然，并非所有公司的人事都具备处理上述所有工作的权利，小一些的公司也许老板会直接参与其中，或者规模较大的企业还会有行政部辅助，但组织架构完善的企业，基本上都会规划出人力资源部，上述职责将会统统放权给该部门，但这些与我们没有太大关系，重点把注意力放在第二条，这是作为求职者需要关注的。 那些千年不变的只招不聘岗HR是求职路上的第一关，通常会负责应聘者的简历筛选，但先记住：有些HR并非真心招聘。这具体是怎么回事呢？ 想要弄明白这个问题，就不得不先说清HR的绩效机制。KPI绩效考核制度是大部分企业中都存在的，一个员工绩效系数的高低，也将直接影响其工资收入，而人事部门同样涵盖在绩效考核的范围内，一般HR的绩效指标有如下几点。 成本控制率：对员工的工资、奖金、福利补贴等成本不能超出预算。 员工离职率：通常是指自己负责招入的新员工，需要控制离职率。 内部满意度：主要指内部员工是否对人事有不满意、投诉，出现则会影响绩效。 培训完成率：督办一场培训时，是否顺利完成、员工到场比例、员工满意度等。 招聘完成率：主要跟面试邀约数量、到公司应聘人数、新员工的入职人数等挂钩。 …… 这里抛开其他无关的绩效指标不谈，重点看最后一条关于招聘类的绩效指标，其中面试邀约数、实际应聘数、新员工入职人数等都会影响HR的绩效，这一条也是专门负责招聘的HR，在绩效考核制定中，对绩效系数影响最大的一个指标，意味着该指标会直接影响某些公司的HR收入，因此市场上也有不少“非真心”的HR出现。 当你投递简历后，被对方邀请过去面试时，可能你只是她刷KPI的工具，对方发布这个招聘需求属于“只招不聘”，你的作用在于帮她完成当月的绩效指标，为什么有些HR会这么干呢？ 其实经过前面的绩效分析后，相信大家不用我说也就明白了，也就是为了把自己的招聘完成率提高，拉高自己的绩效系数罢了。 PS：对于这点大家简单了解即可，虽然市场上有这类情况，但毕竟与整体情况对比，那也只是少数，所以不必太过在意，心里有谱就行。更多的招聘需求还是真心为了招人，而并非HR刷绩效的手段。 为什么大部分 HR 会比较热情？相信大家见到的很多HR，在接待你时都比较热情，这是为什么呢？ 一方面是出于礼貌和职业素养，而另一方面则有关她的利益，除开能够帮她提高绩效系数外，同时还有一些额外的好处： 因为有人过去面试可以帮她刷绩效，同时假设入职了，她有一定的奖金（这笔奖金不多），如果后续入职员工比较稳定，在厂里转正之后，又会得到一笔不小的奖金。 听了上述回答后，相信大家应该能够想明白下面这三个问题。 你的面试能给 HR 带来什么？ 你的入职能给 HR 带来什么？ 你的转正能给 HR 带来什么？ 但她当时是在工厂做HR，负责工厂的招工。对于IT公司的HR来说，可能细节上会有所不同，但你的面试、入职、转正，多多少少都会给她带来一些好处或奖励。 OK，对于HR招聘的那些事就此打住，大家只要稍微对这些有了解就好了，毕竟只是为了让你更熟悉HR，更重要的是接下来的内容：技术行业的HR是如何筛选简历的呢？ 二、技术行业的 HR 是如何筛选简历的？想要了解技术行业的HR是如何筛选简历的，那得先明白一个道理：九成八以上的人事并不懂技术，但你投递简历后第一步就是人事做筛选。不知是否有人存在这种经历： 明明我简历上技术写得很牛逼，项目写得也很优秀，但为啥一投简历就没反应啊？ 如果你有这个困扰，那很有可能是因为你的简历太丑了，或者太过花哨了，这容易遭到HR的排斥。毕竟她也不懂技术啊，当她打开你的简历之后，映入眼帘的就是排版不公正、样式特别丑、模板花里胡哨……问题时，可能她就是啪地一下，很快啊，就把简历关了，然后拖进回收站，整套动作一气呵成。 所以，牢记一点，你想要简历的通过率高一点，第一步应该至少保证足够整洁，不说要让人家眼前一亮，但至少别给人家留下负面印象，因为一个岗位往往有很多人投简历，多你一个不多，少你一个也不少，简历如果很丑的话，的确会影响简历通过率。 HR 筛选简历的流程明白HR并不懂技术这个前提后，接着来聊聊HR筛选简历的流程，以及HR在不懂技术的情况下，她是如何筛选简历的、关注点又会放在哪儿。 先来说说筛选流程： 美好的一天，元气满满的HR坐到电脑桌前，打开了招聘平台…… 随机点开一份投递的简历，简单看两眼快速扫描简历的整体信息。 如果简历整体信息满足需求，再花费8~15秒搜索简历中的关键指标。 浏览简历搜索到关键信息后，接着会对简历进行评估，合适的单独拎出来。 对于评估合格的简历，HR会花费1~3分钟仔细阅读，重点关注是否与招聘需求匹配。 简历经过仔细审阅后，各项条件都符合招聘需求，接着联系应聘者，发出面试邀约。 上述这个过程是“人肉式简历筛选”的过程，也是中小型企业会采用的方式。但国内一些大厂除外，它们往往具备完善的人力资源系统，内部会有招聘流程模块。 大厂的大致简历筛选流程如下： 简历首先被录入系统（从招聘渠道对接），简历会进入初审状态。 然后交给系统AI进行筛选，AI会快速过滤掉一批不合适的简历。 接着会从简历中快速提取关键指标、词汇，生成应聘者的个人画像（报表&#x2F;图像）。 通过求职者的个人画像比对投递的岗位JD，判断求职者是否适合这个岗位。 匹配岗位JD的求职者，才会真正由系统交给HR进行最终评估，合适则会锁住简历。 …… 对比前面“纯手工”筛选简历的方式，大厂这种使用程序介入处理的方式更为智能，尤其是应对大厂每天接到的海量简历，这种系统能极大程度上减轻HR的工作量。 而且要注意一点，大厂为了防止每天出现海量的重复简历，通常这类系统对简历都有冷却期，也就是当你的简历被pass过一次之后，需要等待一段时间后才能继续投递。在冷却期间内，就算多次反复投递也无法生效，系统在最开始就会自动过滤掉冷却期内的简历。 HR 在筛选简历时的关注点前面简单了解简历筛选的流程后，下面说说HR在筛选简历时的关注点，这将直接影响到简历的通过率。只有当大家真正明白了HR的关注点之后，才能写出一份比较不错的简历，但本章不会过多阐述简历优化的内容，这些东西都是后话，本章旨在洞悉人事。 HR在上述不同的环节中，对简历信息的关注是不同的，如果你简历在任一环节有问题，都有可能影响简历的通过率。 先来聊聊HR刚打开简历的第一眼会关注什么呢。简历整洁性、应聘者的基本信息，如果简历上的字七扭八歪或者比较“辣眼睛”，这是很有可能被淘汰的，毕竟HR大多数是女性，女性通常喜美厌丑，简历的美观整洁程度确实会成为筛选的第一原则。 不过正常套用简历模板的情况下，基本不会由于外观被pass，所以下面就来聊聊HR会关注哪些基本信息。学历、年龄、工作年限，看这些信息是因为能够通过这些信息做最快筛选，学历、工作年限不合格者会直接pass，同时看年龄是为了核实简历真实性，可以根据年龄来简单推断学历、工作年限是否真实。 通过前面的快速筛选阶段后，接着HR会对满足条件的简历进行快速过滤，这时的关注点会在期望薪资、上家公司信息与业务、以及历史工作履历上，第一点就不必我多说了，从这点能精准地得知是否能开起你想要的工资，如果给不到你想要的期望薪资，也会直接pass。 正是由于这点原因，所以很多人会在简历写上“薪资面议”，要不要写面议呢？简历优化篇再细聊。 除开期望薪资外，还会去瞅你的工作经历，主要是看你任职的上家公司，在此期间，会关注上家规模、你的岗位以及公司业务性质，这三点会决定你与公司的匹配度。 如果你上家公司是500强、国内&#x2F;外大厂，这无疑是你很大的加分项。 看了你上家公司的规模后，接着会看一下你在上家公司的岗位，是否与目前招聘的岗位匹配，对于匹配度高的应聘者会优先选择，比如招项目经理，你有过项目经理的履历，无疑你会更合适一些。 最后，HR还会分析你的上家，与目前公司的业务匹配度，如果是同一业务类型的项目，这绝对将成为大大滴加分项。比如： 一个做金融性质的企业招聘，那最希望的是：招到一个之前具有金融经验的人。毕竟有经验代表上手速度快，如果招了一个之前专门写管理系统的新人进来，先不论技术如何，就光金融领域内的一堆业务概念，理解起来也需要不短的时间。 分析完你上家公司的情况后，接着会看看你的工作生涯，也就是你历史从业经历。如果你频繁地在不同公司内横跳，这无疑是会被pass的类型。例如你在每家公司待的平均工龄是一年，那HR心里会想：“我假设把你招进来了，一年之后你业务熟了，活干得也越来越快了，是不是很有几率也会跑路呢？” 企业用人的第一原则是追求稳定，谁都不希望自己的企业内招到一个不稳定的人，所以具备“不稳定因素”的应聘者会直接在简历筛选中pass。 经过上述两轮筛选后，HR手中留下的简历，既满足公司招聘的硬性条件，同时又贴合公司的业务线、岗位需求，所以接下来HR会做最终的评选阶段，也就是看应聘者的“个人技术栈与项目经历”。诸多小伙伴看到这里就疑惑了：你前面不是说HR不懂技术吗？！？？为啥HR会去看个人技术栈啊？ 想要弄懂此问题，就得先知道：HR发布的招聘需求怎么来的？无非就两个方式。 来源一：用人部门写的。需要招聘一个什么能力的人，最清楚的莫过于用人部门本身。当部门缺人时，尤其存在技术岗位空缺时，HR并不清楚要招一个什么技术的人进来啊，所以大部分公司会由用人部门本身去写招聘需求，然后交给HR对外发布。 来源二：用人部门给的关键字去复制同行的。不是所有公司的技术部门，都会亲自给HR写招聘需求，毕竟大部分“技术人”的文笔水平欠佳，你叫我形容一下招什么人可以，但叫我写出标准的招聘需求就有些为难，通常这种情况下，用人部门只会给出一些技术栈关键字。但HR看不懂这些技术栈啊，为此就直接去参考同行的招聘，将对应的招聘关键字套入其中，从而形成了自己的招聘需求。 但无论HR是通过哪种方式弄到的招聘需求，但最终手里都会有一份技术关键字的清单，虽然HR不能直接筛选出技术达标的简历，但起码也能大概淘汰一些技术不达标的简历。 所以，在最后这个筛选阶段中，HR会通过用人部门给出的关键字，对简历进行精准匹配，尽量把简历的精准度提高（最后这个详细评审阶段中，有些专业的HR会详细阅读你的简历，从而判断你与当前岗位到底合不合适）。 HR 也许不是最终决断者经过前面HR的一系列筛选后，你的简历经过千辛万苦，终于通过了重重难关，此时屏幕对面的你，也许会歪嘴一笑：“嘿，就你这小小HR，能难住我？” 但此刻别高兴得太早，因为HR只是你简历的第一关，我们都懂HR不会技术这个道理，相信招聘的公司也不会不懂，所以当HR筛选出一批相对满意的简历后，接着会递给懂技术的用人部门！ 纳尼？技术面试官这时就出场了？Yes，越专业、规模越大的企业招聘，技术面试官参与简历筛选的几率也就越大。身为求职方的我们，不想去参加一场无意义的面试，而作为招聘方的企业同样如此，与其喊很多人过来面试，不如从中再挑选出一批优秀者发出邀约，这样也能极大程度上减少多场不必要的面试。 既然技术面试官会参与简历筛选，而同为技术人的他，在看简历时会关注什么呢？ 现在幻想你是一位面试官，现在手里有份简历，你站在技术人的角度出发，首先会关注什么？ 毫无疑问，必然是关注对方的技术，当HR给坐在工位上的你，递来一份简历时，场景如下： （用漫不经心的目光一瞥，稍后嘴角上扬邪魅一笑）：嘿，让我看看这小子技术怎么样！ 技术面试官在看简历时，并不会去关注你年龄多大、学历多高，更看重的是你的技术能力，也正因他与你同为技术人，所以对技术的考查会更加专业，看简历时大多数抱着这三个想法。 ①先看看找工作的这小子，他会的我会不会，懂得有没有我多～ ②这小子会得不少，再看看他懂得有多深！ ③这小子技术不错，让我看看他做过什么项目，有没有我手上的项目牛～ 综上，技术面试官在筛选简历时，通常会看技术广度、深度，以及项目经验这三点，所以想要通过技术面试官的简历筛选，这三点上面要下功夫，既不能太装，也不能显得太弱，毕竟太装了容易面试遭到惨打，太弱了入不了对方法眼。 这三点具体该如何写，也会在后面《简历优化篇》中详细阐述，这篇只了解大概的简历筛选流程。 最后记住一点：简历是第一关，也是最重要的一关！当技术面试官看完你的简历后，通知人事给你发起面试邀约，这意味着你的简历至少得到了他的认可，你要做的就是在面试中发挥出简历上的水平，薪资能在对方接受的范围之内时，你拿到Offer的几率八九就不离十了（除开有比你更合适的人选，或你的性格、价值观不合适外）。 三、公司招聘时的意中人是怎样的？截至目前，大家认真阅读完前面的内容之后，相信对HR、技术面试官如何筛选简历的流程，已经熟透于心了。最后这个阶段，来聊聊企业招聘时，到底想招到什么样的人。 众所周知的一点，现如今找工作越来越难，当准备开启一场面试之旅时，从自信到自闭的人不在少数，似乎现在找工作变得很困难了，是不？你这么想，实则企业也是这样想的，HR也是这么想的。 此时你小小的脑袋应该有着大大的疑惑：“找工作的人这么多，为什么企业招人还难啊？” 其实更为具体一点来说，是企业想招到一个满意的人难，如今市场的技术人才鱼龙混杂，会吹技术差的、技术强不会吹的、没经验硬包装的、技术好又会吹但脾气差的……各色各样的求职者比比皆是，这就导致了企业想要招到“意中人”的难度大大提升，那企业眼中的“意中人”长啥样呢？ 身披黄金甲，脚踏七彩云…… 呸，走错片场了，通常企业招聘时真正的意中人要求如下。 ① 能干活：掌握的技术能力可以满足公司业务的基本需求。 ② 上手快：做过与公司业务接近的项目，熟悉公司所用的技术栈，要花费的培养成本低。 ③ 够稳定：入职后能够持续给公司贡献价值，不会入职一段时间后就提桶跑路。 ④ 高性价比：除开能完全与空缺岗位相匹配外，能干活的前提下还“不贵”。 ⑤ 潜力高：具备不错的学习能力，能随着公司业务的不断发展持续成长。 活好价廉够稳定，这是企业眼中的意中人，是不是与大家求职时的“钱多事少离家近”很像？理想很丰满，现实却很骨感，求职往往很难找到一份“钱多事少离家近”的工作，最终结局大多以“凑合着干”结尾，而企业招聘时亦是如此，最终也只能满足于“又不是不能用”这个水准。 我们聊这个话题有何意义呢？很简单，我们要做的就是：把自己变成别人喜欢的样子。企业招聘想要上手快的，我们投简历时，就可以专门去找和上家公司业务接近的岗位。企业想要高性价比的，那就执行之前聊到的降维打击方案……总之，尽量去迎合企业的用人需求，呈现给企业一种 “我是最合适” 的感觉即可。 最后也对本章的简历筛选流程做个简单总结，不多废话了，上个图就一清二楚，如下： 简历优化篇（上）：怎样撰写一份与自身情况最匹配的简历？简历优化，一个十分美妙的词汇，也是很多人在苦苦追求的“求职秘方”，这也是许多标题党、网课惯用的词汇。不知大家是否见过以下这些标题： 简历到底怎么写，才能让面试邀约的电话被打到爆？ 如何优化才能打造一份让HR为之倾心的高光简历？ 最近面试接到手软，原来全靠这样去做简历优化！ 如何有效打造出一份杀手级的王牌简历！ …… 大家首次看到这些标题时，当时一定是两眼放光，但当你点击详细了解之后，绝对是期待有多高、失望就有多大，因为这类标题的背后，往往都是一些软文引流、营销广告……相信经历过的小伙伴肯定深有体会！ 那简历到底有没有优化技巧呢？其实有，优化简历能为你接到更多的面试，但打铁还需自身硬，它并不能成为你拿下Offer的王牌手段，属于锦上添花。 事先声明：简历优化属于求职途中比较重要的阶段，不会三言两语草草结尾，而是尽量做到事无巨细，所以篇幅较长，分为了上下两篇，大家阅读时请保持耐心。 一、个人简历的基本原则与要素撰写、优化简历时，首先要记住：不存在最好的简历！没有哪份简历能让所有HR都满意，就好像一个人再怎么完美，也不可能受到所有人的喜欢。为此，在写简历时不要追求所谓的最好，写出一份适合自己实际情况的简历才最重要。 同时，往往诸多小伙伴在写简历前，喜欢去从网上找写好的简历模板、找朋友要简历，这种做法能理解，毕竟自己写简历时脑子难免有些短路，不知从何下手，所以想要参考一些相关的简历，尝试从中得到启发。 参考他人简历确实是一种不错的方法，但参考不是照搬，千万不能找到一份简历后，把里面的名字等各类信息一改，大部分内容直接照搬，最后就形成了自己的个人简历，显然这并不合适。 虽然照搬的效率最高，但每个人的技术掌握度、经历都有所差异，所以大家的简历也要根据自身情况进行调整，结合之前的知识树以及自我画像，多花点时间认真去写，才能得到一份最符合自己的简历。 但写简历时怎么根据个人情况去写呢？下面先一起聊聊写简历时的基本要素。 写简历时最基本的第一要素，是保证简历的排版工整性。在上章中曾聊到过，如果简历不够工整，HR打开后可能会直接关掉。比如这样的简历： 大家以正常人的目光来看，简历信息七扭八歪、中英文混乱、字体忽大忽小……如果你每天都会收到几十份简历，突然打开了一份这样的简历，会怎么做？相信你也会关掉它，毕竟一眼扫过去连信息都分辨不清，更别说美观度了，所以简历的第一要素就是排版工整。 排版工整不仅是上下两行要对齐，而且最好也不要留白，留白会很别扭，并拉长简历篇幅，如下反例： 尤其是上面留白，但下面铺满时，看起来的感觉会更加不协调。最好的方式是多行归并为单行，以平铺的方式撰写基本信息（上述案例中，单行3~4个信息左右）。 除开信息排版工整外，大家在选用简历模板时，别选太花哨的，颜色尽量单调，一份简历中不要超过三种，并且样式也要足够清晰，简历布局最好是从上到下，这样才方便HR阅读。 颜色单调、样式简洁、布局从上到下，这三点要素要遵守。不要试图用花哨的颜色、炫酷的样式、另类的布局来吸引HR注意，更多时候反而起到反作用！我看过许多份求职简历，投简历的人才们，可谓是八仙过海各显神通，举几个典型的反例。 有个应届生的简历中，字体用了渐变色，持续盯个十多秒连眼睛都花了。 还有个简历是用PPT来做的，刚点开就是咔的一下，整出一个开场动画…… 还有许多简历布局花哨，左右布局、前面左右，后面上下布局，阅读起来特别麻烦。 这样做能引起筛选简历的人注意吗？答案是绝对行，比如我至今都记得一些“人才”的简历，但这样“另类吸引力”，结果适得其反，影响阅读效率的简历，大多数都会被直接pass。 除开前面几点外，还要注意一点：字体大小、间距、行距合适。如果简历上的字体大小跟蚂蚁一样，并且前字紧挨后字，上行紧贴下行时，这同样会十分影响阅读体验，当打开这样的简历后，想要看清还得先掏出老花镜。 同时，作为技术人的我们，也要学会省略不必要的信息，比如身高、体重、民族、户籍、是否婚配等，这些信息有必要写吗？ 其实没有必要，因为这些不是技术行业的招聘要求，又不是去面服装模特，你人帅气质佳也好、貌美大长腿也罢，都跟你去面技术岗无关，所以尽量把这些无关信息省掉，没有人愿意去花时间，看一些与自己需求无关的内容。 同时，对简历的篇幅也要稍加控制，最好是2~3页左右，没人愿意浪费时间看长篇大论，为此，必须要用足够短的篇幅吸引眼球！ 我见过的部分简历中，有些求职者恨不得把整个人生经历中的每个细节写上去，最夸张的简历高达十多页。说句公道话，先不说这么长的简历HR有没有耐心看，就算它通过了简历筛选，去面试打印简历时，光打印费就多出五六倍，不知情的人还以为是个作家要出本书呢。 OK，前面把写简历时一些要注意的基本要素就讲明了，最后给一个通用的简历顺序。 ①基本信息：能第一时间让HR了解到你的基本情况。 ②求职意向：说明到岗时间、期望薪资、工作性质等需求。 ③教育经历：额外明显地把你自己的教育背景体现出来。 ④工作经历：可以十分清晰地看到你的职业工作生涯。 ⑤专业技能：对于你的专业能力、水平、技术的良好体现。 ⑥项目经历：自己接手过、负责过的项目可以依次罗列出来。 ⑦个人荣誉：这点有没有都行，如果有特别值得说明的可以单独列出来。 ⑧自我评价：自我给自我的总结，但很多情况下大家都套模板（这点最后细聊）。 简历会出现的几个大项如上，当你写简历时，没有特殊情况，就可以按照上面的优先级撰写，因为这个顺序正好符合HR筛选简历的顺序。当你的简历能让HR看得更舒心时，也自然会给HR留下一个不错的印象（前提是你能够满足人家招聘的要求）。 最后对这些撰写简历的基本要素稍加提炼，给出一个小的总结。 简历信息的排版一定要工整。 选择的简历模板不要太花哨。 简历色调尽量保持单调或统一。 简历信息的布局选择从上到下。 简历中的字体大小、间距、行距要合适。 简历的篇幅最好控制在2~3页左右。 按照HR筛选的流程做好简历排序。 一份简历遵守上述各个要素，基本上能够得到一个初稿，为啥是初稿呢？ 因为这样写出来的简历属于通用版，后续还需要根据自身的情况，对初稿进行适当调整，从而显得更加合理，也能让自己的简历做到扬长避短！但往往许多小伙伴写简历时，写到这里就止步了，原因在于不清楚如何继续优化，那接下来就一起聊聊这个话题吧。 二、如何优化出最适合自己的简历？经过前面的一些叨叨絮絮，现在终于来到了大家最感兴趣的话题，也就是简历优化。但这里做个声明，下面确实会教大家一些简历优化的技巧，不过技巧永远只是技巧，可以提高简历的通过率，但还是那句话：打铁必须自身硬，如果本身自己的技术就不强，履历很一般，那再好的技巧也是无力回天。 简历优化这个话题比较大，本节先说通用的优化技巧，也就是任何人都可以用的优化手段；在下节中再聊大家比较关心的内容，即如何制造亮点、如何描述技术栈、怎样阐述项目经验等内容。 重视简历上的优先级“优先级”这个概念，在《技术突击篇》中曾讲到过，对于自己需要提升&#x2F;复盘的技术栈，首先应该按优先级进行排序，接着再制定相应的学习路线，这样才能确保自己准备的内容对目前最有利。 而任何事情都分轻重缓急，简历上的信息也不例外。简历各个信息，也应该分清先后顺序，例如： ①自我评价 ②兴趣爱好 ③所获荣誉 ④基本信息 ⑤项目经历 ⑥工作经验 …… 以上述这个顺序撰写简历行不行？No，如果你敢这样写简历，HR就敢第一个pass你，为什么？因为HR筛选简历时，大半天都找不到她要的信息在哪个位置，每次寻找一个信息都需要做“全表扫描”，所以遇到这样的简历时，第一时间会被pass。 这也是为何强调顺序的原因，方便HR就是方便自己，所以一份基本的简历应该分清主次，哪些内容写前面，哪些内容写后面，心里要有个底。前面第一阶段中已经给了一个通用排序，这里就不重复啰嗦了，此处强调优先级的目的，主要是为了在后面讲优化技巧时，能帮助大家理解为什么要这样优化。 基本信息的优化简历简历，意味着简历该简，不应该过多叙述的一些内容，在简历上就要省去。这点在前面就已提及，但一个技术人的求职简历，基本信息这栏要留下哪些内容呢？ 姓名：起码能够让人家知道你叫啥，这点必须在。 性别：这点写不写都无所谓，但一般邀约中都会有先生&#x2F;女士这类称呼，所以写上最好。 年龄：有些招聘方会卡年龄，例如大厂，所以超过30岁的小伙伴可以省略。 工作年限：招聘方一般都有工作经验要求，这点必须在，突出匹配度。 电话：这点不做过多解释，毕竟人家面试邀约、电话面试、入职邀约等都可能直接打电话。 邮箱：这点大家也都懂，有些公司发面试邀约、入职Offer，都会直接以邮件形式通知。 学历：敲门砖，大多数HR第一时间关注的信息中，就包含了这项内容，必须写。 这里把工作年限、学历单独拎出来讲一下，我知许多人喜欢包装年限，尤其是培训出身的小伙伴。 毕竟在之前的IT市场中，工作年限越高就意味着薪资越高，包括现在的市场也依旧遵守这个潜规则，所以包装年限的人不在少数。但记住包装的经验要经得起推敲，比如： 年龄22岁，学历专科，工作经验四年。 这显然并不合理，正常的专科毕业就20岁了，你目前22岁，哪儿来的四年工作经验？所以这类经不起推敲的简历，必然是HR第一批淘汰的目标。为此，包装可以，但请一定要合理！ 也许这时有一些特殊的小伙伴又要说了：“我情况不一样啊，专科是自考&#x2F;成考&#x2F;函授等方式拿到的，我18岁就做程序员了，按理来说的的确确有四年工作经验呀！” 对于这类特殊群体而言，如果学历并不是统招全日制，就只能说明自身情况，这样可以避免你在第一轮筛选中被淘汰（或者你简历上的年龄也包装一下，但入职时如何解释就看个人发挥了）。 那把年龄从简历上删了可以吗？不行，大部分HR在看不到年龄的情况下，因为她不清楚你的具体情况，只会感觉你的简历经不起推敲，所以你的简历依旧会被淘汰。 PS：我给出的基本信息这一栏，似乎没写毕业院校是不？很多人会习惯性地把这个写上，其实写的意义不大，毕竟后面还会有教育经历这一栏，里面会包含毕业院校的，所以你在基本信息中省掉也无大碍。 最后，简历要不要放照片呢？贴照片这点本身没有错，但最好不要贴照片，要贴的话也别贴生活照，而是从专业照相馆中拍出来的证件照。 除非你拥有例如彭于晏、胡歌……以及我这样的颜值，这时你贴什么类型的照片都没关系，而且还能给你的简历加分，毕竟人都是追求美的动物，更何况许多HR都是女孩子呢。 当然，还有一种人特别适合贴照片，即看起来就很强的大佬，看起来很强是啥意思呢？聪明绝顶的大佬！说人话就是拥有地中海发型的大佬，当你贴上一张这样的照片时，整个简历无需过多的描述，懂行的人一眼就能看出你是大牛，发型就是技术的最好证明！ 小总结：对于基本信息的优化，主要是省去不必要的信息，能够经得起推敲，以及方便HR阅读即可。 求职意向的优化求职意向这一栏，有些小伙伴会下意识忽略它，或者就简单写个目标岗位，但其实，这栏最好还是在简历上单独列出来，并且优先级排第二最佳！ 在我看过的简历中，求职意向通常都写成这样： 先来聊聊上面的到岗时间，许多人喜欢写随时到岗，其实这种做法并不太好，虽然HR面的时候，招聘方会再次主动询问到岗时间，但这里最好也写成“一周内到岗”。 这样做的好处是：当你收到Offer之后，可以谈出一周左右的缓冲期，在这个时间内可以再去面其他公司，拿到多个Offer后再综合考虑选择谁！身为求职者的我们，也应该具备选择的权利，把主动权牢牢掌握在自己的手中。 同时求职意向这栏中，如果自己目前还在职，属于骑驴找马者的话，也应适当描述自己的现状，例如： 写出自己的现状，这方便HR筛选时，判断你是否合适，如果无法接受较长的到岗时间，就自然不会邀请你去面试。同时也方便了自己，因为如果不写明这点，当你面试通过拿Offer时，对方发现你无法在短时间内与上家交接，很可能就会放弃你重新招聘，最终导致你这场面试相当于白搞。 接下来，对期望薪资这点再展开聊聊，这点不用想，至少80%+的人都喜欢写“面议”，那到底该不该写“面议”呢？ 这其实要分情况来看，写“面议”的好处在于能接到更多的面试，毕竟招聘方不清楚你的期望薪资，所以在你简历还不错的情况下，都会对你发出面试邀约。 这样听起来似乎写“面议”很好对不对？但并非如此，你把具体的期望薪资写上会更好，Why？说到这里很多人犯迷糊了，为什么面试多了还不好啊？道理很简单，虽然写上期望薪资后面试会变少，但这些面试邀约将会更精准！ 更加精准的含义是指：既然招聘方看完了你的期望薪资，还依旧对你发出面试邀约，这代表对方可以接受你的报价！也就是只要你能力达标，对方就可以给你满意的薪资，所以，虽然表面看起来面试少了，但得到的效果反而会更佳。 那到底要不要写上期望薪资呢？前面说过要因人而异，如果你目前处于待业状态，迫切想找到一个新工作，此时简历写“面议”的效果比较好，毕竟这样面试机会更多。 但如果你目前还在职，属于骑驴找马这类人，写出具体薪资会更合适，既能够减少很多不必要的面试（毕竟面试需要请假或者抽时间），同时还能让自己的面试邀约更精准。 最后，还有一类人就算离职了，也适合写具体薪资，就是对自己的技术较为自信，或者技术能力比较出色，同时也不急着找到一份新工作的人，毕竟你都不急了，自然面试更精准更好一些。 如果你决定写期望薪资，尽量写成范围值，并且比真实的期望薪资，多出一点点，这样有利于后续的谈薪。 小总结：对于求职意向的优化，主要针对到岗时间、目前现状、期望薪资这三点，小伙伴可以根据实际情况来做优化调整。 教育经历的优化教育经历这玩意儿呢，很多小伙伴都喜欢放在第二栏，重点突出自己的教育背景，HR打开简历之后，第一眼就能瞅着，把它放在这里真的合适吗？也要因人而异，比如这种情况： 合适吗？不合适，因为专科学历并非是一种优势，或者说并不是一个亮点，所以对于专科、双非本或者非统招学历者，我的建议是放到后面几栏去。 什么样的人适合把教育经历放在第二栏呢？三类人： ①具备国内985/211名校背景，例如清华大学、北京大学、复旦大学等； ②具备高学历，例如硕士研究生学位、博士研究生学位等； ③具备海外名校的留学经历，如英国剑桥大学、美国哈佛大学等。 符合这三类标准的小伙伴，就可以把教育经历放在第二栏这个显眼的位置，毕竟这属于你的优势，也是你本身的亮点之一，不仅要把位置靠前，还可以重点把这块区域的字体加粗（虽然有点刻意，但不免是一种引起HR注意力的手段）。 PS：走校招路线的应届生，不管院校背景如何，都可以把教育经历放在第二栏。 小总结：对于教育经历的优化，主要强调了在简历中的优先级，什么人才适合放在第二栏。 工作经历的优化工作经历这一栏，相信参考过一些简历的小伙伴，应该熟悉其通用模板，如下： 先写任职时间、公司名称、所在部门、担任职务这四项，下面的子栏中，则详细写出自己的工作职责，将自己的从业经验按公司划分，分别套入其中之后，能够清晰反映出自己的工作经历，但这里面有三个小技巧要说一下。 第一个技巧，工作经历以倒序的形式描述。有些人写工作经验时，喜欢根据从业时间线从早写到如今，但这种方式有点不好就在于：无法将上家第一时间呈现给HR。所以最好以倒序的手法描述工作经历，也就是最近的一家公司放最前面，因为HR看工作经验这一栏时，重点会关注你的上家公司。 第二个技巧，如果存在多段比较短的工作经历，可以合并成一份工作经验。虽然这样做听起来不地道，但却是求职途中惯用的伎俩，毕竟上章聊过，HR除开关注上家公司外，还会关注你在每家公司的任职时间，如果每家公司的任职时间都不长，说明你是个十分不稳定的人，很有可能由于此原因造成简历被淘汰（但多段工作经验合成一段时，最好是将之前的工作经验合并，如果是最近的一两家公司，是可以通过社保缴纳情况查出来的，所以合并经历时也要视情况而定）。 第三个技巧，适当控制工作经历的篇幅。工作年限较长的小伙伴，可能待过很多家公司，如果每段经历都描述得很详细，一方面自己很难回忆起来，另一方面也会大幅度拉长篇幅。为此，如果年限比较长，那把最近两家公司的工作职责写细即可，其他公司的经历可以略写（如上图中的第三段工作经历）。 OK，掌握上述三个技巧后，接着再说说另外两个比较重要的优化手段，但聊之前得先认识项目中的不同角色，我不知大家的简历，是否属于这样的情况，以Java为例： 求职意向：Java开发工程师。 第一份工作担任的岗位：Java开发工程师。 第二份工作担任的岗位：Java开发工程师。 第三份工作担任的岗位：Java开发工程师。 …… 虽然我没见过诸位的简历，但我相信简历类似这种情况的小伙伴有很多，求职意向也好，还是工作履历也罢，所有职位都写XXX工程师，首先声明：其实这样写并没有问题，但也可以做得更好，怎么做呢？ 先聊聊项目中的不同角色，通常项目中都会分为三类人。 普通成员：负责项目中边角业务的相关工作，例如开发、文档撰写、测试…… 核心骨干：承担项目中核心业务功能的处理工作。 项目主管：作为项目的负责人，主导项目进度的正常推进，参与产品设计、规划等工作。 任何技术团队都有这三类角色，初中级水平的技术人一般站在成员梯队，中高级水平的技术人通常站在骨干梯队，而高级&#x2F;资深水平的人，往往站在主管梯队，这也是业内的一种潜规则，能力越强的人必然职位越高，因此你可以借助这些去优化工作经历，例如： 第一份工作：XXX开发工程师。 第二份工作：XXX主程、XXX核心开发。 第三份工作：项目负责人、项目经理、技术总监、XXX架构师。 当然，我上面只是举例说明，这么干的好处在哪儿呢？能让HR看到你的职位在随着工作不断上升，也就是你的履历呈现上升趋势，而不是干了N年的“基层杂役”，从而制造一定的优势。 看到这里许多人又来了疑惑：“可是我的项目就只有三个人啊，项目很小怎么办？”其实这是好事，Why？你想想，既然你这个项目只有三个人，那你属不属于项目的核心开发？是不是项目的主程？答案当然是的，所以请放心大胆地写在工作经历上，别再写XXX工程师了，直接写XXX主程或XXX核心开发工程师。 当然，如果你这个项目只有你一个人负责的话，那这更是天大的好事啊，信我的，直接写项目负责人、项目经理，在HR筛选你简历的时候，绝对能让她高看一眼。就事论事，这撒谎了吗？显然没有，只是把事实换了一种手法论述罢了，但最终呈现的结果却完全不同。 注意：当你在简历上写下XXX核心、主程、负责人时，也一定要做好相关的准备，如何准备呢？相信你在以往公司一定有上级吧？你就把他的工作职责写成你的就行，毕竟任何一家企业在招聘时，不可能详细了解到你在以往公司的内部情况，所以请把你那颗忐忑不安的心放在肚子里。 最后，对于工作职责如何写呢？如下： 参与了XXX系统的研发工作，主要负责AAA、BBB、CCC...工作； 与某某部门的XX成员进行对接，协助其完成MMM、NNN、ZZZ.....工作； 负责项目的aaa、bbb、ccc....等工作，基于XXX完成某某工作； …… 看着上面这些用语，有没有一种熟悉的感觉？相信大部分人都是这样写的，看着似乎没有大毛病，但没有问题就是最大的问题，这样去写能否突出你的优势？显然不能，你与其他人对比，同样平平无奇，没有任何亮点存在，那究竟该如何写呢？比如： 参与系统重构工作，解决了长期存在的代码臃肿问题，极大程度上提升了项目的拓展性； 负责主导项目中XX模块的优化工作，解决了XXX延迟问题，成功将响应速度提升200%； 与XX部门携手攻克性能问题，解决了XX时间段的并发问题，自此项目的吞吐量提升四倍； …… 对比前面常规的通用写法，后面这种手法描看着是不是更有冲击力？至少技术面试官在筛选你简历时，他肯定对你这些工作中，如何解决问题的具体手段额外感兴趣，因此对比前面那种普通写法的求职者来说，你的简历将会更有竞争力。 这种阐述手法，也被称之为**STAR法则**，也就是在形容一项工作时： 先说执行此项工作的情景（Situation） 接着再说本次工作的任务（Task） 然后再说本项工作的行动过程（Action） 最后再说此项工作落实后取得的结果（Result） 大家在描述工作职责时，尽量摆脱传统简历模板中的描述手法即可，多运用这种所谓的STAR法则来套入就行。 最后，对于个人的工作职责来说，有两类人可以适当做出其他调整。 ①技术管理：可以写明自己的管理规模，再写出自己带团队的成果等。 ②技术牛人：写出实际工作收益，如在职期间解决了大流量、高并发（亿级流量、百万并发）。 小总结：对于工作经历的优化技巧不算少，首先说了描述工作经历时的三个小技巧，接着讲明白了项目中的不同角色，最后又聊到工作职责该如何去写。写工作经历时要多运用前面提到的原则、技巧，尽可能地提升“简历的竞争力”。 简历优化篇（下）：如何美化专业技能与打造项目技术亮点？在《简历优化上篇》中，我们已经打造了一份“基本”的简历，但对于求职的技术人而言并不够，毕竟技术行业的简历，最关键的还是专业技能的表达，以及项目经验的描述。为此，本章中会详细讲到这些内容： 怎样写专业技能才能显得不一样？ 如何去打造项目经验中的亮点呢？ 怎么写简历上的自我评价才诚恳？ 针对不同的JD该如何微调简历？ 现在就不再多说废话啦，让我们直接开始吧！ 一、怎样写好简历上的专业技能作为技术从业者的我们，在简历上表露自身的技术能力，这自然是必不可少的一项，毕竟这可是咱们吃饭的看家本领！那在简历上描述个人技术时，到底是该吹牛呢，还是谦虚啊？吹牛怕被面试官吊打，谦虚又怕别人看不上，这可怎么办？没关系，下面我们就逐步聊聊简历的专业技能该如何写。 遵循六条基本原则在描述简历上的专业技能时，首先得遵循下述六条原则： 描述技术栈形容的词汇需保持一致； 各项标点符号要统一（包括符号的输入法）； 包含英文的技术关键字，遵循驼峰命名法； 对技术按属性分类分项，条条罗列更清晰； 对掌握的技术按热度、掌握度排序； “精通”要慎用，要确定自己能驾驭再用。 接下来会先展开讲讲这六条原则，然后再讲解如何对其进行优化，从而突出自己的技术优势。 第一条，形容技术的词汇要统一。这是指对于所有技术的掌握程度，应该使用相同性质的形容词汇进行描述。例如，最常用、也是最经典的一组形容词汇：了解、熟悉、熟练掌握、精通，这分别代表技术的四个掌握层次。简历上描述技术能力时，通常要使用同一组词去描述，不能出现下述这种情况： 熟悉 XXX、专注 XXX、精通 XXX、善于 XXX…… 虽然上述这种用不同表达词的描述手法也可以，但最好还是用同一性质的形容词汇（至少看起来不要脱离一个词系），这样能直接把你对技术的掌握程度反馈给面试官，能让面试官清楚你对各项技术的掌握度。 第二条，标点符号统一。主要指中英符号一致、结尾符号一致，这是为了保证简历的美观程度。毕竟中、英模式下的各个符号，相对都有所差异，如果不统一的情况下，显然会影响简历的整洁性，例如： 这样的简历看上去有些潦草感，HR筛选简历时，也会注重整洁性问题的。为此，在描述专业技能时，一定要统一标点符号，如：所有符号都为中文符号，每一项都以。句号结尾。 第三条，英文单词的开头字母大写，不同单词间遵循驼峰命名法。作为IT开发人员，掌握的专业技能中，难免会有许多技术关键字是英文，因此要注意这些关键字的大小写。以Java为例，SpringMVC不能写成springmvc、SPRINGMVC、sPrINgMvC等形式，毕竟这样写严重影响美感，并且还显得自身不够专业（同时单词也不能打错，字母顺序也不能打错，注意多加检查）。 第四条，对技术按属性分类分项。有些小伙伴为了图方便，描述专业技能时会将其写成一段话。但其实要想让简历更直观、更便于阅读，专业技能最好分成多项去描述。不过分项时要注意，最好按属性做分类，而不是随意罗列。 以全栈开发举例，假设通过如下方式描述： 精通 Nginx、Vue、CSS、Spring、MQ、JVM、React、gRPC…… 你觉得合理吗？并不合理，毕竟这些技术都不属一个领域！最好的做法是按照属性的不同，将每个属性单开一项进行描述，如前端分一项、Java 分一项、中间件分一项…… 第五条，技术栈按热度、掌握度排序。面试官看专业技能这一栏的目的是啥？想要看出你会什么，并判断你与空缺岗位所需的技术栈是否匹配。为此，在写专业技能时，一定要按技术热度进行排序，热度越高代表需求更高，匹配度自然也越高，因此将热度高的技术栈放在前面，更便于招聘方“检索”信息。除开热度外，也可以适当地将自己比较擅长的技术放前面，比如“精通”的优先级应该要高于“了解”。 第六条，“精通”要慎用！ 很多人在写专业技能时，都存在一个疑惑：“我这项技术到底是写了解，还是熟悉、熟练掌握、精通呢？”大家很难把握这个度，因此往往会遵循下面这个原则： 听过写了解，学过写熟悉，用过写熟练掌握，研究过底层写精通。 这样做有没有问题呢？其实前三项问题不大，但“精通”这个词要慎用！因为只要你敢写“精通”，那后果绝对是会引来面试官的狂轰滥炸。为此，如果你对某项技术有绝对自信，有过全面且深入性的研究，能 Hold 住吹出去的牛，那简历上就放心大胆地吹。反之，尽量谦虚为上，不要去写“精通”。 遵守上述六条原则撰写简历上的专业技能，最后能得到一份“初稿”，接着可以再建立在“初稿”的基础之上，对其不断进行优化与改进即可。 正常人如何美化自己的专业技能？对技术栈的描述，许多人都停留在用“了解、熟悉、熟练掌握、精通”这套词，然后就没有然后了…… 举个尤为常见的例子，如下： 熟练掌握AAA； 熟悉BBB； 了解CCC； 学习过DDD； 有过XXX经验。 这样可以吗？当然可以，但你没有真正表达出对技术的掌握度，比如你写熟悉BBB，但你到底熟悉到什么程度呢？看你简历的人无从得知，假设你是一位面试官，想要基于简历进行提问时，又该如何提问？你不清楚，只能按自己的推断去提问。 也正是由于上述原因，所以在描述技术栈可以稍加美化，如下： 原文：精通Spring框架。 美化：精通Spring框架，曾阅读过IOC、AOP、MVC、事务机制的源码。 原文：熟悉Nginx。 美化：熟悉Nginx代理技术，能熟练运用Nginx搭建服务的热备集群。 也就是给面试官一个方向，看到你的这项技术栈之后，能明确知道你具体对哪方面有过深入研究，至少能在面试中，给予对方一个提问的方向，而并不是让对方盲目提问。简单来说就是：对于自己掌握的技术栈，不要再用一个单调的词汇形容，而是加上一些修饰语去引导。 经验丰富者又该如何优化专业技能？前面所说的方法都只适用于“初、中、高级”水平的人，随着工作年限的不断增长，个人的技术栈也在不断丰富，所以一些工作多年的技术人，所掌握的技术栈十分多，再按照前面的方式就容易写出长篇大论。我见过的简历中，甚至见过专业技能写了三十多项的牛人，但这样去写，不如换成下面这种方式（以后端为例）： 十年IT开发经验，六年系统架构经验，具备丰富的大型项目处理经验； 精通大流量、高并发、海量数据处理，擅于构建高吞吐低延迟架构； 精通常用开源框架，如Spring体系框架，阅读过大部分框架底层源码； 精通分布式&#x2F;微服务架构，熟知分布式架构各难点排除及解决方案； 精通关系型数据库、非关系型数据库，擅于搭建大流量系统存储中心； 精通Shell脚本语言编写，具备搭建可持续化自动部署&#x2F;监控中台经验； 精通中间件技术、线上问题排除、系统故障分析、应用性能优化手段； …… 看上述这段专业技能描述，虽说没有指明具体的技术栈，但常人看到这段描述就能感受出：是个大佬！ Why？因为这段描述是提炼过的内容，不再拘泥于某个技术细节，更多的是在突出自己的优势，所以这也是每位资深技术人应该要掌握的能力，即：学会提炼自己的专业技能，重点突出自身的优势，而并非长篇大论。 不过话说回来，干到资深水准的小伙伴，基本上也无需通过投简历的方式找工作。毕竟自身工作经验丰富，所以人脉关系并不差，换工作更多是被挖，或者走内推、猎头的途径。 二、项目经验不应该写成流水账聊完了专业技能如何撰写后，接着再来说说项目经历，项目经历估计是大家头疼的一栏，很多时候不知道如何去描述项目，为此，这里先给出一个 通用模板。 基本信息：项目名称（项目开发周期）。 技术架构：项目开发中所使用的技术栈。 项目背景：如果是自研项目，说明项目的背景。 项目描述：大概形容一下这个项目是干嘛的。 个人职责：说清自己在项目中做的事情。 技术描述：罗列一些自己在项目中用到的技术亮点（可以与个人职责合二为一）。 个人收获：大概讲讲做完这个项目给自己带来的成长（可选项，中级以上建议不写）。 大家在描述项目经验时，都可以按照这个模板往里套，给个简单的示例，如下： 按模板去套自己的项目，你的项目经历就能较为全面地体现出来。但对于年限较长的小伙伴而言，因为工作的时间不算短，所以接手过的项目不在少数，请牢记：千万不要把项目经历写成流水账！ 项目经历怎么写才更吸引人？不要写成流水账是啥意思呢？就是简历无需写太多的项目，我的建议是来4个左右就够了，而这几个项目中，至少前两个一定要选比较有吸引力的，即技术面试官感兴趣的！但问题又来了：什么样的项目算比较有吸引力的呢？ 具备吸引力的项目主要有如下几类： 知名度比较高，例如淘宝、京东（这里是举例，稍微有点名气也行）； 用户量比较大，用户基数大代表流量大，对性能、技术要求会更高，知名度也不会低； 技术难度比较大，用到了较复杂或较新的技术开发的项目，如直播、金融类型项目等。 描述项目经历时，从接手过的项目中，选几个符合上述条件的即可，千万别把所有项目都写上去！因为这样干，会造成简历篇幅过长，同时还容易写成流水账，看着虽然多，但没有核心，所以写项目经历讲究：浓缩的才是精华。 但如果你从业时间较短，接手过的项目并不多，则可以把做过的项目都写上去。同时，如果项目都算不上很出色，你也可以用一点小手段，也就是所谓的“包装大法”。找一两个你认为比较出色的项目，写在你的简历上也行，但这样的做的前提是：你对“包装”的项目，必须得像自己做过的一样熟悉，如果无法吃透包装的项目，自然在面试中很容易露出鸡马脚。 平凡的项目如何制造亮点？相信诸位都有一个苦恼：“平时工作就是打螺丝，简历上的项目该如何写出不一样的感觉啊？” 这是导致大家项目经历看着很平凡的罪魁祸首，很多人往往就是因为不知如何优化项目经历，所以只能按事实陈述，导致项目经历一点也不突出。 下面就来教大家优化项目的方法。 优化项目主要依靠两条准则，第一条是通过语言美化，第二条则是塑造技术亮点。 1. 善用语言去美化先来说一则小故事： 一个小和尚问方丈：“师父，我念经的时候可以抽烟吗？” 方丈怒道：“当然不行！”另一个小和尚也问这个方丈：“师父，我吸烟的时候可以念经吗？” 方丈的回答是:“自然可以。” 从这个故事中大家能明显感受到语言的魅力，同样的一件事情，用不同方式去表达，事情的核心并没有改变，但得到的结果却完全不同。这个道理很容易懂，但却很少有人能真正用好它。怎样才叫用好这个道理呢？例如： A：我要教人搞传销诈骗！ B：现在传销诈骗日益猖獗，为了防止大家上当，我将以犯罪人的视角宣传反诈骗！ A：小李兼职摆摊卖炒饭，昨天赚了15块，今天赚了60块。 B：小李兼职摆摊卖炒饭，今日相较昨日，收益环比增长300%！ 上面两个例子，大家是不是有种熟悉感？日常生活中有着许多类似的案例，但具体有哪些就不指出了。这里重点是在强调：一件相同的事情在不同的语言修饰下，产生的结果自然不同！想要给自己简历上的项目做美化，首先就得利用这个原则去落实。 但搞技术的人里面，大部分都缺乏这项能力，因为大家更偏向于理工科，文学功底有所欠缺，想利用这个准则用来美化项目，会存在些许难度，因此这里给出两个示例参考。 原文：两三个人负责一个项目，自己负责写代码、在开发周期内交付项目。 美化：推动项目正常进度，参与需求分析与系统架构设计，负责项目核心模块的开发工作。 原文：把写好的项目丢到服务器上，以后出问题了再负责改一下 Bug。 美化：主导项目的上线部署工作，跟进线上实际运行状况，及时排查与解决线上故障。 这些示例中，事情的本质有改变吗？其实没有，归根结底说的还是同一件事，但当换了一种表达方式后，给人的感觉完全不同。比如第一个示例中，按照正常的写法去形容，给人的感觉就是个做业务开发的螺丝仔，但换了一个说法之后，你便化身成了团队主程、核心骨干，少了你肯定不行（2～3个人负责开发的项目，少了你的确不行）。 OK，上述内容便是优化项目的第一个技巧，也就是把同样的事情，用听起来更加牛逼的方式表达出来。但这里要牢记：适当塑造确实可以提升竞争力，但塑造时也千万不要过度。比如你在飞机上打了两颗螺丝，结果写成参与了整架飞机的制造，甚至对外宣称你造了架飞机，这可以吗？不行，因为实际考察时，稍微一问就露馅了，那什么叫适当地塑造呢？可以把“给飞机打了几颗螺丝”改为“参与了飞机零部件的制造”。 简历的项目经历中，这个技巧可以用在项目描述、技术描述、职责描述等各方面。好比项目职责描述中，我见过的许多简历，往往是下面这样： 负责开发XXX模块，实现了AAA、BBB功能。 这样写虽然可以，但会显得有点平平无奇，那如何优化呢？套下面的模板： 负责开发XXX模块，利用XXX等技术，解决了XXX问题，达到了XXX效果。 有小伙伴会说，我不会套啊，能不能给个例子啊？那就来一个吧（以后端举例）： 负责XX模块开发，利用MQ、Redis中间件，解决了系统并发吞吐低的问题，经实测由500QPS提升至4000QPS。 这样看起来是不是好多了？所以在写项目经历时，这个美化技巧一定要利用好。 2. 学会塑造技术亮点接着再聊聊第二个优化技巧：制造技术亮点。 为啥要制造技术亮点？因为技术面试官在看项目时，重点只关注三方面。 项目的背景：规模大不大、名气大不大、技术难度高不高、业务复不复杂…… 你是什么角色：你在项目中是负责边角料开发的螺丝仔，还是核心开发，或者负责人…… 项目中的技术亮点：项目中有没有比较难的问题，会用到令人眼前一亮的技术或方案…… 前两点在前面讲过了，现在把目光放在最后一点，这点对于大家来说，似乎是个不小的问题，我天天就是打螺丝，哪儿来的什么技术亮点啊？利用CV大法日码一万行算不算亮点？ 由于工作的局限性，似乎项目中很难出现技术亮点是不？这点我能理解，不过大可不必担忧，既然你做项目时没有亮点，那你在平时瞎逛时，有没有遇到过令你眼前一亮的技术解决方案、疑难排查呢？如果有，就请把它写在你的简历上。 这样做合适吗？当然没问题，但前提也需要你能吃透写的亮点，因为你既然写了，那么面试中80%几率会被问到，如果Hold不住自己写的亮点，面试结果自然可想而知！ 那有哪些属于技术亮点呢？以后端举例（其他岗位我不是很熟悉，大家根据自己情况来定）： 分布式系统中需要传递一个全局唯一的 ID，用于串联分布式系统中请求的链路日志记录。 亮点 1：如何确保全局唯一？可以延伸分布式ID生成策略，如拓展到雪花算法。 亮点 2：并发情况下，如何保证不同请求的ID不会冲突？可以延伸到ThreadLocal。 项目中某个接口调用后响应速度缓慢，每次用户访问时需要等待很久，如何做的优化？ 亮点 1：线上排查手段，如何精准定位到响应缓慢的接口、造成缓慢的原因…… 亮点 2：性能优化手段，如何优化了响应时间？拓展到MQ中间件、多线程、缓存…… …… 总之，所谓的技术亮点，就是写一些比较难、吸引人的问题，这样面试官在看的时候，自然会对你解决问题的方案感兴趣，因此你的简历吸引力会更大。并且在面试过程中，也可以大概率引导面试官的提问。 综上，我们可以总结出项目经历描述与优化的要点，其实重点就是做好三方面：选好适合的项目、美化好项目经历、突出技术亮点。这三个是技术面试官会关注的点，所以针对简历的项目优化，围绕着这核心的三点展开即可。 最后，额外说明一点，如果你所负责的项目是面向C端的业务，可以适当贴出演示地址，这样有助于让招聘方充分了解到你的项目，尤其是针对同业务类型的招聘方，看到你的实际项目时，会对你更加满意。 三、简历上其他容易忽略的技巧认真对待自我评价至此，简历上会出现的每项信息，都给出了编写时的建议及优化技巧，但前面忽视了一项内容，也就是“自我评价”这一栏，大家在写这栏时，基本上全靠在网上抄。正因如此，很多简历的自我评价都会出现下述这些信息： 我的建议是最好别这么写，而是结合个人的实际情况，诚恳地写出一段自我评价！因为有些 HR 在看简历时，会优先查看你对自己的评价，所以写的时候，可以优先考虑写上自己的优势，如： 平时热衷于技术研究与分享，XX签约作者、XX博客专家、XX畅销书原作者、XX技术核心贡献者…… N年服务端、后端开发经验，N年大型项目架构经验，主导过十余个大型项目研发及落地，多个项目用户规模达到千万级、全站单日并发达到百万级…… 上述这段自我评价中，就能够将你自己的优势完美体现出来，但如果没有优势的话，一段发自内心的诚恳评价，也能给人留下良好的印象。不过对于技术人来说，这段评价的影响也并不大，有句话叫做“无过便是功”，能写出一段有优势最好，如果文笔功夫实在欠缺，从网上复制一段也OK。但千万不要自作聪明，在自我评价中大肆吹嘘、夸奖自己，否则只能适得其反。 不要一份简历打天下JD（全称Job Description）是指职位描述，即你在招聘网站上看到的招聘需求。 在求职的过程中，当你看到一个JD很满意，薪资待遇、福利、技术栈、业务等方面都特别合适，那针对这样的JD就要额外珍惜，别抱着“一份简历打天下”的想法。 面对自己满意的招聘，尤其是工作年限较长的伙伴，可以了解下招聘方的业务范围，适当把简历的项目调整成与招聘方业务更匹配的。同时再参考JD上的技术要求，调整一下自己的专业技能顺序。 为此，大家在写好一份通用简历的前提下，也要做好随时微调的准备，匹配度越高的简历，会更受招聘方的欢迎。对于招聘方而言，想要招到一个业务经验、技术能力十分匹配的人才并不容易，如果你能够通过微调达到对方满意的标准，简历上项目的业务属性、个人的技术栈，都与招聘方相匹配时，那自然成功几率会更高。 写好简历后要做的三两事当你按照文中所说，撰写并优化好了简历之后，首先记得多复查两遍，看看整份简历是否可以再精简一些。如果可以，请再次对简历动刀，毕竟写简历是个修修补补的过程，多番打磨后才能得到更好的成品。同时，复查也能解决不细心带来的后患，例如错别字、英文单词的字母顺序反了、某些内容重复……这类问题。 确保简历内容完全正确，并且足够精简时，可以把你的简历发给同为技术人的几位朋友、同学看看，如果你的朋友看了之后，觉得你的简历比他写得要好，那相对来说你的简历就很不错啦！同时，朋友看你简历的过程，相当于他人帮你复查了一次，也相当于别人给你筛选了一次，说不定他们还能给出一些额外的调整建议。 最后，简历成品出来之后，一定不要忘了导成PDF格式噢！如果是.doc、.md或其他格式，当你投递简历的时候很容易出现打不开，或者打开出现乱码、排版混乱的问题，而转换成.pdf格式后自然就不存在这些问题。 自我练习篇：自我介绍、项目介绍该怎么说面试官才会听？自我介绍、项目介绍，这属于技术面试必不可少的两个环节，但往往许多小伙伴，要么不会表达，刚开始介绍没多久就结束了，或者开始介绍后，就不知道该如何停下来，又或者不知怎样介绍得更好，做到扬长避短…… 正因上述一些情况，所以大家会遇到下面两个困扰： 面试中的自我介绍，怎么说才合理？ 面试中的项目介绍，怎么说才更合适？ 想要做好这两点，需要经过充分准备与一定练习，整个过程需要一点时间，也需要克服一些困难，具体怎么做呢？下面我们一同来探讨探讨吧～ 一、自我介绍该怎么说才合理？自我介绍是许多面试的第一问。当你与面试官初次见面时，通常都会让你先做个简单的自我介绍。估计有些人会犯嘀咕：“你是没长眼吗？简历上都写着还叫我介绍？” 简历上有求职者的大致信息，这点我们懂，其实面试官也懂，但为何还要让人做自我介绍呢？原因如下： 面试官想对你有个初步的了解，毕竟你们也许是第一次见面，之前对你不熟悉； 面试官想从这里判断你的语言组织能力、沟通能力怎么样，以及性格是否内向等； 虽然简历上有你的大致信息，但面试官需要时间浏览，自我介绍则起到缓冲作用； 看你自我介绍时的语言表述，和简历信息是否一致，以此来推断简历信息的真实性； 面试官想要通过你做自我介绍，来打破四目对视的尴尬场景，起到缓解气氛的作用。 由于上述几点因素，所以自我介绍才成了面试中常有的环节。不过也并非所有面试都会叫你做自我介绍，尤其是技术面试官，很多时候没那么讲究，可能上来就直接聊技术。 但有可能不需要做自我介绍，不代表咱们不需要准备，那自我介绍怎么说才合适呢？我们一起来分析下这个话题。 自我介绍的模板和注意点 问候语 + 姓名 + 年龄 + 毕业院校 + 工作年限 + 目标岗位 + 专业技能 + 上家经历 + 工作职责 + 结束语 将自己的信息套入这个模板中，就能够得到一个自我介绍的初稿。但是，有以下三点要切记。 第一点，注意扬长避短。如果自己的学历是专科或非统招学历，可以适当省去毕业院校，毕竟这是你的短处。反之，如果你拥有名校背景，则可以在自我介绍中重点突出。其他方面，例如项目经历、工作履历、个人荣誉……亦是同理。 第二点，注意控制时长，不要太短也不要太长。 这里分享之前我做面试官的两个经历： 经历一：我让候选人做个自我介绍，结果一分钟没到就完了，当时我连简历都没看完。 经历二：我让候选人做自我介绍，我趁机快速浏览一下简历，结果候选人嘴不带停，从基本信息一直介绍到了项目经历，讲了十多分钟还在描述项目细节…… 由上面案例可得知，自我介绍也需要一定的技巧，太短的话可能面试官连简历都没看完，太长的话则会变成面试官一直等着你，无论哪种情况都容易给人留下不好的印象。为此，一定要学会控制自我介绍的时长。 下面结合前面给出的模板，给出一个自我介绍的例子： 面试官你好，我叫竹子爱熊猫，今年29岁，17年于清华大学硕士毕业，至今从事Java开发已有六年时间，今天是因为在Boss上看到了贵公司的招聘，所以过来应聘Java架构师一职。 平时个人比较热爱技术，主要擅长XXX、XXX...等方面，对XXX、XXX...都有过深入研究（这里最好简短，不要把所有掌握的技能都讲一遍）。 毕业以来曾先后就职于公司1、公司2等多家企业，上份工作是在XXX担任技术总监一职，在职期间内曾主导项目1、项目2、项目3等多个项目的研发工作，平时主要负责职责1、职责2.... 以上大致就是我个人的基本介绍，如果你有其他需要了解的，我这边可以再做补充。 又或者： 你好，我叫竹子爱熊猫，今年22岁，因为我是培训出身，所以参加工作的年份比较早，20xx年的时候就出来上班了，到现在已经工作了有三年时间，技术栈这块，个人比较擅长...... 在我工作的三年以来，一直在XXX公司做Java开发，在职期间内，曾参与过项目1、项目2、项目3等项目的设计与研发工作，平时自己主要是负责职责1、职责2....（如果自己感觉较短，这里也可以补充一个最近做过的项目）。 今天主要是看到了贵公司在Boss上的招聘，仔细阅读招聘需求后，发现自身能力与贵公司的需求比较匹配，同时之前自己也做过XX方面的业务，所以过来面试Java开发一职。 在给出的两个自我介绍示例中，虽然不是很长，但却涵盖了个人基本信息、工作年限、从哪来的、来干嘛的、之前在哪些公司待过、在上家公司是做啥的、上家公司做过哪些项目等内容，整段介绍看起来简短，但已经将面试官想要知道的所有信息都做了介绍（案例仅供参考，如若有更好的方式可以结合一下，不必完全套入）。 同时，第一点提到的“扬长避短”要充分发挥好！比如第一个示例中，高学历+名校背景，显然是候选人的优势，因此可以在自我介绍中重点突出；而后者因为是培训出身，所以学历这块可以适当跳过。 另外，第三个切记点是：在自我介绍的最后，一定要记得加上结束语！ 这是许多小伙伴会遗漏的点，但加上它之后效果会很好：一方面可以给自我介绍收场，避免叨叨絮絮个没完，不知道如何停下介绍的尴尬场景；另一方面还能给面试官留下提问的“衔接口”，也就是最后那句“如果你有其他需要了解的，我这边可以再做补充”，面试官就可以接话提问。 自我练习的方式将自身的情况套入给出的模板中，能够得到一个最基本的初稿，可以先调整优化一下，接着可以背两遍，熟悉稿子之后再多加练习。 练习的方式主要有三种。 对镜练习：自己正对着镜子，然后盯着自己的双眼，开始模拟做自我介绍。 录音练习：通过手机自带的录音软件，或者用通信软件语音功能，录制一段自我介绍。 录像练习：利用手机的相机录像功能，调整好角度之后录制一段自我介绍。 看到这三种练习方法，相信许多小伙伴会有些排斥，心里可能会想着：“我都已经把稿子写好了，面试直接按稿子说就好了呀，干嘛还要这么去练？”如果你的内心也有这个想法，其实很正常，但请一定要去尝试练习！ 为什么一定要去练习呢？心里默念难道不可以吗？ 如果你是个社牛，练不练习都无关紧要，毕竟性格本身就很外向，在面试中自然可以做到侃侃而谈。但如若性格偏内向或者性格普通，就一定要多加练习！这个练习不仅仅是为了做好自我介绍，而且还可以改善面试中整体的个人表现。 对镜练习对镜练习时，先盯着自己的双眼，或者盯着自己的眉心，然后再开始练习自我介绍，并且不是练习一遍就完事，一定要多次练习，至少也要在10次以上，最好做到30次以上！Why？自我介绍练习个三五遍就滚瓜烂熟了，至于练这么多遍吗？ 咱们不能只看表象，其实这里是在练习眼神！我见过许多人在回答问题时，都会出现眼神飘忽的现象，比如当我一直盯着他时，最多三秒，就会避开与我的眼神接触，这显然是不自信的表现。甚至有些候选人，在面试时整个眼神摇摆不定，喜欢东瞟西看，这更会给人留下不好的印象。 而对镜练习就能很好地改善眼神问题，当你习惯与自己对视时，你的眼神也会逐渐坚定，经过多次练习后，在以后真正的面试场景中，也会下意识地盯着面试官的眼睛回答问题。直视他人是一种尊重他人的表现，也是一种自信的表现，更能给人留下一个好印象。 不知大家身边是否有入伍多年的“兵哥哥”，当你跟他们待在一起时，你会发现他们的气场完全不一样。当然，我们就算对镜练习两年半，也不一定能够达到军人的气质，但至少能够改善原本眼神上的一些小毛病，起码能习惯与人对视，不至于面试时怯场，从而表现得很糟糕。 录音练习对镜练习好眼神之后，接着是录音练习，因为当你在说话时，是无法感受到自己的谈吐好坏，就算说话语气词、口头禅很多，在事后也不会有所察觉。这件事相信大家都有所体会，比如身边有些朋友或领导，说话时带很多语气词或口头禅，听的人都能感受到，但他自身却觉察不到。录音练习主要解决的就是这类问题。 当准备好自我介绍的稿子后，可以把自我介绍录下来，但要记住：无论是对镜练习、录音练习还是后面的录像练习，就算发挥不好，也要坚持下去！许多小伙伴在做一件事情时，如果没做好的第一反应就是重做，比如跟朋友发语音，说着说着出现一点卡壳时，通常会取消重新说一遍，但在练习时千万不要这么做！ 录制好一段自我介绍的音频后，接着你要放大声音去听。当你前几次听自己的录音时，可能会感觉有点尴尬，迫切地想关掉不听，这是十分常见的情况，请不要在意，认真去找录音中自己认为不足的地方，并且加以改善后再次录制，直到自己感觉没问题为止。 不过自我介绍在录音练习时，往往无法反映出自己说话的问题，因为自我介绍经过前面的练习后，在你内心已经滚瓜烂熟了，所以录制时会更加自然一点。为了充分反映出自身的问题，可以预设一个主题自由发挥，比如“以猫为主题讲个故事、谈谈你对XXX技术的看法……”，只要不是事先准备的都行，单个录音至少要保持在10分钟以上。 这样做的好处在于：一方面能充分找出自己说话时的问题，另一方面还能锻炼自己的临场发挥能力，就算是在胡言乱语也没关系，当你录制好之后再去听的时候，就能明显感觉到问题所在。比如找找自己说话的过程中，是否经常出现“嗯、啊、吗、额、可能”等语气或停顿，如果有，就换个主题录音练习，但在下次练习的时候，脑海里强迫自己注意减少这些语气词和停顿。 通常经过5~8个主题的切换后，你说话的小毛病能得到不小改善，最主要的是你能习惯临场发挥，从而能做到在面试中侃侃而谈。这也是为什么有些人一开口时，总能如滔滔江水般连绵不绝的原因，难道他们与生俱来就有这个能力吗？并不是，都是靠锻炼出来的，大部分人最开始都是支支吾吾，经历多了之后才逐渐变得能说会道。 录像练习对镜练习能改善眼神气质问题，录音练习能改善谈吐与增强临场发挥能力，而录像练习的作用是干嘛呢？许多小伙伴似乎感觉录像和录音的差距不大呀？为什么还要多此一举呢？实则不然，录像练习的最大好处在于改善小动作。 小动作这个情况，许多人一紧张或尴尬时就会出现，比如摸鼻子、撩头发、扭脖子、舔嘴唇、两个手相互触碰、手掌从大腿搓到膝盖……总之人在紧张时，就容易出现各种肢体小动作。与口头禅、语气词的状况类似，这些小动作也是潜意识下做出的反应，当事人也很难觉察，录像练习的作用，就是解决这类问题。 同样随机找个主题，然后准备录制视频练习，但私下一人练习很难产生紧张、尴尬的情绪，所以在录制视频时，你还需要通过“想象”来辅助。比如，你目前录制一个自我介绍的视频，但在自己做自我介绍的时候，脑海里面去想一些紧张的场景： 目前在考试你正打算作弊，目前你站在几百人的大会台上发言…… 或者想象一些尴尬的场景也行，例如： 在人来人往的广场上跳舞，在许多人吃饭的食堂里大声唱歌…… 上面列出的一些场景是不是想象着就紧张？听起来就很尴尬？你在录像练习时，需要的就是这种情绪来辅助，只有当你处于这种情绪之下，才能把潜意识中的那些小动作“唤醒”，这种情况下录制的视频，才真正能反映出你不好的习惯。 录制好之后，当自己去看视频的时候，同样会感觉很尴尬，此时要抱着“鸡蛋里面挑骨头”的心态去找问题，将发现的不足记录下来，然后加以改善，最后就能控制好自己在紧张&#x2F;尴尬情绪下的表现。 对镜练习、录音练习、录像练习，针对于求职前的自我练习就讲到这里啦，我并不确定有多少人会去落实这些，或许没人去这么做，又或很多人跟着方法做，这我都无从得知。但我真心希望大家可以去尝试练练，虽然听起来这么做会有点尴尬，但当你真正尝试后，真正改善掉自身不足时，你得到的将是一个全新的自己，这些练习带来的好处不仅仅是满足面试，更能让你在以后的日子中长久受益。 二、面试时如何介绍项目？技术人的社招面试而言，更多会围绕着项目展开话题，因此项目介绍成为了面试必然存在的环节。一场技术面试也许可能没有自我介绍，但绝不会少了项目介绍，所以除开要准备自我介绍外，准备项目介绍也必不可缺。 但有些人在介绍项目时，会遇到两个问题。 不会说：不知道如何描述自己的项目，以及自己在项目中的职责。 不会停：一旦开始介绍之后，从整体描述讲到实现细节，不知道如何收场。 这是我个人经验中，在候选人身上看到的两个问题，归根结底就是不会去形容项目，所以才会导致这些现象出现。那项目介绍又该遵循什么样的原则呢？如下： 面试官没有指定项目的情况下，优先介绍自己最熟悉、最好的项目； 以简历上写的作为基础，但千万不要介绍得和简历写的一模一样； 以讲故事的方式去形容自己的项目，才能更加吸引面试官的注意力； 针对项目中的技术亮点和个人职责，多运用STAR法则去进行阐述。 上述四点是项目介绍时要遵守的原则，其中第一点很容易理解就不多说了。第二点则是许多人常犯的错误，简历上怎么写的就怎么介绍，但请大家一定要杜绝这种情况出现，毕竟面试官让你说，主要是想听点不一样的，而并不是让你把简历上的内容重复一遍。 前面提到的四点原则中，第一、二点比较容易理解，但第三、四点如何运用起来呢？待会儿会用社区买菜来举例说明，但在此之前，会先讲一下项目介绍的通用模板，然后基于给出的示例来讲述第三、四条原则。 项目介绍的模板与注意点 基本信息 + 项目背景 + 项目描述 + 技术架构 + 个人职责 + 技术亮点 + 结束语 这个模板咋套进去呢？结合社区买菜案例，套进去给个示例： 项目背景：我最近做过的一个项目叫XX买菜，因为随着互联网时代的进步，人们购物愈发依赖于网购平台，相较于传统的门店、商场购物，网上购物更加便捷。但当我们想要在这些平台上购买日常需要的家庭食材时，如蔬菜水果、肉禽水产之类的，由于快递的周期普遍在三天左右，所以到货时基本都不怎么新鲜。为此，既要如网购般方便、又要保证新鲜程度的需求就产生了，这也是我们做这个项目的初衷。 基本信息：为了尽快将这个项目落地，当时组建了一个XX人的研发团队，从需求分析到初版上线，整个过程大致耗费了六个月。 项目描述：XX买菜是一个依托于社区的买菜平台，用户通过网上下单，平台通过线下专员配送的方式，结合本地仓库、专属配送链、社区提货点等机制，从而实现了当天买、隔日达的需求，由于是依托社区作为提货点，所以十分便于用户提货。并且结合冷链配送、社区保鲜保证了食材的新鲜度，相较于传统的线下市场、超市买菜，线上买菜更加便捷、可挑选的种类也更多，同时价格上更实惠，也能保障足够新鲜…… 结合业务需求和分布式架构思想，我们将其拆分成了XX1、XX2....等多个子系统，XX1子系统主要负责….、XX2主要负责….（简单概述） 技术架构：考虑到系统的可用性及拓展性，核心服务都采用了弹性集群部署，同时也为了保障程序性能，项目中也引入了XX、XX等中间件，而整个项目的技术架构为...... 个人职责：我在项目中主要负责....等工作（最好不要只说编码，可以拓展到推进项目、跨部门对接….）。 技术亮点：在项目的开发过程中，其实我们也遇到并解决过过很多难点问题，例如并发情况下单机锁失效问题、服务故障的无感切换、基于全局ID实现分布式链路追踪、线上突发故障的定位排查等等。 结束语：以上就是我最近一个项目的大致情况，如果您有其他想了解的，可以随时问我，我这边可以再做补充。 上述这个项目介绍的方式，首先能说明项目的基本情况，也能说明为什么要做这个项目、项目大概是干嘛的、里面用了什么技术、自己在里面做了什么事、项目中有没有遇到什么难点问题……基本也将面试官想知道的说出来了。经过大致介绍后，面试官也能根据他感兴趣的方向进行提问。 PS：这仅是一个通用的模板，如果你有更好的方式去介绍自己的项目，也不一定要套用这个模板，这里只是给出案例当作参考，如果你不会做项目介绍时，则可以套入模板提前准备。 但不管你是否要套模板，项目介绍时也要注意以下两个点。 一是控制时长。千万不要超过五分钟，太长就显得太过啰嗦，面试官听完之后抓不住你要表达的主题。 二是加结束语。我见过许多候选人都没有这个习惯，自我介绍也好，项目介绍也罢，说着说着就戛然而止了，我都不知道候选人到底是已经说完了，还是想缓口气接着说，所以加上结束语后，更便于面试官接话。 运用讲故事手法和 STAR 法则前面提到的第三点原则，是多用讲故事的手法介绍项目。相信大家在前面给出的示例中能感受出来，在示例的一开始，并未直接进行枯燥的项目介绍，而是以讲故事的形式，先讲述了项目的产生背景和平台描述，从而能让面试官更有兴趣听下去。为了能让大家产生对比感，下面也贴一个反例： 我最近做过的项目叫XXX，里面被分成了N大模块，XX1模块是用来……XX2模块是负责…… 这样去介绍项目虽然精简，但不免有种乏味感在内，缺失了一定的铺垫，很难让面试官代入进去，尤其当你介绍的时间一长，面试官甚至到后面都不会听了，而是等着你说完就开始提问……所以，讲故事的手法主要是为了引起面试官兴趣，至少别让别人听起来就感觉很枯燥。 接着聊聊起初说到的第四点，个人职责和技术亮点多运用STAR法则。通常我建议个人职责和技术亮点结合在一起去说，这样有助于消除职责介绍时的枯燥感，因为很多小伙伴在讲个人职责时，更多的停留在业务的介绍，例如： 我主要负责XXX...模块的开发，XX1模块是用来...，里面主要又N个功能，功能1...、功能2... 这样去介绍，时间一长，同样会带来很重的枯燥感，所以适当地控制业务介绍，掺入一些技术亮点的穿插效果会更佳，例如： 我主要负责XX...模块的开发，X1模块是用来...，里面包含了x1、x2...等核心功能，XX2模块...。 在我做订单模块的开发过程中，由于晚上十一点会有新的菜品库存补货，此时订单量会剧增造成系统并发过高，因而导致系统访问较为缓慢，为了解决这个问题，我用到了XXX...等技术与XXX方案，经过实测后，业务高峰期的1.5s延迟降到了140ms左右。 这样去介绍个人职责是不是比前面好多啦？既避免了过多业务介绍带来的枯燥，又为后续面试官的发问留下了话题，所以一定要多结合技术去做职责介绍，并且运用上STAR法则，因为什么出现了这个问题、怎么处理的问题、处理之后得到的成效（但只建议展开1~2个亮点细说，其他的亮点可以轻略带过，太多反而是副作用）。 OK，到这里就是如何做好项目介绍的全部内容啦，在大家准备项目介绍时，最好也是把它写出来，写出之后可以再次微整，整体描述要显得精简，同时也可以结合提到的原则稍加美化。当项目介绍调整好之后，就不用再做自我介绍时的那些练习了，但也记得在心中默念几次，加深印象之后才能表达得更为自然。 未完待续…","tags":["面经","大厂"],"categories":["秋招指南"]},{"title":"分布式系统｜理论基础","path":"/post/系统与体系结构/distributed-systems-theoretical-foundations/","content":"分布式系统概念单机就不说了，分辨一下「集群」和「分布式」的区别： 集群是相同应用的多备份部署，同一份代码，功能相同，相当于多台单机，有效负载均衡，不过耦合度太高。 分布式则是将业务拆成了多个不同的子业务，每个子业务有单独的服务部署，这些子业务构成一个完整的系统。 熟悉了分布式的概念，这里需要强调一下「分布式」和「微服务」的关系： 微服务是一种软件设计理念，它是面向服务的，将大的系统或者是服务，拆分成一组小的且相互独立的服务。这些小的服务都是都是独立运行的，并且每个小服务有自己的数据库、业务逻辑，服务之间通过网络进行通信和协作。这组小服务一起协作对外提供服务，共同完成一个系统的任务。 微服务其实是一种特定的分布式系统架构风格，分布式是一种系统架构的范畴，而微服务是分布式系统的一种具体实现方式，微服务将应用程序拆分成小的、自治的服务单元，通过网络进行通信和协作来完成系统任务。分布式有很多种实现方式，微服务并不是它唯一的实现方式。 分布式理论基础由于分布式系统中的程序是部署在多个节点上的，各个节点通过网络通信。一旦有网络通信，就会有网络的可靠性问题，延迟问题，以及各个节点的故障问题等等。可能出现有的节点能正常工作，而有的节点挂掉，导致有的请求达到正常节点就能正常处理，而打到故障节点又会失败。又或者因为网络故障，导致有的写操作在部分节点成功，而在另一些节点失败，总之可能存在种种状态不一致的情况，这些问题的存在影响着系统在高性能，高可用等方面的设计。而随着分布式的发展，人们总结出了一套分布式设计理论，这套理论对于后来分布式系统设计有着指导意义，这就是大名鼎鼎的 CAP 理论。 CAP 原理 更多：阮一峰｜CAP 定理 1. CAP 理论由来Lynch 教授提出了一个影响深远的概念，如在一个不稳定（要么消息错乱，要么消息丢失）的网络环境里（异构模型），想始终保持数据一致是不可能的，这个概念为后来 CAP 理论的发展奠定了重要基础。 在 CAP 理论出来之前，并没有一个明确的方向性的指导。所以在设计实现分布式系统时会显得很混乱。可能在分布式系统中，不同的子模块有着不同的设计标准，对同一个系统而言，这显然不是很合理 比如在一个由两个模块构成的分布式系统中，这两个模块 A 和 B 之间能够互相通信 A 模块的设计原则是：A 发送请求给其他模块，如果节点间出现了故障，会选择不断的重试，一直等到节点通信恢复。可以理解为提供高质量服务。 B 模块的设计原则是：B 发送请求给其他模块，如果节点间出现了故障，会选择直接断开，并记下当前状态，等待后续处理，可以理解为提供高可用服务。 显然，系统中如果出现了通信故障，A 往 B 发请求，会出现不断重试，而 B 往 A 发请求，则会出现直接断开的情况，整个系统会很混乱。 所以，IT界的研究者们长期以来一直在探索指导原则来指导分布式系统的设计，在 2000 年 Eric Brewer 教授在 PODC 会议上首次提出了 CAP 理论。然而，当时这一理论还没有被正式证明，所以只能称为 CAP 猜想。 这个猜想一经提出，就在业界引起了极大的关注，因为它为分布式系统设计提供了一个简单而有力的框架。到了 2002 年，Seth Gilbert 和 Nancy Lynch 通过理论证明了 CAP 猜想的正确性，从而使 CAP 理论正式确立，并成为分布式系统设计中的重要理论基础之一。 2. CAP 理论在一个分布式系统中，一致性（Consistency）、可用性（Availability）和分区容错性（Partition Tolerance）这三个目标无法同时满足，最多只能同时满足其中的两个。 2.1 数据一致性（C）「数据一致性」是指在分布式系统中的所有节点，在同一时间点上拥有相同的数据副本。比如某个节点数据有更新，那么其他的节点数据要跟着更新，要求所有的读请求都必须读到这个新数据。 写操作（增、删、改）：数据变更 读操作 当数据服务有多个节点的时候，当数据服务接收到写请求时，怎样判定数据服务上所有的节点都一起发生了变更呢？ 当然有的分布式系统由不同的策略配置，比如 MySQL 的主从集群，当配置为全同步时，即每次写数据只有当主库把数据都同步到从库后，才会返回成功，这样返回写成功后，称之为数据一致性改变。 如果不是这种配置策略，比如半同步，只有部分从库同步完了数据，也会返回成功，那么从从库读数据的话，可能就会读取不到新值，就不能称之为数据一致性改变。 假设「一主两从」的 MySQL 集群系统，在网络通信正常情况下，如果经过一次写请求后，两个从库节点都发生了数据变化。然后，读请求把这些变化后的数据都读取到了，我们就把这次数据修改称为数据发生了一致性改变。 假设系统内部发生了通信问题，主库和从库 2 之间的通信发生了故障，而主库和从库 1 之间的通信正常，那么写入操作成功之后，从库 1 可以读取到 V1 版本数据，而从库 2 无法读取到 V1 版本数据，地区到的还是旧数据。此时，系统中的节点就没有发生一致性改变。 2.2 可用性（A）「可用性」是指系统要处于 100% 的可用状态，对于每一个请求，正常节点要在合理的时间给出正确的响应，即系统能够正常提供服务。 必须在合理时间内给出响应，时间根据业务要求来定。 只要正常的节点都能做出响应（无论数据是否最新）： 如果系统内的某个节点或者是某些节点宕机了，但是其他的正常节点可以在合理的时间内做出响应。 节点正常，但是节点上的数据有问题，比如不是最新数据，如果有请求达到这个节点上了，依然不能拒绝请求，要正常返回这个旧数据。 2.3 分区容错性（P）「分区容错性」是指分布式系统能够在网络分区的情况下继续运行对外提供服务，即系统能够在节点之间进行通信的网络出现故障或延迟的情况下，保证系统的正常运行。 网络分区 网络分区只在分布式集群中，在分布式系统中，多个节点之间的网络本来是连通的，但是由于某些故障导致节点之间网络不通了，形成不同的子集，子集中节点之间网络互通，而子集与子集之间网络不通，整个网络就形成了几块区域，就是网络分区。 上图中，G1 和 G2 是两台跨区的服务器。G1 向 G2 发送一条消息，G2 可能无法收到。系统设计的时候，必须考虑到这种情况。 一般来说，分区容错无法避免，因此可以认为 CAP 的 P 总是成立。CAP 定理告诉我们，剩下的 C 和 A 无法同时做到。 3. CAP 为什么不能同时满足这个问题看似是论证一致性、可用性、分区容忍性为什么只能选择其中的两个同时满足，其实并非如此。因为在分布式系统中分区容错性（Partition-tolerance ） 是不得不选择的。假设不考虑分区容错性，那就相当于把数据只存放在一个节点上，因为数据依旧集中在一个地方，一旦这个节点出现故障，整个系统毫无疑问会随之瘫痪，这在实际的生产环境中通常是不可接受的，而且数据集中在一个地方，这本身也与分布式相矛盾。 ✅ 在分布式系统中，分区容错性（ P ）是一定要满足的，剩下的一致性（ C ）和可用性（ A ）只能满足其一。因此，分布式架构不可能选择 CA 架构，只能选择 CP 架构 或者 AP 架构。 由于存在分区容错性，所以存在 server2 写入 X&#x3D;2 失败，而 server1 写入 X&#x3D;2 成功，那么此时 client2 和 client3 就会读取到不一样的值，client2 读取到 X&#x3D;2，而 client3 读取到 X&#x3D;1，此时系统可用，但是违背了一致性，保证了 A，但是违背了 C，属于 AP 架构。 假设此时要保持 X 值的一致性，server1 和 server2 的 Write 操作必须同时成功，系统必须等待 server2 也写入成功，在失败的这段时间里，系统是不可用状态，这样的话就保证了一致性 C，但是也降低了系统的可用性，违背了 A，此时属于 CP 架构。 由此可见，在分布式系统中，无法同时满足 CAP 定律中的 “一致性”、“可用性” 和 “分区容错性” 三者。 4. CAP 如何选择任何方案选型都要根据业务场景出发，看业务场景适合哪种，就选哪种，一般而言： CP 使用场景：比较典型的 CP 系统是分布式数据库，数据的一致性是最基本的要求。在极端情况时，优先保证数据的强一致性，代价就是放弃系统的可用性。例如，类似 Redis、HBase 这种分布式存储系统，以及 ZooKeeper 这种分布式协调系统。另一个常见场景就是金融领域，为了资金安全一般需要确保强一致性。 AP 使用场景：AP 则是适应于目前大多数对于用户体验要求高的互联网应用场景，比如社交媒体，内容分发业务，像微博、Instagram。用户量大，主机众多，分布式部署，而且集群的规模越来越大，节点故障、网络故障时有发生，要保证系统的可用性，保障 AP 放弃 CP 是常见的一种做法。 5. CAP 的不足CAP 最大的不足其实也就是一致性（Consistency）、可用性（Availability）的强取舍问题。 在实际应用中，一致性和可用性并不只是简单的二选一问题，而是取决于各自的优先级。当我们强调一致性时，并不意味着系统的可用性会完全丧失。比如，在 Zookeeper 中，只有在主节点出现问题时，系统才可能会出现短暂的不可用状态，但在其他时间，系统通过各种方式来保证其可用性。同样，强调可用性时，通常也会采用技术手段来确保数据最终能够保持一致性。CAP 定理并没有详细说明这些细节。 ✅ 其实简单来说，就是在设计分布式系统时，对于一致性和可用性希望有一些折中的手段，而不是选择了其中一个特性，就要完全舍弃另一个特性。 BASE 原理正因为 CAP 理论存在一些局限性，eBay 的架构师 Dan Pritchett 基于他在大规模分布式系统中的实践经验，总结出了 BASE 理论。BASE 理论是对 CAP 理论的进一步扩展，其核心思想是，即便无法实现强一致性（Strong Consistency），应用程序也可以通过适当的方法达到最终一致性（Eventual Consistency）。 BASE 理论是一个更具工程实践意义的理论，它弥补了 CAP 理论过于抽象的问题，同时也为 AP 系统提供了整体的工程实践思想。目前 BASE 理论已经成为分布式系统中的核心理论之一。 1. 数据一致性BASE 理论对数据一致性做了一些更细致的分类，从而对 CAP 理论作了进一步的扩展。数据一致性大致可以分为以下几类： 1.1 强一致性数据更新操作完成之后，数据立即生效，后续的所有访问当中都能得到最新的结果。 1.2 弱一致性数据更新操作完成之后，不要求立即可以读到最新写入的值，能容忍在更新发生之后，部分情况下无法访问到新数据的情况。 1.3 最终一致性数据更新操作完成之后，能容忍更新后一段时间内无法访问到最新数据，不需要实时保证系统数据的强一致性，但是经过一段时间的同步之后，最终可以达到一个一致的状态。所以，最终一致性可以看作是弱一致性的一个特例。 而在 CAP 理论中的 C 指的是强一致性，所以要分析什么样的系统适合 AP，什么样的系统适合 CP，其实就是在强一致性和可用性之间做权衡，根据业务情况，看那些业务能够容忍最终一致性，而很在乎用户体验，这样的业务就适合 AP，而对于强一致性要求高的业务则适合用 CP。 2. BASE BA 基本可用（Basically Available）：系统在遇到不可预知的故障时，允许损失部分可用性，就是说即使系统不能完全正常工作，但是仍然有部分功能可用。换句话说，但至少能够提供部分服务。例如，响应时间比平时长或者某些功能暂时不可用。 响应性能变弱：比如正常情况下请求响应为 0.3s，但是出现了某个故障之后，虽然还能正常响应，但是响应时长变为了 2s 系统功能有损：比如商城双十一活动时，评论模块出现故障，但不会影响交易、商品等核心模块的流程使用 S 软状态（Soft state）：指允许系统中的数据存在中间状态，这种状态可能是不一致的，但是这种中间状态的存在不会影响系统的整体可用性，因为数据在不同节点之间的同步可能存在延迟。 E 最终一致性（Eventual Consistency）：系统不要求数据实时地达到一致性，而是允许数据在一段时间后最终达到一致状态。这意味着在经过一定的时间之后，所有副本的数据会最终到达一致的状态。 既然在分布式系统中分区容错性我们无法回避，而根据 CAP 理论，我们要么选择 AP 模型，要么选择 CP 模型。但是在很多的场景中，尤其是对可用性要求高的场景往往既需要可用性，又想保证一致性，这里就出现了矛盾。所以这里可以在选择可用性的同时，弱化强一致性，但是并不是永远放弃一致性，在分区故障恢复后，根据各自的业务特点，经过一段时间系统应该达到最终一致性。而系统中一部分不一致时，系统仍需要保持系统整体“主要可用”，也就是基本可用。其实 Base 理论可以理解为：分区容错性 + 基本可用性 + 最终一致性；其实就是对 CAP 理论的一种延伸。","tags":["分布式系统","CAP","BASE"],"categories":["系统与体系结构"]},{"title":"分布式系统｜共识算法 Paxos","path":"/post/系统与体系结构/distributed-systems-paxos.md/","content":"分布式系统 · 协调与协定（XMU Curriculum） 本章为「2024 春季课程」分布式系统的部分重要内容，仅作归纳，便于理清框架。 ✅ L6-时间同步与全局状态 时钟同步 物理时钟同步问题（机器本地时间） NTP 网络时间协议：使用中心化的全局时间同步来保证各节点的时间统一 Berkeley 算法：服务器主动定期询问每台机器的时间，服务器基于客户的回答计算出平均值，告知它们拨快或者拨慢时间 —— 主动式服务（与 Cristian 算法中的被动式时间服务器相反） Cristian 算法：一台机器设为时间服务器，其他的每台机器周期性地向时间服务器发送请求消息以获得当前标准时间 逻辑时钟（时钟的内部一致性） Lamport 算法：为了同步逻辑时钟，Lamport 定义了一个二元 关系，称作“先发生”的关系… 全局状态 全局一致性快照 Chandy-Lamport 算法：引入「分布式快照」概念 Initiating a snapshot Propagating a snapshot Terminating a snapshot ✅ L7-协调与协定 分布式互斥 Ricart-Agrawala 算法 选举算法 Bully 拜占庭与共识问题 拜占庭 共识算法 Paxos Raft ✅ L8-并发控制与分布式事务 原子事务 ACID 特性 事务实现 私有工作空间与影子更新 写前日志 分为单层事务、嵌套事务、分布式事务 并发控制：当多个事务在不同的进程（在不同的处理机上）中同时执行时，需要一些机制以保证它们互不干扰，这种机制称为并发控制算法 两阶段封锁协议（2PL）：恰好在需要或不再需要锁时去请求或释放锁；可能会死锁 乐观的并发控制：做自己想做的，有问题出现再说（避免了死锁，允许最大的并行度；有时可能会失效，这时所有的事务都必须退回重新运行一遍） 时间戳：每个文件带有对它操作的最后一个提交事务的读时间戳、写时间戳 分布式事务 CAP 理论：一致性、可用性、分区容错性 BASE 理论：基本可用、软状态、最终一致性 分布式事务解决方案 CP 方式：强一致性，弱可用 AP 方式：高可用，但弱一致 基于这两种思想，延伸出了很多分布式事务解决方案（2PC、3PC、TCC 等） 两阶段提交协议（2PC） 准备阶段 Prepare：取得一致决定 执行阶段 Commit/Rollback：执行命令（提交或废弃） 三阶段提交协议（3PC）：在协调者和参与者中都引入超时机制，并且把两阶段提交协议的第一个阶段分成了两步 CanCommit：与 2PC 的 Prepare 阶段类似 PreCommit：协调者将通知事务参与者准备提交或取消事务，写本地的 redo 和 undo 日志，但不提交 DoCommit：提交或回滚，如果无法及时收到来自协调者的信息之后，他会默认执行提交，不会一直锁定资源处于阻塞状态 TCC：解决 2PC 中的资源锁定和阻塞问题，减少资源锁定时间 Try：资源的检测和预留 Confirm：执行的业务操作提交，要求 Try 成功，Confirm 一定要成功 Cancel：预留资源释放 1. 分布式互斥1.1 集中式算法（仿照单机）选一个进程作为协调者，进程若要进入临界区，它向协调者发送请求消息，协调者负责处理 优点: 易实现、通信量少 (请求-许可-释放) 缺点: 单点故障、瓶颈、无法辨认服务器崩溃 1.2 分布式互斥算法（Ricart-Agrawala 算法）Lamport 提出了一种分布式互斥算法，Ricart 等对它作了进一步的改进。 步骤 1：当一个进程想进入一个临界区时 ，它构造一个消息，其中包含它要进入的 &lt;临界区的名字、它的进程号、当前时间&gt;，然后它将该消息发送给所有其他的进程。 步骤 2：当一个进程接收到来自另一个进程的请求消息时，它根据自己与消息中的临界区相关的状态来决定它要采取的动作。 若接收者不在临界区也不想进入临界区，它就向发送者发送一个 ok 消息 若接收者已经在临界区中，它不进行应答，而是将该请求放入队列中 如果接收者想进入临界区但尚未进入时，它将对收到的消息的时间戳与包含在它发送给其余进程的消息中的时间戳（本身的时间戳）进行比较，时间戳最早的那个进程获胜。如果收到的消息的时间戳比较早，那么接收者向发送者发回一个 ok 消息。如 果它本身的时间戳比较早，那么接收者将收到的请求放入队列中，并且不发送任何消息 步骤 3：在发送了请求进入临界区的请求消息后，进程进行等待，直到其他所有进程都发回了允许进入消息为止，一旦请求进程得到了所有进程的允许，它就可以进入临界区了。 步骤 4：当它退出临界区时，它向其队列中的所有进程发送 ok 消息，并将它们从队列中删除。 缺点： n 点失败 n 点瓶颈 2(n-1) 个消息 改进方案： 超时重发 组通信 简单多数同意 1.3 令牌环算法进程没有固定顺序，可以用软件的方法构造出一个逻辑环，环中为每个进程都分配了一个位置（如按网络地址），不管按什么方式分配，每个进程要知道谁在它的下一个位置上。进程从它邻近的进程得到令牌后，检查自己是否要进入临界区。如果自己要进入临界区，那么它就进入临界区，做它要做的工作，然后离开临界区。在该进程退出临界区后，它沿着环继续传递令牌。 2. 选举算法许多分布式算法需要一个进程充当协调者，发起者，排序者或其他特定的角色。 2.1 欺负算法（Bully）当一个进程 P 发现协调者不再响应请求时，它发起选举。进程 P 选举过程如下 P 向所有号码比它大的进程发送选举 (Election) 消息 若无人响应，P 获胜成为协调者 若有号码比它大的进程响应，响应者接管，P 的工作完成 由于总是号码最大的进程取胜，因而将该算法命名为欺负算法 … 3. 拜占庭问题与共识算法3.1 拜占庭将军Lamport 在 1982 年发表的论文《The Byzantine Generals Problem》描述了拜占庭将军投票问题，借以映射分布式系统中计算机通信容错问题。 Wikipedia 一组拜占庭将军分别各率领一支军队共同围困一座城市。为了简化问题，将各支军队的行动策略限定为进攻或撤离两种。因为部分军队进攻部分军队撤离可能会造成灾难性后果，因此各位将军必须通过投票来达成一致策略，即所有军队一起进攻或所有军队一起撤离。因为各位将军分处城市不同方向，他们只能通过信使互相联系。在投票过程中每位将军都将自己投票给进攻还是撤退的信息通过信使分别通知其他所有将军，这样一来每位将军根据自己的投票和其他所有将军送来的信息就可以知道共同的投票结果而决定行动策略。 投票系统的问题在于，军队中可能存在叛徒和敌军的间谍，左右将军们的决定又扰乱整体军队的秩序。这时候在已知有成员可能不可靠的情况下，其他忠诚的将军如何在不受叛徒和间谍影响的情况下意见达成一致，这就是拜占庭将军问题。 拜占庭将军问题提供了对「分布式共识」问题的一种情景化描述：  拜占庭将军：即分布式系统的服务节点  忠诚的将军：即分布式系统正常的服务节点  叛变的将军：出现故障并发送误导信息的服务节点  信使被杀：通信故障导致信息丢失  信使被间谍替换：服务节点进行网络通信过程中信息被黑客攻击，通信存在劫持以及信息伪造 1998 年，Lamport 发表了名为《The Part-Time Parliament》 的论文， 这是 Paxos 算法第一次公开发发布，为网络异常情况下分布式系统如何保证数据一致性提供了一个解决思路。注意 Paxos 算法是有特定前提的，即先不考虑拜占庭将军问题（消息篡改）的情况。 《The Part-Time Parliament》中使用了大量的数学证明，考虑到大多数人理解起来比较困难，Lamport 于 2001 年发表了另一篇论文《Paxos Made Simple》，使用了逻辑推导来论述 Paxos 算法。 … 共识理论1. 什么是共识「共识」是指在分布式系统中，多个节点对某个数据值或决策达成一致意见。 用数学术语来描述一下分布式系统的共识问题：在一个包含 n 个实例的分布式系统中，集合 &#123;0,1,2,…,n−1&#125; 表示这些实例。每个实例 i 拥有一个初始值 vi。这些实例之间可以相互通信。系通过某种算法，使得即使部分实例出现故障，系统中的所有非故障实例仍能达成一致，选择出一个不可更改的最终决定值 vf。 共识算法三个性质： 终止性（Termination）：所有非故障的实例最终都会确定某一个值并终止算法执行。换句话说，算法不会无限期地执行下去，实例们都会在有限的时间内达成决议。 一致性（Consistency）：所有非故障的实例最终选择的值 vf 必须是相同的。 完整性（Integrity）：如果所有节点提议相同的值，那么该值一定会被最终选定为共识结果。 这些性质确保了在分布式系统中，即使面临部分节点故障或网络延迟等问题，系统仍然能够达成一个一致的决策，避免数据不一致的问题。 2. 一致性和共识一致性：指的是在分布式系统中，多个节点在执行一系列操作后，通过遵循某些协议，确保它们对外部呈现的数据和状态保持一致。简单来说，就是确保所有节点上的数据是完全同步的，并且在某个提案（Proposal）上达成共识。 共识：指的是多个节点在分布式系统中就某个状态或决定达成一致的过程。 ✅ 换句话说，一致性强调的是最终的状态是否一致，而共识则是实现这种一致性的手段。 3. 为什么要达成共识在分布式系统中，多个节点（如服务器、进程等）共同协作来完成任务，对外感觉就像是一个单机的服务。由于是分布式的环境，一定会存在网络问题，时钟问题，以及节点故障问题，这些问题都将导致系统出现各种各样的问题，其可靠性得不到保证。比如： 选主（Leader Election）：在需要一个主节点进行写操作的分布式数据库中，系统必须确保在所有节点之间达成共识，选出一个主节点。如果网络出现故障，可能会导致出现多个主节点的情况，这样会引发数据冲突和一致性问题。共识算法能够保证在这种情况下，系统能够选出唯一的主节点。 原子提交（Atomic Commit）：在涉及多个节点或分区的分布式事务中，所有节点必须一致地决定是提交还是回滚事务，以保证事务的原子性。如果事务在某些节点上成功，而在其他节点上失败，系统就需要使用共识机制来确保所有节点做出统一的决定，要么全部提交，要么全部回滚。 可见，共识是分布式系统正常运转的最基本保障，只有在共识的帮助下，分布式系统才能保证一致性，像单一节点一样工作，对外提供可靠的服务。 4. 共识算法「共识算法」也叫「一致性协议算法」，是用于在分布式系统中让多个独立的节点就某个决策或状态达成一致的一类算法。分布式系统中的每个节点都可能会因为网络分区、节点故障、延迟等问题，导致它们之间无法完全同步状态。因此，共识算法的目标是在这种不确定性和潜在的故障情况下，确保所有非故障节点最终能够就某个值或操作达成一致。 共识算法通常具备以下几个关键特性： 终止性（Termination）：所有非故障的实例最终都会确定某一个值并终止算法执行。换句话说，算法不会无限期地执行下去，实例们都会在有限的时间内达成决议。 一致性（Consistency）：所有非故障的实例最终选择的值 vf 必须是相同的。 完整性（Integrity）：如果所有节点提议相同的值，那么该值一定会被最终选定为共识结果。 4.1 常见的共识算法 Paxos：一种经典的共识算法，被认为是分布式一致性问题的基础解决方案 Raft：一种更易于理解和实现的共识算法，解决了 Paxos 的复杂性问题 ZAB (ZooKeeper Atomic Broadcast protocol)：ZooKeeper 使用的原子广播协议，确保分布式系统中的状态一致性 Paxos 算法 「共识算法」本质就是「一致性算法」 相关链接： The Part-Time Parliament (Paxos 算法) Paxos Made Simple (Paxos 推导) Paxos 算法 Paxos 算法原理及推导 [知乎专栏] Paxos、Raft 分布式一致性最佳实践 Paxos 算法是由 Leslie Lamport 在 1990 年代提出的一种基于消息传递共识算法。在讨论分布式算法时，Paxos 几乎是一个绕不开的话题。在过去的几十年中，它已经成为分布式共识的象征，许多流行的共识算法都是基于 Paxos 进行改进的，比如 Fast Paxos、Raft、ZAB 等协议。虽然 Paxos 算法可以认为是一些共识算法的基础，但是其本身也相对较复杂，理解起来有一定的难度。 Paxos 算法包括两个主要部分： Basic Paxos 算法：分布式系统中的多个节点如何就某个数据值达成共识 Multi-Paxos 算法：Multi-Paxos 是在 Basic Paxos 的基础上扩展而来，用于在分布式系统中就一系列的值达成共识 1. Basic Paxos在正式介绍 Basic Paxos 算法之前，首先来看一个问题。 假设有一个分布式的 key-value 存储集群，有 A，B，C 三个节点，对外提供只读服务。也就是说，key-value 键值对一旦被创建，就不能再被修改。 假设此时，有两个客户端 client1 和 client2 同时发起创建键值对的请求，且创建的键值对 key 都为”Name”，client1 试图创建 “Name：张三”，client2 试图创建“Name：李四”，在这种情况下，这个分布式集群如何达成共识，实现在 A，B，C 各个节点上，Key 为”Name”的值是一致的呢。 这里其实就需要一种共识机制，保证集群中的 A，B，C 三个节点能达成一致，每个节点写入一样的值，Paxos 算法就能保证这样一种共识。 1.1 Paxos 涉及的概念Basic Paxos 的工作机制主要分为三个角色和两个主要阶段。 1.1.1 提案（Proposal）提案指的是需要在多个节点之间达成一致的某个值或操作，提案是由提案编号（n）和提案的值（v）组成的，可以表示为 [n, v]。每个提案的提案编号是唯一的。 1.1.1.1 提案编号提案编号一般不是由 Paxos 算法生成的，而是由外部传入的。所以不同的业务场景可以按照自身业务需求，自定义提案编号的生成逻辑，只需要保证提案编号全局唯一并且单调递增即可。 比如在只有一个 Proposer 的环境中可以简单地使用自增 ID 或时间戳作为提案编号。例如，使用时间戳 1693702932000。在有两个 Proposer 的环境中，可以为不同提议者分配不同的编号序列。 例如，一个提议者使用奇数（1, 3, 5…），另一个提议者使用偶数（2, 4, 6…）。在有多个 Proposer 的环境中，可以为每个 Proposer 分配一个固定的 ServerId，并将自增序号或时间戳与 ServerId 组合，生成唯一的提案编号。例如，1.1 或者 1693702932000.1 表示 Proposer1 生成的第一个提案编号。每个 Proposer 在发起 Prepare 请求后如果没有得到超半数响应时，会更新自己的提案号，再重新发起新一轮的 Prepare 请求。 1.1.1.2 提案值在 Paxos 算法中，提案值的具体内容也是根据实际业务需求来定义的。提案值可以是数值、字符串、命令（cmd），甚至是一些操作。比如在分布式数据库的场景中，可以将数据的插入、更新、删除操作等作为提案值。这种灵活性允许 Paxos 算法适应各种不同的应用场景。 1.1.2 三个角色在 Paxos 算法中，角色分为提议者（Proposer）、接受者（Acceptor）和学习者（Learner），它们的关系如下： 提议者（Proposer）：处理客户端请求，主动发起提案（proposal）给所有的接受者（Acceptor），提议者的角色通常由集群中的某些节点担任 接受者（Acceptor）：被动接受提案，对提案进行投票，并存储已经接受的值，返回投票结果给 Proposer 以及发送通知给 Learner 学习者（Learner）：不参与提案和投票，只被动接收提案结果 一个节点，既可以是提议者，也可以是接受者！ 在实际的分布式业务场景中，一个服务器节点或进程可以同时扮演其中的一种或几种角色，而且在分布式环境中往往同时存在多个 Proposer、多个 Acceptor 和多个 Learner。 1.1.3 两个阶段1.1.3.1 准备阶段（prepare）提议者（Proposer）：生成一个唯一的提案编号 n，并向所有的接受者（Acceptor）发送一个准备请求（Prepare Request），请求内容是编号 n，注意在准备阶段请求只会包含请求编号，而不会包含提案值。 接受者（Acceptor）：在收到准备请求后，接受者（Acceptor）会做出如下承诺： 如果接受者（Acceptor）收到过比此次提案编号n更大的准备请求，将丢弃这次准备请求，不作响应 否则： 接受者（Acceptor）承诺不再通过编号小于等于 n 的提案的准备（Prepare）请求 接受者（Acceptor）承诺不再通过编号小于 n 的提案的接收（Accept）请求，也就是不再通过编号小于 n 的提案 如果接受者（Acceptor）已经通过某一提案，则承诺在准备请求的响应中返回已经通过的最大编号的提案内容，即提案值。如果没有通过任何提案，则在 prepare 请求的响应中返回空值，即尚无提案 从 prepare 流程可知：集群中的每个 Acceptor 会存储自己当前已接受（Accept）的最大提案编号和提案值。 1.1.3.2 接受阶段（accept）提议者（Proposer）：在收到大多数接受者（Acceptor）的准备响应后，提议者将正式发起一个带有提案编号 n 和提案值 v 的接受请求 [n, v] 给所有接受者。 ⚠️ 注意：这里提议者（Proposer）设置提案值 v 有一定的规则：如果在准备（prepare）请求的响应中，部分 acceptor 已经批准过的提案值，则 v 为 prepare 请求的响应中编号最大的提案值，否则可以由 proposer 任意指定。 接受者（Acceptor）：接受者（Acceptor）会根据准备阶段的响应情况作出如下承诺： 如果此时接受者没有通过编号大于 n 的准备请求，则会批准通过提案 [n, v]，并返回已通过的编号最大的提案（也就是 n） 如果此时接受者已经通过了编号大于 n 的准备请求，则会拒绝提案 [n, v]，并返回已通过的编号最大的提案（大于 n 的编号，比如 m） 提议者（Proposer）会统计收到的 accept 请求的响应，如果响应中的编号等于自己发出的编号，则认为该 acceptor 批准通过了该提案。如果存在大多数 acceptor 批准了该提案，则认为该提案已达成共识，即该提案被通过。如果没有大多数 acceptor 批准该提案，则重新回到 prepare 阶段进行协商。 需要注意的是：在准备请求中，proposer 只会发提案编号 n。而 accept 请求，proposer 会发送提案编号和提案值，也就是 [n, v]。 1.1.4 算法流程 先明确几个变量的意思： minProposal：当前 acceptor 在 prepare 请求中通过的最大提案编号 acceptedProposal：当前 acceptor 在 accept 请求中通过的最大提案编号 acceptedValue：当前 acceptor 在 accept 请求中通过的最大提案编号的提案值 Acceptor 需要持久化存储 minProposal、acceptedProposal、acceptedValue 这 3 个值 算法流程如下： 第一阶段：Prepare 阶段 为提案生成一个全局唯一且递增的提案编号 n Proposer 会向所有 Acceptor 节点发送一个包含提案编号 n 的 准备请求（Prepare(n)） 当 Acceptor 接收到准备请求（Prepare(n)）时，会将 n 与其已知的最小提案编号 minProposal 进行比较，如果 n &gt; minProposal，则更新 minProposal 为 n，并返回其当前已经接受的提案编号 acceptedProposal 和对应的值 acceptedValue 给 Proposer，如果 n 小于或等于 minProposal，则该请求将被拒绝，不作处理 Proposer 接收到大多数 （过半）Acceptor 的响应后，如果发现有 Acceptor 返回了 acceptedValue，那么 Proposer 将选择所有响应中编号最大的 acceptedProposal 对应的 acceptedValue 作为本次提案的值。 如果所有 Acceptor 都没有返回 acceptedValue，Proposer 可以自由设置本次提案的值 第二阶段：accept 阶段 在确定提案的值后，Proposer 将向所有 Acceptor 节点广播接收请求（Accept(n, value)） Acceptor 接收到 Accept(n, value) 请求后，再次比较 n 与其当前的 minProposal，如果 n &gt;&#x3D; minProposal，则 Acceptor 更新 minProposal 和 acceptedProposal 为 n，并将 value 设置为 acceptedValue，然后持久化该提案并返回确认。如果 n &lt; minProposal，则该请求将被拒绝，并返回当前的 minProposal Proposer 接收到大多数 Acceptor 的确认后，若发现有返回值 result（minProposal） &gt; n，表示有更新的提议，跳转到步骤 1，否则认为当前提案已经达成一致 1.1.5 最终值选定Acceptor 在每次同意新的提案值后，会将结果同步给 Learner。Learner 通过汇总各个 Acceptor 的反馈，判断是否已获得多数同意（超过半数）。如果达成共识，即获得了多数同意，Learner 会向所有 Acceptor 和 Proposer 发送广播消息，并结束提案。在实际应用中，Learner 通常由多个节点组成，每个 Learner 都需要接收到最新的投票结果。对于 Learner 的实现，Lamport 在其论文中提供了两种方案： 主从 Learner 架构：选定一个 Learner 作为主节点，专门接收投票结果（Accepted 消息），其他 Learner 节点作为备份节点。主节点接收数据后再将其同步到其他 Learner 节点。这种方案的缺点在于可能产生单点故障问题，如果主节点宕机，将无法获取投票结果。 分布式 Learner 同步：Acceptor 同意提案后，将结果同步到所有 Learner 节点，然后每个 Learner 节点再将结果广播给其他 Learner 节点。尽管这种方式避免了单点故障，但由于涉及多次消息传递，效率相对较低。 1.1.6 算法模拟还是以开篇的例子来进行分析，在实际应用中，通常提议者（Proposer）是集群中的某些节点，接收客户端请求，将其封装成提案（proposal）。这里为了方便演示，将 Client1 和 Client2 看作提议者，并不会影响 Paxos 算法的本质。 准备阶段（prepare）： 假设 Client1 的提案编号是 1，Client2 的提案编号是 6，Client1 和 Client2 分别向所有的接受者发送准备请求 紧接着，节点 A 和节点 B 收先到提案者 Client1 的准备请求，编号为 1，节点 C 先收到提案者 Client2 的准备请求，提案编号为 6 分析各个节点在接收到第一个准备请求的处理过程 节点A、B：由于之前没有通过任何提案，所以节点 A 和节点 B 都将返回“尚无提案”的准备提案请求响应，并承诺，后续不再响应编号小于 1 的准备请求，也不会通过编号小于 1 的提案 节点 C：由于之前没有通过任何提案，所以节点 A 和节点 B 都将返回“尚无提案”的准备提案请求响应，并承诺，后续不再响应编号小于 6 的准备请求，也不会通过编号小于 6 的提案 接下来，节点 A 和节 B 收到提议者 Client2 发出的编号为 6 的提案，而节点 C 会收到提议者 Client1 发出的编号为 1 的提案 节点 A、B：此时收到的准备请求提案编号为 6，大于之前响应的准备请求的提案编号 1，并且节点 A 和节点 B 都还未通过（accept）任何提案，所以均返回“尚无提案”的准备提案请求响应，并承诺，后续不再响应编号小于 6 的准备请求，也不会通过编号小于 6 的提案 节点 C：由于节点 C 此时接收到的提案编号 1 小于之前响应的准备请求的提案编号 6，所以丢弃该准备请求，不作响应 接收阶段（accept）： Client1 和 Client2 收到大多数节点的准备响应之后，开始发送接收请求（accept） Client1：Client1 在接收到大多数的接受者（节点 A，B）的准备响应之后，会根据响应中的提案编号最大的提案值来设置接受请求的值。由于节点 A, B 均返回“尚无提案”，即提案值为空，所以 Client1 会自己设置一个提案值“张三”，把自己的提议值 “张三”作为该提案的值，发送接受请求 [1, “张三”] 给 A, B, C 三个 acceptor Client2：同理 Client2 在接收到大多数接受者的准备响应后，也会根据响应中的提案编号最大的提案的来设置接受请求的值。由于节点 A, B, C 均返回“尚无提案”，即提案值为空，所以 Client2 会自己设置一个提案值 “李四”，把自己的提议值 “李四” 作为该提案的值，发送接受请求 [6, “李四”] 节点 A，B，C 收到 Client1 和 Client2 的接受请求之后 由前面的准备阶段响应可知，节点 A，B，C 承诺可以通过的最小提案编号为 6，而此时节点 A，B，C 接收到的 Client1 发出的接受请求为 [1, “张三”]，提案编号 1 小于承诺的提案编号 6，所以 [1, “张三”] 被拒绝，并向 Client1 返回当前 accepter 在准备请求中通过的最大提案编号 6 节点 A，B，C 收到 Client2 发出的接受请求为 [6, “李四”]，提案编号 6 不小于承诺的提案编号 6，所以提案 [6, “李四”] 被通过，节点 A，B，C 达成了共识，接收 Name 的值为 “李四” 假设集群中还有学习者，在接受者通过了某个提案后，会通知所有学习者。一旦学习者确认多数接受者都同意了这个提案，它们也会同意并采纳提案的值。 1.1.6.1 接受者存在已通过提案的情况在上述例子中，在准备阶段和接受阶段均不存在已通过提案的情况，准备阶段接受者的请求响应都是“尚无提案”，假设有节点已经通过了提案点又是什么场景呢？想象出这样一个场景： 假设节点 A，B 已经通过了 [6, “李四”] 提案，而节点 C 尚未通过任何提案，此时，新增一个提议者 Client3，Client3 的提案为 [8，“王五”] Client3 向节点 A，B，C 发送提案编号为 8 的准备请求。 节点 A 和 B 将接收 Client3 的准备请求，由于节点 A 和 B 已经通过了编号为 [6, “李四”] 的提案，所以它们在准备响应中会包含这个提案的详细信息。而节点 C 因为之前没有通过任何提案，因此它返回的是‘尚无提案’的准备响应。 在接收到来自节点 A、B、C 的准备响应后，Client3 随即向这些节点发送接受请求。特别要注意的是，Client3 会根据响应中提案编号最大的提案值来确定接受请求的值（1.1.3.2 小节的注意事项）。由于准备响应中包含了提案 [6, “李四”]，因此 Client3 将接受请求的提案编号设为 8，提案值设置为“李四”，即客户端 3 发送的接受请求为 [8, “李四”]。 节点 A, B, C 接收到提议者 Client3 的接受请求，由于提案编号 8 不小于三个节点承诺可以通过的最小提案编号 6，因此均通过提案 [8, “李四”]。 1.1.7 活锁问题先看一个例子，这里 Server1 和 Server4 既作为 Proposer，又作为 Acceptor，Server1 即 Proposer1，Server4 即 Proposer4。所有的 server 都是 acceptor。P1.1 表示 Proposer1 发起的编号为 1 的 prepare 请求，P2.4 表示 Proposer4 发起的编号为 2 的 prepare 请求，以此类推。A1.1 X 表示 Proposer1 发起的 accept 请求，提案编号为 1，提案值为 X，A2.4 Y 表示 processe4 发起的 accept 请求，提案编号为 2，提案值为 Y，以此类推。 client1 向 server1 即 Proposer1 发起写入 X 的请求，client2 向 server4 即 Proposer4 发起写入 Y 的请求。 随着时间线从左往右看，server3 即 acceptor3 先收到 proposer1 发起的 prepare 请求 P1.1，由于没有通过任何提案，所以尚无提案，承诺不通过提案编号小于 1 的提案，随后 acceptor3 收到了 proposer4 发起的 prepare 请求 P2.4，由于此次天的编号 2 大于之前承诺的提案编号 1，所以向 proposer4 返回，承诺不再通过提案编号小于 2 的提案。 紧接着 acceptor3 收到 proposer1 发起的 accept 请求 A1.1 X，由于之前承诺了不再通过提案编号小于 2 的提案，而此次收到的 accept 提案编号为 1，所以拒绝。proposer1 发起的 accept 提案被拒绝了，所以它加大编号，又发起了 P3.1 的 prepare 请求，此次提案编号为 3，大于 acceptor3 承诺的最大提案编号 2，所以做出响应，回应承诺不再通过提案编号小于 3 的提案，随后 proposer4 发来 accept 请求 A2.4 Y，此时由于提案编号为 2，小于 acceptor3 刚刚承诺的最大提案编号 3，所以这个 accept 请求也会被决绝。proposer4 又加大 prepare 的提案编号，如此循环往复….. 一直通过多个 Proposer 的 prepare 请求，但是不能通过 accept 请求，导致一直没有提案通过，这样就形成了活锁。 1.1.7.1 活锁的定义在多个提议者同时提出提案时，由于出现竞争，这几个提议者不断的更新提案编号，发起新的提案，导致一直没有 accept 请求被通过，导致提案一直不能通过，而陷入这样的死循环，就是活锁问题。 1.1.7.2 活锁的解决方案 随机延迟重试：当一个 Proposer（提议者）发现支持它的 Acceptor（接受者）数量小于半数时，Proposer 并不会立即更新编号并再次发起提案，而是会随机延迟一小段时间。这样做的目的是为了错开多个 Proposer 之间的冲突。 设置 Proposer 的 Leader：可以在系统中选举一个 Proposer 作为 Leader，让这个 Leader 负责发起所有的提案。其他 Proposer 不再主动提案，只在需要时响应 Leader 的请求。 2. Multi-PaxosBasic Paxos 算法虽然能一定程度解决分布式系统的共识问题，但是存在很多的局限性： 它只能对一个值形成决议 提案的最终确定至少需要两次网络来回，在高并发情况下可能需要更多的网络来回，因此性能低下 当存在多个 Proposer 的时候，极端情况下甚至会形成活锁 因此 Basic Paxos 算法几乎只是用来做理论研究，并不直接应用在工程实践中。 有没有更好的算法策略能够有效解决 Basic Paxos 算法带来的这些问题呢？基于这种目的随即出现了 Multi-Paxos 算法 2.1 Multi-Paxos 算法概念Multi-Paxos 算法其实是 Lamport 提出的一种思想，而并非具体的算法。可以认为，Multi-Paxos 算法是一类算法的总称，这类算法都基于 Multi-Paxos 思想，实现了一系列值共识。 2.2 Multi-Paxos 思想总的来说，multi-paxos 思想基于 basic-paxos 算法做了两点改进： 2.2.1 领导者选举在所有 Proposers 中选举出一个 Leader，让这个 Leader 唯一地提交提案（Proposal）给 Acceptors 进行表决。这样一来，就没有多个 Proposer 之间的竞争，从而解决了活锁问题。在只有一个 Leader 提交提案的情况下，Prepare 阶段可以被跳过，从而将原本的两阶段过程简化为一阶段，从而显著提高了系统的效率。 2.2.2 优化 Basic Paxos 执行过程准备阶段的意义在于让 Proposer 通过发送 Prepare 请求来了解各个 Acceptor 节点上已通过的提案，但有了领导者（Leader）后，只有领导者才可发送提议，领导者独自负责提出提案，所以领导者能够保证提案的最新性和唯一性。因此，领导者的提案就已经是最新的了。所以不再需要通过准备阶段来发现之前被大多数节点通过的提案。领导者可以直接跳过准备阶段，进入接受阶段（Accept Phase），从而减少不必要的通信开销和 RPC 调用次数。 3. Paxos 面试题3.1 Prepare 与 Accept 阶段工作过程差不多，为什么需要 Prepare 过程呢，Paxos 算法在设计之初为什么不直接进行 Accept 阶段呢因为在 basic proxos 算法中，有多个 proposer 可以发起提案，一个 acceptor 可能通过不同的 proposer 发起的提案，prepare 请求的主要作用就是获取各个 acceptor 节点上已通过的最新提案，保证最新性和唯一性。 3.2 提案编号可以怎么生成在只有一个 Processer 的环境中可以简单地使用自增 ID 或时间戳作为提案编号。例如，使用时间戳 1693702932000。在有两个 Processer 的环境中，可以为不同提议者分配不同的编号序列。例如，一个提议者使用奇数（1, 3, 5…），另一个提议者使用偶数（2, 4, 6…）。在有多个 Processer 的环境中，可以为每个 Processer 分配一个固定的 ServerId，并将自增序号或时间戳与 ServerId 组合，生成唯一的提案编号。例如，1.1 或者 1693702932000.1 表示 Processer1 生成的第一个提案编号 3.3 Paxos 协议的活锁问题怎么解决 随机延迟重试：当 Proposer 接收到响应，发现支持它的 Acceptor 小于半数时，不立即更新编号发起重试，而是随机延迟一小段时间，来错开彼此的冲突 设置 Proposer 的 Leader：可以在系统中选举一个 Proposer 作为 Leader，让这个 Leader 负责发起所有的提案，其他 Proposer 不再主动提案，只在需要时响应 Leader 的请求，等同于 Multi-Paxos 算法","tags":["分布式系统","Paxos","拜占庭"],"categories":["系统与体系结构"]},{"title":"暑期实习面经","path":"/post/秋招指南/intern-interview/","content":"腾讯 CDG 金融科技｜后台开发一面算法题2. 两数相加（从头开始加）｜ACM 模式给你两个 非空 的链表，表示两个非负的整数。它们每位数字都是按照 逆序 的方式存储的，并且每个节点只能存储 一位 数字。 请你将两个数相加，并以相同形式返回一个表示和的链表。 你可以假设除了数字 0 之外，这两个数都不会以 0 开头。 示例 1： 123输入：l1 = [2,4,3], l2 = [5,6,4]输出：[7,0,8]解释：342 + 465 = 807. 1️⃣ 迭代：先按照链表访问顺序逐个累加（类似大数之和），有进位就加到下一个节点。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */#include &lt;iostream&gt;using namespace std;struct ListNode &#123; int val; ListNode* next; ListNode(int x) : val(x), next(nullptr) &#123;&#125;&#125;;ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; ListNode dummy; ListNode* cur = &amp;dummy; int carry = 0; while (l1 || l2 || carry) &#123; int res = 0; if (l1) &#123; res += l1-&gt;val; l1 = l1-&gt;next; &#125; if (l2) &#123; res += l2-&gt;val; l2 = l2-&gt;next; &#125; res += carry; carry = res / 10; cur = cur-&gt;next = new ListNode(res % 10); &#125; return dummy.next;&#125;// 辅助函数：创建链表（支持逐个输入）ListNode* createList() &#123; int val; ListNode dummy(0), *tail = &amp;dummy; // cin.peek(): 检测换行，确保能正确读取链表数据 while (cin.peek() != &#x27; &#x27; &amp;&amp; cin &gt;&gt; val) &#123; tail = tail-&gt;next = new ListNode(val); &#125; cin.ignore(); // 忽略换行符 return dummy.next;&#125;// 辅助函数：打印链表void printList(ListNode* head) &#123; while (head) &#123; cout &lt;&lt; head-&gt;val &lt;&lt; &quot; &quot;; head = head-&gt;next; &#125; cout &lt;&lt; &quot; &quot;;&#125;int main() &#123; ios::sync_with_stdio(false); cin.tie(0); // cin.eof() 是 (cin) 的一个方法，用于检查 输入流是否到达文件结束（EOF, End Of File）。 // cin.eof() 只有在尝试读取失败后才会变 true, 所以最好改为 while(cin) // while (!cin.eof()) &#123; // ListNode* l1 = createList(); // ListNode* l2 = createList(); // ListNode* result = addTwoNumbers(l1, l2); // printList(result); // &#125; while (cin) &#123; // 这样可以避免额外的空行 ListNode* l1 = createList(); ListNode* l2 = createList(); ListNode* result = addTwoNumbers(l1, l2); printList(result); &#125; return 0;&#125; 另一种调用输入输出方式： 1234567891011121314151617181920212223242526272829303132333435363738// 输入:// 243// 564// 输出:// 708// 辅助函数：创建链表（支持整数输入）ListNode* createList(const string&amp; num) &#123; ListNode dummy(0), *tail = &amp;dummy; for (char c : num) &#123; tail-&gt;next = new ListNode(c - &#x27;0&#x27;); tail = tail-&gt;next; &#125; return dummy.next;&#125;// 辅助函数：打印链表void printList(ListNode* head) &#123; while (head) &#123; cout &lt;&lt; head-&gt;val; head = head-&gt;next; &#125; cout &lt;&lt; &quot; &quot;;&#125;int main() &#123; ios::sync_with_stdio(false); cin.tie(0); string num1, num2; while (cin &gt;&gt; num1 &gt;&gt; num2) &#123; ListNode* l1 = createList(num1); ListNode* l2 = createList(num2); ListNode* result = addTwoNumbers(l1, l2); printList(result); &#125; return 0;&#125; 如果输入末尾有空格： 123␣ 表示空格1 2 3␣1 2 3␣ 12345678910111213141516171819202122232425262728293031// 方法一ListNode* createList() &#123; int val; ListNode dummy(0), *tail = &amp;dummy; // cin &gt;&gt; 会自动跳过所有空格 while (cin &gt;&gt; val) &#123; // 读取整数 tail-&gt;next = new ListNode(val); tail = tail-&gt;next; if (cin.peek() == &#x27; &#x27;) break; // 如果下一个字符是换行符，就停止 &#125; cin.ignore(); // 忽略换行符 return dummy.next;&#125;// 方法二#include &lt;sstream&gt;ListNode* createList() &#123; string line; if (!getline(cin, line) || line.empty()) return nullptr; // 读取一整行，如果为空则返回 stringstream ss(line); int val; ListNode dummy(0), *tail = &amp;dummy; // getline() 读取整行，stringstream 解析数字，自动跳过多余空格！ while (ss &gt;&gt; val) &#123; // 解析一行中的所有整数 tail-&gt;next = new ListNode(val); tail = tail-&gt;next; &#125; return dummy.next;&#125; 2️⃣ 递归：直接在 L1 链表上改（L2 比 L1 长则交换 swap 节点），看似递归，实则迭代，本质递归的只有头节点。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;iostream&gt;using namespace std;struct ListNode &#123; int val; ListNode* next; ListNode(int x) : val(x), next(nullptr) &#123;&#125;&#125;;ListNode* addTwoNumbers(ListNode* l1, ListNode* l2, int carry = 0) &#123; if (!l1 &amp;&amp; !l2) &#123; return carry ? new ListNode(carry) : nullptr; &#125; if (!l1) &#123; swap(l1, l2); &#125; int sum = carry + l1-&gt;val + (l2 ? l2-&gt;val : 0); l1-&gt;val = sum % 10; l1-&gt;next = addTwoNumbers(l1-&gt;next, (l2 ? l2-&gt;next : nullptr), sum / 10); return l1;&#125;void createList() &#123; int val; ListNode dummy(0), *tail = &amp;dummy; while(cin.peek() != &#x27; &#x27; &amp;&amp; cin &gt;&gt; val) &#123; tail-&gt;next = new ListNode(val); tail = tail-&gt;next; &#125; cin.ignore(); return dummy.next;&#125;void printList(ListNode* head) &#123; while(head) &#123; cout &lt;&lt; head-&gt;val &lt;&lt; &quot; &quot;; head = head-&gt;next; &#125; cout &lt;&lt; &quot; &quot;;&#125;int main() &#123; ios::sync_with_stdio(false); cin::tie(0); while(cin) &#123; ListNode* l1 = createList(); ListNode* l2 = createList(); ListNode* head = addTwoNumbers(l1, l2); printList(head); &#125;&#125; 思考：本题的链表是从数字的最低位开始的，如果改成从最高位开始，要怎么做呢？ 206. 反转链表 445. 两数相加 II 445. 两数相加 II（从尾开始加）给你两个 非空 链表来代表两个非负整数。数字最高位位于链表开始位置。它们的每个节点只存储一位数字。将这两数相加会返回一个新的链表。 你可以假设除了数字 0 之外，这两个数字都不会以零开头。 示例1： 12输入：l1 = [7,2,4,3], l2 = [5,6,4]输出：[7,8,0,7] 1️⃣ 迭代：本题等价于「206. 反转链表（迭代写法）」+「2. 两数相加（迭代写法）」 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; ListNode* pre = nullptr; ListNode* cur = head; while (cur) &#123; ListNode* nxt = cur-&gt;next; cur-&gt;next = pre; pre = cur; cur = nxt; &#125; return pre; &#125; ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; l1 = reverseList(l1); l2 = reverseList(l2); ListNode dummy; ListNode* cur = &amp;dummy; int carry = 0; while (l1 || l2 || carry) &#123; int res = carry; if (l1) &#123; res += l1-&gt;val; l1 = l1-&gt;next; &#125; if (l2) &#123; res += l2-&gt;val; l2 = l2-&gt;next; &#125; carry = res / 10; cur = cur-&gt;next = new ListNode(res % 10); &#125; return reverseList(dummy.next); &#125;&#125;; 2️⃣ 递归：本题等价于「206. 反转链表（递归写法）」+「2. 两数相加（递归写法）」 123456789101112131415161718192021222324252627282930313233343536373839404142/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; if (!head || !head-&gt;next) &#123; return head; &#125; ListNode* new_head = reverseList(head-&gt;next); head-&gt;next-&gt;next = head; head-&gt;next = nullptr; return new_head; &#125; ListNode* addTwo(ListNode* l1, ListNode* l2, int carry = 0) &#123; if (!l1 &amp;&amp; !l2) &#123; return carry ? new ListNode(carry) : nullptr; &#125; if (!l1) &#123; swap(l1, l2); &#125; int sum = carry + l1-&gt;val + (l2 ? l2-&gt;val : 0); l1-&gt;val = sum % 10; l1-&gt;next = addTwo(l1-&gt;next, (l2 ? l2-&gt;next : nullptr), sum / 10); return l1; &#125; ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; l1 = reverseList(l1); l2 = reverseList(l2); ListNode* head = addTwo(l1, l2, 0); return reverseList(head); &#125;&#125;; 3️⃣ 栈：对两个链表分别入栈 s1 和 s2 1234567891011121314151617181920212223242526272829303132333435363738394041/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; stack&lt;int&gt; s1, s2; while (l1) &#123; s1.push(l1-&gt;val); l1 = l1-&gt;next; &#125; while (l2) &#123; s2.push(l2-&gt;val); l2 = l2-&gt;next; &#125; int carry = 0; ListNode* nxt = nullptr; while (!s1.empty() || !s2.empty() || carry) &#123; int sum = carry; if (!s1.empty()) &#123; sum += s1.top(); s1.pop(); &#125; if (!s2.empty()) &#123; sum += s2.top(); s2.pop(); &#125; carry = sum / 10; ListNode* node = new ListNode(sum % 10, nxt); nxt = node; &#125; return nxt; &#125;&#125;; 72. 编辑距离｜ACM 模式给你两个单词 word1 和 word2， 请返回将 word1 转换成 word2 所使用的最少操作数 。 你可以对一个单词进行如下三种操作： 插入一个字符 删除一个字符 替换一个字符 示例 1： 123456输入：word1 = &quot;horse&quot;, word2 = &quot;ros&quot;输出：3解释：horse -&gt; rorse (将 &#x27;h&#x27; 替换为 &#x27;r&#x27;)rorse -&gt; rose (删除 &#x27;r&#x27;)rose -&gt; ros (删除 &#x27;e&#x27;) 1️⃣ 递推 · 动态规划｜ACM 模式代码：我初始化的时候只初始化 dp[0][0] = 0 😭 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;string&gt;using namespace std;int editDistance(const string &amp;s1, const string &amp;s2) &#123; int m = s1.size(), n = s2.size(); vector&lt;vector&lt;int&gt;&gt; dp(m + 1, vector&lt;int&gt;(n + 1, 0)); // 初始化值需要注意 for (int i = 0; i &lt;= m; ++i) dp[i][0] = i; for (int j = 0; j &lt;= n; ++j) dp[0][j] = j; for (int i = 1; i &lt;= m; ++i) &#123; for (int j = 1; j &lt;= n; ++j) &#123; if (s1[i - 1] == s2[j - 1]) &#123; dp[i][j] = dp[i - 1][j - 1]; &#125; else &#123; dp[i][j] = min(&#123;dp[i - 1][j] + 1, dp[i][j - 1] + 1, dp[i - 1][j - 1] + 1&#125;); &#125; &#125; &#125; return dp[m][n];&#125;int main() &#123; ios::sync_with_stdio(false); cin.tie(0); string s1, s2; while (cin &gt;&gt; s1 &gt;&gt; s2) &#123; cout &lt;&lt; editDistance(s1, s2) &lt;&lt; &quot; &quot;; &#125; return 0;&#125; 自我介绍｜面试官我们这边主要做信用卡分期和信用卡还款这一块的业务（微信信用卡还款、分期之类的业务），聚焦金融，所以对事务性开发比较重视。 介绍面试流程： 让你做自我介绍，然后简单聊一聊 两题笔试题 40 分钟，做完针对笔试聊一聊 针对简历内容和基础知识面谈 笔试题445. 两数相加 II 72. 编辑距离 八股文 如何高效地将字符串&#x2F;char[]进行追加，假设 char[] 开辟了很大的空间：memcpy 处理底层会比较快 1. C++ 虚函数实现机制C++ 虚函数用于实现多态，它的核心机制依赖于虚函数表 vtable 和虚指针 vptr，当一个类中包含虚函数时： 编译器会为该类生成一个虚函数表，其中存储了该类所有虚函数的指针 每个对象都会包含一个虚指针，它指向该类的虚函数表 通过虚指针 + 虚函数表，可以在运行时调用正确的函数，实现动态绑定 没有虚函数的普通继承｜静态绑定，编译时绑定 由于 show() 不是虚函数，调用 obj-&gt;show() 在编译时已决定 调用 Base::show()，不会检查 Derived 是否有 show()。 123456789101112131415161718#include &lt;iostream&gt;class Base &#123;public: void show() &#123; std::cout &lt;&lt; &quot;Base::show()&quot; &lt;&lt; std::endl; &#125;&#125;;class Derived : public Base &#123;public: void show() &#123; std::cout &lt;&lt; &quot;Derived::show()&quot; &lt;&lt; std::endl; &#125;&#125;;int main() &#123; Base* obj = new Derived(); obj-&gt;show(); // ❌ 调用 Base::show()（静态绑定） delete obj; return 0;&#125; 使用虚函数｜动态绑定，运行时绑定 show() 是 虚函数（virtual），因此 Base* obj 在运行时会调用 Derived::show()。 这个过程是 通过虚指针（vptr） 和 虚函数表（vtable）实现的。 123456789101112131415161718#include &lt;iostream&gt;class Base &#123;public: virtual void show() &#123; std::cout &lt;&lt; &quot;Base::show()&quot; &lt;&lt; std::endl; &#125;&#125;;class Derived : public Base &#123;public: void show() override &#123; std::cout &lt;&lt; &quot;Derived::show()&quot; &lt;&lt; std::endl; &#125;&#125;;int main() &#123; Base* obj = new Derived(); obj-&gt;show(); // ✅ 调用 Derived::show()（动态绑定） delete obj; return 0;&#125; 举个例子：代码结构如下 1234567891011class Base &#123;public: virtual void show(); int data;&#125;;class Derived : public Base &#123;public: void show() override; int moreData;&#125;; 虚函数表的内存分布： 123456789101112131415Base 对象：┌────────────┐│ vptr 指针 │ ---&gt; 指向 Base 的 vtable├────────────┤│ data │└────────────┘Derived 对象：┌────────────┐│ vptr 指针 │ ---&gt; 指向 Derived 的 vtable├────────────┤│ data │├────────────┤│ moreData │└────────────┘ 虚函数表 vtable： 123456789Base vtable:┌────────────────────┐│ &amp;Base::show() │└────────────────────┘Derived vtable:┌────────────────────┐│ &amp;Derived::show() │ （覆盖 Base::show()）└────────────────────┘ 如果是多继承下的虚函数，当一个类继承多个基类时，每个基类都有自己的 vptr 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;class A &#123;public: virtual void showA() &#123; std::cout &lt;&lt; &quot;A::showA()&quot; &lt;&lt; std::endl; &#125;&#125;;class B &#123;public: virtual void showB() &#123; std::cout &lt;&lt; &quot;B::showB()&quot; &lt;&lt; std::endl; &#125;&#125;;class Derived : public A, public B &#123;public: void showA() override &#123; std::cout &lt;&lt; &quot;Derived::showA()&quot; &lt;&lt; std::endl; &#125; void showB() override &#123; std::cout &lt;&lt; &quot;Derived::showB()&quot; &lt;&lt; std::endl; &#125;&#125;;int main() &#123; Derived d; A* pa = &amp;d; B* pb = &amp;d; pa-&gt;showA(); // ✅ 调用 Derived::showA() pb-&gt;showB(); // ✅ 调用 Derived::showB() return 0;&#125; 由于 Derived 继承了 A 和 B，其内存布局如下： 123456789101112Derived 对象：┌────────────┐│ vptr_A 指针 │ ---&gt; 指向 Derived 继承 A 的 vtable├────────────┤│ A 的成员变量 │├────────────┤│ vptr_B 指针 │ ---&gt; 指向 Derived 继承 B 的 vtable├────────────┤│ B 的成员变量 │├────────────┤│ Derived 的成员变量 │└────────────┘ 2. 虚函数外的成员函数会放在虚函数表中吗？还是其他什么地方？在 C++ 中，虚函数以外的普通成员函数 并不存储在对象的内存中，而是存储在代码段（text segment）。这是因为： 成员函数是代码，而不是数据，成员变量（数据成员）存储在对象本身的内存中，而成员函数属于程序代码，并不会在每个对象中占据额外空间。 所有对象共享同一份成员函数：由于非虚函数的调用是静态绑定的（编译时确定），同一类的所有对象都共用相同的成员函数。 函数地址不会存储在对象中：调用普通成员函数时，编译器直接用 函数地址 进行调用，不需要在对象中存储额外的信息。 普通成员函数和静态成员函数都是存储在「代码区」，虚函数本身存储在「代码区」，但如果有虚函数，每个对象会包含一个虚表指针 vptr 用于指向虚函数表 vtable，而虚函数表通常存储在「静态存储区」。 3. 一个派生类继承两个父类，这两个父类同时有一个共同基类，如果你去调用两个父类的基类对象函数，会有问题吗？ 注：在 Java 中，由于 Java 不支持多重继承，所以菱形继承问题也不存在。 Java 使用接口来替代多重继承，接口只定义了一些抽象的方法，而没有具体的实现。 这是 C++ 多重继承造成的菱形继承问题，如果一个派生类继承了两个拥有相同基类的父类，那么基类的成员会被继承两次，这会导致 “二义性问题” 和 “冗余存储”。 ❌ 编译错误！ 123456789101112131415161718#include &lt;iostream&gt;class Base &#123;public: void show() &#123; std::cout &lt;&lt; &quot;Base::show()&quot; &lt;&lt; std::endl; &#125;&#125;;class Parent1 : public Base &#123;&#125;; // 继承自 Baseclass Parent2 : public Base &#123;&#125;; // 继承自 Base// 多重继承class Derived : public Parent1, public Parent2 &#123;&#125;;int main() &#123; Derived d; d.show(); // ⚠️ 编译错误：二义性 return 0;&#125; 4. 出现二义性问题，在 C++ 中怎么解决这种菱形继承问题？&#x3D;&#x3D;&gt; 虚基类 Base｜class Derived : virtual public Base1️⃣ 解决方案一：使用作用域解析符 缺点：Derived 仍然包含 两个 Base 实例，数据冗余，而且每次调用 show() 需要手动指定作用域，不优雅。 123456int main() &#123; Derived d; d.Parent1::show(); // 访问 Parent1 继承的 Base d.Parent2::show(); // 访问 Parent2 继承的 Base return 0;&#125; 2️⃣ 使用虚继承｜最佳方案 ✅ 虚继承是为了让某个类做出声明，承诺愿意共享它的基类，这个被共享的基类就是虚基类 多继承除了造成命名冲突，还有数据冗余等问题，为了解决这些问题，C++ 引进了「虚继承」 这样能够保证 Derived 只含有一个唯一的 Base 实例。 12345678910111213141516171819#include &lt;iostream&gt;class Base &#123;public: void show() &#123; std::cout &lt;&lt; &quot;Base::show()&quot; &lt;&lt; std::endl; &#125;&#125;;// 让 Parent1 和 Parent2 进行虚继承class Parent1 : virtual public Base &#123;&#125;;class Parent2 : virtual public Base &#123;&#125;;// 继承 Parent1 和 Parent2class Derived : public Parent1, public Parent2 &#123;&#125;;int main() &#123; Derived d; d.show(); // ✅ 现在可以直接调用，不会有二义性 return 0;&#125; 不使用 virtual 时 Derived 会有两个 Base 对象，导致二义性问题。 内存浪费（两个 Base 子对象的冗余）。 使用 virtual 继承 Parent1 和 Parent2 不会各自包含 Base 的副本，而是共享同一个 Base 实例。 Derived 只会有一个 Base 实例，所以调用 show() 时不会有二义性。 再看个虚继承的例子： 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;class Base0 &#123;public: int var0; void fun0() &#123; cout &lt;&lt; &quot;Member of Base0&quot; &lt;&lt; endl; &#125;&#125;;class Base1 : virtual public Base0 &#123;public: int var1;&#125;;class Base2 : virtual public Base0 &#123;public: int var2;&#125;;class Derived : public Base1, public Base2 &#123; //定义派生类Derived public: int var; void fun() &#123; cout &lt;&lt; &quot;Member of Derived&quot; &lt;&lt; endl; &#125;&#125;;int main() &#123; Derived d; d.var0 = 2; //直接访问虚基类的数据成员 d.fun0(); //直接访问虚基类的函数成员 return 0;&#125; 将 Base0 类作为它的直接派生类 Base1 和 Base2 的虚基类，即 Base1 虚继承 Base0，Base2 虚继承 Base0。之后 Derived 再继承 Base1 和 Base2，在 Derived 对象里面就不会存在 Base0 类的双份的成员。 Derived 对象包含着从 Base1 继承的成员和从 Base2 继承的成员，但是从 Base1 继承的 Base0 成员实际上这个地方放了一个指针，这个指针指向真正的 Base0 成员，Base2 的也是。所以实质上从最远的基类继承过来的成员，在最远派生类中只有一份。 5. STL 库中 vector、list、map 实现的底层原理和应用场景？关于 STL 库中所有的结构的底层实现原理：https://zhuanlan.zhihu.com/p/542115773 顺带了解了 set、map、unordered_map、unordered_set 之间区别： set、map：底层使用红黑树实现，有序，插入、查找、删除的时间复杂度为 $O(logn)$ 优点：有序性，内部实现红黑树使得很多操作都在 $O(logn)$ 时间复杂度下完成 缺点：空间占用率高，需要额外保存父节点、孩子节点和红&#x2F;黑性质 unordered_set、unordered_map：底层使用哈希表实现，无序，查找的时间复杂度为 $O(1)$ 优点：因为内部实现了哈希表，因此其查找速度非常的快 缺点：哈希表的建立比较费时 1️⃣ vector 动态数组 vector 底层是动态数组，元素连续存储在堆上 自动扩容机制： vector 采用几何增长策略（通常是 2 倍扩容） 当 size() == capacity() 时，会申请更大的内存空间，然后拷贝旧数据到新空间 由于 realloc 可能导致数据搬移，push_back() 的均摊时间复杂度为 $O(1)$，但最坏情况 $O(n)$（扩容时） ❓所以有可能 vector 的插入操作可能导致迭代器失效：因为 vector 动态增加大小时，并不是在原空间后增加新空间，而是以原大小两倍在开辟另外一片较大空间，然后将内容拷贝过来，并释放原有空间，所以迭代器失效。 适用场景： ✅ 高效的随机访问（O(1)）。✅ 批量尾部插入&#x2F;删除（push_back()）。❌ 不适合频繁插入&#x2F;删除中间元素（O(n)）。❌ 扩容会导致数据搬移（不适合超大数据集）。 2️⃣ list 双向链表 list 底层是双向链表，每个节点存储数据和两个指针 插入和删除操作非常高效，不影响其他元素 不支持随机访问，必须顺序遍历才能找到某个元素 $O(n)$ 不会发生扩容问题，适合频繁插入&#x2F;删除的场景 适用场景： ✅ 高效插入&#x2F;删除（O(1)，特别是中间位置）。✅ 不关心随机访问，仅需遍历。❌ 不适合频繁随机访问（O(n)）。❌ 额外的指针开销（内存占用比 vector 高）。 3️⃣ map 平衡二叉搜索树——红黑树 map 底层实现是红黑树（Red-Black Tree），一种自平衡二叉搜索树 key 是有序的 插入、删除、查找 $O(logn)$，因为树的高度是 $O(logn)$ 迭代遍历按照 key 顺序进行 操作 时间复杂度 说明 插入 insert() $O(log n)$ 需要维护红黑树平衡 删除 erase() $O(log n)$ 删除节点后可能需要旋转 查找 find() $O(log n)$ 通过 BST 进行搜索 适用场景： ✅ 需要有序存储的数据结构（默认按照 key 递增）。✅ 需要高效查找、插入、删除（O(log n)）。❌ 不适合频繁变更 key（因为 key 作为 BST 节点的一部分）。❌ 遍历效率比 unordered_map 低（有序存储开销大）。 6. 红黑树有了解吗？红黑树的查找、插入、删除的时间复杂度？红黑树是一种自平衡二叉搜索树（BST），广泛应用于 C++ STL 的 map、set、multimap、multiset 以及 Linux 进程调度、内核数据结构等场景。 红黑树在每个节点上存储一个额外的颜色位（红&#x2F;黑），并满足以下五条性质： 每个节点是红色或黑色。 根节点必须是黑色。 所有叶子节点（NIL）是黑色（有些实现省略 NIL）。 红色节点不能连续出现（红色节点的子节点必须是黑色）。 任意节点到其所有叶子节点的路径上，黑色节点的数量相同。 这些性质确保了红黑树的近似平衡特性，使得最长路径不超过最短路径的 2 倍。 红黑树的插入、删除、查找的时间复杂度都在 $O(logn)$ 红黑树的应用： C++ STL map 和 set Linux 内核任务调度（完全公平调度 CFS）：采用红黑树作为调度队列的数据结构，用于管理所有可运行的进程，并确保进程公平分配 CPU 时间 每个可运行进程存储在红黑树中，按照 vruntime（虚拟运行时间）排序。 vruntime 是进程实际运行时间的加权值，nice 值（进程优先级）影响 vruntime 的增长速度。 调度器总是选择 vruntime 最小的进程运行（即红黑树的最左节点）。 进程执行后，vruntime 增长，然后被重新插入红黑树中，确保所有进程轮流执行。 文件系统（Ext3 &#x2F; Ext4） Ext3 是 Ext2 的升级版，支持日志，增强数据一致性。 数据结构： 基于 inode 和目录索引（采用 h-tree，即 B+ 树变种）。 日志模式：数据日志模式、元数据日志模式、无日志模式。 缺点：大文件性能不佳，目录性能有限。 Ext4 是 Linux 默认文件系统，在 Ext3 基础上做了多项优化： 延迟分配：优化写入性能。 多块分配：减少磁盘碎片。 HTree 索引目录：加速大目录的查找，采用红黑树进行元数据管理。 日志优化：降低磁盘 IO，提高数据一致性。 Redis 有序集合（ZSet） ZSet（Sorted Set） 是 Redis 中的一种数据结构，支持有序存储，每个元素带有一个 score 值（排序依据） ZSet 的底层数据结构： 跳表（Skip List）：默认用于有序集合，支持 O(log n) 级别的插入、删除、查找。 哈希表（Hash Table）：用于快速定位元素（score → key）。 红黑树（可能被用作持久化存储结构）。 7. MySQL 的聚集索引和非聚集索引的区别？ 好文：https://blog.csdn.net/white_ice/article/details/115478367 二叉查找树 —— 平衡二叉树 —— B 树 因为内存的易失性。一般情况下，我们都会选择将 user 表中的数据和索引存储在磁盘这种外围设备中。但是和内存相比，从磁盘中读取数据的速度会慢上百倍千倍甚至万倍，所以，我们应当尽量减少从磁盘中读取数据的次数。另外，从磁盘中读取数据时，都是按照磁盘块来读取的，并不是一条一条的读。如果我们能把尽量多的数据放进磁盘块中，那一次磁盘读取操作就会读取更多数据，那我们查找数据的时间也会大幅度降低。如果我们用树这种数据结构作为索引的数据结构，那我们每查找一次数据就需要从磁盘中读取一个节点，也就是我们说的一个磁盘块。我们都知道平衡二叉树可是每个节点只存储一个键值和数据的。那说明什么？说明每个磁盘块仅仅存储一个键值和数据！那如果我们要存储海量的数据呢？ 可以想象到二叉树的节点将会非常多，高度也会极其高，我们查找数据时也会进行很多次磁盘 IO，我们查找数据的效率将会极低！ B 树 图中的 p 节点为指向子节点的指针，二叉查找树和平衡二叉树其实也有，因为图的美观性，被省略了。 图中的每个节点称为页，页就是我们上面说的磁盘块，在 MySQL 中数据读取的基本单位都是页，所以我们这里叫做页更符合 MySQL 中索引的底层数据结构。 从下图可以看出，B 树相对于平衡二叉树，每个节点存储了更多的键值（key）和数据（data），并且每个节点拥有更多的子节点，子节点的个数一般称为阶，下图中的 B 树为 3 阶 B 树，高度也会很低。基于这个特性，B 树查找数据读取磁盘的次数将会很少，数据的查找效率也会比平衡二叉树高很多。 B+ 树 B+ 树是对 B 树的进一步优化。让我们先来看下 B+ 树的结构图： 根据下图我们来看下 B+ 树和 B 树有什么不同： 1️⃣ B+ 树非叶子节点上是不存储数据的，仅存储键值，而 B 树节点中不仅存储键值，也会存储数据。 之所以这么做是因为在数据库中页的大小是固定的，InnoDB 中页的默认大小是 16KB。 如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的 I&#x2F;O 次数又会再次减少，数据查询的效率也会更快。 另外，B+ 树的阶数是等于键值的数量的，如果我们的 B+ 树一个节点可以存储 1000 个键值，那么 3 层 B+ 树可以存储 1000×1000×1000&#x3D;10 亿个数据。一般根节点是常驻内存的，所以一般我们查找 10 亿数据，只需要 2 次磁盘 IO。 2️⃣ 因为 B+ 树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的。 那么 B+ 树使得范围查找、排序查找、分组查找以及去重查找变得异常简单。而 B 树因为数据分散在各个节点，要实现这一点是很不容易的。 有心的读者可能还发现下图 B+ 树中各个页之间是通过双向链表连接的，叶子节点中的数据是通过单向链表连接的。 其实上面的 B 树我们也可以对各个节点加上链表。这些不是它们之前的区别，是因为在 MySQL 的 InnoDB 存储引擎中，索引就是这样存储的。 也就是说下图中的 B+ 树索引就是 InnoDB 中 B+ 树索引真正的实现方式，准确的说应该是聚集索引（聚集索引和非聚集索引下面会讲到）。 通过下图可以看到，在 InnoDB 中，我们通过数据页之间通过双向链表连接以及叶子节点中数据之间通过单向链表连接的方式可以找到表中所有的数据。 MyISAM（MySQL 另一存储引擎）中的 B+ 树索引实现与 InnoDB 中的略有不同。在 MyISAM 中，B+ 树索引的叶子节点并不存储数据，而是存储数据的文件地址。 在 MySQL InnoDB 存储引擎中，索引分为聚集索引（Clustered Index） 和 非聚集索引（Secondary Index），二者的区别主要在于数据存储方式和查询性能。 聚集索引表示表中存储的数据按照索引的顺序存储，检索效率比非聚集索引高，但对数据更新影响较大；非聚集索引表示数据存储在一个地方，索引存储在另一个地方，索引带有指针指向数据的存储位置。非聚集索引检索效率比聚集索引低，但对数据更新影响较小。 聚集索引一个表只能有一个；而非聚集索引一个表可以存在多个。聚集索引存储记录是物理上连续存在；而非聚集索引是逻辑上的连续，物理存储并不连续。 1️⃣ 什么是聚集索引（Clustered Index）？ 聚集索引 &#x3D; 数据与索引存储在一起 B+ 树索引的叶子节点存储了整行数据 每张表只能有一个聚集索引（因为数据只能有一种物理存储顺序） 主键（PRIMARY KEY）默认是聚集索引，如果没有定义主键，InnoDB 会自动选取一个 UNIQUE 索引或创建一个隐式主键 示例 12345CREATE TABLE users ( id INT PRIMARY KEY, -- 主键自动成为聚集索引 name VARCHAR(50), age INT) ENGINE=InnoDB; id 是聚集索引，B+ 树的叶子节点存储整个行数据 存储结构 123456聚集索引 B+ 树（按 id 组织）----------------------------------| 1 | Alice | 25 || 2 | Bob | 30 || 3 | Charlie | 22 |---------------------------------- 叶子节点存储完整行数据 查询 id=2 时，B+ 树直接找到整行数据，速度快 特点： ✅ 查询主键时效率高（索引 + 数据一起存储，减少磁盘 I&#x2F;O）✅ 范围查询快（数据按主键顺序存储，连续读取）❌ 插入时如果 id 不是自增，会导致频繁调整 B+ 树，影响性能❌ 更新主键会导致数据移动，影响性能 2️⃣ 什么是非聚集索引（Secondary Index）？ 非聚集索引（非主键索引）&#x3D; 索引和数据分开存储 B+ 树的叶子节点存储的是主键，而不是数据本身 查询时，需要先查索引，再回表查询数据（回表查询，Extra: Using index） 比如查询 name=&#39;Bob&#39; 时，需要先找到 id=2，再去主键索引查整行数据 一张表可以有多个非聚集索引 示例 123456CREATE TABLE users ( id INT PRIMARY KEY, name VARCHAR(50), age INT, INDEX idx_name(name) -- 创建 name 非聚集索引) ENGINE=InnoDB; name 是非聚集索引，叶子节点存储的是 id 而不是整行数据。 存储结构 123456非聚集索引 B+ 树（按 name 组织）--------------------------------| Alice | 1 || Bob | 2 || Charlie | 3 |-------------------------------- 叶子节点存储的是 id（主键） 查询 name=&#39;Bob&#39; 时，需要先找到 id=2，再去主键索引查整行数据 特点 ✅ 可以加速非主键字段的查询（如 name）。✅ 一个表可以有多个非聚集索引（name、age 等）。❌ 查询时可能需要“回表”查询完整数据，性能较低。❌ 更新索引字段时，需要维护额外的索引，影响写性能。 创建索引时，你需要确保该索引是应用在 SQL 查询语句的条件(一般作为 WHERE 子句的条件)。 实际上，索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录。 索引虽然能够提高查询性能，但也需要注意以下几点： 索引需要占用额外的存储空间。 对表进行插入、更新和删除操作时，索引需要维护，可能会影响性能。 过多或不合理的索引可能会导致性能下降，因此需要谨慎选择和规划索引。 3️⃣ 聚集索引 vs. 非聚集索引 对比 对比项 聚集索引（Clustered Index） 非聚集索引（Secondary Index） 存储结构 索引叶子节点存储整行数据 索引叶子节点存储主键 查询性能 主键查询快（不需要回表） 需要回表查询完整数据 索引大小 整个表的大小 比聚集索引小（只存索引 + 主键） 插入性能 主键顺序插入快（如自增 ID） 插入影响较小 更新性能 更新主键影响大（数据移动） 更新索引字段影响较大 排序性能 按照主键存储，查询范围快 查询非主键字段排序时，可能用索引覆盖 适用场景 主键查询、范围查询、高效分页 辅助查询，如 WHERE name=&#39;Bob&#39; 5️⃣ 什么时候选择聚集索引 &amp; 非聚集索引？ ✅ 适合用聚集索引（PRIMARY KEY） 查询主键： SELECT * FROM users WHERE id = 10; 范围查询： SELECT * FROM users WHERE id BETWEEN 1 AND 100; 分页查询（ORDER BY 主键）： ORDER BY id LIMIT 10; 高效数据存储（自增主键 INSERT 快） ✅ 适合用非聚集索引（Secondary Index） 非主键查询： SELECT * FROM users WHERE name = &#39;Alice&#39;; 模糊匹配（LIKE）： SELECT * FROM users WHERE name LIKE &#39;A%&#39;; 组合索引： INDEX (name, age) 可优化 WHERE name=&#39;Alice&#39; AND age=25 ❌ 避免使用非聚集索引的场景 频繁更新索引列（影响性能） 非主键大范围查询，可能导致大量回表 8. 谈谈你对 redis 的了解？ Redis 面试题：https://zhuanlan.zhihu.com/p/427496556 范围太广了。 Redis（Remote Dictionary Server） 是一个高性能的 Key-Value 存储 NoSQL 数据库之一，用于缓存、持久化、分布式锁、消息队列等场景。基于内存存储（In-Memory），访问速度远快于磁盘数据库。单线程模型（IO 多路复用），并发性能极高。 支持多种数据结构（String, Hash, List, Set, Sorted Set, HyperLogLog, Bitmap, GeoSpatial）。 数据类型；说明；应用场景 String：最基础数据类型；缓存字符串、计数器、分布式锁 List：双向链表；消息队列、文章列表 Set：无序集合、去重；标签、用户好友关系、抽奖系统 Hash：存储对象、节省内存；用户信息存储 Sorted Set (ZSet)：有序集合、可排序；排行榜、延时任务队列 Redis 与 Memcached 的区别 特性 Redis Memcached 数据结构 多种（String、List、Set、Hash、ZSet） 仅支持 Key-Value 持久化 RDB、AOF 无持久化 分布式 支持主从复制、哨兵、集群 需要额外支持 线程模型 单线程（IO 多路复用） 多线程 过期策略 可配置（LRU、LFU） FIFO&#x2F;LRU Redis 持久化策略： RDB (Redis Database Snapshot) 快照存储，定期将数据存储到磁盘 触发方式： save：同步保存，影响性能 bgsave：后台异步保存 优点：适合灾难恢复（冷启动）；备份文件体积小，加载快 缺点：可能丢失最近的写入数据（触发快照前的写入） AOF (Append-Only File) 记录所有写操作，类似 MySQL binlog 写模式： always：每次写入后 fsync，最安全但慢 everysec：每秒 fsync，默认 no：由 OS 决定 优点：最高的数据安全性，可用于数据恢复 缺点：日志体积大，写入速度较慢 ✅ 最佳实践： 两者结合使用（AOF 提高数据安全性，RDB 提高启动速度）。 appendonly yes + save 900 1（开启 AOF + RDB 定期备份）。 Redis 过期策略： 定期删除：Redis 每秒扫描一部分 key，删除已过期的 key（减少开销）。 惰性删除：访问 key 时，若已过期则删除。 Redis 淘汰策略： noeviction：不删除，返回错误 volatile-lru：LRU 淘汰（仅对有 TTL 的 key） allkeys-lru：淘汰最近最少使用（LRU）key volatile-random：随机删除 TTL 设定的 key allkeys-random：随机删除任意 key volatile-ttl：删除最近过期的 key Redis 主从复制 &amp; 哨兵 &amp; 集群： 主从复制（Master-Slave） slaveof &lt;master-ip&gt; &lt;port&gt; 配置从节点 主从同步 全量复制（初次同步） 增量复制（接收后续写操作） 读写分离，提高性能；备份数据，防止单点故障 哨兵（Sentinel） 作用：负责自动故障转移 监控 Master 节点的健康状态 主节点宕机后，自动提升 Slave 为 Master 高可用 Redis 方案 集群（Cluster） Redis Cluster 实现数据分片 数据存储在多个节点 客户端直连节点（无中心节点） 适用于大规模分布式场景（高并发、高数据量） Redis 并发控制 &amp; 事务： 事务 MULTI &#x2F; EXEC &#x2F; DISCARD 事务机制 不支持回滚（失败不会撤销之前的命令） Redis 分布式锁 使用 SETNX（SET if Not Exists） 避免并发超卖、分布式任务调度 Redis 面试高频问题总结： Redis 为什么快：基于内存 + 单线程 IO 多路复用 持久化方式：RDB（快照）+ AOF（日志） 淘汰策略：LRU、LFU、TTL 集群模式：主从复制、哨兵、集群 如何防止缓存穿透：布隆过滤器、NULL 缓存 如何防止缓存雪崩：设置不同 TTL、分布式缓存 缓存穿透指的是查询一个数据库中不存在的数据，导致： 缓存中没有命中 请求直接落到数据库，增加数据库负担 大规模恶意请求可能导致数据库崩溃（如 DDoS 攻击） 如何防止缓存穿透： 方法一：使用布隆过滤器（位数组 + 多个哈希函数）快速判断某个 key 是否可能存在，判定不存在则直接返回，不查询数据库（存在假阳性） 方法二：使用 NULL 缓存，对于查询后发现不存在的数据，在 Redis 缓存一个短时间的 NULL 值，下次相同请求，直接返回 NULL，避免数据库压力 缓存雪崩指的是大量缓存同时失效，导致： 短时间内大量请求落到数据库 数据库压力剧增甚至崩溃 可能由于 Redis 故障、集群宕机或缓存过期时间相同导致 如何防止缓存雪崩： 方法一：设置不同 TTL，避免所有 Key 同时失效（随机过期时间） 方法二：分布式缓存（多级缓存），使用多个 Redis 实例进行分片存储，引入本地缓存减少 Redis 依赖，结合 CDN 缓存缓解高并发访问压力 9. 谈谈你对 ceph 的了解？ceph.io 10. 分布式容灾有哪些方法？1. 数据库主从复制（Master-Slave Replication） 原理：主库写入数据后，同步到从库。 场景：MySQL、PostgreSQL、Redis、MongoDB。 容灾策略： 主库故障时，从库自动切换为主库。 数据实时同步或异步同步。 2. 多副本（Replication） 数据复制成多份，存储在不同的机器或地域中。 典型方案： 3 副本机制：如 HDFS、HDFS 等。 数据损坏时自动从其他副本恢复。 3. 数据分片（Sharding） 数据分散到多个节点，单节点故障影响有限。 常用于 Cassandra、HBase、Redis Cluster。 容灾策略： 节点故障后自动迁移数据。 数据重平衡（Rebalance）。 4. 冷备、热备、同城&#x2F;异地容灾 冷备（Cold Backup）：数据定期备份到远程磁盘，灾难时手动恢复。 热备（Active&#x2F;Standby）：实时同步，故障发生立即切换备机。 温备（Warm Backup）：备份节点正常运行但不处理用户请求，发生故障快速激活。 5. 多活数据中心（多地容灾） 部署在多个地理位置的数据中心，彼此实时或异步同步。 一旦某个数据中心发生故障，流量自动切换到其他数据中心。 常见策略： 同城双活：两个数据中心同时提供服务。 异地容灾：跨城市或国家部署数据中心，抵御灾难性事故（如地震、火灾）。 6. 故障转移（Failover） 服务宕机时自动转移到备份服务节点。 常用技术： DNS 切换 虚 IP（VIP）漂移（如 Keepalived） 心跳检测（Heartbeat） 7. 降级和限流 降级：当部分节点故障时，降低服务质量或关闭非核心服务。 限流：限流可防止故障扩散，避免雪崩效应。 8. 数据快照（Snapshot）和备份（Backup） 快照：短时间内完整复制数据状态。 备份：定期保存数据，用于数据恢复。 9. 服务熔断与限流 熔断：当服务响应变慢或故障率较高，自动熔断请求，防止故障蔓延。 限流：控制请求量，避免超载。 10. 灾难演练和混沌工程 通过人工或自动化工具进行故障注入，验证系统容灾能力。 如：Chaos Engineering 工具（ChaosBlade、Chaos Mesh、Gremlin） 11. 你理解的设计模式？为什么会有设计模式？你觉得设计一个软件怎么应用这些设计模式？以及你在开发方面的一些心得？ ❓主要是面试官看到了我的个人博客，我回复提到了「设计模式」，所以面试官就接着话题往下问了。 设计模式是一系列在软件设计过程中经过反复实践、总结、优化的通用解决方案或经验总结。设计模式体现了一种思想和经验，而不是具体的代码。它是面向对象软件开发过程中的最佳实践，常见的设计模式分为三大类： 创建型模式：关注对象的创建，例如工厂方法、抽象工厂、单例、建造者、原型模式等。 结构型模式：处理类或对象的组合，例如适配器、装饰器、代理、桥接、组合、外观、享元模式等。 行为型模式：描述对象之间的通信和职责划分，例如观察者、策略、命令、模板方法、状态、责任链、迭代器模式等。 为什么会有设计模式？ 提高复用性：设计模式是经验的总结，能被反复地重用，减少设计过程的试错成本。 提供通用解决方案：很多开发中的问题和场景都是重复的，设计模式给出了通用的、经过验证的解决方案。 提升代码可维护性和可读性：设计模式使得开发人员之间有一种共同语言，团队更易于交流和协作，有助于提高代码的易读性和易维护性。 提高设计的灵活性和扩展性：合理使用设计模式能降低代码耦合度，增强系统扩展性，应对需求变更和演化。 如何应用设计模式？ 在实际项目中，并非一定要强行使用设计模式，而应根据实际需求、规模、复杂性等选择合适的模式，遵循以下原则： 分析和识别需求场景：设计模式不是盲目套用的工具，而是用来解决具体问题的。因此需要仔细理解业务需求，识别是否存在典型场景。 选取合适模式：根据具体场景选择最适合的模式。比如： 当需要统一对象创建方式时，使用工厂模式。 当多个对象需要监听同一事件变化时，使用观察者模式。 需要动态给对象添加额外的职责时，选择装饰器模式。 注意适度原则：设计模式的滥用可能带来过度抽象，使简单的问题复杂化。因此必须注意“适度”和“恰当”，不应过度设计。 实践经验总结 先设计，再编码。设计模式应当在设计阶段思考和确定，不是为了模式而模式。 多结合实际项目实践进行总结，只有这样，才能准确把握设计模式的精髓。 开发方面的心得 重视基础，少做炫技：软件开发本质是为了解决问题，而不是为了炫耀技术。很多时候用最简单的方案解决问题远好过追求模式、框架的复杂应用。 敏捷迭代，避免过度设计：很多时候，我们都无法精确预知项目未来变化，因此初始设计应当足够灵活，避免盲目追求复杂架构。 关注代码可读性和维护性：优秀的开发者不仅考虑代码是否运行，更考虑代码是否易于维护和扩展，设计模式在提升代码可读性和维护性上帮助极大。 保持开放、持续学习：技术在不断演进，开发人员必须保持开放心态，持续学习新模式、新技术，但同时谨记避免盲目跟风。 12. 一份代码里面写了很多设计模式，这好不好？不一定是好事，虽然一定程度上提高了代码的可维护性和可扩展性，降低代码耦合。 但是过度设计会造成 代码复杂、冗长、难以理解，增加了维护成本； 同时影响代码性能 滥用设计模式也会导致开发效率降低，比如一个简单的 if-else 选择逻辑，如果强行用 策略模式，会导致代码可读性下降 简历拷打 项目应用在哪些场景？ 在内存中设计为索引前缀树，那在非易失性存储介质中呢？也是索引前缀树，还是全表查找？ ART：https://zhuanlan.zhihu.com/p/645064049 LearnedTLB 是为什么能达到降低 CPU 访存次数？ LearnedTLB 在哪些场景下适用&#x2F;比较好？ 你们模拟的故障注入场景有哪些？怎么注入故障？ 如果系统故障注入后，如何进行恢复？ 故障注入的报告是什么内容？ 博客之类的文章我上去看了一些，有没有让你比较深刻学到很多的内容可以分享一下？ 反问环节Q1：金融是不是对安全要求比较高？ A1：金融这块有几个核心的业务点： 安全性：数据安全、法律合规、权限管理（数据存储、通信链路、日志打印） 可用性：金融对可用性要求比较高，就比如刚刚为什么我问了很多分布式容灾的一些相关内容，因为你有做过故障这方面的模拟和注入经验，我觉得是一些很可贵的经验。金融对故障演习、故障注入、自动化报表、业务恢复情况比较重视。 资金流的状态机：金融会从订单整体状态机的严谨性，流程对账，资金流水的日志方便审计 注意 To B 的合作：金融这一行肯定是和国企打交道，所以 to B 的属性比较重，每个银行都有很多特性，特性的多样化你怎么在你的业务上整合起来，不可能给每个银行写一套代码 随心 talk 你刚刚说对老师周五开组会，一般是上午还是下午，要多久。 那比如说你下午在公司订个会议室，你自己跟导师聊一聊也 OK 吧，你自己周五也能来公司吧？一定要去线下参加吗？ 如果说你到时候来参加实习，周五就线上参与？ 这个不是问题，如果线上的话，我理解也没啥问题。 最后一个问题，你对 Linux 熟悉吗？ 如果过了一面，下次面试应该是 3-5 天，或者一周左右。 结果我没办法自己拍，要跟领导沟通一下。 二面（挂） 提前准备 0️⃣ 自我介绍：首先说自己是厦门大学研二在读 本科：java、前端、服务器-域名、linux、golang 研究生（大四）：提前来实验室、C++、杭州实习、西安实习、中科院实习、系统与体系结构 1️⃣ 主要表现对这一块业务感兴趣。 聊一聊自己对金融这块业务的理解，问一问某些部分你们都是怎么优化的？然后说一说我的思考？多请教。 假设问最近有关注什么事吗 &#x3D;&#x3D;&gt; deepseek 5 天开源的内容 (3FS) 关于 ceph 这块，实验室刚接了一个国重项目，我想问问您对这块了解吗，关于 ceph 内的故障恢复机制，我个人挺感兴趣的，而且对你们这个业务和方向也感兴趣，感觉自己研究生的一些研究方向和你们业务也相匹配。 因为金融业务需要保证高度的可用性，所以我想请教下你们架构上是怎么做分布式容灾的呢？ 当前团队在研发的金融业务，有哪些主要的技术难点或者挑战？ 能否介绍一下当前部门使用的主要技术栈和工具链？ 腾讯金融科技部门日常技术挑战中，最常遇到的难点或技术瓶颈有哪些？ 金融领域的数据安全和合规管理，你们是怎么保障和实现的？ 在高并发、高可用、容灾方面，你们具体用了哪些方案或技术？ 2️⃣ LeetCode Hot 100 3️⃣ 夯实简历中科院实习的故障注入的内容 4️⃣ 八股文背熟 多注重分布式存储、容灾、安全这一块的问题 注意事务相关的问题 MySQL 得看看 快排如何把空间复杂度降到 $O(1)$：还是降低不到 O(1)，递归调用会带来 $O(logn)～O(n)$ 的栈空间消耗（取决于划分的平衡性），可以通过尾递归优化减少栈空间消耗：每次递归选择较短的子数组进行递归，而较长的子数组用循环来代替递推。 1. 转账业务 从你的银行账户里转 1 块钱到我的银行账户里，具体流程？ 先减还是先增？—— 减 根据日志回滚？但是日志也不一定是正确的？ 2. rand7() 实现 rand10() ⚠️ 腾讯、字节常考的面试题！ 本题重点是相等概率！ 本质：就是将 7 进制数转为 10 进制数，即 rand7() * 7 + rand7()，范围为 [14, 56]，取模 %10，剔除范围外的数字即可。 面试的时候回答两个 Rand7() 相乘，被腾讯面试官问比如 13 这种数就没办法生成怎么办？ 由面试官一步步引导回答出来，不过还是建议用 (rand7() - 1) * 7 + rand7() 121. rand7() * 7 + rand7() =&gt; [14, 56]2. [14, 56] % 10 + 1 解法 112345678910// The rand7() API is already defined for you.// int rand7();// @return a random integer in the range 1 to 7class Solution &#123;public: int rand10() &#123; return (rand7() + rand7() + rand7() + rand7() + rand7()) % 10 + 1; &#125;&#125;; 🔥 解法 2123456789101112131415// The rand7() API is already defined for you.// int rand7();// @return a random integer in the range 1 to 7class Solution &#123;public: int rand10() &#123; while (true) &#123; // res =&gt; 等概率 [1, 49] int res = (rand7() - 1) * 7 + rand7(); if (res &gt;= 1 &amp;&amp; res &lt;= 40) return res % 10 + 1; &#125; &#125;&#125;; 腾讯 PCG QQ｜后台开发一面（挂） unordered_map 与 map 的区别 C++ 多态怎么实现的 C++ 异常处理机制 Redis 自旋锁 计算机网络 socket 编程 linux 内存分配机制 进程和线程的区别 进程间通信方式 协程 智能指针 mysql 的 SQL 注入问题 mysql MVCC https 与 http 怎么查看线程堆栈大小？正常大小为多少？ Linux 用户态与内核态的区别？ 如何理解 Linux 一切皆文件？ x. 项目 x. 两数之和 + 64匹马8赛道最少几轮决前4 —— 11轮&#x2F;10轮 都可 1. C++ 多态实现多态主要分为： 静态多态（编译期实现）：如函数重载、模板。 动态多态（运行时实现）：通过虚函数（virtual）来实现，常用于继承关系中。 针对动态多态具体来说，编译器会为每个含有虚函数的类创建一个虚函数表（vtable），表中存放该类所有虚函数的地址。每个该类对象内部也会额外存储一个指向虚函数表的指针（vptr）。 当调用虚函数时，编译器在底层会通过以下方式实现： 首先，通过对象内部的虚指针找到对应的虚函数表； 然后，根据调用的虚函数在表中的位置，找到函数指针； 最终，调用这个函数指针指向的实际函数。 ⚠️ 注意： 每个类对象会多占用一个指针大小（通常8字节或4字节，取决于平台），存储虚指针。 每个类只会存在一个虚函数表实例，无论创建多少个对象，都只共享一个虚函数表。 虚函数调用相较于普通函数调用会增加一次间接寻址的开销，但开销非常小，通常不会造成明显性能问题。 若基类的析构函数不是虚函数，则在用基类指针删除派生类对象时会出现未定义行为，故通常建议将基类析构函数定义为虚函数。 2. C++ 异常处理机制C++ 的异常处理是通过 try、catch、throw 三个关键字实现的，具体机制如下： 抛出异常（throw） 当程序中出现错误或异常情况时，可以使用 throw 抛出一个异常对象。 12if (denominator == 0) throw std::runtime_error(&quot;除数不能为0&quot;); 捕获异常（try-catch） 异常被抛出后，程序控制权会自动转移到相应的 catch 块，前提是异常抛出位置位于对应的 try 块内。 12345try &#123; int result = divide(x, y);&#125; catch (const std::runtime_error&amp; e) &#123; std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;&#125; 异常传播与栈展开 当异常被抛出后，程序会逐级向上查找匹配的 catch 语句，如果找到匹配，则进入相应的处理逻辑；若没有对应的处理，则异常继续向调用栈的上层传播。 如果直到 main() 函数都未捕获异常，程序会调用 std::terminate() 终止。 异常对象 异常对象通常以值的方式抛出，以引用方式捕获，以避免拷贝开销。 1catch (const ExceptionType&amp; e) &#123; ... &#125; 栈展开（stack unwinding） 当异常抛出后，程序会从抛出点开始逐层向上退出栈帧（函数调用），直到捕获异常为止。 在栈展开过程中，局部对象会按顺序调用析构函数释放资源，这保证了资源的正确释放（RAII 机制）。 注意：异常中断了程序的正常流程，从而可能导致对象处于无效或未完成的状态，或者资源没有正常释放等问题。那些在异常发生期间正确执行了“清理”工作的程序被称作异常安全的代码（编写困难）。 3. 自旋锁自旋锁（Spinlock）是一种用于实现并发控制的同步机制。它的原理非常简单：当线程试图获取锁时，如果锁已被其他线程占用，则该线程不会进入睡眠，而是持续地循环（自旋）检查锁的状态，直到锁被释放为止。 优点： 避免线程切换（上下文切换）的开销，减少线程调度成本。 在锁被占用时间非常短暂的场景中效率高，比如对共享变量做简单操作（原子操作）。 缺点： 长时间占用CPU，造成资源浪费。 如果锁持有时间过长，自旋等待将极大降低系统性能。 适用场景： 临界区代码执行非常短，线程争用的情况不频繁。 多核环境下效果更好，尤其是锁争用时间非常短的时候。 自旋锁（Spinlock） 互斥锁（Mutex） 等待方式 忙等待（Busy Waiting） 线程睡眠（Sleep） CPU资源占用 较高（不停地检查锁状态） 较低（线程阻塞时不占CPU资源） 适用场景 临界区短、小规模并发 临界区较长的场景 1234567891011std::atomic_flag lock = ATOMIC_FLAG_INIT;void lock() &#123; while (lock.test_and_set(std::memory_order_acquire)) &#123; ; // 忙等待 &#125;&#125;void unlock() &#123; lock.clear(std::memory_order_release);&#125; 解释： 当锁已被其他线程占用时，当前线程会反复检测锁状态，直到锁被释放。 自旋锁的核心就是“自旋等待”，并不会切换到其他线程，或调用系统 API 进入睡眠状态。 4. 计算机网络｜Socket 编程计算机网络中的 Socket 编程 是一种通过网络进行通信的软件开发技术。 Socket（套接字）是应用层与传输层之间的编程接口。 它本质上是对 TCP&#x2F;IP 协议栈的一种封装，允许开发者实现网络中进程之间的通信。 Socket 分类通常有两种类型： 类型 描述 常见应用协议 流式套接字（SOCK_STREAM） 提供面向连接、可靠的传输，基于TCP协议 HTTP、FTP、SMTP等 数据报套接字（SOCK_DGRAM） 提供无连接、不保证可靠传输，基于UDP协议 DNS、DHCP 等 Socket 编程步骤Socket 编程的一般步骤如下： 服务端流程： 创建套接字 (socket()) 绑定地址和端口 (bind()) 监听连接请求 (listen()) 接受连接请求，返回一个新的套接字 (accept()) 通过新套接字进行通信 (recv()&#x2F;send()) 关闭套接字 (close()) 服务端代码示例123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;unistd.h&gt;#include &lt;arpa/inet.h&gt;int main() &#123; int server_fd = socket(AF_INET, SOCK_STREAM, 0); sockaddr_in server_addr&#123;&#125;; server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = INADDR_ANY; // 监听所有地址 server_addr.sin_port = htons(8080); // 端口8080 bind(server_fd, (struct sockaddr*)&amp;server_addr, sizeof(server_addr)); listen(server_fd, 5); sockaddr_in client_addr&#123;&#125;; socklen_t addr_len = sizeof(client_addr); int client_fd = accept(server_fd, (struct sockaddr*)&amp;server_addr, &amp;addr_len); char buffer[1024]&#123;&#125;; recv(client_fd, buffer, sizeof(buffer), 0); std::cout &lt;&lt; &quot;接收到消息: &quot; &lt;&lt; buffer &lt;&lt; std::endl; const char* msg = &quot;收到！&quot;; send(client_fd, msg, strlen(msg), 0); close(client_fd); close(server_fd);&#125; 客户端流程（TCP） 创建套接字 (socket()) 发起连接请求 (connect()) 发送与接收数据 (send()&#x2F;recv()) 关闭套接字 (close()) 客户端示例代码12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;unistd.h&gt;int main() &#123; int sock_fd = socket(AF_INET, SOCK_STREAM, 0); sockaddr_in serv_addr&#123;&#125;; serv_addr.sin_family = AF_INET; serv_addr.sin_port = htons(8080); serv_addr.sin_addr.s_addr = inet_addr(&quot;127.0.0.1&quot;); connect(sock_fd, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr)); const char* msg = &quot;你好，服务端！&quot;; send(sock_fd, msg, strlen(msg), 0); char buffer[1024]&#123;&#125;; recv(sock_fd, buffer, sizeof(buffer), 0); std::cout &lt;&lt; &quot;服务器回复：&quot; &lt;&lt; buffer &lt;&lt; std::endl; close(sock_fd);&#125; 常用 API 函数 函数名 功能 socket() 创建套接字描述符 bind() 绑定IP地址和端口 listen() 监听传入连接请求 accept() 接受新的连接，创建通信socket connect() 客户端连接服务端 send() 发送数据 recv() 接收数据 close() 关闭socket Socket 编程注意事项： TCP是面向连接的，需明确服务端和客户端角色。 网络字节序（大端、小端）问题，通常用htons()和htonl()处理。 Socket操作可能发生阻塞，需关注阻塞与非阻塞模式。 注意处理边界情况（数据发送和接收可能分多次完成）。 5. Linux 内存分配 参考链接：https://zhuanlan.zhihu.com/p/73468738 https://zhuanlan.zhihu.com/p/149581303 阿秀网站 6. SQL 注入是什么？如何防范？SQL 注入是一种常见的安全漏洞，攻击者利用应用程序未对用户输入进行严格过滤，向数据库注入恶意SQL语句，从而获取、篡改甚至删除数据。 常见示例： 1SELECT * FROM users WHERE name = &#x27;$name&#x27;; 攻击者可能输入： 1&#x27; OR &#x27;1&#x27;=&#x27;1 导致SQL语句变成： 1SELECT * FROM users WHERE name = &#x27;&#x27; OR &#x27;1&#x27;=&#x27;1&#x27;; 直接绕过认证，返回所有用户。 预防SQL注入的措施： 使用预编译语句（Prepared Statement），参数化绑定输入。 对输入进行严格校验与转义，避免SQL拼接。 数据库权限严格控制，避免高权限SQL执行。 7. MySQL MVCC 机制 ⚠️ 供学习：DuckDB —— MVCC 和增删改查 MVCC（多版本并发控制）是 MySQL InnoDB 引擎用于控制事务并发的一种机制，其核心思想是： 每个事务读到的数据版本可能不同，事务之间无需加锁即可实现并发读取。 在事务修改数据时，并不会立刻删除旧数据，而是创建一个新的数据版本，旧版本的数据暂时保留，从而避免读写冲突。 MVCC 依赖的核心技术： undo log（回滚日志），用于版本链维护。 每行数据有隐藏字段（如事务 ID）记录版本信息。 快照读（Snapshot Read）： 读取的是事务开始时数据的版本快照，不会被其他事务干扰。 如 SELECT 非锁定读。 当前读（Current Read）： 会读最新版本，并锁定行，防止并发修改（如 SELECT FOR UPDATE）。 8. HTTP 和 HTTPS 区别HTTP 和 HTTPS 的核心区别在于通信是否加密： 区别点 HTTP HTTPS 安全性 明文传输，不安全 使用 SSL&#x2F;TLS 协议，加密传输，更安全 默认端口 80 443 身份认证 无认证机制 使用证书认证，防止中间人攻击 性能 快（无加密开销） 较慢（握手与加密开销） 应用场景 普通网站，不敏感数据 涉及登录、支付、敏感信息场景 HTTPS 通信过程简单描述： 客户端请求服务器，服务器返回公钥证书。 客户端校验证书有效性，生成会话密钥，用公钥加密并返回给服务器。 服务器解密获得会话密钥，双方以会话密钥通信。 9. 如何查看线程堆栈（Stack）信息在 Linux 中，有几种常用方法查看线程堆栈信息： 方法一：使用 gdb 调试工具12gdb -p &lt;进程ID&gt;thread apply all bt 方法二：使用 Linux 系统工具（pstack）1pstack &lt;进程ID&gt; 方法三：程序中主动打印堆栈 如使用 backtrace() 系列函数。 常见线程堆栈大小查看默认情况下，线程栈大小为 8 MB，可以通过 ulimit -s 命令查看。 1ulimit -s # 默认线程栈大小 或在程序内： 12345pthread_attr_t attr;size_t stacksize;pthread_attr_init(&amp;attr);pthread_attr_getstacksize(&amp;attr, &amp;stacksize);printf(&quot;线程堆栈大小: %zu 字节 &quot;, stacksize); 注意：线程堆栈默认大小通常为8MB（Linux环境），但具体依系统、配置可能有所不同。 10. Linux 中的内核态和用户态有什么区别？在 Linux 操作系统中，进程运行分为两个模式，即内核态（Kernel Mode） 和 用户态（User Mode）： 区别维度 用户态 (User Mode) 内核态 (Kernel Mode) 权限级别 权限受限，仅能访问有限资源 权限最高，可访问所有资源和硬件设备 可执行指令 受限指令不能执行，如直接I&#x2F;O操作 所有CPU指令均可执行，包括硬件控制指令 内存访问 有虚拟地址空间隔离，不能直接访问物理内存 可直接管理物理内存和地址空间映射 CPU 模式 CPU运行在非特权模式 CPU运行在特权模式（Ring 0） 进入方式 默认状态，程序启动后即为用户态 系统调用、异常、中断等事件进入内核态 稳定性影响 用户态程序崩溃不影响系统稳定性 内核态崩溃通常会导致系统崩溃 状态切换的场景 用户态 → 内核态： 程序执行系统调用（如文件读写、网络请求等） 发生中断或异常时也会进入内核态 内核态 → 用户态： 系统调用处理完成，返回用户程序； 中断处理完成，返回被中断进程继续执行。 为什么区分内核态与用户态？这种区分主要是基于以下考虑： 安全性： 避免普通用户程序直接访问硬件设备或重要的内核数据，防止用户程序破坏系统。 稳定性：用户程序崩溃不影响内核，保护整个系统稳定运行。 权限隔离：防止恶意程序或错误程序直接损坏核心系统。 11. 如何理解 Linux 一切皆文件｜VFS？在 Linux 系统中，“一切皆文件” 是一个核心设计哲学，它意味着系统中的几乎所有内容都可以被看作是文件，包括常规文件、目录、设备、进程间通信等。这个设计理念有助于保持系统的一致性和灵活性，使不同类型的资源可以用相同的方式进行访问和操作。 1. VFS 的作用VFS 主要提供了一套通用的文件系统接口，使得用户可以无感知地操作不同类型的文件系统和设备。例如，应用程序不需要关心底层存储介质使用的是 ext4 还是 XFS，而是通过相同的系统调用（如 open、read、write）来访问文件。 VFS 的主要作用包括： 文件系统抽象：支持不同的物理文件系统（如 ext4、NTFS、FAT）。 文件对象抽象：无论是普通文件、设备文件，还是管道、套接字，VFS 都用相似的方式处理。 统一接口：提供一致的 open()、read()、write() 方式，使用户不需要关心底层实现。 2. VFS 结构VFS 由多个核心数据结构组成： super_block：表示挂载的文件系统信息，如磁盘类型、大小等。 inode：存储文件的元数据（如权限、大小、时间戳）。 dentry（目录项）：表示目录和文件的路径关系，加速文件查找。 file：表示打开的文件，包含文件描述符等信息。 3. VFS 如何支持“一切皆文件” 文件类型 VFS 视角 示例路径 普通文件 inode + dentry + file /home/user/file.txt 目录 inode + dentry /home/user/ 设备文件 设备驱动注册为文件 /dev/sda（磁盘），/dev/tty（终端） 进程信息 伪文件系统 /proc /proc/1234/cmdline 内核参数 伪文件系统 /sys /sys/class/net/eth0/ 套接字 文件接口 /var/run/docker.sock 管道 通过 VFS 管理 /tmp/mypipe VFS 允许不同类型的文件系统（如 ext4、NFS、tmpfs）在 Linux 内核中无缝协作，同时也将设备、网络等资源抽象为文件。 算法题[1] 两数之和 思维题❓问题：一共有 64 匹马，一次只能跑 8 匹（8 个赛道），没有计时器，只能通过比赛判断相对名次。目标是选出最快的前 4 匹马，问至少需要几轮？ 1️⃣ 第一步：分组初赛 首先，将 64 匹马分成 8 组，每组 8 匹。 每组各进行一次比赛，一共需要 8 轮 比赛。 进行到这里一共用了 8 轮。 每组排名确定了，但组与组之间的实力还无法确定。 2️⃣ 第二步：小组冠军对决 将第一轮8个小组赛中的第1名放在一起，再跑一轮，共计 1轮。 到此累计轮数：8轮（初赛）+ 1轮 &#x3D; 9轮。 此时确定： 第9轮比赛的第1名，就是全局最快的马。 第9轮的结果，可以帮我们明确排除掉一些马： 比如第9轮中第8名所在小组，其余7匹马都不可能进前4，因为这组冠军本身就在冠军赛中排倒数第1。 同理，第9轮的第7名的原始小组，其余马也不可能进入前4。 依此类推，还能继续排除。 3️⃣ 第三步：确定剩余竞争马匹 现在仔细分析剩余可能进入前4的马匹有哪些： 假设第9轮的前四名分别为：A组第1名，B组第1名，C组第1名，D组第1名（按成绩从好到差排列）。 第9轮比赛中： 第1名所在小组（A组）：A组原来的第2名、第3名、第4名都可能进入前四； 第2名所在小组（B组）：B组原来的第2名、第3名可能进入前四； 第3名所在小组（C组）：C组原来的第2名也可能进入前四； 第4名所在小组（D组）：只有冠军可能进前四，其他名次马匹绝无可能。 其余小组（第9轮的第5至8名所在组），其余所有马匹都不可能进前4，完全排除。 因此，目前仍有可能进入前4名的马匹数量： 第9轮的前四名：A1, B1, C1, D1 共4匹 A组的2,3,4名：3匹 B组的2,3名：2匹 C组的2名：1匹 D组的2-8名：0匹 其他组全部排除：0匹 一共剩余：4（前四名）+3+2+1 &#x3D; 10匹。 但是注意： 第9轮的第1名（A1）已经确认冠军，不用再跑。 目标是找出前四，已确认第1名，实际上仅需再明确第2、3、4名。 所以最后一次比赛只需在剩余的10 - 1 &#x3D; 9匹中选择出最快的3匹即可。 下面的分析就是最好情况下（其中 1 匹马超过 B 即可）的次数了：10 轮 如果最坏情况下，还是需要多跑一轮的。 9匹马，一轮只能跑8匹，因此显然9匹不能一轮搞定。因此必须更优化分析！ 但是上面分析中，我们实际少算了一个关键点： 实际上，第9轮第4名的马（D1）不可能在第10轮中再被后面的马超越，因为它已证明了自己比所有除ABC之外的其他小组冠军都快，且已经赛过这些剩余的其他组选手。也就是说，第9轮第4名（D1）不会被任何之前的非冠军马超过，所以不需再参与下一轮比赛，实际上可以排除。 因此，重新整理一次： 已经确定第1名（A1）。 第9轮第4名（D1）已无法被超越，无需参与最后轮次。 因此实际需要再比的马匹减少为8匹，正好8赛道跑一轮即可搞定： 第9轮的第2名（B1），第3名（C1），需要再确认名次。 A组的第2、3、4名（3匹） B组的第2、3名（2匹） C组的第2名（1匹） 加起来正好 8匹。 4️⃣ 第四步：最终决赛（最后1轮） 将上述8匹马跑最后一轮，直接决出前4名中剩余的第2、第3、第4名。 到此累计轮数：8轮（初赛）+ 1轮（冠军组赛）+ 1轮（最终确认赛）&#x3D; 10轮。 ✅ 答案：最少需要 10轮 比赛 一般来说是 11 轮。 腾讯 PCG QQ｜后台开发 业务主要是做：推荐算法，而非 golang 开发 一面（挂）业务 功能开发（CRUD）：golang 搜索、推荐算法、AI 落地：对性能比较高，用 C++ QQ 内部很多历史代码都是 C++，更要求候选人懂 C++ 1. 实习与项目拷打… ‼️2. 什么情况下会用到右值引用？ 等价于问题：右值引用的主要用途 右值引用（T&amp;&amp;）主要用于实现移动语义和完美转发： 移动语义： 当一个临时对象或不再使用的资源，需要被高效地“移动”而不是拷贝时，就用到右值引用： 12std::vector&lt;int&gt; v1 = &#123;1,2,3&#125;;std::vector&lt;int&gt; v2 = std::move(v1); // 此时v1内容转移给v2，避免深拷贝 完美转发： 模板中利用万能引用（forwarding reference）配合std::forward实现任意类型参数的原始性质传递： 1234template&lt;typename T&gt;void wrapper(T&amp;&amp; arg) &#123; func(std::forward&lt;T&gt;(arg)); // 原样传递arg（左值传左值，右值传右值）&#125; 总结一下右值引用的使用场景： 避免不必要的内存拷贝（提升效率） 转移资源所有权（移动语义） 模板泛型函数完美转发（提高泛型代码通用性） ‼️3. move() 底层原理std::move() 的底层原理实际上非常简单，它本身并不真正执行移动，而是一个类型转换工具，用来将左值（lvalue）强制转换为右值引用（rvalue reference），从而允许移动语义发生。 一、源码分析（典型实现）在C++标准库中，std::move() 一般可实现为如下模板函数： 1234template &lt;typename T&gt;constexpr std::remove_reference_t&lt;T&gt;&amp;&amp; move(T&amp;&amp; arg) noexcept &#123; return static_cast&lt;std::remove_reference_t&lt;T&gt;&amp;&amp;&gt;(arg);&#125; 上述代码可以解析为： T&amp;&amp; arg：这是一个万能引用（forwarding reference），能够绑定到左值或右值。 remove_reference_t&lt;T&gt;：移除模板参数 T 可能带有的引用限定符，保证返回的确实是一个右值引用类型。 static_cast&lt;remove_reference_t&lt;T&gt;&amp;&amp;&gt;：进行强制类型转换，将传入参数从左值转换为右值引用。 二、原理分析std::move() 本身没有发生移动动作，它只是一个类型转换工具： 转换前：变量（对象）本身是左值，只能调用拷贝构造函数或拷贝赋值。 转换后：变量变为右值引用，具备调用移动构造函数或移动赋值的资格。 本质是告诉编译器：“这里的对象我不再需要了，可以放心进行资源的移动操作。” 例如： 123std::string str1 = &quot;Hello&quot;;std::string str2 = std::move(str1); // str1 的内容被“窃取”，str2 可能直接接管内部缓冲区，而非复制 三、实际的“移动”如何发生？实际的移动（资源转移）是通过被调用对象的移动构造函数或移动赋值运算符实现的，而不是通过std::move()实现： 例如，std::string 的移动构造函数的伪代码： 1234567// 移动构造函数示意string(string&amp;&amp; other) noexcept &#123; data_ = other.data_; size_ = other.size_; other.data_ = nullptr; // 原对象失去所有权 other.size_ = 0;&#125; std::move() 提供右值引用，而真正资源转移的逻辑，由类的移动构造或移动赋值完成。 四、注意事项 std::move()不会清空对象： 调用std::move()后的对象处于有效但未指定状态（valid but unspecified state），通常对象变为空或默认状态。 你可以继续赋值或析构，但不应该继续访问对象原先的资源。 移动语义要求类本身支持移动构造或移动赋值： 若类本身未定义移动构造或移动赋值，调用std::move() 仍然可能降级成拷贝。 问题 结论 std::move()本质是什么？ 类型转换函数，从左值转为右值引用 真正的移动操作在哪里发生？ 类的移动构造函数或移动赋值运算符 调用后原对象的状态？ 有效但未指定 std::move() 本身几乎没有开销，它只是一个编译期的类型转换工具，真正的开销和行为由类型本身的移动构造和赋值函数决定。 4. 智能指针，shared_ptr 怎么实现自动管理内存？shared_ptr通过引用计数（reference counting） 实现对堆内存自动管理： 具体实现原理： shared_ptr内维护两个指针： 资源指针：指向实际对象的指针。 引用计数指针：指向一个额外分配的计数器对象（含引用计数和弱引用计数）。 构造时：资源分配一次，引用计数设置为1。 复制构造（shared_ptr之间复制）：引用计数增加1。 析构时： 引用计数减1。 若引用计数变为0，则自动释放资源（调用delete或自定义deleter） 123456789101112131415161718192021template&lt;typename T&gt;class shared_ptr &#123; T* ptr; size_t* ref_count;public: explicit shared_ptr(T* p = nullptr) : ptr(p), ref_count(new size_t(p ? 1 : 0)) &#123;&#125; shared_ptr(const shared_ptr&amp; other) : ptr(other.ptr), ref_count(other.ref_count) &#123; if (ptr) (*ref_count)++; &#125; ~shared_ptr() &#123; if (ptr &amp;&amp; --(*ref_count) == 0) &#123; delete ptr; delete ref_count; &#125; &#125;&#125;; 5. shared_ptr 下的多线程问题shared_ptr对引用计数本身是线程安全的（C++11起）： 同一个shared_ptr的多个拷贝对象，在多个线程并发调用拷贝构造、赋值、析构时，不需要额外同步保护。 但对shared_ptr指向对象的访问本身并不保证线程安全： 如果多个线程访问同一个对象资源时，需要额外的锁机制保护资源本身： 1234567std::shared_ptr&lt;MyObject&gt; sp = std::make_shared&lt;MyObject&gt;();// OK：引用计数线程安全auto sp2 = sp; // 并发安全，无需锁// 需要额外保护：sp-&gt;modify(); // 若多个线程调用modify，必须额外加锁保护 简单总结： 行为 是否线程安全？ 说明 引用计数自身 是 内部使用原子操作 对象访问 否 需自行实现同步 6. GCC 编译流程 预处理、编译、汇编、链接 GCC的编译过程大致分四步： 预处理（Preprocessing）： 处理宏定义、条件编译、头文件展开。 命令示例：gcc -E main.c -o main.i 编译（Compilation）： 将预处理后的代码（.i文件）编译成汇编语言（.s文件）。 命令示例：gcc -S main.i -o main.s 汇编（Assembly）： 汇编代码转成二进制目标文件（.o文件）。 命令示例：gcc -c main.s -o main.o 链接（Linking）： 将一个或多个目标文件（.o）链接，合并成最终的可执行程序（a.out或其他指定文件名）。 命令示例：gcc main.o -o main 7. 可执行文件加载到内存里，其内存布局是怎样的？当可执行文件（如Linux ELF格式）加载到内存中运行时，其典型内存布局为： 从低地址到高地址顺序： 内存段 功能说明 代码段（text segment） 存放程序的机器指令（只读、可执行） 数据段（data segment） 已初始化的全局变量和静态变量 BSS段（bss segment） 未初始化或初值为零的全局变量和静态变量 堆（Heap） 动态分配的内存（由低地址向高地址增长） ↕️ （动态增长空间） 栈（Stack） 函数调用栈帧（由高地址向低地址增长） 具体示意图： 1234567891011121314+-----------------------------+ 高地址| 栈 Stack || ↓ 向下增长 || || || ↑ 向上增长 || 堆 Heap |+-----------------------------+| 未初始化数据 BSS (.bss) |+-----------------------------+| 初始化数据 Data (.data) |+-----------------------------+| 代码段 Text (.text) |+-----------------------------+ 低地址 代码段：函数指令 数据段：全局或静态变量（初值不为0） BSS段：全局或静态变量（初值为0或未初始化） 堆段：动态内存（malloc&#x2F;new） 栈段：函数调用的局部变量、调用返回地址、临时变量等 算法题：手撕 LRULeetCode LRU 缓存：https://leetcode.cn/problems/lru-cache/description/ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172struct Node &#123; int key; int value; Node* prev; Node* next; Node(int k = 0, int v = 0) : key(k), value(v) &#123;&#125;&#125;;class LRUCache &#123;private: Node* dummy; int capacity; unordered_map&lt;int, Node*&gt; key_to_node; void remove(Node* node) &#123; node-&gt;prev-&gt;next = node-&gt;next; node-&gt;next-&gt;prev = node-&gt;prev; &#125; void push_front(Node* node) &#123; node-&gt;prev = dummy; node-&gt;next = dummy-&gt;next; dummy-&gt;next-&gt;prev = node; dummy-&gt;next = node; &#125; Node* get_node(int key) &#123; if (!key_to_node.count(key)) &#123; return nullptr; &#125; Node* node = key_to_node[key]; remove(node); push_front(node); return node; &#125;public: LRUCache(int capacity) : capacity(capacity) &#123; dummy = new Node(); dummy-&gt;next = dummy; dummy-&gt;prev = dummy; &#125; int get(int key) &#123; Node* node = get_node(key); return node ? node-&gt;value : -1; &#125; void put(int key, int value) &#123; Node* node = get_node(key); if (node) &#123; node-&gt;value = value; return; &#125; node = new Node(key, value); if (key_to_node.size() == capacity) &#123; Node* last = dummy-&gt;prev; key_to_node.erase(last-&gt;key); remove(last); delete last; &#125; push_front(node); key_to_node[key] = node; &#125;&#125;;/** * Your LRUCache object will be instantiated and called as such: * LRUCache* obj = new LRUCache(capacity); * int param_1 = obj-&gt;get(key); * obj-&gt;put(key,value); */ 快手深广搜｜C++ 开发一面（挂）算法题：合并 K 个有序链表LeetCode: https://leetcode.cn/problems/merge-k-sorted-lists/description/ 123456789101112131415161718192021222324252627282930313233343536/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeKLists(vector&lt;ListNode*&gt;&amp; lists) &#123; auto cmp = [](const ListNode* a, const ListNode* b) &#123; return a-&gt;val &gt; b-&gt;val; &#125;; priority_queue&lt;ListNode*, vector&lt;ListNode*&gt;, decltype(cmp)&gt; pq; for (auto head : lists) &#123; if (head) &#123; pq.push(head); &#125; &#125; ListNode dummy&#123;&#125;; ListNode* cur = &amp;dummy; while (!pq.empty()) &#123; ListNode* nxt = pq.top(); pq.pop(); cur-&gt;next = nxt; cur = cur-&gt;next; if (nxt-&gt;next) &#123; pq.push(nxt-&gt;next); &#125; &#125; return dummy.next; &#125;&#125;; 时间复杂度 在使用最小堆（或优先队列）合并 K 个升序链表时，时间复杂度主要由以下两个部分组成： 初始化最小堆：将 K 个链表的头节点插入最小堆中。由于每次插入操作的时间复杂度为 O(logK)，因此这一步的总时间复杂度为 O(K logK)。 合并过程：在合并的过程中，需要进行 N 次插入和删除操作，其中 N 是所有链表节点的总数。每次插入和删除操作的时间复杂度均为 O(logK)，因此这部分的总时间复杂度为 O(N logK)。 综上，使用最小堆合并 K 个升序链表的总体时间复杂度为 $O(N logK)$。这种方法的优势在于利用最小堆高效地获取当前最小的节点，从而在合并过程中保持链表的有序性。 顺便复习下「堆排序」 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;// 调整堆，使以 start 为根的子树满足最大堆性质void maxHeapify(std::vector&lt;int&gt;&amp; arr, int start, int end) &#123; int dad = start; int son = dad * 2 + 1; // 左子节点索引 while (son &lt;= end) &#123; // 确保子节点在范围内 if (son + 1 &lt;= end &amp;&amp; arr[son] &lt; arr[son + 1]) // 选择较大的子节点 son++; if (arr[dad] &gt; arr[son]) // 如果父节点大于子节点，则调整完毕 return; else &#123; // 交换父子节点 std::swap(arr[dad], arr[son]); dad = son; son = dad * 2 + 1; &#125; &#125;&#125;// 堆排序主函数void heapSort(std::vector&lt;int&gt;&amp; arr) &#123; int len = arr.size(); // 构建最大堆 for (int i = len / 2 - 1; i &gt;= 0; i--) maxHeapify(arr, i, len - 1); // 进行排序 for (int i = len - 1; i &gt; 0; i--) &#123; std::swap(arr[0], arr[i]); // 将最大值交换到数组末尾 maxHeapify(arr, 0, i - 1); // 重新调整堆 &#125;&#125;int main() &#123; std::vector&lt;int&gt; arr = &#123;3, 5, 1, 8, 2, 7, 6, 4&#125;; heapSort(arr); for (int num : arr) std::cout &lt;&lt; num &lt;&lt; &quot; &quot;; std::cout &lt;&lt; std::endl; return 0;&#125; 项目问题 应用场景？ ART 索引的优势？ 考虑 PM 成本？ Vivo C&#x2F;C++ 嵌入式开发一面（挂） 介绍你的项目和实习 就问 OPPO 项目几个问题而已 怎么优化系统性能 合理使用缓存机制，如内存缓存、Redis 等 利用多线程或多进程技术，让更多的处理器核心参与计算，提升吞吐量 选择高效的算法和数据结构可以显著提升系统性能 编写高质量的代码，避免冗余计算，减少函数调用和内存分配，合理使用同步和异步操作 采用集群等高可用架构，避免单点故障，确保系统在高负载下仍能稳定运行 负载均衡，通过将请求分配到多台服务器上，避免单一服务器的性能瓶颈 使用消息队列实现高并发下的异步处理，削峰填谷，缓解系统压力 perf 工具查看系统性能瓶颈 开启编译优化 -O2、-O3 C++ 多态怎么实现：静态多态（重载，模板）、动态多态（继承与虚函数） C++11 新特性有哪些？ auto 变量自动类型推导、decltype 表达式自动类型推导 lambda 智能指针 move 右值引用 final、override 模板 nullptr 取代 NULL constexpr delete 范围 for 循环 列表初始化 … C++ class 和 C struct 的区别 默认权限：C struct public、C++ class private；同时 C 语言中不支持继承和多态 嵌入式系统的特点 工作中遇到复杂的问题，如何解决 反问：校招生没有嵌入式经验，会排斥吗 腾讯 CSIG 腾讯云｜后台开发一面（挂）1. 操作系统中对于物理内存是怎么做管理的？操作系统设计了虚拟内存，每个进程都有自己的独立的虚拟内存，我们所写的程序不会直接与物理内存打交道。 有了虚拟内存之后，它带来了这些好处： 第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。 第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。 Linux 是通过对内存分页的方式来管理内存，分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。 最初的内存管理采用固定分区或可变分区（最先适应分配算法、最优适应分配算法、最坏适应分配算法…） 之后才出现了分页、分段，与分区方式互斥 虚拟地址与物理地址之间通过页表来映射，如下图： 页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的工作。 而当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。缺页异常会触发 2. C++ 程序有一个全局变量，同时起两个进程跑，该全局变量的地址会一样吗？ 应该是考进程间的隔离性 不会一样：即虚拟地址可能一样（如果内存布局完全相同），但是物理地址一定不一样。 具体来说： 进程地址空间独立性： 每个进程都有自己独立的虚拟地址空间。同一个程序启动两次，实际上创建了两个不同的进程，每个进程都有各自的独立地址空间。因此，尽管程序本身是一样的，但两个进程里的全局变量地址是在它们各自的虚拟地址空间里分配的，地址可以看起来相同（因为虚拟地址的布局通常一样），但实际上对应不同的物理内存。 物理地址不同： 虽然可能两个进程中相同的变量虚拟地址看起来是一样的（比如在 Linux 中经常全局变量起始地址会是相似的，例如 0x601040），但实际上操作系统的内存管理机制会通过页表将相同虚拟地址映射到完全不同的物理内存上。 举例说明： 比如你定义了一个全局变量： 1int global_var = 10; 编译运行程序两次，会创建两个不同的进程，比如进程A、进程B。 进程A里：&amp;global_var &#x3D; 0x601040（虚拟地址） 进程B里：&amp;global_var &#x3D; 0x601040（虚拟地址） 表面上看起来一样，但它们实际上分别映射到不同的物理页中，实际在内存中的位置并不相同，彼此不会产生冲突。 3. 1G 物理内存，代码中申请 2G 内存块（malloc），同时起两个进程会发生什么？ 这是一个经典的面试问题，背后涉及虚拟内存管理、内存映射机制和缺页异常的知识。 简而言之：如果【物理内存 + Swap 分区】小于申请的内存大小，那么就有可能发生 OOM（假设没法回收旧页面），因为虚拟内存 &#x3D; 物理内存 + Swap 分区大小 物理内存（RAM）：1 GB 进程尝试申请：4 GB 内存 假设系统启用了 Swap，比如还有 2 GB 的 Swap 空间 问题是：还会发生 OOM 吗？ Linux 默认允许 overcommit，也就是说，即使系统没有足够物理内存+Swap，也可能“允许”你申请 4GB。但是等到真正**使用那块内存（写入）**的时候，系统发现分配不出来，就会发生 OOM。 你有 1GB RAM + 2GB Swap &#x3D; 3GB 实际可用虚拟内存。你请求了 4GB -&gt; 系统可能允许你分配，但用到第 3GB 时，系统发现真没空间了。 📛 此时如果： 没有更多 Swap； 没法换出其他内存页； 系统无法通过页面回收等手段分配新内存； → 就会触发 OOM，并且 Linux 会启用 OOM Killer 杀掉你进程，避免系统崩溃。 你是“申请”还是“实际写入”？这个差别很关键！ malloc &#x2F; new 只是申请，系统可能只是“画个圈”，并没有真的分配物理页（lazy allocation）； 只有当你写入内存时（触发页缺失），系统才真正分配页框，如果那时分配失败，才会 OOM。 总结： 你真的“写满”了这 4GB 内存； 而系统的 RAM + Swap 不足以支撑； 并且系统不能释放或交换出其他内存页； 那么最终还是会触发 OOM。 4. 对于这两个进程 malloc 出来的内存块首地址会不会一样？可能一样，也可能不一样，具体取决于操作系统和内存分配策略，但在大多数现代操作系统（比如 Linux）中，这两个进程 malloc 得到的内存块首地址通常是一样的。 为什么通常会一样？ 虚拟地址空间独立： 每个进程拥有独立的虚拟地址空间，因此两个进程可以有相同的虚拟地址，彼此之间不会冲突。这种机制叫虚拟地址空间隔离。 操作系统的内存映射规则： 现代操作系统（特别是 Linux）常使用相似的内存布局策略： 例如 Linux 下程序启动后的虚拟地址空间布局几乎一致： 123456789栈空间（高地址）↓堆空间（malloc/brk 向上增长）↓数据段/BSS段↓代码段↓操作系统内核（低地址） 因此，两个进程几乎同时启动后，其虚拟地址布局极为类似，两者用 malloc 申请的内存，很可能分配到同样的虚拟地址上。 虽然虚拟地址相同，但物理地址不同。每个进程的内存映射到不同的物理内存页，保证了进程间的内存隔离。 并不是100%一样，但一般来说非常常见： 如果内存布局完全相同（相同的程序、相同的运行环境、几乎同时启动），虚拟地址往往相同。 如果出现地址随机化（如 ASLR 技术打开），地址可能稍微不同。 5. 进程进行了一次 read 操作，请你说一下这个过程？ 🔥 追加问题： 1️⃣ 用户态转换为内核态，细节一些，怎么转的？ 2️⃣ 我就写了个 read，也没写其他东西，他是怎么调用内核代码的？ 3️⃣ 你有办法在用户态写代码去读文件吗，不调用库函数的情况下？ 不用标准库，只用 syscall，你可以不调用 glibc 的 read()，而是自己写 syscall 汇编代码来触发系统调用 用户态 I&#x2F;O 提供了 UIO， 4️⃣ 或者你认为底层在读写文件时实际上在操作什么东西？ 实际上，文件描述符只是用户态的一个索引，它指向内核中的 file 结构。而真正底层在操作的是文件系统定位出的磁盘块，通过驱动发起 DMA（DMA 控制器来搬运数据），把这些块从硬件搬到内存的页缓存中。所以底层操作的实际是设备上的数据块，而不是文件描述符本身。 5️⃣ 最后怎么让你的硬件设备把文件弄到内存里？ 通过系统调用，触发内核层级联动，最终驱动告诉 DMA 控制器去读磁盘扇区，把数据搬到内存中。 程序的内存分布，其中包括内核空间（在内存中），联想一下即可理解。 read 操作全流程一、进程发起 read 调用 用户态进程想要从文件、管道、网络套接字、或设备中读取数据时，通常会调用系统调用（read()）： 1ssize_t read(int fd, void *buf, size_t count); 进程将准备好参数： 文件描述符 fd（指明从哪里读） 缓冲区指针 buf（读入到哪里） 读取字节数 count（读入多少） 二、用户态到内核态的切换（陷入内核） 调用read函数后，C库(glibc) 会触发一个CPU陷入内核（trap）操作： 具体实现一般是通过syscall指令或中断机制（例如int 0x80或sysenter/syscall指令）。 CPU权限级别从用户态（ring3）切换到内核态（ring0）。 内核从用户态堆栈取出系统调用号（表示read）和参数。 此时进入内核态。 三、内核态的系统调用处理流程 进入内核后，系统调用处理例程开始运行： 保存上下文：内核会保存用户态的寄存器环境到内核堆栈，以便调用结束后能够恢复用户态现场。 参数检查和解析 检查文件描述符（fd）是否有效。 检查缓冲区地址buf是否是合法用户空间地址。 检查读取的字节数是否合理（不能超过系统限制等）。 根据文件描述符找到内核文件结构 内核根据fd从进程的文件描述符表中找到对应的文件结构（file结构）。 根据文件结构再找到具体的设备或文件的操作方法集（file_operations结构）。 四、具体数据的读取操作 内核确定文件类型后，调用具体设备或文件系统的read函数。 如果是普通文件： 内核从进程对应的文件偏移位置（file position）开始，调用文件系统的read方法，从文件缓存（page cache）或磁盘读取数据。 如果数据不在内存（Page Cache 是 Linux 内核用来缓存磁盘文件内容的一块内存区域），就会触发页面缓存缺页： 内核调用磁盘驱动程序，通过DMA方式把数据从磁盘读入内存缓存。 进程会进入阻塞状态，等待数据从磁盘读入内存完成。 DMA完成后产生磁盘I&#x2F;O中断，唤醒进程继续执行。 内核将数据从内核缓冲区（page cache）拷贝到用户空间提供的缓冲区buf中。 如果是网络socket或管道等： 内核检查管道或socket缓冲区是否已有数据。 如果没有数据，进程通常阻塞在wait queue（等待队列）上，等待数据到达。 数据到达后，内核再将数据从内核态缓冲区拷贝到用户态缓冲区。 五、内核态到用户态的返回（返回用户态） 数据拷贝完成，系统调用返回时： 内核将读取到的字节数返回给调用进程（作为read返回值）。 如果读取出错，则返回负数并设置对应的错误码（errno）。 内核恢复之前保存的用户态寄存器上下文。 CPU从内核态返回用户态（通过iret、sysret等特殊指令），进程恢复执行。 如何在不调用库函数的情况下，对硬件设备进行读写？👉 可以不调用标准库函数（如read、fread），但： 你不能绕过系统调用本身。 因为 读文件必须依赖内核提供的能力（文件系统访问、设备 I&#x2F;O），这些都是用户态无法直接访问的。 方法一：不用标准库，只用 syscall，你可以不调用 glibc 的 read()，而是自己写 syscall 汇编代码来触发系统调用： 示例（x86_64 Linux 下） 123456789101112131415161718192021#include &lt;unistd.h&gt;#include &lt;sys/syscall.h&gt;#include &lt;fcntl.h&gt;int main() &#123; char buf[100]; // open 文件 int fd = syscall(SYS_open, &quot;test.txt&quot;, O_RDONLY); // 读文件 long n = syscall(SYS_read, fd, buf, 100); // 写到 stdout syscall(SYS_write, 1, buf, n); // 关闭文件 syscall(SYS_close, fd); return 0;&#125; 🔸这里你没用 read()、open() 等库函数，完全绕过了 glibc，只用 syscall。 底层其实还是通过 syscall 指令陷入内核，所以你仍然走的是： 用户态 → 内核态 → 文件系统 → 块设备 → 驱动 → 硬件 这条链路。 方法二：手写汇编 syscall（进一步硬核） 你甚至可以直接写汇编触发 syscall： 12345mov rax, 0 ; SYS_readmov rdi, fd ; 参数1: 文件描述符mov rsi, buf ; 参数2: 缓冲区mov rdx, 100 ; 参数3: 字节数syscall ; 执行系统调用 可以嵌入到 C 中用 asm 关键字，或者纯汇编实现。但本质仍然是调内核提供的功能。 完整的内核 I&#x2F;O 链路内核中的 I&#x2F;O 链路是一个比较复杂的流程，涉及到从系统调用层到驱动程序再到硬件控制器，最终完成数据交换。下面用详细且清晰的方式完整描述一下 Linux 内核中典型的 I&#x2F;O 链路（以磁盘读写为例）： 用户进程发起 I&#x2F;O 请求 ⬇️ 系统调用层（如read()&#x2F;write()） ⬇️ 虚拟文件系统层 (VFS) ⬇️ 具体文件系统层（如 ext4、xfs） ⬇️ 块设备层（Block Layer） ⬇️ I&#x2F;O 调度层（如 CFQ、Deadline、noop） ⬇️ 通用块设备接口（Generic Block Layer） ⬇️ 设备驱动层（如 SATA、NVMe 驱动） ⬇️ 硬件接口层（设备控制器，如 AHCI 控制器） ⬇️ 硬件设备（磁盘、SSD 等物理设备） ⬇️ 设备执行完成，产生硬件中断通知 CPU ⬇️ 内核中断处理程序完成后续动作（如唤醒进程） 🔥 下面是一个完整的、详细的 I&#x2F;O 请求处理链路（以一次文件读取操作为例）： （1）用户进程发起系统调用 用户程序调用标准库函数：read(fd, buf, count); 陷入内核态，内核获取调用参数。 （2）系统调用层 (sys_read) 内核调用 sys_read： 检查文件描述符有效性； 获取内核的文件结构体（struct file）。 （3）虚拟文件系统层 (VFS) 内核通过 VFS 层调用文件对应的操作函数，调用对应文件系统的 read 方法：file-&gt;f_op-&gt;read_iter(...) （4）具体文件系统层（如 ext4） 文件系统层通过文件的 inode 结构确定要读取的数据位于哪些逻辑块。 文件系统根据 inode 中的映射结构确定物理磁盘上的位置（磁盘扇区号）。 （5）块设备层（Block Layer） 文件系统调用块设备接口（bio 接口）发起数据请求。 此时内核创建一个 bio 结构体 表示一次 I&#x2F;O 请求：submit_bio() 块设备层对 bio 进行进一步封装，形成更底层的 request 结构。 （6）I&#x2F;O 调度层（IO Scheduler） request 进入 I&#x2F;O 调度器队列，常见调度器如： CFQ（Completely Fair Queueing，完全公平队列） Deadline noop BFQ（新版本） I&#x2F;O 调度器决定请求的先后顺序，进行排序和合并优化，减少磁盘寻道延迟。 （7）通用块设备接口（Generic Block Layer） I&#x2F;O 调度器调度好的请求传入通用块设备层。 通用块设备层对请求做进一步通用处理，比如： 合并相邻请求 分发到具体的设备驱动 （8）设备驱动层（Device Driver） 通用块设备接口将 request 分发给具体驱动，比如： SATA 磁盘驱动 (ahci.ko) NVMe 驱动 (nvme.ko) 驱动程序将 request 翻译成硬件控制器能理解的指令集： 对于磁盘：ATA&#x2F;SCSI 命令 对于 NVMe：NVMe 命令 驱动程序将命令写入设备控制器寄存器，触发 DMA（直接内存访问）数据传输。 （9）硬件接口层（设备控制器） 硬件控制器（如 AHCI 控制器）根据命令从物理磁盘读取数据： 控制磁盘机械臂移动，进行磁道寻址； 寻道完成后，读取数据到控制器缓存； 通过 DMA 把数据传输到内存中的内核缓冲区（Page Cache）。 （10）硬件设备完成数据传输（DMA） DMA 数据传输完成后，硬件设备发起硬件中断通知 CPU，表示操作完成。 （11）中断处理流程（Interrupt Handler） CPU 响应硬件中断，内核执行相应中断处理程序： 确认硬件完成状态； 标记 request 已经完成； 唤醒阻塞在此请求上的进程或任务（如被阻塞的 read 调用）。 （12）返回数据到用户进程 唤醒进程后，内核从内核缓冲区（Page Cache）将数据拷贝到用户空间缓冲区。 系统调用返回，用户进程继续执行。 ⚡ 三、几个关键的数据结构： bio：表示一次块设备的 I&#x2F;O 请求，描述了内存中的缓冲区、目标设备扇区等信息。 request：更底层的结构，描述了请求的具体物理扇区位置和传输数据量。 request_queue：存放 request 的队列，由 I&#x2F;O 调度器管理。 📌 四、再总结一次链路精简版： 12345678910111213141516171819202122232425用户进程read ↓内核sys_read() ↓VFS虚拟文件系统 ↓文件系统(ext4等) ↓块设备层 (bio) ↓I/O调度层(request) ↓通用块设备层 ↓设备驱动程序（SATA/NVMe） ↓硬件接口控制器（AHCI） ↓物理硬件磁盘（DMA） ↓硬件中断（通知内核） ↓内核中断处理程序 ↓唤醒进程，数据拷贝回用户空间 算法题146. LRU 缓存123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172struct Node &#123; int key; int value; Node* prev; Node* next; Node(int k = 0, int v = 0) : key(k), value(v) &#123;&#125;&#125;;class LRUCache &#123;private: Node* dummy; int capacity; unordered_map&lt;int, Node*&gt; key_to_node; void remove(Node* node) &#123; node-&gt;prev-&gt;next = node-&gt;next; node-&gt;next-&gt;prev = node-&gt;prev; &#125; void push_front(Node* node) &#123; node-&gt;prev = dummy; node-&gt;next = dummy-&gt;next; dummy-&gt;next-&gt;prev = node; dummy-&gt;next = node; &#125; Node* get_node(int key) &#123; if (!key_to_node.count(key)) &#123; return nullptr; &#125; Node* node = key_to_node[key]; remove(node); push_front(node); return node; &#125;public: LRUCache(int capacity) : capacity(capacity) &#123; dummy = new Node(); dummy-&gt;next = dummy; dummy-&gt;prev = dummy; &#125; int get(int key) &#123; Node* node = get_node(key); return node ? node-&gt;value : -1; &#125; void put(int key, int value) &#123; Node* node = get_node(key); if (node) &#123; node-&gt;value = value; return; &#125; node = new Node(key, value); if (key_to_node.size() == capacity) &#123; Node* last = dummy-&gt;prev; key_to_node.erase(last-&gt;key); remove(last); delete last; &#125; push_front(node); key_to_node[key] = node; &#125;&#125;;/** * Your LRUCache object will be instantiated and called as such: * LRUCache* obj = new LRUCache(capacity); * int param_1 = obj-&gt;get(key); * obj-&gt;put(key,value); */ 24. 两两交换链表中的节点123456789101112131415161718192021222324252627282930/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* swapPairs(ListNode* head) &#123; if (!head) return head; ListNode dummy(0, head); ListNode* node0 = &amp;dummy; ListNode* node1 = head; while (node1 &amp;&amp; node1-&gt;next) &#123; ListNode* node2 = node1-&gt;next; ListNode* node3 = node2-&gt;next; node2-&gt;next = node1; node1-&gt;next = node3; node0-&gt;next = node2; node0 = node1; node1 = node3; &#125; return dummy.next; &#125;&#125;; 腾讯 WXG 企业微信｜测试开发一面（挂）0. 业务介绍base：广州 测试开发岗位（前后端都需要会）：用例管理平台、脑图承载、多端协同编辑、管理业务&#x2F;研发&#x2F;测试进度、增量测试、覆盖率、基于大模型自动化测试的工具、版本用户量大需要压测 0. 简历拷打 —— 项目有什么难点吗？这点需要优化到后续的回答中… 1. C++ 虚函数虚函数（virtual function）是为了实现 多态 而设计的。基类使用 virtual 关键字修饰成员函数，派生类可以重写该函数，在运行时根据对象的实际类型决定调用哪个函数。 特点： 虚函数支持运行时动态绑定。 基类析构函数如果有派生类，必须定义为虚函数，否则析构时可能不会调用派生类析构函数，导致资源泄露。 虚函数表（vtable）和虚表指针（vptr）是实现机制。 2. new 和 malloc 的区别，二者类型安全吗？ 特性 new malloc 语言 C++ C 返回类型 类型安全，返回实际类型指针 void*，需强转 调用构造函数 ✅ ❌ 内存分配失败 抛出异常 bad_alloc 返回 NULL 可重载 ✅（可自定义 new&#x2F;delete） ❌ 对象生命周期 构造 + 析构 仅内存分配 类型安全： new 是类型安全的，返回类型是分配对象的实际类型指针。 malloc 不是类型安全的，返回 void*。 3. C++ 多线程一般怎么去实现？使用 &lt;thread&gt; 头文件中的 std::thread 类可以很方便地创建并管理线程。 常用方式： 12345678910#include &lt;thread&gt;void func() &#123; // 执行任务&#125;int main() &#123; std::thread t(func); t.join(); // 等待线程结束&#125; 4. C++ 用什么创建线程?主要方式有： std::thread（C++11 起） std::async（用于异步任务） 低级：pthread（POSIX 多线程，平台相关） 高级库：Boost.Thread，Intel TBB 等 最推荐现代 C++ 使用 std::thread。 5. 同步机制怎么做的？主要有以下几种方式： 同步方式 用法 std::mutex 互斥锁，用于保护共享资源 std::lock_guard 自动管理锁，RAII 风格，防止忘记 unlock std::unique_lock 可灵活 unlock&#x2F;lock，支持条件变量等待 std::condition_variable 线程等待与唤醒 std::atomic 原子变量，避免使用锁的轻量级同步 6. 条件变量的使用场景有哪些？条件变量适用于： 生产者消费者模型 线程等待某个状态满足（如缓冲区非空） 资源准备就绪通知 关键点： 需要搭配 std::unique_lock&lt;std::mutex&gt; 使用。 使用 wait() 挂起线程，notify_one() 或 notify_all() 唤醒。 7. C++ 实现生产者消费者场景（多生产者多消费者）123456789101112131415161718192021222324252627282930313233#include &lt;queue&gt;#include &lt;mutex&gt;#include &lt;thread&gt;#include &lt;condition_variable&gt;#include &lt;iostream&gt;std::queue&lt;int&gt; buffer;const unsigned int max_size = 10;std::mutex mtx;std::condition_variable cv;void producer(int id) &#123; int val = 0; while (true) &#123; std::unique_lock&lt;std::mutex&gt; lock(mtx); cv.wait(lock, [] &#123; return buffer.size() &lt; max_size; &#125;); buffer.push(val++); std::cout &lt;&lt; &quot;Producer &quot; &lt;&lt; id &lt;&lt; &quot; produced: &quot; &lt;&lt; val &lt;&lt; &quot; &quot;; lock.unlock(); cv.notify_all(); &#125;&#125;void consumer(int id) &#123; while (true) &#123; std::unique_lock&lt;std::mutex&gt; lock(mtx); cv.wait(lock, [] &#123; return !buffer.empty(); &#125;); int val = buffer.front(); buffer.pop(); std::cout &lt;&lt; &quot;Consumer &quot; &lt;&lt; id &lt;&lt; &quot; consumed: &quot; &lt;&lt; val &lt;&lt; &quot; &quot;; lock.unlock(); cv.notify_all(); &#125;&#125; 8. 代码中用什么来实现互斥资源量？✅ 1. 封装成类（推荐）把资源数量和互斥量封装到一个类里，避免污染全局命名空间，同时更清晰、更安全。 12345678910111213141516171819202122232425262728#include &lt;mutex&gt;#include &lt;iostream&gt;class ResourcePool &#123;public: explicit ResourcePool(int total) : count(total) &#123;&#125; bool acquire(int id) &#123; std::lock_guard&lt;std::mutex&gt; lock(mtx); if (count &gt; 0) &#123; --count; std::cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot; acquired. Remaining: &quot; &lt;&lt; count &lt;&lt; &quot; &quot;; return true; &#125; std::cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot; failed to acquire. &quot;; return false; &#125; void release(int id) &#123; std::lock_guard&lt;std::mutex&gt; lock(mtx); ++count; std::cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot; released. Remaining: &quot; &lt;&lt; count &lt;&lt; &quot; &quot;; &#125;private: int count; std::mutex mtx;&#125;; 然后在主线程或线程函数中创建并传入对象引用或智能指针： 123456void worker(ResourcePool&amp; pool, int id) &#123; if (pool.acquire(id)) &#123; std::this_thread::sleep_for(std::chrono::milliseconds(200)); pool.release(id); &#125;&#125; 这样你就可以灵活控制资源池了，而且没有全局变量。 ✅ 2. 使用 std::shared_ptr 或 std::unique_ptr 管理资源池实例避免手动管理生命周期： 12auto pool = std::make_shared&lt;ResourcePool&gt;(5);std::thread t1(worker, std::ref(*pool), 1); ✅ 3. 用 std::counting_semaphore（C++20）代替资源变量+锁如果你只关心控制同时访问资源数量，C++20 的 std::counting_semaphore 更优雅： 12345678910111213#include &lt;semaphore&gt;#include &lt;iostream&gt;#include &lt;thread&gt;std::counting_semaphore&lt;5&gt; sem(5); // 初始5个资源void worker(int id) &#123; sem.acquire(); std::cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot; acquired resource &quot;; std::this_thread::sleep_for(std::chrono::milliseconds(200)); std::cout &lt;&lt; &quot;Thread &quot; &lt;&lt; id &lt;&lt; &quot; releasing resource &quot;; sem.release();&#125; 不用手动管理 mutex，也不用资源计数变量，线程会自动阻塞在 acquire()，直到有资源可用。 9. 线程 thread_local 的作用是什么？ 它是线程单独拥有的资源，没办法作为共享资源 thread_local 是 C++11 引入的存储类型说明符，用于为每个线程创建独立的变量副本。 使用场景： 每个线程都需要使用一个自己的变量（如缓存、计数器等），避免同步。 类似于线程的“全局变量”，但互不干扰。 示例： 1thread_local int counter = 0; ✅ 示例场景：日志系统中用 thread_local 缓存上下文 在多线程程序中，很多系统会给每个线程维护一份独立的日志信息，比如线程 ID、调用栈、临时日志缓存等。如果所有线程都用一个共享变量，会导致锁竞争、效率低下。 这时候就可以用 thread_local 给每个线程一份独立副本！ 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;string&gt;class Logger &#123;public: static void log(const std::string&amp; message) &#123; log_context += message + &quot; &quot;; &#125; static void flush() &#123; std::cout &lt;&lt; &quot;[Thread &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot;] &quot;; std::cout &lt;&lt; log_context &lt;&lt; std::endl; log_context.clear(); &#125;private: static thread_local std::string log_context; // 每个线程一份&#125;;thread_local std::string Logger::log_context;void thread_task(int id) &#123; Logger::log(&quot;Start work in thread &quot; + std::to_string(id)); Logger::log(&quot;Doing some work...&quot;); Logger::log(&quot;Finish work in thread &quot; + std::to_string(id)); Logger::flush();&#125;int main() &#123; std::thread t1(thread_task, 1); std::thread t2(thread_task, 2); t1.join(); t2.join(); return 0;&#125; 10. static 关键字作用？在 C++ 中，static 有不同作用： 函数内局部变量：静态存储，生命周期贯穿整个程序（只初始化一次）。 类的成员变量：属于类，而非对象，所有对象共享。 函数或变量（全局作用域）：限制作用域为当前文件（编译单元），实现内部链接。 类外静态变量：通常用于全局资源池、计数器等。 11. 死锁产生的条件是什么？经典的 死锁四条件（同时满足才可能死锁）： 互斥：资源不能共享。 占有并等待：线程持有资源，同时等待其他资源。 不剥夺：资源不能被强制释放。 循环等待：多个线程形成资源请求的环路。 解决思路：破坏其中任何一个条件即可。 12. 进程间通信的方式有哪些？你用过哪些？常见 IPC 方式： 方式 特点 管道（pipe）&#x2F;命名管道（FIFO） 简单、高效，适合父子进程 消息队列（msg queue） 类似任务队列，适合异步通信 共享内存（shm） 最快，直接访问同一内存区域，需加锁 信号量 控制资源访问（同步） 套接字（socket） 支持不同主机&#x2F;网络通信 mmap 映射共享文件到多个进程内存空间 你用过哪个取决于你开发的系统场景，比如服务端常用 socket，系统编程多用 pipe、shm、semaphore。 13. 多进程使用场景？Web服务器（如 nginx 的 worker） 数据库服务（PostgreSQL） 守护进程（如 init、cron） 高可靠性要求（一个崩了不影响其他） 分布式调度框架（如 Hadoop 的 Task） 14. 多线程使用场景？计算密集型并发（CPU 多核加速） I&#x2F;O 密集型任务并发（如网络请求处理） GUI 线程 + 后台线程分工 游戏引擎（渲染、物理计算、AI 并发执行） 15. 进程与线程的区别？ 比较项 进程 线程 内存空间 独立 共享（如堆） 创建开销 大 小 通信方式 IPC 共享内存即可 崩溃影响 互不影响 一个线程崩溃可能导致整个进程崩溃 调度粒度 粗 细 16. 进程上下文切换会发生什么？发生切换时操作系统会： 保存当前进程的寄存器、程序计数器、栈指针等 CPU 状态（上下文） 更新 PCB（进程控制块） 加载目标进程的上下文，恢复 CPU 状态 更新内存页表（虚拟地址） 这是一个非常重的操作（相对线程切换）。 17. 查询发现 SQL 慢查询，怎么处理？ 🔥 可以参考链接：”慢SQL”治理的几点思考 给你张表，发现查询速度很慢，你有那些解决方案？ 子问题：怎么知道有没有建索引？ 子问题：怎么判断索引是否被使用？ 分析查询语句：使用 EXPLAIN 命令分析 SQL 执行计划，找出慢查询的原因，比如是否使用了全表扫描，是否存在索引未被利用的情况等，并根据相应情况对索引进行适当修改。 创建或优化索引：根据查询条件创建合适的索引，特别是经常用于 WHERE 子句的字段、Orderby 排序的字段、Join 连表查询的字典、group by 的字段，并且如果查询中经常涉及多个字段，考虑创建联合索引，使用联合索引要符合最左匹配原则，不然会索引失效 避免索引失效：比如不要用左模糊匹配、函数计算、表达式计算等等。 查询优化：避免使用 SELECT *，只查询真正需要的列；使用覆盖索引，即索引包含所有查询的字段；联表查询最好要以小表驱动大表，并且被驱动表的字段要有索引，当然最好通过冗余字段的设计，避免联表查询。 **分页优化：**针对 limit n,y 深分页的查询优化，可以把Limit查询转换成某个位置的查询：select * from tb_sku where id&gt;20000 limit 10，该方案适用于主键自增的表， 优化数据库表：如果单表的数据超过了千万级别，考虑是否需要将大表拆分为小表，减轻单个表的查询压力。也可以将字段多的表分解成多个表，有些字段使用频率高，有些低，数据量大时，会由于使用频率低的存在而变慢，可以考虑分开。 使用缓存技术：引入缓存层，如Redis，存储热点数据和频繁查询的结果，但是要考虑缓存一致性的问题，对于读请求会选择旁路缓存策略，对于写请求会选择先更新 db，再删除缓存的策略。 GPT: 使用 EXPLAIN 分析执行计划 看是否走了索引？是否全表扫描？ 添加合适的索引（前缀、联合索引） 拆分复杂 SQL（子查询、JOIN） 规范字段类型（不要 varchar vs int 比较） 分库分表、缓存热点数据 数据量大时考虑归档冷数据 18. 索引底层数据结构是什么？大多数数据库（如 MySQL InnoDB）使用的是 B+ 树 19. 为什么用 B+ 树而不是哈希表？ 对比项 B+ 树 哈希表 有序查询 ✅ ❌ 范围查询 ✅ ❌ 最小&#x2F;最大值查询 ✅ ❌ 磁盘友好 ✅ ❌（哈希冲突+链表） 空间利用率 ✅ 可能很低（冲突链表） 哈希适合精准匹配，B+ 树适合数据库查询场景 20. B+ 树怎么存这些数据？所有数据都存在叶子节点（不同于 B 树） 叶子节点通过指针相连，支持范围查询 非叶子节点只存索引 key，不存数据（占内存小） 多路搜索树，分支因子高，减少磁盘 IO 次数 21. 访问一个网页，中间会发生什么过程？输入 URL 浏览器查找缓存，若无发起 DNS 查询 DNS 解析出 IP 地址 建立 TCP 连接（可能含 TLS 握手） 发送 HTTP&#x2F;HTTPS 请求 服务器处理、返回响应 浏览器渲染页面，解析 HTML&#x2F;CSS&#x2F;JS 发起后续资源请求（图片、脚本等） 22. 如果响应很慢，可能在哪个环节出现问题？ 阶段 问题可能 DNS 解析慢、DNS 池老化 TCP 连接 三次握手慢 TLS 握手 证书链、密钥协商慢 服务器响应 数据库慢、CPU 高负载、缓存未命中 网络 丢包、拥堵 浏览器渲染 JS 执行慢、资源大、阻塞 23. I&#x2F;O 多路复用（select、poll、epoll）I&#x2F;O 多路复用是一种在单个线程中同时监听多个文件描述符（fd）的方法，在非阻塞 I&#x2F;O 模型中广泛使用，例如网络服务器中同时监听多个 socket 的可读&#x2F;可写事件。 常见的三种 I&#x2F;O 多路复用方式 技术 特点 系统调用 文件描述符数量限制 通知机制 select 最早的接口，简单 select() 有（FD_SETSIZE，默认1024） 遍历全部 fd poll 改进了 fd 数量限制 poll() 无限制（理论上） 遍历全部 fd epoll 高效，Linux 专属 epoll_create &#x2F; epoll_wait 几乎无限制 事件驱动（回调机制） 🥇1. select 工作原理 参数是一个fd 集合（数组），用 bitmap 表示。 每次调用 select() 都要重新传入 fd 集合。 内核遍历这个集合，检测哪些 fd 准备就绪。 成本：线性扫描 + 拷贝开销大。 代码示例： 1234fd_set read_fds;FD_ZERO(&amp;read_fds);FD_SET(sock_fd, &amp;read_fds);select(maxfd + 1, &amp;read_fds, NULL, NULL, NULL); 🥈2. poll 工作原理 传入一个 pollfd[] 数组。 没有 fd 数量上限限制，但还是要遍历全部 fd。 每次都要传入整个数组，重复系统调用，效率不高。 代码示例： 1234struct pollfd fds[10];fds[0].fd = sock_fd;fds[0].events = POLLIN;poll(fds, nfds, timeout); 🥇🥇3. epoll 工作原理（Linux 专属，最常用） 提供三大函数： epoll_create()：创建 epoll 实例 epoll_ctl()：注册&#x2F;修改&#x2F;删除监听的 fd epoll_wait()：阻塞等待事件发生 核心优势是：事件通知机制（event-driven），不像前面两个要轮询。 内核维护一个就绪队列，只返回活跃 fd。 epoll 的两种触发模式： 模式 特点 应用建议 LT（Level Trigger） 默认，状态还在就继续通知 简单，适合多数场景 ET（Edge Trigger） 状态变化才通知一次，必须把数据一次读完 性能高，但使用复杂，需要非阻塞 IO epoll 示例代码： 123int epfd = epoll_create(1024);epoll_ctl(epfd, EPOLL_CTL_ADD, sock_fd, &amp;event);epoll_wait(epfd, events, MAX_EVENTS, timeout); 📊 性能对比（大致） 接口 大量连接场景下性能 fd 扫描 内核空间到用户空间拷贝 select 差 需要全量扫描 是 poll 一般 需要全量扫描 是 epoll 优 事件通知，无需扫描 否（一次事件返回多个 fd） ✅ epoll 使用建议 所有 socket 设置为 非阻塞（O_NONBLOCK） ET 模式下必须 循环读取&#x2F;写入直到返回 EAGAIN 最常用于高并发网络服务（如 nginx、redis、netty） 🚀 小结对比 特性 select poll epoll 平台支持 跨平台 跨平台 Linux 专属 fd 限制 有 无 无 触发机制 水平触发 水平触发 支持边缘 &#x2F; 水平 性能 差（fd 多时） 一般 高 使用复杂度 简单 简单 略高（注册 + wait） 🧠 真实应用场景 select：老旧兼容系统、简单网络工具（不推荐新项目用） poll：稍大系统、兼容跨平台库（如 libevent） epoll：高并发服务端框架（nginx、redis、libuv、netty） 24. 如果 HTTPS 握手失败，你怎么分析原因？抓包分析（Wireshark） 检查证书链是否完整（浏览器或 openssl s_client） 检查时间是否同步 TLS 协议版本是否兼容（客户端&#x2F;服务器） CipherSuite 不兼容 服务器是否强制 SNI &#x2F; HTTP&#x2F;2 支持问题 25. 如果证书过期，会有什么表现？浏览器提示安全警告（NET::ERR_CERT_DATE_INVALID） curl、API 请求失败，显示证书验证失败 客户端拒绝建立 TLS 连接 HTTPS 请求直接失败或被降级为 HTTP（极少数） 算法题415. 字符串相加123456789101112131415161718class Solution &#123;public: string addStrings(string num1, string num2) &#123; int i = num1.length() - 1, j = num2.length() - 1, add = 0; string ans = &quot;&quot;; while (i &gt;= 0 || j &gt;= 0 || add) &#123; int x = i &gt;= 0 ? num1[i] - &#x27;0&#x27; : 0; int y = j &gt;= 0 ? num2[j] - &#x27;0&#x27; : 0; int result = x + y + add; ans.push_back(&#x27;0&#x27; + result % 10); add = result / 10; i--; j--; &#125; reverse(ans.begin(), ans.end()); return ans; &#125;&#125;; 230. 二叉搜索树中第 K 小的元素1234567891011121314151617class Solution &#123;public: vector&lt;int&gt; ans; void preOrder(TreeNode* node) &#123; if (node == nullptr) return; preOrder(node-&gt;left); ans.push_back(node-&gt;val); preOrder(node-&gt;right); &#125; int kthSmallest(TreeNode* root, int k) &#123; preOrder(root); return ans[k - 1]; &#125;&#125;; 354. 俄罗斯套娃信封问题贪心 + 二分查找：先排序，再按照 LIS 二分贪心模板求最长递增子序列。 因为二者都必须是递增的，所以第二维度需要逆序排序，使得第一维度相同的多个数，最后一个插入的一定是最小值，这样能嵌套的信封最多。 DP 会超时 123456789101112131415161718class Solution &#123;public: int maxEnvelopes(vector&lt;vector&lt;int&gt;&gt;&amp; envelopes) &#123; sort(envelopes.begin(), envelopes.end(), [](const auto&amp; a, const auto&amp; b) &#123; return a[0] &lt; b[0] || (a[0] == b[0] &amp;&amp; a[1] &gt; b[1]); &#125;); vector&lt;int&gt; g; for (auto&amp; e : envelopes) &#123; auto it = lower_bound(g.begin(), g.end(), e[1]); if (it == g.end()) &#123; g.push_back(e[1]); &#125; else &#123; *it = e[1]; &#125; &#125; return g.size(); &#125;&#125;; 美图基础架构｜C++ 开发（基础架构）一面（拒）主要问项目相关的内容，他自身也没提问八股文相关的知识，主要做「预研」，遂拒。 卓驭智驾端到端｜C&#x2F;C++ 嵌入式开发（OC）一面1. 项目拷打这部分问得比较细致 OPPO：ioctl 调用了哪些函数、你做了哪些工作 中科院软件所：evenodd 实现 PM 项目：为什么用 art 替代 bucket，有什么好处（之后记得去看下性能指标提升多少 —— 参考其他论文） 2. C 语言 static 关键字… 3. C 语言如何实现结构体？… 4. C++ 如何防止内存泄露？1️⃣ 代码规范，智能指针或 RAII 机制管理资源 2️⃣ 正确捕获处理异常&#x2F;回滚式编程 3️⃣ 弱引用解决循环引用问题造成的内存泄露 5. C++ 智能指针？… 6. C++ 有哪些构造函数？… 7. C++ 的构造函数可以是虚函数吗？… 8. ++a 和 a++ 的区别？… 9. 深拷贝和浅拷贝的区别？… 10. C++ 11 的新特性… 11. 如何实现多线程？… 12. 进程与线程的区别？… 字节跳动｜推荐架构系统实习生一面简历主要简单聊了聊重删的分块算法 算法题v1 = [2,2,2,2,2,3,3,3]、v2 = [4,4,4,5,5,5,6,6] 压缩表示： v1 = &#123;&#123;2,5&#125;,&#123;3,3&#125;&#125;、v2 = &#123;&#123;4,3&#125;,&#123;5,3&#125;,&#123;6,2&#125;&#125; 向量如何压缩表示 乘积、如何优化（非逐步，取二者个数最小值）、不修改原数组怎么实现（双指针） 时间复杂度 反问环节 业务：抖音视频推荐、C++ 二面（挂） 项目中遇到最难的问题 用代码描述整个流程 腾讯 CSIG 腾讯云｜后台开发一面（挂）在线笔试，见笔试复盘文档📄：腾讯 CSIG 一面·笔试题 字节跳动 AML 应用机器学习（未投）… 华为计算产品线｜软件开发（池子泡死）机试 开发一个简单任务调度系统 地震救灾路线 云计算服务器 GPU 分配 技术面绩点排名、竞赛得奖情况 四次奖学金是本科还是研究生 智能指针 排序算法（快排、堆排、归排 二叉树的前中后序遍历 … LeetCode 中等题 主管面自我介绍（过于简洁） 项目拷打（OPPO + 之江实验室）： oppo 业界最新解决方案 之江实验室 和 中科院哪个实习人数较多 之江实验室做了什么工作 项目中遇到最大的挑战，如何解决 团队协作遇到冲突怎么处理 论文阅读量有多少 遇到新知识如何快速上手 平时如何调节压力 对华为价值观的理解 你的性格是乐观还是悲观 反问： 华为实习生培养制度 计算产品线的技术栈 字节跳动基础架构｜后端开发实习生 IaaS一面（挂） 组内做「数据库内核、存储引擎」相关的 拷打简历项目（非常感兴趣 —— 前缀树、） C++ 八股：线程、锁、条件变量、存储相关、各层访问时间和访问粒度大小、I&#x2F;O relative… 手撕 148. 排序链表：太久没撕了，20 分钟磕磕绊绊大致撕出来，还 coredump 了… 1. 引用传递和指针传递的区别指针：存储变量的内存地址，可以为空（nullptr），需要通过解引用操作符*访问指针指向的值。指针可以在运行时重新指向不同的对象。指针可以有多级。 引用：是变量的别名，必须在初始化时绑定到一个有效的对象，且绑定后无法更改。引用不能为空，始终指向初始化时绑定的对象。引用只有一级。 const修饰： 指针：const可以修饰指针本身或指针指向的对象。 指向常量的指针：const int* ptr &#x2F; int const* ptr 表示指针指向的值是常量，不能通过该指针修改值，但可以改变指针本身的指向。 常量指针：int* const ptr表示指针本身是常量，不能改变指针的指向，但可以通过指针修改指向的值。 指向常量的常量指针：const int* const ptr表示指针本身和指针指向的值都是常量，既不能修改指针的指向，也不能修改指向的值。 引用：引用本身不能是常量，但可以引用一个常量对象。 指向常量的引用：const int&amp; ref表示引用绑定到一个常量值，不能通过该引用修改值。常量引用常用于函数参数，允许函数接受常量或非常量实参而不进行拷贝。 2. unique_ptr 和 share_ptr 的区别unique_ptr 和 shared_ptr 都是 C++11 引入的智能指针，用来自动管理动态内存，避免手动调用 delete。其中 unique_ptr 是独占所有权的，也就是说某个资源只能由一个 unique_ptr 来管理，不能复制，只能移动，所以它的性能更好，也更安全，适合那种资源只需要一个拥有者的场景。 而 shared_ptr 是共享所有权的，可以有多个 shared_ptr 管理同一块资源，它内部通过引用计数来跟踪有多少个指针在使用这个对象，最后一个指针析构时才释放资源。shared_ptr 使用更灵活，但引用计数本身会带来一些开销。总体来说，如果资源只需要一个拥有者，就用 unique_ptr，如果资源会在多个地方共享，就用 shared_ptr。 3. 上一题的使用场景在实际使用中，unique_ptr 适合那种资源只需要有一个拥有者的情况，比如工厂函数返回对象、函数内部创建的临时资源，或者类内部管理的成员对象。比如你写一个类，它有个成员变量只由它自己控制，就很适合用 unique_ptr，这样能确保资源不会被其他地方误用或者重复释放。 而 shared_ptr 更适合多个对象或模块共享同一份资源的场景，比如观察者模式中多个观察者需要持有被观察对象的指针，或者任务队列中多个线程要访问同一个任务数据。在这种情况下，用普通指针很容易造成资源被提前释放或者内存泄漏，用 shared_ptr 可以自动处理好引用计数，资源在最后一个引用释放时才会销毁。 简单来说，unique_ptr 用在“一个人负责到底”的场景，shared_ptr 用在“大家共同拥有”的场景。 4. 读锁和写锁，及其使用场景 读写锁和传统互斥锁的区别在于，能支持多个读线程并发执行 在多线程编程中，读锁和写锁通常是配合**读写锁（读写互斥锁）**使用的，目的是在多个线程并发访问共享资源时提供更高的效率。简单来说，**读锁（共享锁）允许多个线程同时读取资源，但不允许写操作；而写锁（独占锁）**则是排他的，同一时间只能有一个线程持有写锁，且写锁期间不允许任何其他线程读或写这个资源。 这个机制的好处在于：在读多写少的场景下，我们不必像传统互斥锁那样每次都加排它锁，而是可以让多个读线程并发执行，提升性能。 具体的使用场景比如： 读锁适合的场景：多个线程同时查询一个共享缓存、配置文件、数据库快照等，数据是只读的，不会被修改。 写锁适合的场景：当某个线程需要更新缓存、修改配置或写入日志文件等操作时，为了避免其他线程读到不一致的数据，就需要加写锁。 在 C++ 中，像 std::shared_mutex 就是一个典型的读写锁实现，可以配合 std::shared_lock 和 std::unique_lock 分别实现读锁和写锁。 读&#x2F;写优先是基于读写锁中的策略选择而已，不要搞混了 在使用读写锁时，读优先和写优先指的是当读线程和写线程同时竞争锁资源时，系统会优先允许哪一类线程先获取锁。 读优先的策略意味着：如果当前有读线程在读，或者有新的读线程请求读锁，就会优先满足它们，哪怕有写线程已经在等待。这种策略的好处是读性能非常高，适合“读远远多于写”的场景。但问题是如果读操作持续不断，写线程可能会长时间得不到执行，造成“写饥饿”。 写优先则反过来：一旦有写线程在等待，新的读线程就要等写线程先执行完。这种方式能保证写操作不会被饿死，但也意味着读线程可能会频繁被阻塞，尤其在写比较多时，整体并发度会下降。 还有一种是公平策略，就是无论读还是写，谁先请求谁先执行。这种方式平衡了读写，防止任何一方饿死，但也可能带来一点性能损耗。 实际使用中，选择哪种策略要看业务特点： 如果系统是典型的读多写少，比如缓存、配置系统，用读优先可以提升整体吞吐； 如果写操作比较关键，比如数据库更新或者日志记录，写优先更合适； 如果两者都重要，或者对延迟比较敏感，可以用公平策略。 C++ 标准库里的 std::shared_mutex 是不保证写优先的，如果确实要实现写优先或者公平策略，可能需要第三方库（比如 Boost）或者平台相关的原语。 5. 内存对齐是为了解决什么问题？为什么内存对齐能减少访存次数？内存对齐是在哪一存储层次对齐的？内存对齐的本质目的是：为了让 CPU 访问内存时更加高效，避免跨越多个存储单元（比如 cache line 或总线周期），减少访问次数和性能开销。 不对齐会导致： 读取数据跨多个内存块或 cache line； 可能需要多次访存、数据拼接； 某些平台（如 ARM）甚至直接报错。 为什么内存对齐能减少访存次数？ 现代 CPU 是以“块”单位读取数据的，比如 64 字节的 cache line。 如果数据起始地址对齐，就能在一个 cache line 内读完，一次访问就搞定；但如果不对齐，数据可能跨两个块，就会导致： CPU 需要 两次访问 才拿到完整数据； 多占用一次 cache、总线带宽； 增加延迟、降低效率。 所以对齐能保证数据落在一个块内，提高命中率，减少访存。 内存对齐是在哪一存储层次对齐的？ 主要是在这两个层次： 内存 → Cache（尤其是 L1 Cache）之间：为了避免数据跨多个 cache line（通常是 64 字节）导致多次 cache 访问 总线传输层（memory bus）：CPU 和内存之间的数据传输有对齐要求，总线通常按 4 字节、8 字节或更大位宽传输数据，不对齐可能增加传输次数或触发异常 不是针对寄存器本身，寄存器只是最终使用数据的地方。对齐主要作用在数据加载阶段（load from memory），不是计算阶段。 6. CPU 读数据时怎么读取的｜OS 基础知识CPU 读取数据的整个过程，从指令到数据拿到手，可以分 5 个关键步骤： CPU 发出“我要读某个地址的数据”的请求当程序运行到一个需要访问内存的地方，比如： 1int x = arr[5]; 编译后的指令告诉 CPU：我要从内存地址 0x12345678 取出 4 字节数据（假设 int 是 4 字节）。 地址先查 一级缓存 L1 CacheCPU 先查它最近的 L1 Cache（通常分为指令缓存和数据缓存）。 如果数据已经在 L1 Cache，就直接拿了，称为 Cache 命中，访问速度非常快（1~3 个 CPU 周期）。 如果没找到，就会查 L2 → L3 Cache，逐层退而求其次。 如果三级缓存都没有（Cache Miss），那就要去主内存（RAM）找。 Cache 没命中时，CPU 会发出总线请求去 主内存 DRAM此时，CPU 会通过**内存控制器（Memory Controller）**发出一个读请求：“我要读地址 0x12345678”。 现代 CPU 通过**总线（或更高级的互联结构如 AMD 的 Infinity Fabric、Intel 的 UPI）**把请求传给内存控制器。 主内存把数据**按块（通常是一个 cache line，比如 64 字节）**读取出来DRAM 的访问不是按“字节”来的，而是按 “行&#x2F;列&#x2F;页&#x2F;块（cache line）”来的。比如你只要了 4 字节，内存也会把从 0x12345640 开始的 64 字节全读出来，然后一块塞给 Cache。 这个过程比从 Cache 拿要慢很多（几十到几百个 CPU 周期），这就是 Cache 的意义所在。 Cache 把数据交给 CPU，再装入寄存器数据先进入 L1 Cache，然后传给 CPU 的寄存器用于计算。同时 Cache 会记录这个数据，以便下次再访问能命中。 整套流程 Load 操作：把内存数据加载进 CPU； 内存层级（Memory Hierarchy）优化的目标：尽量让数据停留在 Cache，而不是反复从 DRAM 取。 💡 补充：跟内存对齐有什么关系？ Cache 是按“块”读取的（通常 64 字节）； 如果变量没对齐，可能跨两个块； CPU 就要读两块再拼，影响性能； 对齐让变量刚好落在一个块内，减少访存次数。 7. prefetch 操作是做什么的？prefetch 操作是为了提高程序的执行效率，很好地利用了“时间局部性”和“空间局部性”两个原理。 所谓时间局部性是指如果一块数据被访问过，很可能在不久的将来还会被再次访问； 空间局部性则指如果访问了某个地址的数据，很可能也会访问它附近的数据。 CPU 就是基于这两个原则设计了预取机制，也就是在你还没显式访问数据之前，它就先偷偷把数据从内存加载到缓存里，比如 L1 或 L2 Cache，这样等你真正用到的时候就可以直接从缓存中取，避免因为访问内存而带来的延迟。预取可以由硬件自动完成，比如遍历一个数组时 CPU 会自动预取后面的元素；也可以由程序员手动发起，比如用 __builtin_prefetch 告诉编译器某段数据即将被用到，让它提前搬进 Cache。合理的预取可以有效减少 cache miss，提升吞吐量，但如果预取过多或时机不当，也可能导致 cache 污染，占用宝贵的缓存空间。 总的来说，prefetch 是把局部性原理落地到缓存访问上的一种性能优化手段。 8. 多线程之间是如何通信的？线程之间怎么交互的？ &lt;mutex&gt; 和 &lt;condition_variable&gt; 答案就是条件变量 多线程之间的通信和交互主要是通过共享内存来实现的，也就是说多个线程可以访问同一个进程的内存空间，从而读写同一份数据。但因为线程可能同时访问同一块数据，会产生竞态条件，所以通常需要同步机制来保证数据的一致性和正确性。 常用的同步方式包括互斥锁（mutex）、读写锁（rwlock）、信号量（semaphore）、条件变量（condition variable）等，这些机制帮助线程协调访问顺序，防止数据冲突。 此外，线程间还可以通过消息队列、事件通知等方式传递信息，尤其在异步或生产者-消费者模式中常见。现代操作系统和语言运行时通常提供了丰富的线程同步和通信工具，确保线程间可以高效且安全地交互和协作。 9. 存储结构各层次访问粒度和时延 寄存器 一般来说： 通用寄存器的大小：取决于 CPU 的架构位数，比如： 32 位 CPU：寄存器是 32 位（4 字节） 64 位 CPU：寄存器是 64 位（8 字节） 寄存器的数量： x86 架构下（64 位）有 16 个通用寄存器（RAX, RBX, RCX 等） ARM 64（AArch64）也有 31 个通用寄存器（X0–X30） 此外还有一些专用寄存器，比如： 程序计数器（PC） 栈指针（SP） 条件标志寄存器（FLAGS） 浮点寄存器、SIMD（如 AVX、NEON）寄存器等，宽度可达 128、256、512 位 层级 访问粒度 访问延迟（大约） 容量 描述说明 🟢 寄存器 1 个字（4&#x2F;8字节） 1 个 CPU 周期（约 0.3~1ns） 极小（几十个，共几百字节） CPU 内部最快速的存储，直接参与计算 🔵 L1 Cache 64 字节（1 个 cache line） 3~5 个周期（约 1ns） 通常 32~128KB 每个核心私有，分数据&#x2F;指令两块 🟡 L2 Cache 64 字节 10~15 周期（约 4~7ns） 256KB ~ 1MB 每个核心私有或共享 🟠 L3 Cache 64 字节 30~50 周期（约 10~20ns） 数 MB（如 8MB、32MB） 多核心共享，跨核通信重要通道 🟤 主内存（DRAM） 64 字节~几 KB 100~300 周期（约 50~150ns） 几 GB（如 16GB） 外部内存，延迟远高于 cache ⚫ 磁盘（SSD&#x2F;HDD） 几 KB~几 MB SSD：**几十微秒（us）**HDD：几毫秒（ms） 上百 GB~数 TB 非易失性存储，延迟非常高 ⚪ 网络存储&#x2F;云存储 几 KB~几 MB 毫秒级甚至更慢 几 TB~PB 比本地磁盘更慢，非直接访问 结语关于暑期实习的故事到这里就结束了，笔主（🐷）未能有一个很好的去向，挺遗憾的，感觉相比以前少了一些心气，秋招加油吧。","tags":["C++","面经","大厂","实习"],"categories":["秋招指南"]},{"title":"分布式系统｜共识算法 Raft","path":"/post/系统与体系结构/distributed-systems-raft/","content":"Raft 算法 Raft 动图演示：http://www.kailing.pub/raft/index.html 更多链接： 分布式系统一致性模型与共识算法：Raft 详解 深度解析 Raft 分布式一致性协议 1. Raft 背景Paxos 算法虽然理论上能够解决分布式的共识问题，但是其过于复杂，难以理解。实现 Paxos 算法的开源软件很少，比较有代表性的是 Google 的 Chubby。 正是由于 Paxos 算法的复杂性和实现难度，使得其在实际工程中的应用受到了限制。然而，分布式系统的发展迫切需要一种既高效又易于实现的分布式一致性算法。在这种背景下，Raft 算法应运而生，成为一种更具实用性和可读性的替代方案。 Raft 算法由斯坦福大学的 Diego Ongaro 和 John Ousterhout 在 2013 年发表的《In Search of an Understandable Consensus Algorithm》中提出。Raft 算法是一类基于日志复制的分布式共识算法，由于 Raft 算法易于理解和实现，在提出后，迅速获得了广泛关注，并成为了分布式系统中实际应用最广泛的一致性算法之一。目前，已经有十多种语言的 Raft 算法实现框架，比较有代表性的有 etcd、Consul，CockroachDB 等。 所以说掌握了 Raft 算法，就能比较轻松地处理绝大部分的一致性场景和需求，本文的大纲如下： 2. Raft 算法优化思路Raft 算法为了达到易于理解的目的，主要做了两件事： 问题分解：将分布式共识问题拆分成主节点选举、日志复制、安全点，以及成员变更 4 个独立子问题逐一进行解决 状态简化：通过减少算法中需要考虑的状态数，使得算法更加清晰和易于理解 3. 领导者选举（Leader Election）3.1 Raft 角色在一个 Raft 集群中，每个节点有以下三种状态，一般也称这三种状态的节点为 Raft 集群的三种角色 领导者（Leader） 处理客户端请求 管理和同步日志 定期向 Follower 发送心跳（Heartbeat）信号，以表明自己仍然存活，并防止 Follower 发起选举 跟随者（Follower） 被动地响应 Leader 的日志同步请求 响应 Candidate 发起的邀票请求 把客户端打到 Follower 的请求转发给 Leader 候选者（Candidate） 在集群刚启动或 Leader 宕机时，Follower 节点可以转换为 Candidate 并发起选举 当 Follower 长时间未接收到 Leader 的心跳信号时，会认为 Leader 可能已经失效，从而将自己状态转换为 Candidate 并发起选举。Candidate 向其他节点请求选票，若获得超过半数节点的投票，它就会成为新的 Leader 如果选举胜出，Candidate 转变为 Leader；否则，如果有其他节点当选为 Leader，Candidate 会返回到 Follower 状态 节点状态转换如下图所示 从上图可以看出，在集群启动时，所有的节点都处于 Follower 状态，如果在一段时间内，没有收到来自 Leader 的心跳信息，则 Follower 将切换成 Candidate，然后发起投票，如果该 Candidate 收到了多数（超过半数）的 Follower 的投票（包含该 Candidate 自己投给自己的一票），则该 Candidate 将切换成 Leader。在选举过程中，如果该 Candidate 发现有其他节点有比自己更新（即日志条目的任期号更高），它会自动放弃选举，并重新切回 Follower。 一句话概括：系统中最多只有一个 Leader，如果在某一段时间内没有 Leader，Follower 会通过选举投票的方式选出 Leader。Leader 会不停的给 Follower 发送心跳信息，保证自己的存活状态。如果 Leader 挂掉，Follower 会切换成 Candidate 发起投票，重新选出 Leader。 3.2 任期任期是一个整数，用于标识 raft 集群的一个时间段。这个跟国家行政相似，比如上一个五年是领导人人 xx 任期的五年，这个五年是领导人 yy 的任期，可以简单的理解为“朝代”，用递增的整数表示。那对应到 raft 集群中，就可以简单的理解为，任期是某个节点处于 leader 的一个时间段。但这里需要明确一点，可能某些情况下，因为选票的分流，在选举期间内没有成功选出 Leader，则会进入下一个任期。任期示意图如下： 任期包含两个阶段： 选举阶段 已选举出 Leader 的阶段 同上面所说，任期也可能只包含选举阶段，没有 Leader，比如图中的任期 3，这种情况下，会立即进入到下一个任期，开始新的选举。 任期具有如下特点： 每个节点都会保存当前的任期（即一个标识时间段的整数），并随着集群状态的变化进行更新 Follower 等待 Leader 的心跳超时后，会推举自己为 Candidate 发起投票，此时会将当前任期编号加 1。比如当前该 Follower 保存的任期为 1，在推举自己为候选人邀票时，会将任期编号增加到 2 当一个节点发现自己保存的任期编号比另一个节点的任期编号小，它会主动更新自己的任期编号到最新的较大的任期编号，比如节点 A 当前的任期编号是 1，当收到来自节点 B 的请求投票 的 RPC 消息时，因为消息中包含了节点 B 的任期编号，且编号为 2，那么节点 A 将把自己的任期编号更新为 2 如果一个节点接收到一个比自己任期编号小的 RPC 请求，该节点会立即拒绝这个 RPC 请求（无论是投票请求还是日志追加请求）。这是因为这个请求的任期编号已经过时，代表着发出请求的节点拥有的是旧任期，不再被视为合法的领导者或候选者 如果一个 Leader 或者是 Candidate 发现自己的任期编号比其他节点小，该节点会立即退回到 Follower，假设由于网络分区错误，集群中出现了两个 Leader，LeaderA 任期编号为 4，LeaderB 任期编号为 5，当网络分区错误恢复后，LeaderA 收到了来自 LeaderB 的心跳信息，LeaderA 将回退为 Follower，接收 LeaderB 成为 Leader 3.3 随机超时Raft 算法中的随机超时有以下两种情况： Follower 等待 Leader 心跳信息的超时间隔是随机的：这里的随机化的超时机制可以防止多个 Follower 同时转换为 Candidate，减少选举冲突 Candidate 等待选举结果的超时间隔是随机的：当一个节点转换为 Candidate 并发起选举后，会等待其他节点的投票结果，这个等待时间是随机的。如果在这个等待的时间段内，没有获得大多数选票，将再次随机设置一个等待时间，发起新一轮投票。这里的随机化的超时机制降低了多个 Candidate 同时发起选举的可能性 总的来说，在 Raft 算法中，随机超时机制是一个关键设计，保证在大多数情况下只有一个节点发起选举，避免多 Candidate 选举带来的性能问题 3.4 通信方式在 Raft 算法中，节点之间通过远程调用（RPC）进行通信，主要涉及以下三种类型的 RPC： 投票 RPC：由 Candidate 节点在选举过程中向 Follower 发出 附加日志条目 RPC：Leader 节点在日志复制过程中将日志条目发送给其他 Follower 节点，同时也起到维持心跳的作用，确保 Leader 的存活状态 快照 RPC：当 Follower 的日志落后 Leader 太多时，Leader 会发送 Snapshot RPC 请求，通过快照的方式帮助 Follower 快速同步日志 3.5 选举流程 如上图所示：Follower 在收到 Leader 心跳信息超时后，会推选自己为 Candidate，将自身的任期+1，然后发起选举，如果在设置的时间内收到了多数选票，将晋升为新的 Leader，如果没有获得足够多的选票，收到 Leader 的心跳包，则 Candidate 恢复成 Follower 角色。 3.5.1 选举详细流程下面以三个节点的集群来演示下选举的详细流程 初始状态 初始时，每个节点的角色都是 Follower，任期 Term 为 0（假设任期编号从 0 开始），每个节点都设置了一个随机超时时间（节点 A：100ms，节点 B：120ms，节点 C：160ms），如下图： 发起投票 由于节点 A 的随机超时时间是设置的最小的，为 100ms，所以在 A 在 100ms 后倒计时结束被唤醒，成为 Candidate，并为自己发起投票，此时将自己的任期编号加 1，变为 1。先投自己一票，然后向其他的 Follower 发起投票 RPC 请求。 响应投票 Follower 节点 B 和 C 收到 Candidate 节点 A 的投票请求后，会做如下处理： 如果自身已经在任期编号为 1 的投票请求中投过票了，则会忽略该投票请求 否则，将自己的选票投给 Candidate，也就是节点 A，并将自身保存的任期编号设置为 1，然后重置随机超时时间 假设 B 和 C 都没有在任期编号为 1 的投票请求中投过票，此时都将选票投给 A，并设置自身的任期编号为 1，然后重置随机超时时间。 结束投票 3.5.2 多 Candidate 选举从上面的选举过程可知，每个节点都会设置一个随机超时时间，这样可以降低了多个节点在同一时刻被唤醒成为 Candidate 的概率。但是也只是能降低概率，并且由于系统可能存在网络延迟，所以仍然无法完全避免多个 Follower 同时成为 Candidate 发起投票，假设这里有两个 Follower（A 和 B）同时被唤醒，转换为 Candidate 发起投票： 假设 A 和 B 设置的随机超时时间都是 120ms，在 A 和 B 节点被同时唤醒之后，会各自为自己投上一票，然后开始向其他节点发送投票请求，假设节点 C 先收到 A 的投票请求，之后再收到 B 的投票请求，那样 C 将会把选票投给 A，最终节点 A 获得两票（包含自己一票）成为 Leader，而节点 B 只会获得一张选票（自己的一票），则会回退成 Follower. 3.5.3 平票问题一般在集群中，节点的个数都会选择奇数个，很重要的一点就是防止两个 Candidate 同时发起选票获得相同票数，导致系统内无法选出 Leader 的情况。但是由于系统可能出现故障，导致某个节点故障之后，依然可能会存在这个问题。假设集群中的节点是出现了偶数个，结果又会怎样呢？ 假设集群中有 A，B，C，D 四个节点，其中 A，B 两个节点设置的随机超时时间都是 120ms。现在假设 A，B 被同时唤醒了，向其他节点发送投票请求。节点 A 和 B 在同一任期内竞选领导者时，由于每个节点在同一个任期内只能投票一次，A 和 B 都已经投了自己的票，因此不会再给对方投票。然后节点 C 把票投给 A，节点 D 把票投给 B，这样节点 A 和 B 都获得了两张选票，出现了平票的情况，这种情况下是不会有 Leader 被选出来的，所有节点会恢复成 Follower 状态，重新设置随机超时时间，准备下一轮的选举，虽然会有下一次轮的选举，直到选出新的 Leader，但是在这个过程中，集群都是处于不可用状态，所以选举的轮次越多，集群不可用状态越久，因此要尽量避免平票问题。 节点 A 和节点 B 回退为 Follower 之后，重新设置随机超时时间，节点 A 50ms，节点 B 100ms，等待超时时间开启新一轮的选举： 3.5.4 脑裂问题前面所说的情况是在集群完全正常的情况下，一个集群中只会存在一个 Leader。假设在一个集群内发发生了网络分区，形成了两个分区，选举情况将会怎样进行呢？ 这里以 5 个节点的集群为例，集群节点 A,B,C,D,E，节点 A 为集群 Leader。假设发生了网络分区，[A,B,C] 为一个分区，节点 [D,E] 为一个分区，由于 A 本身就是原集群的 Leader，所以 [A,B,C] 分区内还是按照以前的集群模式 A 为 Leader，向 B，C 节点发送心跳。而 [D,E] 由于发生了网络分区，收不到 A 节点的心跳信息了，假设 D 节点设置的随机超时时间较短，那么到时间后，会成为 Candidate，发起投票，成为 [D,E] 这个分区的 Leader，由于经过了一轮选举，那么 [D,E] 这个分区的任期将会比 [A,B,C] 分区的任期大 1。这个时候在整个集群 [A,B,C,D,E] 中就有了两个 Leader A 和 D，这就是“脑裂问题”。 脑裂问题如何解决？ 其实在网络恢复后，虽然有了两个 Leader，Leader 都会向其他的节点发送心跳信息，这里 A 和 C 会互相收到对方发送的心跳信号，但是在 A 节点收到 C 节点发送的心跳之后，会发现携带的任期比自身保存的任期要大，所以 A 节点会退成 Follower，集群会再次恢复成只有一个 Leader 的状态。 4. 日志复制（Log Replication）Raft 算法中第二个很重要的字问题就是日志复制，日志复制（Log Replication）是保证整个集群中的所有节点（follower）一致地存储相同状态的核心机制。它的主要目标是通过将客户端提交的指令（通常是状态变化操作）复制到每个节点的日志中，确保所有节点都达成一致的状态，即一致性。 4.1 日志在 raft 日志其实是一种数据格式，主要用于存储客户端的一些列操作指令，日志由三部分组成，分别是： 索引值（Log index） 任期编号（Term） 指令（Command） 索引值：日志条目对应的索引值，用来标识第几条日志，是一个连续单调递增的整数 任期编号：创建这条日志条目的 Leader 的任期编号 指令：客户端发起请求需要执行的指令，例如指令 X &lt;- 2 表示将 X 变量赋值为 2 一条日志也叫日志项，从上图可以看出，在一个 Leader 的任期内，可以有多个日志项，比如任期 1 内有 3 个日志项，任期 3 内有 4 个日志项。 日志还对应有两个状态： committed（已提交）：针对的是日志，对应于某个日志项被成功复制到集群的大多数节点之后，这个日志项就处于 committed 状态，比如索引值 1-7 所对应的日志项均处于 committed 状态，因为他们都被复制到了大多数节点 applied （已应用）：针对的是状态机即节点，节点要将日志真正应用到状态机，即真正改变了节点上对应变量的值 4.2 日志复制过程集群中只有 Leader 会跟客户端交互，接收客户端的指令，而这些指令除了要在客户端执行以外，还需要通过日志复制的方式讲这些指令复制到各个 Follower 节点，以保证集群的一致性。 日志复制的过程可以总结如下： Leader 接收到客户端请求，请求中的指令创建一个新的日志项，然后追加（append）到当前本地日志中（此时 Leader 中该日志项的状态为 uncommitted） Leader 通过日志复制 RPC 请求将该日志项复制到其他 Follower 节点（此时在各个 Follower 中该日志项的状态为 uncommitted） 当 Leader 确认将日志项成功复制到大多数节点后，Leader 会将该日志项标记为 committed，之后 Leader 会将该日志项应用到自己的状态机，即真正执行指令，修改对应的值 Leader 将执行结果返回给客户端 Leader 通过心跳或新的日志复制请求将提交了该日志项的状态同步给 Follower，如果 Follower 发现 Leader 已提交了该日志项，而自己还没将该日志项应用 apply 至状态机，则会将该日志项应用至自己的状态机中 如果 Follower 节点出现宕机或者由于网络丢包，Leader 会通过不断重试发送日志复制请求来确保日志条目最终复制到 Follower 上 可以看出，在日志复制过程中，只要有半数以上的处于正常工作的状态，整个系统就可用，假如在复制日志的过程中，出现了节点宕机、进程中断等问题，可能导致日志不一致，这种情况会怎么处理呢？ 4.3 日志一致性从前面的日志复制过程可以看出，在日志复制过程中，只要有半数以上的处于正常工作的状态，整个系统就可用，假如在复制日志的过程中，出现了节点宕机、进程中断等问题，可能导致日志不一致，这种情况会怎么处理，怎么来保证各个节点日志的一致性呢？ 首先看一下 Raft 日志的特点，Raft 日志具体如下两个特性： 如果不同日志中的两个日志项有相同的「任期编号」和「索引值」，那么这两个日志项一定有相同的指令 如果不同日志中的两个日志项有相同的「任期编号」和「索引值」，那么这两个日志项之前的所有日志项也全部都相同 通过这两个特征其实可以看出，只要同步到位的日志都是一致的，在 Raft 算法中，其实是以领导者日志为准来实现日志的一致性的，主要包括两个步骤： Leader 通过日志复制 RPC 请求的一致性检查，找到 Follower 节点上与自己具有相同日志项的最大索引值（在该索引值之前的日志项，Leader 和 Follower 是一致的，之后不一致） Leader 强制 Follower 更新不一致日志条目，Leader 强制 Follower 将该索引值之后的所有日志项删除，并将 Leader 该索引值之后的所有日志项同步给 Follower 4.3.1 一致性检查Leader 为了找到 Follower 节点上与自己具有相同日志项的最大索引值，每次日志复制请求除了发送该日志项之外，还要发送一些额外信息，这里引入两个新的概念： prevLogIndex：Leader 当前需要复制的日志项的前一个日志项的索引值 prevLogTerm：Leader 当前需要复制的日志项的前一个日志项的任期编号 如下图，假设 Leader 当前需要将索引值为7的日志项发送复制到 Follower，则 prevLogIndex 为 6，prevLogTerm 为 3 下面以一个具体的例子来看： 当前 Leader 的最大日志项索引为 10，假设当前 Leader 需要将 10 号日志项复制给 Follower，步骤如下： Leader 将索引值为 10 的日志项通过日志复制 RPC 请求发送给 Follower，同时还会发送该日志项的 prevLogIndex（9）和 prevLogTerm（3），Follower 收到消息后，判断自己没有索引值为 9 的日志，因此拒绝更新日志并向 Leader 失败信息 Leader 收到 Follower 的失败响应后，将日志项的索引值减 1，接着发送索引值为 9 的日志项并且携带 prevLogIndex（8）和 prevLogTerm（3）给 Follower，Followe 发现自己索引值为 8 的日志项中任期为 4，指令为 N &lt;- 5，和 Leader 发过来的日志项不一样 ，再次拒绝更新，向 Leader 响应失败 直至需要复制索引值为 7 的日志项时，Follower 发现同步过来的 prevLogIndex 为 6，prevLogTerm 为 3，与自己在索引值为 6 的的日志条目相同（任期也是 3），则接收该日志复制 RPC 请求 Leader 收到跟 Follower 的成功响应后，Leader 通过日志复制 RPC 消息，强制 Follower 复制并更新覆盖索引值为 7 及之后的内容。保证 Follower 与 Leader 的日志状态一致 5. 安全性前面分析了 Raft 算法是如何进行 Leader 选举以及日志复制的，但是这套机制还不能够完全保证每个节点都会严格按照相同的顺序 apply 日志，这就可能造成各个节点的状态机不一致。 假设有如下场景： Leader 将某些日志项复制到了大多数节点上，在 commit 后发生了宕机 某个 Follower 尚未被复制这些日志项，但是在 Leader 挂了之后，进行的选举中，该 Follower 成为了 Leader 这个新的 Leader 又同步并提交了一些新的日志，这些日志覆盖掉了其它节点上的上一任提交的日志 各个节点在进行 apply 时可能应用了不同的日志序列，导致出现不一致 所以要想保证各个节点状态机一致性，光有 Leader 选举和日志复制策略还是不够的，还要有一些额外的措施，这就是本小节要讨论的安全性限制策略。 5.1 对选举的限制回顾上述场景，为什么会出现日志被错误地覆盖，导致不一致。根本问题其实就是在第二部，一个落后的 Follower（还没被复制上一任 Leader 的最新日志）就当选了新的 Leader。那么他接下来的操作肯定会以自己的日志为准，导致集群中其他节点的日志被覆盖掉。所以这个 Candidate 来竞选 Leader 其实是不合格的，Candidate 必须有足够的资格才能当选 leader，所以在 Candidate 发起选举投票的时候，可以加一个条件限制： ⚠️每个 Candidate 发起投票 RPC 请求时必须在请求体中包含自己本地日志最新的任期编号（term）和索引值（index）当 Follower 收到 Candidate 的投票请求时，如果发现该 Candidate 的日志还没有自己的新，则拒绝投票给该 Candidate。 🌟在加了这个条件之后，再结合上本身 Candidate 就必须赢得集群大多数节点的投票才会成为 Leader，同时一条日志只有复制到了大多数节点才能被 commit，所以 Leader 就一定拥有所有 committed 日志。也就是说：Follower 不可能比 leader 多出一些 committed 日志。 比较日志新旧的策略也很简单：(term, index) 比较，先比较 term， term 更大的日志更新，term 相同的话，index 大的日志更新。 5.2 对提交的限制单独的对选举加一定限制还不能保证日志的正确性，不正确的提交（commit）同样会带来问题。回顾一下 commit 的作用： 当 leader 得知某条日志项被成功复制到集群的大多数节点后，就可以进行 commit，表明该日志项可以被 apply 生效到状态机，committed（已提交） 日志项一定最终会被状态机 apply。 但是不正确的 commit 也可能带来日志覆盖的问题，考虑如下场景： 图中的方框内的数字表示该日志项的任期 term，对应坐上面一栏的数字表示该日志项的索引值 index，一条日志项用（term，index）表示，从左到右随着时间集群状变更如下： 阶段 a：S1 是 leader，收到请求后将日志项(2, 2) 只复制给了 S2，尚未复制给 S3，S4，S5 阶段 b：S1 宕机，S5 选举获取了 S3、S4、S5 三票，当选任期（term）为 3 的 leader，收到客户端请求后保存了 日志项（3，2），尚未复制给任何节点 阶段 c：S5 宕机，S1 恢复，S1 重新当选 term 为 4 的 leader，继续将日志项 (2, 2) 复制给了 S3，已经满足大多数节点（S1，S2，S3），于是 S1 将该日志项 commit 阶段 d：S1 又宕机，S5 恢复，S5 选举获得了 S2、S3、S4 三票，重新当选 ，将 日志项(3, 2) 复制给了所有节点并 commit。注意，此时发生了日志覆盖错误，已经 committed 的 日志项(2, 2) 被 (3, 2) 覆盖了 为了避免这个错误，需要在日志的提交阶段也加一个限制： ⚠️ Leader 只允许 commit 包含当前任期 (term) 的日志。 假设有了这个限制，再来模拟一下上述场景，在加了这个限制后，其实上述阶段的阶段 c 就出错了，阶段 c 虽然 S1 恢复当选了 term4 的 Leader，但是其并不能直接将日志项（2，2）commit，因为 S1 当前的日志为（4，3），必须等到（4，3）成功复制后才能 commit。 一旦有了这个限制，在阶段 c 就只存两种情况了： 日志项（2，2）始终没有被 commit，这样 S5 在阶段 d 将其覆盖就是安全的 日志项（2，2）连同（4，3）一起被成功 commit，这样的话，在阶段 d，S5 就无法成功当选 Leader（对选举的限制，当 Follower 收到 Candidate 的投票请求时，如果发现该 Candidate 的日志还没有自己的新，则拒绝投票给该 Candidate），就不存在上述问题了 6. 节点变更问题集群中的节点数量并不是恒定不变的，比如随着业务的发展，集群需要扩容或者是缩容，那么就需要适当的增加或者是减少机器节点，又或者是某些几点出现了故障，需要变更机器等等，都需要变更集群的节点数量。Raft 算法如何处理集群成员节点变更的问题呢？ 6.1 配置在介绍节点变更过程之间，需要先明确一个概念：配置（configuration） 在 Raft 算法中，使用用配置来表示集群的节点集合，比如某个集群由 A、B、C 三个节点构成，那么集群的配置就是 [A, B, C]，在稳定的状态下，所有节点的配置都相同。从这里就可以知道，每个节点是通过这个配置信息来获取集群状态的，比如在选举，日志同步过程中，集群中有哪几个 Follower，Leader 需要向哪几个节点发送 RPC 通信都需要通过配置来获取。 6.2 节点变更可能带来的问题集群中节点的变更很有可能给集群的一致性带来影响，主要是会影响集群的多数派。我们知道在 Raft 中很多场合都需要多数派的支持，比如在投票中，只有当一个节点收到多数派投票（超过半数）才会成为 Leader，在日志同步中，只有当 Leader 确认将日志项成功复制到多数派（超过半数）节点后，会将该日志项标记为 committed，类似的场景还有很多。 而集群节点的变更最主要的就是会影响到多数派，比如在一个三个节点的集群中原本只要 2 个节点就可以达到多数派，假设现在往集群新增两个节点，则需要三个节点才能达到多数派。 在 Raft 集群中，同样是由 Leader 节点负责同步集群的配置信息，当集群中出现节点变更，几乎不能保证所有节点同时进行配置的变更，由于网络先后等因素导致一部分节点配置已变更，另一部分没有变更在所难免，所以就会导致集群中部分节点使用的新的配置信息 C_new，而有的节点使用老的配置信息 C_old。 假设有如下场景中，原来集群有三个节点 [server1,server2,server3]，现在向集群新增了两个节点 server4 和 server5. 当处于画框的时间点时，假如此时出发了选举，server1 和 server2 用的是旧的配置文件 C_old，因此他们会从节点 [server1,server2] 中选出 Leader；而节点 server3，server4 和 server5 已经是新的配置文件 C_new 了，他们会从节点 [server3,server4,server5] 中选出新的 Leader。此时集群就可能会有两个 Leader，出现脑裂问题。 6.3 节点变更策略前面分析了在集群变更的时候很可能导致集群的一致性出现问题，那又没有什么策略可以解决这个问题呢？主要有以下这几种解决方案。 6.3.1 串行更新这种方法就是先将集群原来所有节点关闭，更新其配置后，再启动新的集群，显然这种方法很安全，可以保证集群始终只有一个 Leader，但是这种方法会导致每次成员变更时都需要关闭集群，导致集群无法对外提供服务，对于高可用的业务场景显然不适用。 6.3.2 单节点变更每一次集群的变动只能新增或者删除一个节点，假设集群需要变更多个节点，那么需要分多个步骤来完成，每次只变更一个节点。比如原集群有 3 个节点，先需要扩容到 5 个节点，那么需要分两步，第一步扩充到 4 个节点，再由 4 个节点增加到 5 个节点，所以单节点变更法也叫单步成员变更法。 详细步骤如下： 客户端向 Leader 提交一个集群成员变更请求，请求的内容新增或者删除节点，以及服务节点的地址信息 Leader 在收到请求之后，向本地日志中追加一条配置信息志，其中包含了新的集群配置信息 C_new，之后，这个新的配置信息会随着 RPC 请求（AppendEntries）同步给所有的 Follower 节点。注意：配置信息日志被添加到日志中是立即生效（不需要 commit 之后再生效） 当配置信息日志被复制到新的配置信息 C_new 所标识的所有节点的多数派节点后，就 commit 该日志 提交配置日志的作用： 日志提交之后，才可以响应客户端，完成集群节点变更 标志着本轮节点变更已结束，可以开始下一轮的节点变更 如果集群中有删除节点，那么提交日志之后，被删除的节点可以关机了 6.3.2.1 单步成员变更法为什么可以解决集群节点变更带来的脑裂问题呢？ 这里可以枚举出奇偶节点情况下，新增或者删除节点的情况 从上图可以看出，不管原集群节点数是奇数还是偶数，也不管是在原集群上新增一个节点还是删除一个节点，在集群的节点数变更之后，原集群的多数派和新集群的多数派一定存在交集，那么再同一个任期内，原集群 C_old 和新集群 C_new 中交集的那一个节点只会进行一次投票，要么投票给 C_old，要么投票给 C_new，这样就避免可同一任期出现在两个 Leader 的现象。 需要注意的是：单节点变更法虽然简单，很好理解，但是也有其缺陷，这种方式在串行化的方式下可以保证一个集群只能有一个 Leader，但是并发执行单节点变更，可能会出现一次单节点变更还没完成，新一次单节点变更已经执行，导致集群出现脑裂问题，这里不过多阐述，感兴趣的话可以去看 Raft 论文。 6.3.3 两阶段切换集群成员配置虽然 Raft 论文中认为单步变更是更简单的办法，但节点变更有一定的问题，但是现在主流的实现都使用了 Joint Consensus（联合共识）算法来完成集群变更，也就是小标题所说的两阶段切换集群成员配置。 具体流程如下： 阶段一 客户端将新配置 C_new 发送给 Leader，Leader 取旧配置 C_old 和新配置 C_new 的并集（称为联合配置（表示为 C_old,new））并立即 apply 即生效 Leader 将配置 C_old,new 包装成日志通过 AppendEntries 请求复制到 Follower 节点 Follower 收到 C_old,new 后立即生效，立刻应用该配置作为当前节点的配置，当 C_old,new 的大多数节点（即 C_old 的大多数节点和 C_new 的大多数节点）都切换后，leader 将 commit 该日志 阶段二 紧接着 Leader 将新配置 C_new 包装成日志通过 AppendEntries 请求复制到 Follower 节点 Follower 收到 C_new 后立即生效，如果此时发现自己不在 C_new 列表，则主动退出集群 Leader 确认 C_new 的大多数节点都切换成功后，给客户端发送执行成功的响应 几个概念详细解释一下： C_old,new：比如 C_old 为 [A, B, C]，C_new 为 [B, C, D]，那么 C_old,new 就为他们的并集 [A, B, C, D] C_old,new 的大多数节点：是指 C_old 中的大多数和 C_new 中的大多数，如下表所示，第一行因为 C，D 节点还没有被复制到日志，导致 C_new 的多数派不能达成，所以该日志不能被 commit 上图展示了用两阶段提交方法集群节点变更过程中的几个过渡期： 虚线：表示已经创建但尚未 commit 的成员配置日志 实线：表示 committed 的成员配置日志 在每一个时期，每一个任期下都不可能出现两个 Leader. 原因如下 阶段一：C_old,new 日志尚未 commit 在这个阶段，集群中节点可能处于旧配置 C_old 下，也有可能处于联合配置 C_old,new 下，但无论这两种情况的哪一种，只要原 leader 发生宕机，新 leader 都必须得到旧配置 C_old 下大多数节点的投票，所以不会出现两个 Leader 再次强调一下：C_old 节点发起选举需要 C_old 的大多数，C_old,new 发起选举需要 C_old 和 C_new 两者的大多数 阶段二： C_old,new 已经 commit，C_new 下发之前 在这个阶段，C_old,new 已经被 commit，表示联合配置 C_old,new 已经被应用到了集群的大多数节点上（C_old 的大多数节点和 C-new 的大多数节点），因此当 leader 宕机时，新选出的 leader 一定是已经拥有 C_old,new 的节点，否则票数通不过，所以不可能出现两个 leader 阶段三： C_new 已经下发，但尚未 commit 在这个阶段，集群中可能有三种节点，集群中节点可能处于旧配置 C_old 下，也有可能处于联合配置 C_old,new 下，还有可能处于新配置 C_new 下，但由于已经经历了阶段 2，因此 C_old 节点不可能再成为 leader。而无论是 C_old,new 还是 C_new 节点发起选举，都需要经过大多数 C_new 节点的同意，因此也不可能出现两个 leader 阶段四：C_new 已经 commit 在这个阶段，C_new 已经被 commit，因此只有 C_new 节点可以得到大多数选票成为 leader，所以也不会出现两个 Leader，至此，集群已经安全地完成了这轮变更，可以继续开启下一轮变更了 7. 小结Raft 算法将共识问题分解成了多个相对独立的子问题，从而简化了共识的实现。其主要流程包括领导者选举以及日志复制，集群先选举出 leader，然后 leader 负责复制、提交日志。当然为了在任何异常情况下系统不出错，还需要满足一定的安全性，以及需要对 Leader Election，Log Replication 两个子问题加一些限制条件。最后集群都是动态变化的，所以 Raft 算法也应用了单节点变更以及联合共识机制来保证集群节点安全的变更。","tags":["分布式系统","Raft"],"categories":["系统与体系结构"]},{"title":"Python Wiki","path":"/post/Python/python-wiki/","content":"Python 之禅123456789101112131415161718192021222324import this&#x27;&#x27;&#x27;The Zen of Python, by Tim PetersBeautiful is better than ugly.Explicit is better than implicit.Simple is better than complex.Complex is better than complicated.Flat is better than nested.Sparse is better than dense.Readability counts.Special cases aren&#x27;t special enough to break the rules.Although practicality beats purity.Errors should never pass silently.Unless explicitly silenced.In the face of ambiguity, refuse the temptation to guess.There should be one-- and preferably only one --obvious way to do it.Although that way may not be obvious at first unless you&#x27;re Dutch.Now is better than never.Although never is often better than *right* now.If the implementation is hard to explain, it&#x27;s a bad idea.If the implementation is easy to explain, it may be a good idea.Namespaces are one honking great idea -- let&#x27;s do more of those!&#x27;&#x27;&#x27; Python 命名规范传送门 基本数据类型定义： 12message = &quot;Hello Python!&quot;print(message) 字符串可以是单引号 &#39; &#39;，也可以是双引号 &quot; &quot;，之间可以相互嵌套。 API Document： 123456name = &quot;Gulf Alaska&quot;name.tile()name.upper()name.lower()name.lstrip()name.rstrip() 切片不仅列表有切片，字符串也有： 12345# Python 字符串可以像 Java 中的 char[] 直接取值print(name[0]) # Gprint(name[1]) # uprint(name[2]) # lprint(name[2:7]) # lf Al 数字12345678# 唯一需要注意的是 / 和 **print(3 / 2) # 1.5print(3 ** 3) # 9print(3 // 2) # 1 (整除, 向下取整)# 错误! ==&gt; 为避免类型错误使用str()&#x27;&#x27;&#x27; python数字类型不会自动转string类型, 需要str()支撑 &#x27;&#x27;&#x27;print(&quot;Hello: &quot; + str(143)) 列表Python 中，用方括号 [] 表示列表，并用逗号来分隔其中的元素。 12345lista = [&#x27;hi&#x27;, &#x27;Fighting&#x27;, &#x27;hhh&#x27;]print(lista) # [&#x27;hi&#x27;, &#x27;Fighting&#x27;, &#x27;hhh&#x27;]print(lista[1]) # Fighting# Python为访问列表最后一个元素提供的一种方式print(lista[-1])# hhh 修改元素123456# 同 javalista[0] = &#x27;hello&#x27;# 倒 1 位lista[-1] = &#x27;hello&#x27;# 倒 2 位lista[-2] = &#x27;hello&#x27; 添加元素12lista.append(&#x27;what&#x27;)lista.insert(1, &#x27;hihihi&#x27;) 删除元素1234del lista[0]member = lista.pop() # 最后一个member = lista.pop(3) # 指定弹出某一个lista.remove(&#x27;hi&#x27;) # 根据value来删除元素 排序列表123456numberList.sort()numberList.sort(reverse=True)sorted(numberList)sorted(numberList, reverse=True)numberList.reverse()len(numberList) 遍历列表Python 根据缩进来判断代码行与前一个代码行的关系！ 随意缩进会导致错误！ 1234# for在前、别忘:、注意缩进关系！for x in list: print(x) print(x + str(666)) 数值列表12345678910111213141516171819202122232425262728293031# 数值列表for i in range(1, 5): print(i)# 从 0 遍历到 29, 也可以用于循环次数！for i in range(30): print(i)# 将一系列数值转化为列表: list(range())number = list(range(1, 6))print(number)# 指定步长2for i in range(1, 11, 2): print(i)# 对数值列表进行简单的统计print(min(number))print(max(number))print(sum(number))# x^2加入到列表中x2 = []for x in range(1, 11): x2.append(x ** 2)print(x2)# 列表解析：将上面的平方和数可以转化如下# 在循环中解析出 value**2 并添加到 squaresquare = [value ** 2 for value in range(1, 11)]print(square) 切片切片：即使用列表的一部分 1234567891011121314151617181920# 1.切片techs = [&#x27;vue&#x27;, &#x27;react&#x27;, &#x27;spring&#x27;, &#x27;spring boot&#x27;, &#x27;spring cloud&#x27;, &#x27;java&#x27;, &#x27;javascript&#x27;, &#x27;python&#x27;, &#x27;c&#x27;, &#x27;c++&#x27;, &#x27;go&#x27;]print(techs[1:3])print(techs[2:])print(techs[:4])print(techs[:])# 2.遍历切片for i in techs[2:6]: print(i)# 3.复制切片myStack = techs[:]print(&quot;myStack: &quot; + str(myStack))# 4.引用而非复制: 同一个列表yours = techstechs.append(&quot;is?!&quot;)print(techs)print(yours) 列表的其他操作1234567891011# 判断某个元素是否在列表中！print(&#x27;hi&#x27; in _list) # True!print(&#x27;hi&#x27; not in _list) # False!# 确定列表不为空?request = []if request: print(&#x27;not null&#x27;)else: print(&#x27;null&#x27;) 元组元组：即不可变(不可修改)的列表 12345678# 列表list = [1, 2, 3]# 元组dimensions = (1, 2, 3)for dimension in dimensions: print(dimension)dimensions = (2, 3, 4) # 重新赋值, 可行 相对于列表，元组是更简单的数据结构。如果需要存储的一组值在整个生命周期内都不变，可使用元组。 for 循环、if 条件判断for 循环在前文其实已经谈到了，不清楚的可以回看一下。 注意：for、if、else 这种都不需要括号 ()，但都需要冒号 : 1234567891011121314151617# if判断语句nums = [1, 3, 4, 6, 7, 9, 14]for num in nums: if num &lt;= 6: print(&#x27;small&#x27;) elif 6 &lt; num &lt; 10: print(&#x27;middle&#x27;) else: print(&#x27;big&#x27;)# 判断特定值是否包含在列表中if 6 in nums: print(&#x27;好耶!&#x27;)print(10 in nums)# 判断特定值是否不包含在列表中print(10 not in nums) 布尔表达式1234567891011121314151617181920# 判断特定值是否包含在列表中if 6 in nums: print(&#x27;好耶!&#x27;)print(10 in nums) # True or Falseprint(10 not in nums) # True or False# 确定列表不为空?request = []if request: print(&#x27;not null&#x27;)else: print(&#x27;null&#x27;)# and、orif i &gt; 6 and j &lt; 3: print(&#x27;and&#x27;)elif i &lt; 3 or j &gt;= 6: print(&#x27;or&#x27;) 字典在 Python 中，字典是一系列 ‘键值对‘，好比 Java 中的 Map 数据结构。 1234# Python字典languages = &#123;&#x27;TypeScript&#x27;: &#x27;not&#x27;, &#x27;Java&#x27;: &#x27;good&#x27;, &#x27;C++&#x27;: &#x27;Not Good&#x27;, &#x27;C&#x27;: &#x27;just so so&#x27;, &#x27;Python&#x27;: &#x27;Learning&#x27;, &#x27;Go&#x27;: &#x27;hurry&#x27;&#125;print(languages[&#x27;TypeScript&#x27;]) # notprint(languages[&#x27;Go&#x27;]) # hurry 访问1print(languages[&#x27;Python&#x27;]) 添加12# 添加键值对languages[&#x27;Kotlin&#x27;] = &#x27;Android Language&#x27; 修改12# 修改字典的值languages[&#x27;Go&#x27;] = &#x27;nearly&#x27; 删除12# 删除字典键值对del languages[&#x27;Java&#x27;] 遍历字典123456# 遍历字典for lang, level in languages.items(): print(lang + &#x27;: &#x27; + level)# 也可以, 输出对象for keyValue in languages.items(): print(keyValue) 遍历字典中的所有键1234567# keys()for key in languages.keys(): print(key.title())# 按顺序遍历所有键: sorted()for key in sorted(languages.keys()): print(key.title()) 遍历字典中的所有值字典的键是默认不重复的，那如果想要值也不重复，那么就需要用到 set() 来找出独一无二的元素。 1234567# values()for value in languages.values(): print(value.upper())# set()for value in set(languages.values()): print(value) 嵌套字典嵌套列表；列表嵌套字典；字典嵌套字典；列表嵌套列表。无异于 JavaScript。 字典列表 列表中存储字典 1234567# 字典列表obj1 = &#123;&#x27;key1&#x27;: &#x27;val1&#x27;&#125;obj2 = &#123;&#x27;key2&#x27;: &#x27;val2&#x27;&#125;obj3 = &#123;&#x27;key3&#x27;: &#x27;val3&#x27;&#125;objList = [obj1, obj2, obj3]for obj in objList: print(obj) 字典中存储列表12345678910111213# 字典中存储列表pizza = &#123; &#x27;crust&#x27;: [&#x27;thick&#x27;, &#x27;think&#x27;], &#x27;toppings&#x27;: [&#x27;mushrooms&#x27;, &#x27;extra cheese&#x27;]&#125;for key, value in pizza.items(): print(&#x27;key: &#x27; + key) for topping in value: print(&#x27;value: &#x27; + topping)for topping in pizza[&#x27;toppings&#x27;]: print(topping) 字典中存储字典123456789101112131415161718# 字典中存储字典users = &#123; &#x27;user1&#x27;: &#123; &#x27;name&#x27;: &#x27;hi&#x27;, &#x27;age&#x27;: 19 &#125;, &#x27;user2&#x27;: &#123; &#x27;name&#x27;: &#x27;hello&#x27;, &#x27;age&#x27;: 20 &#125;, &#x27;user3&#x27;: &#123; &#x27;name&#x27;: &#x27;halo&#x27;, &#x27;age&#x27;: 21 &#125;,&#125;# info字典一定要使用str()转为str,否则: TypeError: can only concatenate str (not &quot;dict&quot;) to strfor username, info in users.items(): print(username + &quot;: &quot; + str(info)) 列表中存储列表1234567# 列表中存储列表infoList = [ [1, 2, 3], [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]]for info in infoList: print(info) Remember if、elif、else、while 都需要冒号！ 包括后面要学的函数定义，也是如此！ ⭐因为 Python 中 : 等价于 &#123;&#125; 用户输入 input()123456# 用户输入: input()中用于存储提示信息while True: phone = input(&#x27;please input your telephoneNumber: &#x27;) if phone == &#x27;q&#x27;: break print(phone) 使用 int() 获取数值输入12345678while True: ids = input(&#x27;please input your ID: &#x27;) if ids == &#x27;q&#x27;: break # int(): 将str()转化为数值int() ids = int(ids) if ids &gt;= 143: print(ids) 函数基本定义与使用： 12345# 冒号 : 结尾def add_two_number(message): print(message)add_two_number(&#x27;Hello Python!&#x27;) 传递参数位置实参12345def function1(name, age): print(name + &#x27;: &#x27; + str(age))# 根据位置传入 (同Java)function1(&#x27;alawan&#x27;, 23) 关键词实参12345def function1(name, age): print(name + &#x27;: &#x27; + str(age))# 关键词实参function1(age=26, name=&#x27;hhh&#x27;) 默认值使用默认值时，在形参列表中必须先列出没有默认值的参数，再列出有默认值的参数。 1234567# age 不能定义在 name 后面！def function2(age, name=&#x27;Judge&#x27;): print(name + &quot;: &quot; + str(age))function2(16)function2(16, &#x27;notDefault&#x27;) 返回值12345678910# 有返回值直接return, 跟函数定义格式无关def function3(message): return message# 同msg = function3(&#x27;GG&#x27;)msg = function3(&#123;&#x27;name&#x27;: &#x27;p&#x27;, &#x27;age&#x27;: 19&#125;)msg = function3([1, 2, 3]) 传递列表 传递参数中存在一个比较特殊的情况，也就是形参是列表： 普通传入的话，函数是可以修改列表的，也就是和列表共用一个引用对象 还有一种的禁止函数修改列表方式的传入 但不论怎么传入函数的，函数的定义还是一样。 1234567891011121314# 传递列表def greet_users(users): for user in users: print(&#x27;hello: &#x27; + user)_users = [&#x27;qqq&#x27;, &#x27;www&#x27;, &#x27;eee&#x27;, &#x27;rrr&#x27;, &#x27;ttt&#x27;]# 传入列表副本: 禁止函数修改列表greet_users(_users[:])print(_users)# 直接传入: 函数可修改列表greet_users(_users)print(_users) 传递任意数量的实参结合使用位置实参和任意数量实参1234567891011# 传递任意数量的实参def any_args_function(*langs): for lang in langs: # 不换行! 参数之间用 \\t 隔开 print(lang, end=&#x27;\\t&#x27;) # print(lang)# 传递了2个参数, 1个是列表, 1个是字典any_args_function([&#x27;Go&#x27;, &#x27;Java&#x27;, &#x27;C&#x27;, &#x27;C++&#x27;, &#x27;Python&#x27;, &#x27;PHP&#x27;, &#x27;TypeScript&#x27;], &#123;&#x27;name&#x27;: &#x27;q&#x27;, &#x27;age&#x27;: 19&#125;)# 传递了3个参数any_args_function(&#x27;Go&#x27;, &#x27;Python&#x27;, &#x27;C++&#x27;, &#x27;C&#x27;) 使用任意数量的关键字实参12345678910# 使用任意数量的关键字实参def build_profile(first, last, **user_info): profile = &#123;&#x27;first_name&#x27;: first, &#x27;last_name&#x27;: last&#125; for key, value in user_info.items(): profile[key] = value return profileuser_profile = build_profile(&#x27;Gulf&#x27;, &#x27;Alaska&#x27;, key1=&#x27;value1&#x27;, key2=&#x27;value2&#x27;)print(user_profile) 模块import 语句允许在当前运行的程序文件中使用模块中的代码。 1234# 1.导入整个模块: module_name.function_name() ==&gt; module_name.py - function_name()import packaeg_name.module_namemodule_name.function1() 12345# 2.导入模块中的函数: function_name()from packaeg_name.module_name import function1, function2flag = function1()area = function2() 123# 3.使用 as 给函数指定别名from packaeg_name.module_name import function1 as fnfn() 123# 4.使用 as 给模块指定别名import packaeg_name.module_name as _module_module.function1() 1234# 5.导入模块中的所有函数from modules_name import *function1()function2() 类类中的实例函数形参都需要 self 变量！ 定义和使用类1234567891011121314151617181920212223242526272829303132333435# 定义类class iPhone: def __init__(self, id, number, date): self.id = id self.number = number self.date = date def ringing(self): print(&#x27;Your iphone is ringing!&#x27;) def hang_on(self): print(&#x27;Hang on your phone..&#x27;)class Person: &quot;&quot;&quot;构造函数&quot;&quot;&quot; def __init__(self, name, age, sex): self.name = name self.age = age self.sex = sex self.my_iPhone = iPhone(1, 1183859291, &#x27;2022-03&#x27;) def say_hello(self, other_name): print(self.name + &#x27;: Hello, &#x27; + other_name) self.my_iPhone.ringing() self.my_iPhone.hang_on()person = Person(&#x27;Gulf of Alaska&#x27;, 19, &#x27;F&#x27;)person.say_hello(&#x27;someone&#x27;)print(person) # &lt;__main__.Person object at 0x000002086785EFD0&gt;print(person.name)print(person.sex)print(person.age) 继承1234567891011121314151617181920212223242526272829303132333435363738394041# 父类class Phone: &quot;&quot;&quot;构造函数&quot;&quot;&quot; def __init__(self, id, number, date): self.id = id self.number = number self.date = date def ringing(self): print(self.id + self.number) print(&#x27;Your phone is ringing!&#x27;) def hang_on(self): print(self.date) print(&#x27;Hang on your phone..&#x27;)# 子类: 继承 Phone 类class HuaWei(Phone): def __init__(self): &quot;&quot;&quot;先初始化父类 (因为初始化父类后, 父类才能有属性, 子类才能继承)!!!&quot;&quot;&quot; super(HuaWei, self).__init__(1, 119, &#x27;now&#x27;) print(&#x27;__init__&#x27;) def xiao_yi(self): print(&#x27;这里是小艺, 有什么能帮助你的吗?&#x27;) # 重写父类方法！ # def ringing(self): # print(&#x27;HuaWei is ringing&#x27;) # 重写父类方法！ # def hang_on(self): # print(&#x27;hang on..&#x27;)wd = HuaWei()wd.ringing()wd.hang_on()wd.xiao_yi() 导入类1234567891011121314151617181920# 1.导入单个类from main import Mathmath = Math(2, 3)math.two_sum()# 2.从一个模块导入多个类(一个 .py 就是一个模块)from main import Math, Time# 3.导入整个模块import mainmyMath = main.Math(2,3)myMath.two_sum()# 4.导入模块中的所有类from main import *Math(1, 2).two_sum() 文件和异常文件读取 open() 返回一个文件对象，需要提供实参文件路径 read() 读取文件全部内容 readline() 读取单行 readlines() 读取文件的每一行，然后返回一个列表 文件路径：Windows 使用反斜杠（\\）而不是 Linux&#x2F;OS X 的斜杠（&#x2F;） 1234# 读取文件with open(&#x27;pi_digits.txt&#x27;) as file_object: contents = file_object.read() print(contents) 123456789filename = &quot;my_modules/digits.txt&quot;with open(filename) as file: lines = file.readlines()str = &#x27;&#x27;for line in lines: str += line.strip()print(str[:16] + &#x27;...&#x27;) # 3.14159265358979...print(len(str)) 写入文件写入文件：调用 open() 时需要提供另一个实参，告诉 Python 你要以写入模式打开文件。 1234# 写入文件filename = &#x27;./test.txt&#x27;with open(filename, &#x27;w&#x27;) as file_obj: file_obj.write(&#x27;I love programming.&#x27;) 在这个示例中，调用 open() 提供了两个实参： 第一个实参也是要打开的文件的名称 第二个实参 w 告诉 Python，要以写入模式打开这个文件 读取模式 r 写入模式 w 附加模式 a 读取和写入文件的模式 r+ 如果你省略了该实参，Python 将以默认的只读模式打开文件 写入多行函数 write() 不会在你写入的文本末尾添加换行符！ 12345678# 写入多行filename = &#x27;my_modules/digits.txt&#x27;with open(filename, &#x27;w&#x27;) as file_obj: file_obj.write(&#x27;I love programming.&#x27;) file_obj.write(&#x27;do you?!&#x27;)# 函数 write() 不会在你写入的文本末尾添加换行符！# my_modules/digits.txt: I love programming.do you?! 追加文件内容如果你要给文件追加内容，而不是覆盖原有内容，可以附加模式 a 打开文件。 1234# 追加文件内容filename = &#x27;my_modules/digits.txt&#x27;with open(filename, &#x27;a&#x27;) as file_obj: file_obj.write(&#x27;Yes! I love programming too.&#x27;) 异常Python 使用被称为异常的特殊对象来管理程序执行期间发生的错误。 异常使用 try-except-else 代码块处理，如果你未对异常进行处理，程序将显示 traceback，其中包含有关异常的报告。 try 代码块中无异常则跳转到 else 代码块中，否则跳转到 except 中进行异常处理。 处理 ZeroDivisionError 异常1234567# ZeroDivisionErrortry: answer = 1 / 3except ZeroDivisionError: print(&quot;You can&#x27;t divide by zero!&quot;)else: print(answer) 处理 FileNotFoundError 异常123456789# FileNotFoundErrorfilename = &#x27;Gulf.txt&#x27;try: with open(filename, &#x27;r&#x27;) as file_obj: print(file_obj.read())except FileNotFoundError: print(&#x27;We could not find the file..&#x27;)else: print(&#x27;success reading.&#x27;) 123456789101112131415# 计算一个文件大概有几个单词, 未找到文件则提示def count_file_numbers(filename): try: with open(filename, &#x27;r&#x27;) as file_object: file_contents = file_object.read() except FileNotFoundError: print(&#x27;sorry, the file &#x27; + filename + &#x27; does not exist.&#x27;) else: snippets = file_contents.split() count = len(snippets) print(&#x27;the file &#x27; + filename + &#x27; has &#x27; + str(count) + &#x27; words.&#x27;)count_file_numbers(&#x27;pi_digits.txt&#x27;) # the file pi_digits.txt has 12 words.count_file_numbers(&#x27;Gulf.txt&#x27;) # sorry, the file Gulf.txt does not exist. 存储数据使用 json.dump() 和 json.load() 存储和获取数据。 1234567891011121314151617# 导入Json库函数import jsondef remember(filename): try: with open(filename) as f_obj: username = json.load(f_obj) except FileNotFoundError: username = input(&#x27;Input your name, we will remember it! &#x27;) with open(filename, &#x27;w&#x27;) as f_obj: json.dump(username, f_obj) else: print(&quot;Welcome back, &quot; + username + &#x27; !&#x27;)remember(&#x27;username.json&#x27;) 异常时一声不吭Python 有一个 pass 语句，可在代码块中使用它来让 Python 什么都不做。 123456789import jsontry: with open(&#x27;username.txt&#x27;) as f_obj: username = json.load(f_obj)except FileNotFoundError: passelse: print(&#x27;success&#x27;) pass 充当了占位符的作用，提醒你某个地方什么都没做，并且以后也需要在这里做点什么。 测试测试用例测试类必须继承 unittest.TestCase 类，这样 Python 才知道如何运行你编写的测试。 注意：测试函数必须以 test_ 打头，否则不会被执行。 12345678910111213# 测试import unittestfrom name_function import Nameclass TestCase(unittest.TestCase): # 必须以 test_ 打头, 这样运行 unittest.main() 才会执行 test_first_last_name() 测试函数 def test_first_last_name(self): name = Name().get_name(&#x27;Gulf&#x27;, &#x27;Alaska&#x27;) self.assertEqual(&#x27;Gulf Alaska&#x27;, name)unittest.main() 运行 unittest.main() 的测试结果： 1234567891011121314151617F======================================================================FAIL: test_fist_last_name (__main__.TestCase)----------------------------------------------------------------------Traceback (most recent call last): File &quot;D:\\xxx\\PyCharm\\pythonProject\\www.py&quot;, line 588, in test_fist_last_name self.assertEqual(&#x27;Gulf Alaska&#x27;, name)AssertionError: &#x27;Gulf Alaska&#x27; != &#x27;Gulf Alaska&#x27;- Gulf Alaska? -+ Gulf Alaska----------------------------------------------------------------------Ran 1 test in 0.001sFAILED (failures=1) 测试类各种断言方法： assertEqual(a, b) assertNotEqual(a, b) assertTrue(x) assertFalse(x) assertIn(item, list) assertNotIn(item, list) 方法 setUp() 初始化测试对象： 12345678910111213141516import unittestfrom name_function import Nameclass TestCase(unittest.TestCase): # 初始化测试实例 def setUp(self): self.toTestName = Name() # 必须以 test_ 打头, 这样运行 unittest.main() 才会执行 test_first_last_name() 测试函数 def test_first_last_name(self): name = self.toTestName.get_name(&#x27;Gulf&#x27;, &#x27;Alaska&#x27;) self.assertEqual(&#x27;Gulf Alaska&#x27;, name)unittest.main() 更多Python 手册","tags":["Python"],"categories":["Python"]},{"title":"动图轻松理解 Self-Attention (自注意力机制)","path":"/post/AI-Infra/animated-pictures-to-easily-understand-self-attention/","content":"Self-Attention 是 Transformer 中最核心的思想。我们在阅读 Transformer 论文的过程中，最难理解的可能就是自注意力机制实现的过程和繁杂的公式。本文在 Illustrated: Self-Attention 这篇文章的基础上，加上了自己对 Self-Attention 的理解，力求通俗易懂。希望大家批评指正。 1. Self-Attention 是什么？我们再来讲解一个重要的概念，即 query、key 和 value。这三个词翻译成中文就是查询、键、值，看到这中文的意思，还是迷迷糊糊的。我们来举个例子：小明想在 b 站搜索深度学习，他把深度学习四个字输入到搜索栏，按下搜索键。搜索引擎就会将他的查询 query 映射到数据库中相关的标签 key，如吴恩达、神经网络等等，然后向小明展示最匹配的结果 value。 最后我们来说说 Self-Attention。和 Attention 类似，他们都是一种注意力机制。不同的是 Attention 是 source 对 target，输入的 source 和输出的 target 内容不同。例如英译中，输入英文，输出中文。而 Self-Attention 是 source 对 source，是 source 内部元素之间或者 target 内部元素之间发生的 Attention 机制，也可以理解为 Target&#x3D;Source 这种特殊情况下的注意力机制。 下面我们通过一个简单的例子，来了解 Self-Attention 的计算步骤。 2. 计算步骤2.1 定义 input在进行 Self - Attention 之前，我们首先定义 3 个 1×4 的 input。 pytorch 代码如下： 1234567import torchx = [ [1, 0, 1, 0], # input 1 [0, 2, 0, 2], # input 2 [1, 1, 1, 1] # input 3 ]x = torch.tensor(x, dtype=torch.float32) 2.2 初始化权重每个 input 和三个权重矩阵分别相乘会得到三个新的矩阵，分别是 key(橙色)，query(红色)，value(紫色)。我们已经令 input 的 shape 为 1×4，key、query、value 的 shape 为 1×3，因此可以推出与 input 相乘的权重矩阵的 shape 为 4×3。 代码如下： 这三个不同的权重矩阵（$W_Q、W_K、W_V$）是通过神经网络模型的训练过程自动学习而来的。在自注意力机制中，这些矩阵是模型参数的一部分，它们的初值通常是随机初始化的。然后，通过训练数据和反向传播算法，模型会逐渐调整这些矩阵的值，以最小化预测误差（比如分类任务中的交叉熵损失）。 12345678910111213141516171819202122232425w_key = [ [0, 0, 1], [1, 1, 0], [0, 1, 0], [1, 1, 0]] w_query = [ [1, 0, 1], [1, 0, 0], [0, 0, 1], [0, 1, 1]]w_value = [ [0, 2, 0], [0, 3, 0], [1, 0, 3], [1, 1, 0]]w_key = torch.tensor(w_key, dtype=torch.float32)w_query = torch.tensor(w_query, dtype=torch.float32)w_value = torch.tensor(w_value, dtype=torch.float32)print(&quot;Weights for key: &quot;, w_key)print(&quot;Weights for query: &quot;, w_query)print(&quot;Weights for value: &quot;, w_value) 2.3 计算 key, query 和 value现在我们计算 key, query 和 value 矩阵的值，计算的过程也很简单，运用矩阵乘法即可： key &#x3D; input * w_key; query &#x3D; input * w_query; value &#x3D; input * w_value; 1234567891011121314151617keys = x @ w_keyquerys = x @ w_queryvalues = x @ w_valueprint(&quot;Keys: &quot;, keys)# tensor([[0., 1., 1.],# [4., 4., 0.],# [2., 3., 1.]])print(&quot;Querys: &quot;, querys)# tensor([[1., 0., 2.],# [2., 2., 2.],# [2., 1., 3.]])print(&quot;Values: &quot;, values)# tensor([[1., 2., 3.],# [2., 8., 0.],# [2., 6., 3.]]) 2.4 计算 attention scores例如：为了获得 input1 的注意力分数 (attention scores)，我们将 input1 的 query(红色)与 input1、2、3 的 key(橙色) 的转置分别作点积，得到 3 个 attention scores(蓝色)。 同理，我们也可以得到 input2 和 input3 的 attention scores。 123456attn_scores = querys @ keys.Tprint(attn_scores)# tensor([[ 2., 4., 4.], # attention scores from Query 1# [ 4., 16., 12.], # attention scores from Query 2# [ 4., 12., 10.]]) # attention scores from Query 3 2.5 对 attention scores 作 softmax上一步得到了 attention scores 矩阵后，我们对 attention scores 矩阵作 softmax 计算。softmax 的作用为归一化，使得其中各项相加后为 1。这样做的好处是凸显矩阵中最大的值并抑制远低于最大值的其他分量。 123456789101112131415from torch.nn.functional import softmaxattn_scores_softmax = softmax(attn_scores, dim=-1)print(attn_scores_softmax)# tensor([[6.3379e-02, 4.6831e-01, 4.6831e-01],# [6.0337e-06, 9.8201e-01, 1.7986e-02],# [2.9539e-04, 8.8054e-01, 1.1917e-01]])attn_scores_softmax = [ [0.0, 0.5, 0.5], [0.0, 1.0, 0.0], [0.0, 0.9, 0.1]]attn_scores_softmax = torch.tensor(attn_scores_softmax)print(attn_scores_softmax) 2.6 将 attention scores 与 values 相乘每个 score(蓝色)乘以其对应的 value(紫色)得到 3 个 alignment vectors(黄色)。在本教程中，我们将它们称为 weighted values(加权值)。 12weighted_values = values[:,None] * attn_scores_softmax.T[:,:,None]print(weighted_values) 2.7 对 weighted values 求和得到 output从图中可以看出，每个 input 生成 3 个 weighed values(黄色)，我们将这 3 个 weighted values 相加，得到 output(深绿)。图中一共有 3 个 input，所以最终生成 3 个 output。 123456outputs = weighted_values.sum(dim=0)print(outputs)# tensor([[2.0000, 7.0000, 1.5000], # Output 1# [2.0000, 8.0000, 0.0000], # Output 2# [2.0000, 7.8000, 0.3000]]) # Output 3 3. 回到论文我们在 Attention is all you need 这篇论文中，可以看到这样一个公式： $$Attention(Q,K,V)&#x3D;softmax(\\frac{QK^T}{\\sqrt{d_k}})V$$其实，这个公式就是描述了我们上面计算的过程。我们首先将 Query 与 Key 的转置作点积，然后将结果除以 $\\sqrt{d_k}$ ，再作 softmax 计算，最后将计算的结果与 Value 作矩阵乘法得到 output。 这里有一个点，就是为什么要除以 $\\sqrt{d_k}$？$d_k$ 表示的是词向量的维度。我们除以 $\\sqrt{d_k}$ 是为了防止 $QK^T$ 值过大，导致 softmax 计算时上溢出 (overflow)。其次，使用 $d_k$ 可以使 $QK^T$ 的结果满足期望为 0，方差为 1 的分布。 4. 为什么这样计算？最后的问题是，为什么要像公式那样计算呢？ 我们先从 $QK^T$ 看起，从几何角度看，点积是两个向量的长度与它们夹角余弦的积。 如果两向量夹角为 90°，那么结果为 0，代表两个向量线性无关。 如果两个向量夹角越小，两向量在方向上相关性也越强，结果也越大。 点积反映了两个向量在方向上的相似度，结果越大越相似。 对 $QK^T$ 进行相似度的计算后，再使用 softmax 归一化。最后将归一化的结果与 $V$ 作乘法，计算的结果就是输入经过注意力机制加权求和之后的表示。","tags":["LLM","Self-Attention","ChatGPT","Transformer"],"categories":["AI-Infra"]},{"title":"ChatGPT 是如何处理文字输入的？","path":"/post/AI-Infra/how-does-chatgpt-handle-text-input/","content":"我们清楚了 ChatGPT 模型的输入和输出，实际上就是将文字输入 ChatGPT 模型当中，然后再让模型预测出文字，本质上就是一个“文字接龙”式的语言模型。 而文字在进入 ChatGPT 模型之前，需要先经过一个转换，形成另外一种数据形式。在 ChatGPT 计算处理完之后，也需要将结果再做逆转换，形成文字形式，反馈给用户。这种转换包括两个步骤，Tokenizer 和 Embedding。本文主要介绍这两个模块。 TokenizerChatGPT 官方目前已经开始对服务收费了，收费方式主要是计算用户使用的 token 数，数量越多，收费越高。 例如，用户提问了一条文本，文字（带标点和各种特殊符号）共有 50 个字符，但耗费了 30 个 token，ChatGPT 根据输入生成一条回答，总计 200 个 token，逆转换为文字总共 300 个字，那么用户一共消费的 token 数就是 30+200&#x3D;230 个。那什么是 token 呢？ token 是任何 NLP 神经网络 模型接收用户输入的最小粒度。 token 本身就是一些字符的组合，如英文单词#cat、中文词汇鞋子、英文词缀ly、中文汉字珂等，都可以看作是一个 token。 将用户输入的文本转换为 token 序列的过程就叫做 Tokenizer。它包含两部分，一部分是从文字转换为 token（设置在进入 ChatGPT 之前），另一部分是将 token 转换为文字，也就是逆转换（设置在 ChatGPT 模型输出之后）。 Tokenizer 算法 BPE 执行流程Tokenizer 目前最流行的实现方法是 字符对编码 BPE（Byte Pair Encoding） 算法，它也是 ChatGPT 采用的算法。BPE 算法是根据一份 token 词表（Vocabulary），将输入的文本拆解成若干个 token。其中，每一个 token 都存在于词表。 具体以如下一条输入模型的文本为例： The newest car has a lower price and the lowest fuel. 这条文本中，包含了 53 个字符（包含字母、空格和标点，以及任何键盘可以打出的特殊符号，均输入 ChatGPT 中）。 一般地，模型训练所使用的词表中 token 数量大约从几万~几十万不等。假设 BPE 算法已经生成一个 Token 词表（Vocabulary） ，其部分词表 token 内容如下： #low est #new er #the #car #and #fuel #a #has #have and #thailand #price #dog #old #most … BPE 算法就是根据上述 token 词表对文本进行匹配，从文本中拆分出存在于词表中的 token，将文本转换成如下的形式： The newest car has a lower price and the lowest fuel. &#x3D;&#x3D;&gt; #The, #new, est, #car, #has, #a, #low, er, #price, #and, #the, #low, est, #fuel. 在这条例子中，文本被拆分成 15 个 token。由于英文单词是以空格形式进行分割的，因此，每一个单词的首字母都添加#为单词起始的标识，它可以理解为一个空格，不加#的token表示无法独立成词。一些单词被拆分成若干部分，如newest被拆分成两部分，#new 和 est。然后，模型就接收这样的 token 数据做进一步处理计算。 从上面的例子中，我们可以看出，token 中一般都是以非常高频的字符组合构成的，而且这些 token 往往具备一定的语义。例如，newest被拆解为#new 和 est，前半部分是单词词根，后半部分是英文形容词最高级。 同样地，ChatGPT 模型在回答用户问题，输出答案时，也是首先输出 token 序列，再将 token 序列反转为正常的自然语言文本，这个操作叫做 De-tokenization。它与 Tokenization 是完全互逆的操作。读者可以尝试把上面的 token 序列合并成完整的文本句子。 对于中文而言，常用汉字大约为 7000 个左右，而且文本之间不存在空格。因此，也可以采用上述的算法来完成，唯一的区别就是中文的 token 的开头不添加 # 符号。一些极为常见的中文单词可能合并为一个 token，如我们，而考虑到词频，绝大多数中文依然以单字独立成 token。 Byte-level BPE 算法之前介绍的 BPE 算法是基于字符的，除此之外，还有一种基于字节的 BPE 算法（Byte-level BPE）。这种方法，主要是为了克服基于字符的 token 词表，由于各种特殊字符数量太庞大导致效果变差。 除了我们常用的中文外，ChatGPT 可以随意操作英文、日文、韩文、法文等至少二十多种文字。这些语言的文字和符号更是多种多样，有英文拉丁字母ABCDabcd，中文汉字千百花鸟风月，西里尔字母БГД，日语假名ピンイ，当然也包括很多 emoji 特殊符号💁👌🎍😍。 所有的字符在计算机中都是以 Unicode 编码格式实现的。 Unicode 编码是一种用于计算机表示全球范围内各种语言文字字符的标准编码方式，它为世界上所有的字符都分配了一个唯一的数字编号，解决不同国家和地区使用不同语言文字、字符集的问题。 Unicode 编码采用 16 进制表示，每个字符都有一个唯一的码点，例如汉字“中”在 Unicode 编码中的码点是U+4E2D，其中 U+ 表示 Unicode 编码，4E2D 是该字符的 16 进制码点。若以 UTF-8 编码为例，汉字“中”被转换为 3 个字节（byte） 的二进制数据：11100100 10111000 10101101。 Unicode 常用字符目前总量大约有十多万，如果直接基于字符形式，构造 token 词表的话，那么词表可能会变得非常庞大，达到几十万。过于庞大的词表会对 ChatGPT 模型产生很强的不确定性因素，让模型难以训练。 因此，Byte-level BPE 算法应运而生。这种算法的执行步骤和上述的 BPE 算法完全一致，唯一的区别在于，BPE 算法直接操作 Unicode 字符，而 Byte-level BPE 算法把文本的字节作为直接操作的对象。 由于操作的基本单位是字节而不是字符，因此即使是复杂的、多样化的文字系统（如中文、日文等），其基础元素也仅仅是256个可能的字节值。这相较于直接基于字符的BPE算法，其可能需要包含成千上万个不同的字符，词表大小显著减少。小型词表意味着模型训练和推理时的内存和存储需求大大降低。 例如，在 BPE 算法中，中 字被当作一个字符进行 token 匹配。而在 Byte-level 算法中，它被当作 3 个字符进行匹配（因其 Unicode 占用 3 个字节）。而英文字母如 p 则在两种算法中，都被当作一个字符处理，因为字母的 Unicode 编码只占用一个字节。所有的字节个数全部加起来不过 256 （即一个字节所表示的符号个数 $1\\ Byte &#x3D; 8\\ bit &#x3D; 2^8$）个，这对模型训练是一个巨大的利好。 Byte-level BPE 算法的代码链接：Byte-level BPE，感兴趣的可以阅读一下。 BPE 的词表是如何训练得到的？BPE 的词表主要是根据训练文本语料统计得到的，训练的语料数量越大，得到的 BPE 词表越准确，越具有词根语义。 假设根据一份语料数据，我们可以统计得到如下词汇和其对应出现的次数。 #lowest 7 #lower 4 #newest 5 #older 5 #newer 4 #and 10 #fuel 4 #a 14 #has 4 #oldest 5 #thailand 3 #price 6 #new 7 #old 6 … … 以上均为文本中存在的完整的词汇。 接下来，我们可以按字母进行统计，得到频率最高的字符对为标红的 “es”，共计出现 17 次。我们单独把 “es” 提出来，并把语料中的所有 “es” 看作一个整体。 再重复上面的过程，可以发现“est”可以看作是“es” 和 “t” 的结合体，总计也出现 17 次。因此，可以把“est” 看作一个整体，放入词表，并把语料中所有的 “est” 看作一个整体。 再重复上面的过程，可以发现，“#a” 的频率仅次于 “est”，为 14 次。因此，把 “#a” 放入词表中。 再重复，可以把 “er” 这个字符对提取出来。 以此类推，我们可以逐渐将高频的字符对提取出来，不断放入词表中。 当放入词表中的 token 数达到了预定的最大数 N 时（一般从几万到几十万不等），得到最终的词表，即可用于 BPE 算法的执行流程，拆分每一条文本为若干 token。 Tokenizer 的好处克服长尾效应 OOV在英文单词中，最常出现的 5000 个单词占据了实际使用量的 90%。而那些极低频的单词数量极多，但总共加起来的实际使用量也不超过 2%。这就是自然语言的长尾效应 ， 这种现象也出现在其它语言中。 直接把极低频的单词和字符当作 token，本身意味着数据量的缺乏，会导致它有可能不在词表中（Out Of Vocabulary，OOV），对 NLP 模型的性能产生很大的影响。因此，引入 Tokenizer，采用 BPE 算法可以避免低频词作为 token。 例如，根据上述训练例子得到的词表，#strangest 这个词在训练语料中词频较低，可能不出现在 token 词表中，但 “#strang” 和 “est” 一定以较高的频率出现在 token 词表中。 多语言支持在早期，NLP 神经网络模型功能十分单一，且仅支持某一种语言。一个针对英文的文本分类模型，并不能支持中文的文本分类。而 BPE 算法，包括 Byte-level BPE 算法的设计，使得一份词表中包含了多种语言的字符，支持模型的多语言处理功能。 词嵌入｜EmbeddingChatGPT 的输入文字转换为 token 之后，还需要将 token 再转换为张量，这个过程叫做词嵌入（ Embedding），同时 embedding 也指被转换后得到的张量本身。 在神经网络中，张量（Tensor）是指多维数组，它可以存储和处理大量的数据，是神经网络中最基本的数据结构。张量一般都以浮点数（小数的一种计算机表示形式）作为元素进行填充。 例如，$a&#x3D;[[1.034,0.932,−0.347],[0.023,−1.025,0.256]]$ 就是一个 $(2,3)$ 形状的张量，是一个多维数组。 而向量（vector），就是高中数学中的概念，一般就可以看作是一维张量。 ChatGPT 从功能上看，是一个语言模型，但从结构上看，它是一个多层的、复杂的神经网络模型，每一层的神经网络都在进行浮点数张量（Tensor）的数字计算，而 ChatGPT 的输入是文字符号，token 也是文字符号。因此，token 需要先转换为浮点数字，再进入模型中进行计算。将用户输入的 token 转换为浮点数张量的过程，就叫做词嵌入（Embedding） 。当模型将结果计算完，也要将最终的浮点数转换为具体的 token，作为输出。 #The, #new, est, #car, #has, #a, #low, er, #price, #and, #the, #low, est, #fuel. 仍以上述句子为例，假设 token 词表（Vocabulary）的数量总共为 N，每一个 token 都用一个 M 维的浮点数张量表示，其中每一个 token 都对应了一行张量，即该 token 的 embedding 表示。 例如，#price 这个 token 对应的 embedding 是一个 M 维向量： $#price→ [0.103,0.034,0.129,−0.219,−0.156,…,0.0284,−0.172]$ 这组数据就可以传入 ChatGPT 模型中，做模型的训练和使用。所有的词表组成了一个 $N × M$ 维度的张量，如下图左侧方阵。 根据例子中的前四个 token，我们可以将其对应的 embedding 抽取出来，按 token 的顺序排列成一组 $N_{输入token数}×M$ 的张量，这组张量即可输入 ChatGPT 进行操作，图中白色部分表示词表中的词汇未匹配到 token 序列。换句话说，它完成了由 token 到其对应张量的映射。 在实际模型当中，一次性输入给模型的 token 数量 $N_{输入token数}$ 并不是无限大的，例如，在 ChatGPT 的 gpt-3.5-turbo 版本中，最大的输入 token 数量为 4097 个，超出这个范围则会被模型自动截断。 在自然语言中，文字的顺序是非常重要的，“我喜欢你”，和 “你喜欢我” 表达的含义是完全不同的。所以，ChatGPT 考虑到模型的每个 token 相互之间的顺序不能改变，需要明确地在输入端标识出每个 token 的位置张量（Position Embedding），其大小和 token 的 embedding 是一致的。两者以如下形式融合起来：$embedding_{input}&#x3D;UW_e+W_p$。 其中，$W_e$ 是 token embedding 矩阵，$W_p$ 是 position embedding 矩阵。而其中的 $U$ 是一个上下文矩阵。根据第 3 节的语言模型原理，模型在建模时有上下文限制，针对当前的一个 token，模型只能关注该 token 之前的 $k$ 个 token。因此，$U&#x3D;(u_{-k},…,u_{-2},u_{-1})$，它是一个单位矩阵。 假设 token 数量小于模型可接收的最大数量，那么，上述公式可以退化为：$embedding_{input}&#x3D;W_e+W_p$。 由此，即可输入 ChatGPT 模型进行计算。 第 1 节中提到，ChatGPT 是有多轮对话能力的。 在模型中，需要从输入端将输入1（Q1）、输出1（A1）、输入2（Q2）等部分信息区分出来。这几个部分信息分别叫做一个 segment，其中每一个 segment 都包含了多个 token，它们共享了同一个 segment embedding。具体方式如下： 上图中做了假设：Q1、A1、Q2 分别包含了 4 个 token。当然，在实际输入中，每个 segment 包含的 token 数都是可以灵活变化的；上面对话的轮数仅有两轮，而实际输入中，对话轮数可以非常多，形如 Q1、A1、Q2、A2、…、Qn， 只要所有 segment 对应的 token 总数加起来不超过模型允许的最大 token 数即可。 因此，输入给 ChatGPT 的 embedding可以表示为如下公式：$$embedding&#x3D;embedding_{segment}+embedding_{position}+embedding_{token}$$ Embedding 的好处最早的时候，NLP 是直接处理文本字符串，没有 Embedding 这个操作的。Embedding 这个操作最早是由 word2vec 模型提出并实施的，GPT 系列模型，包括 ChatGPT 已将此操作作为了固定默认步骤。 Embedding 方便接入大规模神经网络我们在第 2 节中论述了，AI 想要有较高水平的智能，其模型规模必然比较大，参数量众多。在机器学习领域，神经网络模型是最容易扩展其模型规模的。我们会在第 8 节讲解神经网络相关的概念。 如果没有 Embedding 操作，那么 NLP 领域依然停留在直接处理字符的层面上，模型的规模扩展难度较大。embedding 将文字对应的 token 转换为抽象的固定维度的张量，标志着 NLP 迈入了深度神经网络的大门。 Embedding 抽象了 token 的语义当我们训练好 ChatGPT 这个模型之后，假设我们抽取出如下 token 对应的 embedding 向量： #price（价格），#cost（开销），#trunk（卡车），#texi（出租车） 其对应的均为 M 维 embedding 向量。计算两个向量相似度的方式主要采用余弦距离，则一定有：$$cos(price,cost)&gt;cos(price,truck) \\cos(truck,texi)&gt;cos(cost,texi)$$其含义为，price 和 cost 在 embedding 上的相似度，要大于 price 和 truck 的相似度，这符合人们的语言直觉。可以得出结论，在自然语言中，语义相近的两个词汇，其 embedding 向量之间的数学意义上的距离更相近。 换句话说，Embedding 建立了自然语言的语义与数学之间的关联关系。 总结 Tokenizer 将模型输入的文字转换为 token 序列。 ChatGPT 使用了 BPE 算法实现 Tokenizer。 Embedding 将 token 序列映射为张量矩阵，方便模型进行张量矩阵运算。","tags":["LLM","ChatGPT","Tokenizer","Embedding"],"categories":["AI-Infra"]},{"title":"ChatGPT 的灵魂：Attention 注意力机制","path":"/post/AI-Infra/the-soul-of-chatgpt-attention-mechanism/","content":"Original Paper：Attention is All You Need ! Recommended Post：Self-Attention Principle OpenAI 的 GPT 系列模型，包括其它科技公司研发的各种最先进的 NLP 模型，甚至图像处理模型，广泛采用了 Attention 注意力机制进行建模，它可谓是当前 NLP 神经网络的灵魂机制。 注意力机制的思想相信大家在学生时期，都被家长或老师提点过：“听课的时候注意力集中点！不要东张西望！” 这里就用到了注意力机制。这句话的含义是，学生应当把注意力集中在接收课堂知识上，而不是放在无关的信息上。 注意力机制的思想实际上广泛应用在各个方面，它可以抽象为如下形式： 一个智能体（人或 AI 模型）从接收到的大量信息（文本、图像、音频）中，剔除不重要、不相关的信息，重点关注与自身密切相关的信息。其核心在于收缩关注的信息范围，实现信息的压缩。 根据第 3 节的介绍，在 NLP 中，ChatGPT 语言模型建模实际上是寻找输入文本的上下文关联关系。例如： 例2：请补全这条语句：掘金社区是一个便捷的技术交流______ 在这条文本中，想要补全最终的语句，应当参考前文的信息，而前文总共 14 个字，对空格处影响最大的是掘金两个字，而像形容词便捷的，系词是一个都不是最关键的影响因素。换句话说，我们应当设计一种注意力机制，让模型能够在输出空格字符的时候，最大限度地注意到掘金两个字。 注意力机制的建模建立权重模式根据第 4 节的介绍，在 NLP 模型中，自然语言是以 token 形式排列输入模型中的。如下图所示，绿色的每一列都是对应的一个 token 的 embedding 向量表示，假设每一个 token 的 embedding 具有 7 维，总共 14 个 token 共同组成一个 embedding 矩阵。我们的模型设计思路，是模型应当能够在输出平台的平 字时，更加关注到掘金二字。 让模型更加关注到掘金两个字，实际上可以认为，给掘金两个字对应的 token embedding 赋予更大的权重。 在神经网络模型中，所有的操作均为矩阵操作，所有的特征均为向量形式。设 $e_i$ 表示第 $i$ 个 token 的 embedding 表示，在例子中，它是一个 7 维的向量，$w_i$ 是第 $i$ 个 token 对应的权重值，它是一个标量值。那么，可以对所有的 token embedding 做一个加权：$$h&#x3D;\\sum_ie_iw_i$$这里，$h$ 是一个加权后的结果，它也是一个 7 维的向量。它的本质含义，是从各个 token 不同的 embedding 中，按重要程度（权重值 $w_i$）做加和，权重值高的 $e_i$ ，对后续操作影响大，权重值低的 $e_i$ ，对后续操作影响小。这就产生了一种更加注意权重高的 $e_i$ 的效果。 softmax 函数 定义：softmax 函数是在机器学习和深度学习中广泛使用的一个非常重要的函数，尤其是在处理分类问题时。它可以将一个含任意实数的K维向量压缩（映射）成另一个 K 维实向量，其中每个元素的范围都在 $(0, 1)$ 之间，并且所有元素的和为 1。因此，softmax 函数的输出可以被视为一个概率分布。 公式：$Softmax(z_i)&#x3D;\\frac{e^{z_i}}{\\sum^K_{j&#x3D;1}e^z j}$ 作用和特点：softmax 函数的输出可以解释为一个概率分布，每个元素的值代表了对应类别的概率。使用指数函数确保所有的输出都是正的，并且可以放大输入向量中的差异。softmax 函数配合交叉熵损失函数，常用于训练阶段的梯度下降优化。这种组合可以给出明确的梯度信息，有利于模型通过学习数据来调整参数，以提高分类的准确性。 应用场景： 多类分类问题：在神经网络的最后一层，用于将神经元的输出转换为预测每个类别的概率。 语言模型：在处理自然语言处理任务，如文本分类或机器翻译时，softmax 被用来预测下一个词的概率分布。 增强学习：在某些策略梯度方法中，softmax 用于从一组可能的动作中选择动作。 上面的加权计算中，$w_i$ 是一个标量值，假设模型经过训练后，针对上述例子的 token 计算得到：$w&#x3D;(w_1,w_2,\\ldots,w_i,w_{14})&#x3D;(2.1,1.3,\\ldots,-1.2,-0.4)$ 其中的数值有正有负，前两个 token 对应的权重标量值较大，说明对后续操作的影响大。若直接进行加权，这不符合人们的一般认知。一般来说，权重占比以概率形式表示，概率值应当大于 0，小于 1，且所有分量的加和等于 1。 例如：今年国内的 GDP 占比中，第一产业占比 14.6%，第二产业占比 35.2%，第三产业占比 50.2%。 这是一个典型的概率分布示例，其总和为1，三产占比最高，权重最大，影响经济的程度最大。 因此，我们应当将 $w$ 转换为概率占比形式，主要采用 softmax 方法：$$α_i&#x3D;\\frac{exp(w_i)}{\\sum_i exp(w_i)}$$其中，$exp$ 是指数计算，$α_i$ 表示第 $i$ 个 token 的 embedding 对应的权重，其值介于 0~1 之间。计算上例，假设：$$w&#x3D;(2.1,1.3,0.1,0,−0.2,−1.3,0.5,0.2,−0.8,0,0.1,−0.7,−1.2,−0.4)$$那么，第 1 个 token 的权重：$$α_1&#x3D;\\frac{exp(2.1)}{\\sum exp(w_i)} &#x3D; \\frac{8.166}{8.166+3.669+1.105+1+\\cdots+0.301+0.67}&#x3D;\\frac{8.166}{21.858}&#x3D;0.374$$ 此外，其它若干 token 的权重为：$$α_2&#x3D;\\frac{exp(1.3)}{\\sum exp(w_i)} &#x3D; \\frac{3.669}{8.166+3.669+1.105+1+\\cdots+0.301+0.67}&#x3D;\\frac{3.669}{21.858}&#x3D;0.167$$ $$α_6&#x3D;\\frac{exp(-1.3)}{\\sum exp(w_i)} &#x3D; \\frac{0.272}{8.166+3.669+1.105+1+\\cdots+0.301+0.67}&#x3D;\\frac{0.272}{21.858}&#x3D;0.012$$ 第 1、2 个 token 对应掘金 两个字，分别占权重 37.4% 和 16.7%，占比较高，第 6 个字是一，它的 token 对应的权重仅 1.2%，占比较低。这说明，在这个模型中更加注重了掘金 的权重，方便后续模型输出正确的字符 token。 这个例子说明了 softmax 算法的一些特性： 1、softmax 可以将一维向量，输出形成概率分布的形式； 2、softmax 利用指数函数，会更加着重值更高的元素，使要关注的元素更加突出； 3、相应地，由于指数函数特性，它也可以尽力压低不需关注的元素的权重。 以公式形式表示，计算模型的所有 embedding 加权后的权重：$$h&#x3D;\\sum_i e_i α_i$$Softmax 函数在神经网络模型中十分常用，除了应用在注意力机制计算外，softmax 还可以完美契合交叉熵损失函数（将在第 8 节中介绍）。 自注意力机制 Self-Attention前文讲述了，利用权重向量 $w$ 就可以找到模型要关注的重点内容。那么，$w$ 从哪来呢？值如何计算出来？ 计算权重，不同的模型、不同的 NLP 任务都有不同的形式。这项技术经过多年的发展，最终趋向于自注意力机制（Self-Attention） ，这也是 ChatGPT 所采用的形式。 $w$ 是一个权重向量，其长度（维度）与 token 的个数相同，其中的每一项是标量值。我们知道，神经网络模型中都是以向量、矩阵等构成的张量作为计算基础的。因此，想要计算得到一个标量值，最简单的形式就是向量点积，我们需要想办法找到两个向量。 假设针对第 $i$ 个 token，有两个向量 $q_i$ 和 $k_i$，两者具有相同的维度，其点积可以得到一个标量值：$w_i&#x3D;q_i k_i$ 依然以前述句子为例。在补全句子时，掘金对要空格处填写的字符，影响最大。而“掘金对要填写什么字符，影响最大”这一认知，依然是我们阅读这个句子本身得到的。换句话说，$w_i$ 权重的信息来源，依然是原句子本身（Self），这就是自注意力命名的原因。 因此，我们可以直接把每个 token 的 embedding 分别当作向量 $q_i$ 和 $k_i$ 进行计算。计算过程如下图所示。 更详细的解析请见：动图轻松理解 Selft-Attention（自注意力机制） 当我们计算第 $i$ 个 token的 $w_i$ 值时，以第 1 个 token 掘字为例，应当先观察整条文本的 token，将所有的 token 都和 掘 token 做计算，这实际上就是在比较 掘 token 和其它 token 的关联关系。 在上图中，$q_i$ 含义为 query（中文含义为查询向量），和 $k_i$ 的含义为 key（中文含义为钥匙向量）。 为何起名 query 和 key？ query 和 key 这两个词，最初是计算机搜索引擎中提出的概念，在 AI 领域中，被引申到注意力机制上。 例如，当我们在 Google 搜索引擎中查询搜索“成都有什么好吃的？”时，搜索引擎会按匹配程度给出若干回答。 其中，用户的搜索问句，就被称为 query，而每一条匹配到的结果，都包含和 query 的关联性，也就是各自的 key。通过 query 和 每一条 key 的匹配，就可以得到问答搜索结果的匹配程度。 回到上图中，当计算 掘 token 的输出向量时，即利用其 query 向量，分别和每一个 token 的 key 向量做点积，并对这个点积 score 做归一化（图中的 2.645 实际上是 $\\sqrt7$，即 query 向量的维度 $\\sqrt{d_q}$）。由此，就得到了熟悉的 $w$ 权重向量，进而执行 softmax，就得到了一个概率分布 $\\alpha$ ，由此可以计算出 掘 token 的输出向量。 为什么要除以 $sqrt{d_q}$ ？神经网络模型的训练过程是采用梯度下降法来完成的。这里具体细节不展开，你可以参考第 8 节的内容。 梯度下降非常像一个人从山顶上走到山脚下。放在神经网络的训练中，一个良好的训练过程，是人能够顺利找到下山的路，平稳下来。而若遇到一段很长的平路，没有向下的坡路，则说明模型训练遇到了阻碍。 既然模型需要做梯度下降，则必须保证模型在做参数运算过程中，梯度值是存在且较大的。而 softmax 函数很容易造成梯度消失，消失原因在于，输入 softmax 函数的值过大。 在上述例子中，$q_i k_i$ 乘积过大，会导致模型训练过程中的梯度消失，进而模型训练失败。因此，为了限制这个乘积值，需要除以这两个向量的维度根号值，确保数值在稳定的范围内。 计算后续每个 token 位置的输出向量均同理。若想计算最后一个输出位（即空格处，第 15 个 token 要填的字）的向量，计算方法也和上面同理。 上述计算方式是一步一步地以向量表示形式展开的。若以矩阵形式做公式计算，则可以表示为：$$Attention(Q,K,V)&#x3D;softmax(\\frac{QK^T}{\\sqrt{d_q}})V$$其中： $Q&#x3D;(q_1,q_2,\\ldots,q_i,\\ldots,q_{d_q})$ $K&#x3D;(k_1,k_2,\\ldots,k_i,\\ldots,k_{d_k})$ $V&#x3D;(v_1,v_2,\\ldots,v_i,\\ldots,v_{d_v})$ 其中，$QK^T$ 就是点积的矩阵形式，最右侧的 $V$ 可以理解为 token embedding 组成的矩阵。$softmax(*)V$ 实际上就是前述各个 embedding 的注意力权重 $\\sum_i e_i \\alpha_i$ 的矩阵表示形式，$e_i$ 表示第 $i$ 个 token 的 embedding 表示，$\\alpha_i$ 是注意力权重概率值。 还需要补充说明的是，我们在讲解注意力机制的计算过程中，默认了 $q_i、k_i、v_i$ 都是 token embedding 本身，在实际的模型中却并不是这样。 第 2 节中，我们提到了 ChatGPT 模型为了体现强大的模型拟合能力，具备较为高级的智能，其模型参数量是随着规模逐渐增大的。到了 ChatGPT 的基础模型 GPT3.5，模型训练的参数规模已经达到了 1750 亿。 神经网络模型之所以很容易契合模型膨胀扩张这一需求。其关键特点在于可以加参数。 在 $q_i、k_i、v_i$ 这里，也可以扩充参数，提升模型的拟合能力。 具体来讲，$Q、K、V$ 三个模型矩阵都是由 token embedding 矩阵做一个矩阵变换得到的。其维度也可以和 embedding 的维度不同。具体形式如下图所示。 具体过程参见「动图轻松理解 Self-Attention.md」 在图中，$W_Q、W_K、W_V$ 均为模型参数，它们都是神经网络模型扩展的可训练参数。其具体计算方法为： $q_i&#x3D;W_Q e_i$ $k_i&#x3D;W_K e_i$ $v_i&#x3D;W_V e_i$ 需要明确的是，$Q$ 和 $K$ 的维度必须是相同的，这样才能保证可执行点积运算。而 $V$ 的维度则可以灵活多变，图中特意以 4 维和 7 维强调这一点。但一般来讲，三者和 token embedding 的维度保持一致即可。 如果我们把注意力机制的输入输出当作一个黑盒，我们可以观察其输入、输出为如下形式： 经过了一层自注意力机制之后，模型的输入和输出结构是相仿的，每一个 token 和其上下文经过对比之后，又生成了一个对应的融合了上下文信息的向量表示。 因此，我们完全可以多多堆叠自注意力层，不断地让模型学习上下文联系。ChatGPT 也确实是这么干的，这将在第 6、7 节中展开讲。 注意力机制的好处通过本节的介绍，我们已经非常清楚，自然语言中自注意力机制是如何将每个 token 的上下文融合起来的，这是目前深度学习模型最流行的操作。 正如例句中，空格处要填写的内容，位于句子的末尾，而信息相关的 掘金 二字则位于句首，中间跨越了很多个 token，寻找两者之间的关联关系，注意力机制非常擅长。技术上讲，这叫注意力机制擅长计算长文本依赖。 而在过去，神经网络里主要使用循环神经网络（RNN）模型结构来处理。RNN 的网络结构可以使用如下公式来解释：$e_i&#x3D;h(e_{i-1},W_{RNN})$。 其中，$h()$ 是 RNN 的计算函数，$e_i$ 是第 $i$ 个 token 的网络内的 embedding 表示，$W_{RNN}$ 是模型参数。它表示了第 $i$ 个 token 必然和其相邻的 第 $i-1$ 个 token 相关联，而*无法跨 token。在处理例句的注意力时，局限性很强。 另外，深度学习中模型的计算量超级大，为了让 ChatGPT 模型能够快速输出结果，就需要采用并行计算的方式。 所谓并行计算，就是一种朴素的加速思想，一个工作，一个人干需要10天，那么找10个人来，一天时间干完。在程序里，主要就是采用多核 GPU 来计算。 注意力机制相比 RNN，更加方便模型在工程上实施并行加速计算。 总结 注意力机制的本质是从大量信息中剔除杂质、无关信息，保留感兴趣的信息。 注意力机制在 NLP 领域的应用主要是 自注意力 Self-Attention 形式，它是神经网络具备充分拟合能力的灵魂。 在第 1 节中，我们提到了，Transformer 是构成 ChatGPT 这座房子的砖块和钢筋，而自注意力机制则是构成 Transformer 的核心要素。下一节，我们就来介绍 Transformer 结构和原理。","tags":["LLM","Self-Attention","ChatGPT","Transformer"],"categories":["AI-Infra"]},{"title":"深入浅出 Docker 技术","path":"/post/开发工具/docker-intro/","content":"Docker 是什么Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 Linux 或 Windows 操作系统的机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。 容器技术容器使软件应用程序与操作系统脱钩，从而为用户提供了一个干净而最小的Linux环境，同时在一个或多个隔离的“容器”中运行其他所有内容。容器的目的是启动一组有限的应用程序或服务（通常称为微服务），并使它们在独立的沙盒环境中运行。 这种隔离可防止在给定容器中运行的进程监视或影响在另一个容器中运行的进程。同样，这些容器化服务不会影响或干扰主机。能够将分散在多个物理服务器上的许多服务整合为一个的想法，是数据中心选择采用该技术的众多原因之一。 容器VS虚拟机首先我们来看下面一张图，下面是虚拟机的实现方式 虚拟机实现资源隔离的方法是利用在主操作系统上运行独立的从操作系统，上图所示，在最底层运行的是我们所熟知的服务器，通常服务器上会运行一个主操作系统. 虚拟机的Guest OS即为虚拟机安装的操作系统，它是一个完整操作系统内核；虚拟机的Hypervisor层可以简单理解为一个硬件虚拟化平台，他负责协调宿主机上的硬件资源分配与管理.一个比较经典的虚拟机软件就是Parallels Desktop. 下面再来看看Docker的实现方式 Docker容器技术的实现要比虚拟机技术的实现减少一层，由于Docker不需要Hypervisor实现硬件资源虚拟化，运行在Docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上Docker将会在效率上有优势. 最后做一个简单的比较. 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为MB 一般为GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般是几十个 Docker 的使用可能有部分读者朋友们没有直接的使用过docker.我们先来举一个例子.在以前没有docker的情况下，假使我们想在linux环境下运行一个mysql，可能我们先要下载压缩包，解压，编译，设置等等流程，十分复杂. 但是当我们使用docker运行mysql时，只需要先运行docker pull mysql就会自动下载最新的mysql镜像. 再运行docker run mysql以后，就可以直接运行，如果你想再运行一份mysql实例，只需要再运行一次docker run的命令，并设置新的端口就能运行，这么一看是不是感觉docker是不是非常好用. docker的功能还远远不止这些，接下来让我们一起走进docker，看看docker是怎么实现的容器技术. Docker 基础概念运行流程 在Docker运行的流程图中，我们可以简单的把image理解为可执行程序，Container就是运行起来的进程。Registry就是代码管理平台. 那么写程序需要源代码，那么“写”image的”源代码”就是dockerfile，docker就是”编译器”。 因此我们只需要在dockerfile中指定需要哪些程序、依赖什么样的配置，之后把dockerfile交给“编译器”docker进行“编译”，生成”可执行程序”image，之后就可以运行这个image了，image运行起来后就是Docker container。 Image(镜像)Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。 镜像不包含任何动态数据，其内容在构建之后也不会被改变。 首先来看一个比较简单的例子: 上图是一个由debian系统作为基础镜像的简历样例，可以看到中间层就是基础的镜像，我们并没有对镜像进行任何定制化的操作，运行起来后就生成了一个容器，容器才是可写的对象. 对于Linux而言，内核启动后，会挂载root文件系统为其提供用户空间支持。而Docker镜像（Image），就相当于是一个root文件系统。 当然，Docker能实现的功能远不止如此，下面我们再来看看如何使用DockerFile构建一个定制化镜像: 1234FROM debianRUN apt-get install emacsRUN apt-get install apache2CMD [&quot;/bin/bash&quot;] Docker设计时，充分利用Union FS的技术，将其设计为分层存储的架构。镜像实际是由多层文件系统联合组成。 镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。 分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。 但是在构建镜像时也要格外的注意，比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。所以在构建镜像时，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。 Container(容器)容器 (container) 的定义和镜像 (image) 几乎一模一样，唯一区别在于容器的最上面那一层是可读可写的。 广义上我们可以将容器理解为，容器 &#x3D; 镜像 + 读写层。 Repository(仓库)镜像构建完成后，可以很容易的在当前宿主上运行，但是如何在其他服务器上运行这个镜像，那么我们就需要一个集中存放镜像文件的场所.这时就引出了Docker Repository的概念. Docker Registry (仓库注册服务器)是一个集中的存储、分发镜像的服务。Docker 仓库的概念跟 Git 类似，注册服务器可以理解为 GitHub 这样的托管服务。实际上，一个 Docker Registry 中可以包含多个仓库 (Repository) ，每个仓库可以包含多个标签 (Tag)，每个标签对应着一个镜像。所以说，镜像仓库是 Docker 用来集中存放镜像文件的地方类似于我们之前常用的代码仓库。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本 。我们可以通过&lt;仓库名&gt;:&lt;标签&gt;的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签.。 仓库又可以分为两种形式： public(公有仓库) private(私有仓库) Docker Registry 公有仓库是开放给用户使用、允许用户管理镜像的 Registry 服务。一般这类公开服务允许用户免费上传、下载公开的镜像，并可能提供收费服务供用户管理私有镜像。 除了使用公开服务外，用户还可以在本地搭建私有 Docker Registry 。Docker 官方提供了 Docker Registry镜像，可以直接使用做为私有 Registry 服务。当用户创建了自己的镜像之后就可以使用 push 命令将它上传到公有或者私有仓库，这样下次在另外一台机器上使用这个镜像时候，只需要从仓库上 pull 下来就可以了。 Docker 架构 Docker是一个C&#x2F;S模式的架构，后端是一个松耦合架构，模块各司其职。 用户的所有命令通过Docker Client与Docker Daemon建立通信，并发送请求给后者。 Docker Daemon作为Docker架构中的主体部分，首先提供Server的功能使其可以接受Docker Client的请求； Engine执行Docker内部的一系列工作，每一项工作都是以一个Job的形式的存在。 在之前的基础概念中，我们已经了解了Registry，Container等概念.接下来就是一些Docker运行过程中的组件介绍. Docker Client Docker Client是和Docker Daemon建立通信的客户端。用户使用docker命令后，Docker Client负责解析对应的命令以及参数，并向Docker Daemon服务端发起请求. Docker Client可以通过以下三种方式和Docker Daemon建立通信： tcp://host:port unix://path_to_socket fd://socketfd Docker Client发送容器管理请求后，由Docker Daemon接受并处理请求，当Docker Client接收到返回的请求相应并简单处理后，Docker Client一次完整的生命周期就结束了。一次完整的请求：发送请求→处理请求→返回结果，与传统的C&#x2F;S架构请求流程一致. Docker Daemon Docker Daemon是docker的守护进程，也是docker运行时的核心.分别有两个部分组成. Docker Server Docker Server相当于C&#x2F;S架构的服务端。功能为接受并调度分发Docker Client发送的请求。接受请求后，Server通过路由与分发调度，找到相应的Handler来执行请求。 在Server的服务过程中，Server在listener上接受Docker Client的访问请求，并创建一个全新的goroutine来服务该请求。在goroutine中，首先读取请求内容，然后做解析工作，接着找到相应的路由项，随后调用相应的Handler来处理该请求，最后Handler处理完请求之后回复该请求。 Engine Engine是Docker架构中的运行引擎，通过执行Job的方式来管理所有的容器与镜像。 在Engine数据结构的设计与实现过程中，有一个handler对象。该handler对象存储的都是关于众多特定job的handler处理访问。举例说明，Engine的handler对象中有一项为：&#123;“create”: daemon.ContainerCreate，&#125;，则说明当名为”create”的job在运行时，执行的是daemon.ContainerCreate的handler。 Job 一个Job可以认为是Docker架构中Engine内部最基本的工作执行单元。Docker可以做的每一项工作，都可以抽象为一个Job。无论是镜像的下载，容器的运行停止等等。Docker Server的运行过程实际也是一个Job，名为serveapi。 Job的概念与Unix中进程相仿。在Unix进程中，对每个进程都有名称，参数，环境变量，标准的输入输出，错误处理，返回状态等，在Docker的Job也都存在. Graph Graph中管理着所有本地已经下载的镜像.其中Graph DB中记录了所有镜像之间的依赖关系. Driver通过Driver驱动，Docker可以实现对Docker容器运行环境的定制，定制的维度主要有网络环境、存储方式以及容器执行方式。 Docker Driver的实现可以分为以下三类驱动：graphdriver、networkdriver和execdriver。 graphdriver graphdriver主要用于完成容器镜像的管理，包括存储与获取。 graphdriver主要用于容器镜像的管理: 负责从Docker Registry下载镜像并进行存储，当用户下载指定的容器镜像时，graphdriver将容器镜像分层存储在本地的指定目录下. 负责从本地镜像存储目录中获取指定的容器镜像，并按特定规则为容器准备rootfs； 负责管理通过指定Dockerfile构建的全新镜像。 networkdriver networkdriver的作用是完成Docker容器网络环境的配置，其中包括: Docker Daemon启动时为Docker环境创建网桥； Docker容器创建前为其分配相应的网络接口资源； Docker容器分配IP、端口并与宿主机做NAT端口映射，设置容器防火墙策略等 execdriver execdriver作为Docker容器的执行驱动，负责创建容器运行时的命名空间，负责管理容器资源使用的统计与限制，负责容器内部进程的真正运行等 在Docker 0.9.0版本之前，只支持使用Linux的LXC驱动进行容器管理，在0.9.0版本之后默认使用native驱动实现，native驱动是docker项目下一个全新的子项目，去除了外部依赖. libcontainer ibcontainer是Docker架构中一个使用Go语言设计实现的库，设计初衷是希望该库可以不依靠任何依赖，直接访问内核中与容器相关的系统调用。 正是由于libcontainer的存在，才使得docker可以不需要依赖LXC或者其他包就可以完成对防火墙，namespaces等的操作。 Docker ContainerDocker Container（Docker容器）是Docker架构中服务交付的最终体现形式。Docker通过DockerDaemon的管理，libcontainer的执行，最终创建Docker容器。Docker容器作为一个交付单位，功能类似于传统意义上的虚拟机（Virtual Machine），具备资源受限、环境与外界隔离的特点。 流程梳理看到这里，我相信各位读者朋友们应该已经对Docker基础架构有了一个大概得认知了，让我们以docker run为例子回顾一下 Docker 各个组件是如何协作的。 假设我们要运行一条: docker run -p 3306:3306 --name mysql -d mysql 容器启动过程如下： Docker 客户端执行 docker run 命令 Docker daemon 通过graghdriver去Gragh中拉取最新的 mysql 镜像 Docker daemon 通过networkdriver建立端口映射 Docker daemon 通过execdriver启动容器 Docker 核心技术实现在了解了这么多Docker实现以后，我们可能还会有最后一些疑问，Docker是如何实现资源隔离的. 在日常使用 Linux 或者 macOS 时，我们并没有运行多个完全分离的服务器的需要，但是如果我们在服务器上启动了多个服务，这些服务其实会相互影响的，每一个服务都能看到其他服务的进程，也可以访问宿主机器上的任意文件，这是很多时候我们都不愿意看到的，我们更希望运行在同一台机器上的不同服务能做到完全隔离，就像运行在多台不同的机器上一样。 Docker实现容器之间的完全隔离一共使用到了三大技术: Namespaces(命名空间)命名空间 (namespaces) 是 Linux 为我们提供的用于分离进程树、网络接口、挂载点以及进程间通信等资源的方法. 进程隔离在Docker Deamon启动的初期，会通过setNamespaces函数去创建一个新的命名空间.在创建命名空间使用的clone函数中传入CLONE_NEWPID参数就完成容器对宿主机之间的进程隔离. 文件资源隔离在创建命名空间使用的clone函数中传入CLONE_NEWNS参数，子进程即可得到父进程挂载的拷贝. 当容器创建时，容器需要一个自己的rootfs来实现与别的容器文件资源隔离，所以当Docker创建容器时，会将容器需要的目录进行挂载，并改变容器能访问的根目录，将容器之间的文件系统隔离. 改变容器能够访问个文件目录的根节点，libcontaine 提供的了pivot_root 或者 chroot 函数。 网络隔离当 Docker 启动时，会自动在主机上创建一个 docker0 虚拟网桥，实际上是 Linux 的一个 bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进行转发。 当创建一个 Docker 容器的时候，同时会创建了一对veth pair接口。这对接口一端在容器内，即是容器内部的eth0； veth pair是成对出现的一种虚拟网络设备接口，一端连着网络协议栈，一端彼此相连，彼此联通的这端数据互通。 另一端在本地并被挂载到 docker0 网桥，名称以 veth 开头。通过这种方式，主机可以跟容器通信，容器之间也可以相互通信。Docker就创建了在主机和所有容器之间一个虚拟共享网络。 Control Groups(控制组)Control Groups（简称 CGroups）能够隔离宿主机器上的物理资源，CGroup提供以下这些功能. 限制进程组可以使用的资源数量（Resource limiting ）。比如：memory子系统可以为进程组设定一个memory使用上限，一旦进程组使用的内存达到限额再申请内存，就会触发OOM（out of memory）。 进程组的优先级控制（Prioritization ）。比如：可以使用cpu子系统为某个进程组分配特定cpu share。 记录进程组使用的资源数量（Accounting ）。比如：可以使用cpuacct子系统记录某个进程组使用的cpu时间 进程组隔离（Isolation）。比如：使用ns子系统可以使不同的进程组使用不同的namespace，以达到隔离的目的，不同的进程组有各自的进程、网络、文件系统挂载空间。 进程组控制（Control）。比如：使用freezer子系统可以将进程组挂起和恢复 物理资源隔离CGroup通过多个子系统来控制系统资源的分配. 我们可以使用lssubsys -m查看当前系统下CGroup对应的子系统目录. cpuset /sys/fs/cgroup/cpuset cpu，cpuacct /sys/fs/cgroup/cpu，cpuacct blkio /sys/fs/cgroup/blkio memory /sys/fs/cgroup/memory devices /sys/fs/cgroup/devices freezer /sys/fs/cgroup/freezer net_cls，net_prio /sys/fs/cgroup/net_cls，net_prio perf_event /sys/fs/cgroup/perf_event pids /sys/fs/cgroup/pids 在宿主机内，首先当Docker启动时，会在上述的所有子系统下创建docker文件夹. 当Docker创建容器时，会在docker文件夹下的task子目录下创建pid对应的新文件对容器资源进行分配以及管控. UnionFS(联合文件系统)Union文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下 在Docker中，每一个镜像层都是建立在另一个镜像层之上的，同时所有的镜像层都是只读的，只有每个容器最顶层的容器层才可以被用户直接读写，所以需要一个文件系统对所有的文件进行管理. 镜像管理在Docker中目前使用了多种文件系统对镜像进行管理，包括当前主流的overlay2，aufs等等. 不同的存储驱动在存储镜像和容器文件时也有着完全不同的实现，有兴趣的读者可以在 Docker 的官方文档Docker storage drivers 中找到相应的内容。 Docker 常用命令🐳 Docker 概念，工作流和实践 - 入门必懂 Dockerfile｜.dockerignore docker build . docker images docker tag &lt;IMAGE_ID&gt; &lt;USER_NAEM/IMAGE_NAME&gt;:&lt;TAG&gt;，比如 docker tag e6f dansoncutnodejs:v1.0 docker login docker push &lt;USER_NAEM/IMAGE_NAME&gt;:&lt;TAG&gt; docker build -t eggpain-image .：构建的时候就指定镜像名 docker rmi -f dansoncut/nodejs:v1.0：后面那串其实就是镜像名 docker run -d &lt;IMAGE_NAME&gt;：-d 是 detached-mode 让容器不占用当前的命令行窗口 docker run -d -p &lt;HOST_PORT:CONTAINER_PORT&gt; --name &lt;CONTAINER_NAME&gt; &lt;IMAGE_NAME&gt; docker ps、docker ps -a docker stop &lt;CONTAINER_NAME&gt; docker rm -f &lt;CONTAINER_ID&gt;/&lt;CONTAINER_NAME&gt; docker exec -it &lt;CONTAINER_NAME&gt; /bin/bash：以终端交互的方式进入容器 Docker 网络模式🐳 Docker 网络模式 Linux【Bridge | Host | None】 sudo docker network ls Bridge：如果没有指定容器的网络，默认加入的都是「默认 Bridge」网络，自定义 Bridge 网络可以提供自动 DNS 解析（默认 Bridge 不会自动为容器间进行 DNS 解析），不同 Bridge 网络还可以实现更好的隔离，所以非常适合单个宿主里运行多个容器。真因为起到隔离作用，容器里的数据要出来需要地址转化，即 NAT，性能会被拉低。 Host：Host 网络就不需要地址转换了，即不需要端口映射（直接指定 --network host），因为容器直接和宿主合体了，适合高网络性能的场景，但存在安全问题；Host 网络没有自己的 IP 地址，在单个容器需要处理大量端口的时候，就不需要像 Bridge 网络那样逐个端口进行关联，但是如果要多个容器用同一个端口会出现端口冲突（该模式仅能在 Linux 主机上实现） None：不能联网，适合进行备份，有些需要网络隔离的一次性操作也非常好用。 sudo docker network create -d bridge &lt;BRIDGE_NAME&gt;：自定义 Bridge 网络，创建的网络可以通过 sudo docker network ls 查看；默认 Bridge 网络范围是 172.17.0.0/16，网关是 172.17.0.1；而新创建的网络则是 172.18.0.0/16，网关为 172.18.0.1。此后会出现一个类似 docker0 的接口。 Docker 安装后会出现一个 docker 0 的端口 sudo docker run -d --name naihe1 --hostname naihe1 --network naihe-bridge &lt;IMAGE&gt;：创建一个容器加入到自定义的 Bridge 网络 sudo docker run -d --name egg --network host &lt;IMAGE&gt;：创建一个 Host 网络下的容器，此时就不需要端口关联了，因为该容器和宿主共用所有网络和端口 sudo docker run -it --network none &lt;IMAGE&gt;：none 网络，无法联网 sudo docker network rm &lt;NETWORK_NAME&gt;：删除网络（Bridge 网络可以有多个，Host 网络只能有一个），注意，默认 bridge、host、none 网络都不能删除；该命令仅针对自定义 Bridge 网络。 dockerfile 与 docker-compose 通俗解释先简单理解 docker 的使用过程，它分为镜像构建与容器启动。 镜像构建：即创建一个镜像，它包含安装运行所需的环境、程序代码等。这个创建过程就是使用 dockerfile 来完成的。 容器启动：容器最终运行起来是通过拉取构建好的镜像，通过一系列运行指令（如端口映射、外部数据挂载、环境变量等）来启动服务的。针对单个容器，这可以通过 docker run 来运行。 而如果涉及多个容器的运行（如服务编排）就可以通过 docker-compose 来实现，它可以轻松的将多个容器作为 service 来运行（当然也可仅运行其中的某个），并且提供了 scale (服务扩容) 的功能。 🙄简单总结： dockerfile: 构建镜像； docker run: 启动容器； docker-compose: 启动服务； 从头开始：dockerfile、docker run、docker-compose 存在的必要性 假如你不用 docker ，搭建 wordpress 怎么弄？先找台 server ，假设其 OS 为 Ubuntu ，然后按照文档一步步敲命令，写配置，对吧？ 用 docker 呢？ 随便找台 server ，不管什么操作系统，只要支持 docker 就行， docker run ubuntu, docker 会从官方源里拉取最新的 Ubuntu 镜像，可以认为你开了个 Ubuntu 虚拟机，然后一步步安装，跟上面一样。 但是这样安装有个显著的缺点，一旦 container 被删，你做的工作就都没了。当然可以用 docker commit 来保存成镜像，这样就可以复用了。 但是镜像一般比较大，而且只分享镜像的话，别人也不知道你这镜像到底包含什么，这些问题都不利于分享和复用。 一个直观的解决方案就是，写个脚本把安装过程全部记录下来，这样再次安装的时候，执行脚本就行了。 Dockerfile 就是这样的脚本，它记录了一个镜像的制作过程。 有了 Dockerfile, 只要执行 docker build . 就能制作镜像，而且 Dockerfile 就是文本文件，修改也很方便。 现在有了 wordpress 的镜像，只需要 docker run 就把 wordpress 启动起来了。 如果仅仅是 wordpress 这也就够了。但是很多时候，需要多个镜像合作才能启动一个服务，比如前端要有 nginx ， 数据库 mysql, 邮件服务等等，当然你可以把所有这些都弄到一个镜像里去，但这样做就无法复用了。 更常见的是，nginx, mysql, smtp 都分别是个镜像，然后这些镜像合作，共同服务一个项目。 docker-compose 就是解决这个问题的。你的项目需要哪些镜像，每个镜像怎么配置，要挂载哪些 volume, 等等信息都包含在 docker-compose.yml 里。 要启动服务，只需要 docker-compose up 就行，停止也只需要 docker-compse stop/down 简而言之， Dockerfile 记录单个镜像的构建过程， docker-compse.yml 记录一个项目（project, 一般是多个镜像）的构建过程。 你说有些教程用了 dockerfile + docker-compose, 是因为 docker-compose.yml 本身没有镜像构建的信息，如果镜像是从 docker registry 拉取下来的，那么 Dockerfile 就不需要；如果镜像是需要 build 的，那就需要提供 Dockerfile. docker-compose是编排容器的。例如，你有一个 php 镜像，一个 mysql 镜像，一个 nginx 镜像。如果没有 docker-compose，那么每次启动的时候，你需要敲各个容器的启动参数，环境变量，容器命名，指定不同容器的链接参数等等一系列的操作，相当繁琐。而用了 docker-composer 之后，你就可以把这些命令一次性写在 docker-composer.yml 文件中，以后每次启动这一整个环境（含 3 个容器）的时候，你只要敲一个 docker-composer up 命令就ok了。 dockerfile 的作用是从无到有的构建镜像。它包含安装运行所需的环境、程序代码等。这个创建过程就是使用 dockerfile 来完成的。 Dockerfile：为 docker build 命令准备的，用于建立一个独立的 image ，在 docker-compose 里也可以用来实时 build。 docker-compose.yml：为 docker-compose 准备的脚本，可以同时管理多个 container ，包括他们之间的关系、用官方 image 还是自己 build 、各种网络端口定义、储存空间定义等。 总结看到这里相信各位读者朋友们对 Docker 已经有了更为深刻的理解. 由于 Docker 更新至今，代码库太过庞大，也只能从低版本的 Docker 源码以及大佬们的 Docker 技术文章中窥其一二，如果有感兴趣的朋友也可以相互交流. 参考文献 《Docker源码分析》(孙宏亮) Docker 核心技术与实现原理 - 面向信仰编程 docker容器技术介绍 Docker基础镜像是什么？都有哪些？ 虚拟化技术介绍 &amp; hypervisor简介 docker容器技术介绍 这可能是最为详细的Docker入门吐血总结 Docker架构简介 VM VS Container 浅谈Hpervisor虚拟化技术和容器技术 Docker常用命令原理图 Linux镜像run起来，六、Docker run 运行镜像","tags":["Docker"],"categories":["开发工具"]},{"title":"Git 个人工作流分享","path":"/post/开发工具/git-workflow/","content":"查看本地分支与远程分支的对应关系1234# 查看远程分支与本地分支的对应关系$ git branch -vv# 查看所有分支（远程 + 本地）$ git branch -a 新建远程分支 | push1234$ git checkout &lt;local-branch&gt;# 本地分支和远程分支的名字可不一样，但一般是同名分支 | 关联后 (--set-upstream) 可直接 push# git push origin master 这个master指的是远程分支，因为本地分支默认为当前分支$ git push origin &lt;local-branch&gt;:&lt;remote-branch&gt; Tip: push 的时候只会上传当前的 branch 的指向，并不会把本地的 HEAD 的指向也一起上传到远程仓库。事实上，远程仓库的 HEAD 是永远指向它的默认分支（即 master，如果不修改它的名称的话），并会随着默认分支的移动而移动的。 --set-upstream 设置远程分支与本地分支关联1234# 关联远程仓库的 master 分支与本地的 master 分支，该方法在 push 中可设置，如果要直接绑定分支但不 push 呢，见下面命令行$ git push --set-upstream origin master:master# 通过 branch 命令直接设置$ git branch --set-upstream-to=origin/feature2 feature2 拉取远程分支 | pull123# 说明：关联后 (--set-upstream) 可直接 push# git pull origin master 这个 master 指的是远程分支，因为本地分支默认为当前分支$ git pull origin &lt;remote-branch&gt;:&lt;local-branch&gt; 根据远程分支上创建本地分支12# 只有远程分支的时候，根据远程分支创建本地分支即可$ git checkout -b &lt;local-branch&gt; origin/&lt;remote-branch&gt; 删除远程分支1234567# 说明：git push origin &lt;local-branch&gt;/&lt;remote-branch&gt;# Method1: 推送空分支到远程分支 remote-branch，相当于删除远程分支$ git push origin :&lt;remote-branch&gt;# Method2: 直接删除远程分支$ git push origin --delete &lt;remote-branch&gt;# Tip: 删除本地分支$ git branch -d &lt;local-branch&gt; 区分 git reset &amp; git checkout⭐Reference: https://blog.csdn.net/longintchar/article/details/82314102 git reset 会带着当前指向的 branch 一起向前推进 git checkout 只会修改当前 HEAD 的指向，可先用 checkout 跳转到某次提交处，然后创建某个分支 feature（此时的 HEAD 并未指向 feature1，而是仅仅处于同一处 commit），最后再使用 checkout 切换到该 feature 分支上（即 HEAD 指向 feature 分支） checkout 签出动作会将 HEAD 与 branch 分离开来，它有一个专门的参数用于让 HEAD 与 branch 脱离且不移动 HEAD 的用法： 1$ git checkout --detach git 各式后悔药git 管理仓库时，往往需要撤销某些操作&#x2F;提交&#x2F;暂存内容。 1. 撤销工作区的文件修改如果工作区的某个文件被改乱了，但还没有执行 git add，可以用 git checkout 命令找回本次修改之前的文件。 1$ git checkout -- [filename] ⭐它的原理是先找暂存区，如果该文件有暂存的版本，则恢复该版本，否则恢复上一次提交的版本。 注意：工作区的文件变化一旦被撤销，就无法找回了。 2. 从暂存区撤销文件如果不小心把一个文件添加到暂存区，可以用下面的命令撤销。 1$ git rm --cached [filename] 上面的命令不影响已经提交的内容。 3. 替换上一次提交信息💔情况一：提交以后，发现提交信息写错了，这时可以使用 git commit 命令的 --amend 参数，可以修改上一次的提交信息。 12$ git commit --amend -m &quot;Fixes bug #42&quot;# git commit --amend 也可 它的原理是产生一个新的提交对象，替换掉上一次提交产生的提交对象。 💔情况二：提交之后，发现提交的文件需要修改！这时先修改好工作区，然后再执行 add 后执行 git commit --amend，因为这时暂存区有发生变化的文件，会一起提交到仓库。 12$ git commit --amend -m &quot;append info&quot;# git commit --amend 也可 所以，--amend 不仅可以修改提交信息，还可以整个把上一次提交替换掉。 4. 撤销某次提交 | 但需新增来覆盖提交一种常见的场景是，提交代码以后，你突然意识到这个提交有问题，应该撤销掉，这时执行下面的命令就可以了。 1$ git revert HEAD 上面命令的原理是，在当前提交后面，⭐新增一次提交(commit+1)，抵消掉上一次提交导致的所有变化(workspace&amp;stage change)。它不会改变过去的历史，所以是首选方式，没有任何丢失代码的风险。 git revert 命令只能抵消上一个提交，如果想抵消多个提交，必须在命令行依次指定这些提交。比如，抵消前两个提交，要像下面这样写。 1$ git revert [倒数第一个提交] [倒数第二个提交] git revert 命令还有两个参数。 --no-edit：执行时不打开默认编辑器，直接使用 Git 自动生成的提交信息。 --no-commit：只抵消暂存区(stage)和工作区的文件变化，不产生新的提交。 5. 丢弃提交 | 回溯如果希望以前的提交在历史中彻底消失，而不是被抵消掉，可以使用git reset命令，丢弃掉某个提交之后的所有提交。 1$ git reset [last good SHA] git reset的原理是，让最新提交的指针回到以前某个时点，该时点之后的提交都从历史中消失。 默认情况下，git reset不改变工作区的文件（但会改变暂存区），--hard 参数可以让工作区里面的文件也回到以前的状态。 123$ git reset --hard [last good SHA]# 或者$ git reset --hard HEAD^1 执行 git reset 命令之后，如果想找回那些丢弃掉的提交，可以使用 git reflog 命令，具体做法参考这里。不过，这种做法有时效性，时间长了可能找不回来。 6. 撤销当前分支的变化你在当前 error 分支上做了几次提交，突然发现放错了分支，这几个提交本应该放到 master 分支。 1234567# 将 error 分支上的&lt;最新一次&gt;提交转移到 master 分支$ git checkout master$ git cherry-pick error# 将 error 分支上的多次提交转移到 master 分支，注意：SHA1 比 SHA2 来得早！$ git checkout master$ git cherry-pick [SHA1] [SHA2] 目标：将 error 分支上的最新两次 commit 转移到 master 分支 先执行 git checkout master 再执行 git cherry-pick [SHA1] [SHA2] 有冲突解决冲突，没冲突即可完成 OK！error 分支想要 reset 就 reset~ 合并分支 | merge由于现在 Git 仓库处于冲突待解决的中间状态（已执行 merge 操作），所以如果你最终决定放弃这次 merge，也需要执行一次 merge --abort 来手动取消它。 12345# 回到 merge 前的状态$ git merge --abort# 在 master 分支上合并 feature 分支$ git checkout master$ git merge feature 主流工作流 Feature Branching这种工作流的核心内容可以总结为两点： 任何新的功能（feature）或 bug 修复全都新建一个 branch 来写； branch 写完后，合并到 master，然后删掉这个 branch。 这就是这种工作流最基本的模型。 从上面的动图来看，这种工作流似乎没什么特别之处。但实质上，Feature Branching 这种工作流，为团队开发时两个关键的问题提供了解决方案： 代码分享 一人多任务 1. 代码分享12345678910111213# 本地电脑$ git checkout -b books$ git push origin books# 同事电脑$ git pull$ git checkout books$ git checkout master$ git pull # merge 之前 pull 一下，让 master 更新到和远程仓库同步$ git merge books$ git push# 删除本地 books 分支，删除远程 books 分支$ git branch -d books$ git push origin -d books 借助 GitHub 的 Pull Request 简化 Feature Branching 工作流 事实上，上面所说的这个流程，还可以利用 Pull Request 来进一步简化。 Pull Request 并不是 Git 的内容，而是一些 Git 仓库服务提供方（例如 GitHub）所提供的一种便捷功能，它可以让团队的成员方便地讨论一个 branch ，并在讨论结束后一键合并这个 branch 到 master。 同样是把写好的 branch 给同事看，使用 Pull Request 的话你可以这样做： 把 branch push 到中央仓库； 在中央仓库处创建一个 Pull Request。以 GitHub 为例： 然后你的同事就可以在 GitHub 上看到你创建的 Pull Request 了。他们可以在 GitHub 的这个页面查看你的 commits，也可以给你评论表示赞同或提意见，你接下来也可以根据他们的意见把新的 commits push 上来，这也页面会随着你新的 push 而展示出最新的 commits。 在讨论结束以后，你们一致认为这个 branch 可以合并了，你只需要点一下页面中那个绿色的 “Merge pull request” 按钮，GitHub 就会自动地在中央仓库帮你把 branch 合并到 master 了： 然后你只要在本地 pull 一下，把最新的内容拉到你的电脑上，这件事情就算完成了。 另外，GitHub 还设计了一个贴心的 “Delete branch” 按钮，方便你在合并之后一键删除 branch。 完整的例子： 12345678910# 拉取 feature2 分支$ git pull origin feature2:feature2$ git branch --set-upstream-to=origin/feature2 feature2$ git branch -vv feature1 c16362b [origin/feature1] Merge branch &#x27;master&#x27; into feature1* feature2 db3024c [origin/feature2] create branch feature2 master 55c2952 [origin/master: behind 2] Merge pull request$ git checkout master# master 分支也要 pull$ git pull origin master:master 2. 一人多任务你正在认真写着代码，忽然同事过来跟你说：「内个……你这个功能先放一放吧，我们最新讨论出要做另一个更重要的功能，你来做一下吧。」 如果你是在独立的 branch 上做事，切换任务是很简单的。你只要稍微把目前未提交的代码简单收尾一下，然后做一个带有「未完成」标记的提交（例如，在提交信息里标上「TODO」），然后回到 master 去创建一个新的 branch 就好了。 123# 切换回 master 主分支！！！因为需要从主分支上创建分支$ git checkout master$ git checkout -b new_feature 查改历史改动记录git log123456789# 在 .bashrc 中设置 git-log 别名，可图形化输出 git log 的信息$ alias git-log=&#x27;git log --pretty=oneline --all --graph --abbrev-commit&#x27;$ git-log# 查看历史改动信息$ git log# 查看详细的历史记录，可以看到每个 commit 的具体改动细节（-p 是 --patch 的缩写）$ git log -p# 查看简要统计，只想大致看一下改动内容$ git log --stat git show123# 查看某个具体的 commit: $ git show 查看当前 commit$ git show &lt;SHA-1&gt;$ git show &lt;SHA-1&gt; &lt;filename&gt; # 具体到某个指定文件 git diff比对本地工作目录与暂存区的内容（即显示未使用 git add 加入暂存区的内容与暂存区的内容的不同之处） 12345678910$ git diffdiff --git a/README.md b/README.mdindex 4b572c1..0f8ceb4 100644--- a/README.md+++ b/README.md@@ -5,3 +5,4 @@ 4. `git branch feature1` &amp;&amp; `git checkout feature1` &amp;&amp; `git checkout master` &amp;&amp; `git merge feature1` (feature1) 5. master branch (feature branching, solve conflict by `pull request`) 6. feature2+7. 哈哈哈哈 比对暂存区与上一条提交的内容（即显示 git add 后的内容与上次 commit 之间内容的不同之处） 123# 二者命令完全等价$ git diff --staged$ git diff --cached 比对工作目录和上一条提交的内容： 使用 git diff HEAD 可以显示工作目录和上一条提交之间的不同，它是上面这二者的内容相加。换句话说，这条指令可以让你看到「如果你现在把所有文件都 add 然后 git commit，你将会提交什么」（不过需要注意，没有被 Git 记录在案的文件（即从来没有被 add 过 的文件，untracked files 并不会显示出来。为什么？因为对 Git 来说它并不存在啊）。 12$ git diff HEAD# 也可 git diff &lt;SHA-1&gt; 实质上，如果你把 HEAD 换成别的 commit，也可以显示当前工作目录和这条 commit 的区别。 不喜欢 merge 的分叉，那就用 rebase 吧rebase —— 变基？！ 其实这个翻译还是比较准确的。rebase 的意思是，给你的 commit 序列重新设置基础点（也就是父 commit）。展开来说就是，把你指定的 commit 以及它所在的 commit 串，以指定的目标 commit 为基础，依次重新提交一次。例如下面这个 merge： 12# merge 过来；rebase 过去$ git merge branch1 master: 1-2-3-4-7 branch1: 1-2-5-6-7 如果把 merge 换成 rebase，可以这样操作： 123$ git checkout branch1# merge 过来；rebase 过去$ git rebase master master: 1-2-3-4-7-8 branch1: 1-2-5-6 master 上的 7、8 是 branch1 上的 5、6 rebase 过去的~ 可以看出，通过 rebase，5 和 6 两条 commits 把基础点从 2 换成了 4 。通过这样的方式，就让本来分叉了的提交历史重新回到了一条线。这种「重新设置基础点」的操作，就是 rebase 的含义。 另外，在 rebase 之后，记得切回 master 再 merge 一下，把 master 移到最新的 commit： 12$ git checkout master$ git merge branch1 master&#x2F;branch1: 1-2-3-4-7-8 为什么要从 branch1 来 rebase，然后再切回 master 再 merge 一下这么麻烦，而不是直接在 master 上执行 rebase？ 从图中可以看出，rebase 后的 commit 虽然内容和 rebase 之前相同，但它们已经是不同的 commits 了。如果直接从 master 执行 rebase 的话，就会是下面这样： 这就导致 master 上之前的两个最新 commit 被剔除了。如果这两个 commit 之前已经在中央仓库存在，这就会导致没法 push 了： 所以，为了避免和远端仓库发生冲突，一般不要从 master 向其他 branch 执行 rebase 操作。而如果是 master 以外的 branch 之间的 rebase（比如 branch1 和 branch2 之间)，就不必这么多费一步，直接 rebase 就好。 ⭐以上情况是不发生冲突的 rebase，如果发生冲突了，那么就需要先解决冲突再执行如下命令： 以下展示另外一个例子！ 1234# 1.修改冲突文件# 2.git add. &amp; git commit -m &quot;fix conflict&quot;# 3.rebase continue$ git rebase --continue 初始状态 git checkout rebase-branch git rebase master：发生 conflict 在 “step 3”！ 解决冲突后，再执行 add 与 commit（⭐甚至这一步都不需要 commit，在 add 之后即可） git rebase --continue git checkout master git merge rebase-branch：相当于 fast-forward！ ⭐总结：需要说明的是，rebase 是站在需要被 rebase 的 commit 上进行操作，这点和 merge 是不同的（相反）。 如何修复倒数第 2 个 commit | 交互式 rebase commit --amend 可以修复最新 commit 的错误，但如果是倒数第二个 commit 写错了，怎么办？ 如果不是最新的 commit 写错，就不能用 commit --amend 来修复了，而是要用 rebase。不过需要给 rebase 也加一个参数：-i。 rebase -i 是 rebase --interactive 的缩写形式，意为「交互式 rebase」。 所谓「交互式 rebase」，就是在 rebase 的操作执行之前，你可以指定要 rebase 的 commit 链中的每一个 commit 是否需要进一步修改。 那么你就可以利用这个特点，进行一次「原地 rebase」。 例如你是在写错了 commit 之后，又提交了一次才发现之前写错了： 1$ git log 现在再用 commit --amend 已经晚了，但可以用 rebase -i： 1$ git rebase -i HEAD^^ 说明：在 Git 中，有两个「偏移符号」： ^ 和 ~。 ^ 的用法：在 commit 的后面加一个或多个 ^ 号，可以把 commit 往回偏移，偏移的数量是 ^ 的数量。例如：master^ 表示 master 指向的 commit 之前的那个 commit； HEAD^^ 表示 HEAD 所指向的 commit 往前数两个 commit。 ~ 的用法：在 commit 的后面加上 ~ 号和一个数，可以把 commit 往回偏移，偏移的数量是 ~ 号后面的数。例如：HEAD~5 表示 HEAD 指向的 commit往前数 5 个 commit。 上面这行代码表示，把当前 commit （ HEAD 所指向的 commit） rebase 到 HEAD 之前 2 个的 commit 上： 如果没有 -i 参数的话，这种「原地 rebase」相当于空操作，会直接结束。而在加了 -i 后，就会跳到一个新的界面： 把 pick 修改成 edit 后，就可以退出编辑界面了： 上图的提示信息说明，rebase 过程已经停在了第二个 commit 的位置，那么现在你就可以去修改你想修改的内容了。 修改完成之后，和上节里的方法一样，用 commit --amend 来把修正应用到当前最新的 commit： 12$ git add 笑声$ git commit --amend 在修复完成之后，就可以用 rebase --continue 来继续 rebase 过程，把后面的 commit 直接应用上去。 1$ git rebase --continue 然后，这次交互式 rebase 的过程就完美结束了，你的那个倒数第二个写错的 commit 就也被修正了： 实质上，交互式 rebase 并不是必须应用在「原地 rebase」上来修改写错的 commit ，这只不过是它最常见的用法。你同样也可以把它用在分叉的 commit 上，不过这个你就可以自己去研究一下了。 丢弃倒数第二个提交 | 强大的 rebase如果要丢弃刚提交的 commit，那只需要执行 git reset --hard HEAD^ 即可，那如果是倒二个呢？ git rebase -i12$ git rebase -i HEAD^^# 上文是修改 pick 为 edit；而该操作只需要将 pick 当行删除即可 git rebase --onto除了用交互式 rebase ，你还可以用 rebase --onto 来更简便地撤销提交。 rebase 加上 --onto 选项之后，可以指定 rebase 的「起点」。一般的 rebase，告诉 Git 的是「我要把当前 commit 以及它之前的 commits 重新提交到目标 commit 上去，这其中，rebase 的「起点」是自动判定的：选取当前 commit 和目标 commit 在历史上的交叉点作为起点。 例如下面这种情况： 如果在这里执行： 1$ git rebase &lt;第3个commit&gt; 那么 Git 会自动选取 3 和 5 的历史交叉点 2 作为 rebase 的起点，依次将 4 和 5 重新提交到 3 的路径上去。 而 --onto 参数，就可以额外给 rebase 指定它的起点。例如同样以上图为例，如果我只想把 5 提交到 3 上，不想附带上 4，那么我可以执行： 1$ git rebase --onto &lt;第3个commit&gt; &lt;第4个commit&gt; branch1 --onto 参数后面有三个附加参数：目标 commit、起点 commit（注意：rebase 的时候会把起点排除在外）、终点 commit。所以上面这行指令就会从 4 往下数，拿到 branch1 所指向的 5，然后把 5 重新提交到 3 上去。 1$ git rebase --onto HEAD^^ HEAD^ branch1 上面这行代码的意思是：以倒数第二个 commit 为起点（起点不包含在 rebase 序列里哟），branch1 为终点，rebase 到倒数第三个 commit 上。 也就是这样： reset 的本质 | 参数解析reset 的三种参数： --hard：重置位置的同时，清空工作目录的所有改动； --soft：重置位置的同时，保留工作目录和暂存区的内容，并把重置 HEAD 的位置所导致的新的文件差异放进暂存区。 --mixed（默认 git reset）：重置位置的同时，保留工作目录的内容，并清空暂存区。 checkout 的本质 | 除了切换分支还可签出某个提交不过实质上，checkout 并不止可以切换 branch。checkout 本质上的功能其实是：签出（ checkout ）指定的 commit。 直接上案例： 1234$ git checkout HEAD^^$ git checkout master~5$ git checkout &lt;SHA&gt;$ git checkout &lt;SHA&gt;^^^ 另外，如果你留心的话可能会发现，在 git status 的提示语中，Git 会告诉你可以用 checkout -- 文件名 的格式，通过「签出」的方式来撤销指定文件的修改： 即撤销工作目录下的修改（此时未添加到暂存区） Emergency！放下你手上的工作 | stash 临时存放工作目录变动“stash” 这个词，和它意思比较接近的中文翻译是「藏匿」，是「把东西放在一个秘密的地方以备未来使用」的意思。在 Git 中，stash 指令可以帮你把工作目录的内容全部放在你本地的一个独立的地方，它不会被提交，也不会被删除，你把东西放起来之后就可以去做你的临时工作了，做完以后再来取走，就可以继续之前手头的事了。 具体说来，stash 的用法很简单。当你手头有一件临时工作要做，需要把工作目录暂时清理干净，那么你可以： 1$ git stash 就这么简单，你的工作目录的改动就被清空了，所有改动都被存了起来。 然后你就可以从你当前的工作分支切到 master 去给你的同事打包了…… 打完包，切回你的分支，然后： 1$ git stash pop 你之前存储的东西就都回来了。很方便吧！ 注意：没有被 track 的文件（即从来没有被 add 过的文件不会被 stash 起来，因为 Git 会忽略它们。如果想把这些文件也一起 stash，可以加上 -u 参数，它是 --include-untracked 的简写。就像这样： 1$ git stash -u 从暂存区撤回工作目录 | restore use “git restore –staged “ to unstage 如果已经将文件添加到暂存区，然后想要撤销暂存区中该文件的内容（打回工作目录），则使用以下命令： 1$ git restore --staged &lt;file&gt; tip：如果文件在工作目录下修改过但未添加到暂存区，则通过前文提到的 git checkout -- &lt;file&gt; 来撤销该修改。 找回丢失的 branch | reflogreflog 是 “reference log” 的缩写，使用它可以查看 Git 仓库中的引用的移动记录。如果不指定引用，它会显示 HEAD 的移动记录。假如你误删了 branch1 这个 branch，那么你可以查看一下 HEAD 的移动历史： 1$ git reflog 从图中可以看出，HEAD 的最后一次移动行为是「从 branch1 移动到 master」。而在这之后，branch1 就被删除了。所以它之前的那个 commit 就是 branch1 被删除之前的位置了，也就是第二行的 c08de9a。 所以现在就可以切换回 c08de9a，然后重新创建 branch1 ： 1$ git checkout -b branch1 这样，你刚删除的 branch1 就找回来了。 注意：不再被引用直接或间接指向的 commits 会在一定时间后被 Git 回收，所以使用 reflog 来找回删除的 branch 的操作一定要及时，不然有可能会由于 commit 被回收而再也找不回来。 reflog 默认查看 HEAD 的移动历史，除此之外，也可以手动加上分支名称查看其他分支的引用移动历史，例如 master 分支： 1$ git reflog master 不可移动的 branch | tagtag 是一个和 branch 非常相似的概念，它和 branch 最大的区别是：tag 不能移动。所以在很多团队中，tag 被用来在关键版本处打标记用。 更多关于 tag：git-scm.com&#x2F;docs&#x2F;git-ta… Git Flow：复杂又高效的工作流除了前面讲到的 “Feature Branching”，还有一个也很流行的工作流：Git Flow。Git Flow 的机制非常完善，很适合大型团队的代码管理。不过由于它的概念比较复杂（虽然难度并不高），所以并不适合新手直接学习，而更适合在不断的自我研究中逐渐熟悉，或者在团队合作中慢慢掌握。基于这个原因，我最终也没有在这本小册里讲 Git Flow，但我推荐你自己在有空的时候了解一下它。","tags":["git"],"categories":["开发工具"]},{"title":"Markdown 数学公式指导手册","path":"/post/开发工具/markdown-mathjax-basic-tutorial-and-quick-reference/","content":"用 Katex 改写数学公式，发现 右括号接下标，不能正常解析，)改成 \\rparen, ]改成 \\rbrack 一、公式使用参考1．如何插入公式LaTex 的数学公式有两种：行中公式和独立公式。行中公式放在文中与其它文字混编，独立公式单独成行。 行中公式示例: $\\sum_&#123;i=0&#125;^n i^2 = \\frac&#123;(n^2+n)(2n+1)&#125;&#123;6&#125;$ 独立公式示例：$$\\sum_&#123;i=0&#125;^n i^2 = \\frac&#123;(n^2+n)(2n+1)&#125;&#123;6&#125;$$ $$ \\sum_{i=0}^n i^2 = \\frac{(n^2+n)(2n+1)}{6} $$ 自动编号的公式可以用如下方法表示： 若需要手动编号，参见 大括号和行标的使用 。 123456$$\\begin&#123;equation&#125;数学公式\\label&#123;eq:当前公式名&#125;\\end&#123;equation&#125;$$ 自动编号后的公式可在全文任意处使用 \\eqref&#123;eq:公式名&#125; 语句引用。 2．如何输入上下标^ 表示上标,_ 表示下标。如果上下标的内容多于一个字符，需要用 &#123;&#125; 将这些内容括成一个整体。上下标可以嵌套，也可以同时使用。 1$$x^&#123;y^z&#125;=(1+&#123;\\rm e&#125;^x)^&#123;-2xy^w&#125; $$ $$ x^{y^z}=(1+{\\rm e}^x)^{-2xy^w} $$ 3．如何输入括号和分隔符()、[] 和 | 表示符号本身，使用 \\&#123;\\&#125; 来表示 &#123;&#125; 。当要显示大号的括号或分隔符时，要用 \\left 和 \\right 命令。 一些特殊的括号： 输入 显示 输入 显示 \\langle $\\langle$ \\rangle $\\rangle$ \\lceil $\\lceil$ \\rceil $\\rceil$ \\lfloor $\\lfloor$ \\rfloor $\\rfloor$ \\lbrace $\\lbrace$ \\rbrace $\\rbrace$ \\lvert $\\lvert$ \\rvert $\\rvert$ \\lVert $\\lVert$ \\rVert $\\rVert$ 1$$ f(x,y,z) = 3y^2z \\left( 3+\\frac&#123;7x+5&#125;&#123;1+y^2&#125; \\right) $$ $$ f(x,y,z) = 3y^2z \\left( 3+\\frac{7x+5}{1+y^2} \\right) $$ 有时候要用 \\left. 或 \\right. 进行匹配而不显示本身。 1$$\\left. \\frac&#123;&#123;\\rm d&#125;u&#125;&#123;&#123;\\rm d&#125;x&#125; \\right| _&#123;x=0&#125;$$ $$ \\left. \\frac{{\\rm d}u}{{\\rm d}x} \\right|_{x=0} $$ 4．如何输入分数通常使用 \\frac &#123;分子&#125; &#123;分母&#125; 命令产生一个分数，分数可嵌套。 便捷情况可直接输入 \\frac&#123;a&#125;&#123;b&#125; 来快速生成一个 。 如果分式很复杂，亦可使用 分子 \\over 分母 命令，此时分数仅有一层。 1$$\\frac&#123;a-1&#125;&#123;b-1&#125; \\quad and \\quad &#123;a+1\\over b+1&#125;$$ $$ \\frac{a-1}{b-1} \\quad and \\quad {a+1\\over b+1} $$ 5．如何输入开方使用 \\sqrt [根指数，省略时为2] &#123;被开方数&#125; 命令输入开方。 1$$\\sqrt&#123;2&#125; \\quad and \\quad \\sqrt[n]&#123;3&#125;$$ $$ \\sqrt{2} \\quad and \\quad \\sqrt[n]{3} $$ 6．如何输入省略号数学公式中常见的省略号有两种，\\ldots 表示与文本底线对齐的省略号，\\cdots 表示与文本中线对齐的省略号。 1$$f(x_1,x_2,\\ldots ,x_n) = x_1^2 + x_2^2 + \\cdots + x_n^2$$ $$ f(x_1,x_2,\\ldots ,x_n) = x_1^2 + x_2^2 + \\cdots + x_n^2 $$ 7．如何输入矢量使用 \\vec&#123;矢量&#125; 来自动产生一个矢量。也可以使用 \\overrightarrow 等命令自定义字母上方的符号。 1$$ \\vec&#123;a&#125; \\cdot \\vec&#123;b&#125;=0 $$ $$ \\vec{a} \\cdot \\vec{b}=0 $$ 12$$ \\overleftarrow&#123;xy&#125; \\quad and \\quad \\overleftrightarrow&#123;xy&#125; \\quad and \\quad \\overrightarrow&#123;xy&#125; $$$$ xy \\text&#123; with arrows:&#125; \\quad \\overleftarrow&#123;xy&#125; \\\\; \\mid \\\\; \\overleftrightarrow&#123;xy&#125; \\\\; \\mid \\\\; \\overrightarrow&#123;xy&#125; $$ $$ \\overleftarrow{xy} \\quad and \\quad \\overleftrightarrow{xy} \\quad and \\quad \\overrightarrow{xy} \\\\ xy \\text{ with arrows:} \\quad \\overleftarrow{xy} \\; \\mid \\; \\overleftrightarrow{xy} \\; \\mid \\; \\overrightarrow{xy} $$ 8．如何输入积分使用 \\int_积分下限^积分上限 &#123;被积表达式&#125; 来输入一个积分。 1$$\\int_0^1 &#123;x^2&#125; \\,&#123;\\rm d&#125;x$$ $$ \\int_0^1 {x^2} ,{\\rm d}x $$ 本例中 \\, 和 &#123;\\rm d&#125; 部分可省略，但建议加入，能使式子更美观。 9．如何输入极限运算使用 \\lim_&#123;变量 \\to 表达式&#125; 表达式 来输入一个极限。如有需求，可以更改 \\to 符号至任意符号。 1$$ \\lim_&#123;n \\to +\\infty&#125; \\frac&#123;1&#125;&#123;n(n+1)&#125; \\quad and \\quad \\lim_&#123;x\\leftarrow&#123;示例&#125;&#125; \\frac&#123;1&#125;&#123;n(n+1)&#125; $$ $$ \\lim_{n \\to +\\infty} \\frac{1}{n(n+1)} \\quad and \\quad \\lim_{x\\leftarrow{示例}} \\frac{1}{n(n+1)} $$ 10．如何输入累加、累乘运算使用 \\sum_&#123;下标表达式&#125;^&#123;上标表达式&#125; &#123;累加表达式&#125; 来输入一个累加。 与之类似，使用 \\prod \\bigcup \\bigcap 来分别输入累乘、并集和交集。 此类符号在行内显示时上下标表达式将会移至右上角和右下角。 1$$ sum_&#123;i=1&#125;^n \\frac&#123;1&#125;&#123;i^2&#125; \\quad and \\quad \\prod_&#123;i=1&#125;^n \\frac&#123;1&#125;&#123;i^2&#125; \\quad and \\quad \\bigcup_&#123;i=1&#125;^&#123;2&#125; R $$ $$ \\sum_{i=1}^n \\frac{1}{i^2} \\quad and \\quad \\prod_{i=1}^n \\frac{1}{i^2} \\quad and \\quad \\bigcup_{i=1}^{2} R $$ 11．如何输入希腊字母输入 \\小写希腊字母英文全称 和 \\首字母大写希腊字母英文全称 来分别输入小写和大写希腊字母。 对于大写希腊字母与现有字母相同的，直接输入大写字母即可。 输入 显示 输入 显示 输入 显示 输入 显示 \\alpha $\\alpha$ A $A$ \\beta $\\beta$ B $B$ \\gamma $\\gamma$ \\Gamma $\\Gamma$ \\delta $\\delta$ \\Delta $\\Delta$ \\epsilon $\\epsilon$ E $E$ \\zeta $\\zeta$ Z $Z$ \\eta $\\eta$ H $H$ \\theta $\\theta$ \\Theta $\\Theta$ \\iota $\\iota$ I $I$ \\kappa $\\kappa$ K $K$ \\lambda $\\lambda$ \\Lambda $\\Lambda$ \\mu $\\mu$ M $M$ u $ u$ N $N$ \\xi $\\xi$ \\Xi $\\Xi$ o $o$ O $O$ \\pi $\\pi$ \\Pi $\\Pi$ \\rho $\\rho$ P $P$ \\sigma $\\sigma$ \\Sigma $\\Sigma$ \\tau $\\tau$ T $T$ \\upsilon $\\upsilon$ \\Upsilon $\\Upsilon$ \\phi $\\phi$ \\Phi $\\Phi$ \\chi $\\chi$ X $X$ \\psi $\\psi$ \\Psi $\\Psi$ \\omega $\\omega$ \\Omega $\\Omega$ 部分字母有变量专用形式，以 \\var 开头。 小写 大写 变量形式 显示 \\epsilon E \\varepsilon $\\epsilon$ \\theta \\Theta \\vartheta $\\theta$ \\rho P \\varrho $\\rho$ \\sigma \\Sigma \\varsigma $\\sigma$ \\phi \\Phi \\varphi $\\phi$ 12．如何输入其它特殊字符若需要显示更大或更小的字符，在符号前插入 \\large 或 \\small 命令。 若找不到需要的符号，使用 Detexify 来画出想要的符号。 (1) 关系运算符 输入 显示 输入 显示 输入 显示 输入 显示 \\pm $\\pm$ \\times $\\times$ \\div $\\div$ \\mid $\\mid$ mid $ mid$ \\cdot $\\cdot$ \\circ $\\circ$ \\ast $\\ast$ \\bigodot $\\bigodot$ \\bigotimes $\\bigotimes$ \\bigoplus $\\bigoplus$ \\leq $\\leq$ \\geq $\\geq$ eq $ eq$ \\approx $\\approx$ \\equiv $\\equiv$ \\sum $\\sum$ \\prod $\\prod$ \\coprod $\\coprod$ \\backslash $\\backslash$ (2) 集合运算符 输入 显示 输入 显示 输入 显示 \\emptyset $\\emptyset$ \\in $\\in$ otin $ otin$ \\subset $\\subset$ \\supset $\\supset$ \\subseteq $\\subseteq$ \\supseteq $\\supseteq$ \\bigcap $\\bigcap$ \\bigcup $\\bigcup$ \\bigvee $\\bigvee$ \\bigwedge $\\bigwedge$ \\biguplus $\\biguplus$ (3) 对数运算符 输入 显示 输入 显示 输入 显示 \\log $\\log$ \\lg $\\lg$ \\ln $\\ln$ (4) 三角运算符 输入 显示 输入 显示 输入 显示 30^\\circ $30^\\circ$ \\bot $\\bot$ \\angle A $\\angle A$ \\sin $\\sin$ \\cos $\\cos$ \\tan $\\tan$ \\csc $\\csc$ \\sec $\\sec$ \\cot $\\cot$ (5) 微积分运算符 输入 显示 输入 显示 输入 显示 \\int $\\int$ \\iint $\\iint$ \\iiint $\\iiint$ \\partial $\\partial$ \\oint $\\oint$ \\prime $\\prime$ \\lim $\\lim$ \\infty $\\infty$ abla $ abla$ (6) 逻辑运算符 输入 显示 输入 显示 \\because $\\because$ \\therefore $\\therefore$ \\forall $\\forall$ \\exists $\\exists$ ot\\subset $ ot\\subset$ ot&lt; $ ot&lt;$ ot&gt; $ ot&gt;$ ot&#x3D; $ ot&#x3D;$ (7) 戴帽符号 输入 显示 输入 显示 \\hat{xy} $\\hat{xy}$ \\widehat{xyz} $\\widehat{xyz}$ \\tilde{xy} $\\tilde{xy}$ \\widetilde{xyz} $\\widetilde{xyz}$ \\check{x} $\\check{x}$ \\breve{y} $\\breve{y}$ \\grave{x} $\\grave{x}$ \\acute{y} $\\acute{y}$ (8) 连线符号 输入 显示 \\fbox{a+b+c+d} $\\fbox{a+b+c+d}$ \\overleftarrow{a+b+c+d} $\\overleftarrow{a+b+c+d}$ \\overrightarrow{a+b+c+d} $\\overrightarrow{a+b+c+d}$ \\overleftrightarrow{a+b+c+d} $\\overleftrightarrow{a+b+c+d}$ \\underleftarrow{a+b+c+d} $\\underleftarrow{a+b+c+d}$ \\underrightarrow{a+b+c+d} $\\underrightarrow{a+b+c+d}$ \\underleftrightarrow{a+b+c+d} $\\underleftrightarrow{a+b+c+d}$ \\overline{a+b+c+d} $\\overline{a+b+c+d}$ \\underline{a+b+c+d} $\\underline{a+b+c+d}$ \\overbrace{a+b+c+d}^{Sample} $\\overbrace{a+b+c+d}^{Sample}$ \\underbrace{a+b+c+d}_{Sample} $\\underbrace{a+b+c+d}_{Sample}$ \\overbrace{a+\\underbrace{b+c}_{1.0}+d}^{2.0} $\\overbrace{a+\\underbrace{b+c}_{1.0}+d}^{2.0}$ \\underbrace{a\\cdot a\\cdots a}_{b\\text{ times}} $\\underbrace{a\\cdot a\\cdots a}_{b\\text{ times}}$ (9) 箭头符号 输入 显示 输入 显示 \\uparrow $\\uparrow$ \\Uparrow $\\Uparrow$ \\downarrow $\\downarrow$ \\Downarrow $\\Downarrow$ \\leftarrow $\\leftarrow$ \\Leftarrow $\\Leftarrow$ \\rightarrow or \\to $\\to$ \\Rightarrow $\\Rightarrow$ \\leftrightarrow $\\leftrightarrow$ \\Leftrightarrow $\\Leftrightarrow$ \\longleftarrow $\\longleftarrow$ \\Longleftarrow or \\impliedby $\\Longleftarrow$ \\longrightarrow $\\longrightarrow$ \\Longrightarrow or \\implies $\\Longrightarrow$ \\longleftrightarrow $\\longleftrightarrow$ \\Longleftrightarrow or \\iff $\\iff$ \\mapsto $\\mapsto$ \\underrightarrow{1℃&#x2F;min} $\\underrightarrow{1℃&#x2F;min}$ 13．如何进行字体转换若要对公式的某一部分字符进行字体转换，可以用 &#123;\\字体 &#123;需转换的部分字符&#125;&#125; 命令，其中 \\字体 部分可以参照下表选择合适的字体。一般情况下，公式默认为意大利体 。 示例中 全部大写 的字体仅大写可用。 输入 说明 显示 输入 说明 显示 \\rm 罗马体 $\\rm{Sample}$ \\cal 花体 $\\cal{SAMPLE}$ \\it 意大利体 $\\it{Sample}$ \\Bbb 黑板粗体 $\\Bbb{SAMPLE}$ \\bf 粗体 $\\rm{Sample}$ \\mathit 数字斜体 $\\mathit{SAMPLE}$ \\sf 等线体 $\\sf{Sample}$ \\mathscr 手写体 $\\mathscr{SAMPLE}$ \\tt 打字机体 $\\tt{Sample}$ \\frak 旧德式体 $\\frak{Sample}$ 转换字体十分常用，例如在积分中： 1234567$$\\begin&#123;array&#125;&#123;c | c&#125;\\mathrm&#123;Bad&#125; &amp; \\mathrm&#123;Better&#125; \\\\\\\\\\hline \\\\\\\\\\int_0^1 x^2 dx &amp; \\int_0^1 x^2 \\\\,&#123;\\rm d&#125;x\\end&#123;array&#125;$$ $$ \\begin{array}{c | c} \\mathrm{Bad} & \\mathrm{Better} \\\\ \\hline \\\\ \\int_0^1 x^2 dx & \\int_0^1 x^2 \\,{\\rm d}x \\end{array} $$ 注意比较两个式子间 dx 的不同。 使用 \\operatorname 命令也可以达到相同的效果，详见 定义新的符号 \\operatorname 。 14．大括号和行标的使用使用 \\left 和 \\right 来创建自动匹配高度的 (圆括号)，[方括号] 和 {花括号} 。 在每个公式末尾前使用 \\tag&#123;行标&#125; 来实现行标。 123456789101112131415$$f\\left( \\left[ \\frac&#123; 1+\\left\\\\&#123;x,y\\right\\\\&#125; &#125;&#123; \\left( \\frac xy + \\frac yx \\right) (u+1) &#125;+a \\right]^&#123;3/2&#125;\\right)\\tag &#123;行标&#125;$$ $$ f\\left( \\left[ \\frac{ 1+\\left\\{x,y\\right\\} }{ \\left( \\frac xy + \\frac yx \\right) (u+1) }+a \\right]^{3/2} \\right) \\tag {行标} $$ 如果你需要在不同的行显示对应括号，可以在每一行对应处使用 \\left. 或 \\right. 来放一个“影子“括号： 123456$$\\begin&#123;aligned&#125;a=&amp;\\left(1+2+3+ \\cdots \\right. \\\\\\\\&amp; \\cdots+ \\left. \\infty-2+\\infty-1+\\infty\\right)\\end&#123;aligned&#125;$$ $$ \\begin{aligned} a=&\\left(1+2+3+ \\cdots \\right. \\\\ & \\cdots+ \\left. \\infty-2+\\infty-1+\\infty\\right) \\end{aligned} $$ 15．其它命令 (1) 定义新的符号 \\operatorname 查询 关于此命令的定义 和 关于此命令的讨论 来进一步了解此命令。 1$$ \\operatorname&#123;Symbol&#125; A $$ $$ \\operatorname{Symbol} A $$ (2) 添加注释文字 \\text 在 \\text &#123;文字&#125; 中仍可以使用 $公式$ 插入其它公式。 1$$ f(n)= \\begin&#123;cases&#125; n/2, &amp; \\text &#123;if $n$ is even&#125; \\\\\\\\ 3n+1, &amp; \\text&#123;if $n$ is odd&#125; \\end&#123;cases&#125; $$ $$ f(n)= \\begin{cases} n/2, & \\text {if $n$ is even} \\\\ 3n+1, & \\text{if $n$ is odd} \\end{cases} $$ (3) 在字符间加入空格 有四种宽度的空格可以使用： \\,、\\;、\\quad 和 \\qquad 。 1$$ a \\, b \\mid a \\; b \\mid a \\quad b \\mid a \\qquad b $$ $$ a , b \\mid a ; b \\mid a \\quad b \\mid a \\qquad b $$ 当然，使用 \\text &#123;n个空格&#125; 也可以达到同样效果 (4) 更改文字颜色 使用 \\color&#123;颜色&#125;&#123;文字&#125; 来更改特定的文字颜色。 更改文字颜色需要浏览器支持，如果浏览器不知道你所需的颜色，那么文字将被渲染为黑色。 对于较旧的浏览器（HTML4与CSS2），支持的颜色较少; 对于较新的浏览器（HTML5与CSS3），额外的124种颜色将被支持 输入 `\\color {#rgb} {text}` 来自定义更多的颜色，其中 `#rgb` 的 `r g b` 可输入 `0-9` 和 `a-f` 来表示红色、绿色和蓝色的纯度（饱和度）。 123456789101112131415161718\\begin&#123;array&#125;&#123;|rrrrrrrr|&#125;\\hline\\verb+#000+ &amp;amp; \\color&#123;#000&#125;&#123;text&#125; &amp;amp; \\verb+#005+ &amp;amp; \\color&#123;#005&#125;&#123;text&#125; &amp;amp; \\verb+#00A+ &amp;amp; \\color&#123;#00A&#125;&#123;text&#125; &amp;amp; \\verb+#00F+ &amp;amp; \\color&#123;#00F&#125;&#123;text&#125; \\\\\\\\\\verb+#500+ &amp;amp; \\color&#123;#500&#125;&#123;text&#125; &amp;amp; \\verb+#505+ &amp;amp; \\color&#123;#505&#125;&#123;text&#125; &amp;amp; \\verb+#50A+ &amp;amp; \\color&#123;#50A&#125;&#123;text&#125; &amp;amp; \\verb+#50F+ &amp;amp; \\color&#123;#50F&#125;&#123;text&#125; \\\\\\\\\\verb+#A00+ &amp;amp; \\color&#123;#A00&#125;&#123;text&#125; &amp;amp; \\verb+#A05+ &amp;amp; \\color&#123;#A05&#125;&#123;text&#125; &amp;amp; \\verb+#A0A+ &amp;amp; \\color&#123;#A0A&#125;&#123;text&#125; &amp;amp; \\verb+#A0F+ &amp;amp; \\color&#123;#A0F&#125;&#123;text&#125; \\\\\\\\\\verb+#F00+ &amp;amp; \\color&#123;#F00&#125;&#123;text&#125; &amp;amp; \\verb+#F05+ &amp;amp; \\color&#123;#F05&#125;&#123;text&#125; &amp;amp; \\verb+#F0A+ &amp;amp; \\color&#123;#F0A&#125;&#123;text&#125; &amp;amp; \\verb+#F0F+ &amp;amp; \\color&#123;#F0F&#125;&#123;text&#125; \\\\\\\\\\hline\\verb+#080+ &amp;amp; \\color&#123;#080&#125;&#123;text&#125; &amp;amp; \\verb+#085+ &amp;amp; \\color&#123;#085&#125;&#123;text&#125; &amp;amp; \\verb+#08A+ &amp;amp; \\color&#123;#08A&#125;&#123;text&#125; &amp;amp; \\verb+#08F+ &amp;amp; \\color&#123;#08F&#125;&#123;text&#125; \\\\\\\\\\verb+#580+ &amp;amp; \\color&#123;#580&#125;&#123;text&#125; &amp;amp; \\verb+#585+ &amp;amp; \\color&#123;#585&#125;&#123;text&#125; &amp;amp; \\verb+#58A+ &amp;amp; \\color&#123;#58A&#125;&#123;text&#125; &amp;amp; \\verb+#58F+ &amp;amp; \\color&#123;#58F&#125;&#123;text&#125; \\\\\\\\\\verb+#A80+ &amp;amp; \\color&#123;#A80&#125;&#123;text&#125; &amp;amp; \\verb+#A85+ &amp;amp; \\color&#123;#A85&#125;&#123;text&#125; &amp;amp; \\verb+#A8A+ &amp;amp; \\color&#123;#A8A&#125;&#123;text&#125; &amp;amp; \\verb+#A8F+ &amp;amp; \\color&#123;#A8F&#125;&#123;text&#125; \\\\\\\\\\verb+#F80+ &amp;amp; \\color&#123;#F80&#125;&#123;text&#125; &amp;amp; \\verb+#F85+ &amp;amp; \\color&#123;#F85&#125;&#123;text&#125; &amp;amp; \\verb+#F8A+ &amp;amp; \\color&#123;#F8A&#125;&#123;text&#125; &amp;amp; \\verb+#F8F+ &amp;amp; \\color&#123;#F8F&#125;&#123;text&#125; \\\\\\\\\\hline\\verb+#0F0+ &amp;amp; \\color&#123;#0F0&#125;&#123;text&#125; &amp;amp; \\verb+#0F5+ &amp;amp; \\color&#123;#0F5&#125;&#123;text&#125; &amp;amp; \\verb+#0FA+ &amp;amp; \\color&#123;#0FA&#125;&#123;text&#125; &amp;amp; \\verb+#0FF+ &amp;amp; \\color&#123;#0FF&#125;&#123;text&#125; \\\\\\\\\\verb+#5F0+ &amp;amp; \\color&#123;#5F0&#125;&#123;text&#125; &amp;amp; \\verb+#5F5+ &amp;amp; \\color&#123;#5F5&#125;&#123;text&#125; &amp;amp; \\verb+#5FA+ &amp;amp; \\color&#123;#5FA&#125;&#123;text&#125; &amp;amp; \\verb+#5FF+ &amp;amp; \\color&#123;#5FF&#125;&#123;text&#125; \\\\\\\\\\verb+#AF0+ &amp;amp; \\color&#123;#AF0&#125;&#123;text&#125; &amp;amp; \\verb+#AF5+ &amp;amp; \\color&#123;#AF5&#125;&#123;text&#125; &amp;amp; \\verb+#AFA+ &amp;amp; \\color&#123;#AFA&#125;&#123;text&#125; &amp;amp; \\verb+#AFF+ &amp;amp; \\color&#123;#AFF&#125;&#123;text&#125; \\\\\\\\\\verb+#FF0+ &amp;amp; \\color&#123;#FF0&#125;&#123;text&#125; &amp;amp; \\verb+#FF5+ &amp;amp; \\color&#123;#FF5&#125;&#123;text&#125; &amp;amp; \\verb+#FFA+ &amp;amp; \\color&#123;#FFA&#125;&#123;text&#125; &amp;amp; \\verb+#FFF+ &amp;amp; \\color&#123;#FFF&#125;&#123;text&#125; \\\\\\\\\\hline\\end&#123;array&#125; $$ \\begin{array}{|rrrrrrrr|} \\hline \\verb+#000+ & \\color{#000}{text} & \\verb+#005+ & \\color{#005}{text} & \\verb+#00A+ & \\color{#00A}{text} & \\verb+#00F+ & \\color{#00F}{text} \\\\ \\verb+#500+ & \\color{#500}{text} & \\verb+#505+ & \\color{#505}{text} & \\verb+#50A+ & \\color{#50A}{text} & \\verb+#50F+ & \\color{#50F}{text} \\\\ \\verb+#A00+ & \\color{#A00}{text} & \\verb+#A05+ & \\color{#A05}{text} & \\verb+#A0A+ & \\color{#A0A}{text} & \\verb+#A0F+ & \\color{#A0F}{text} \\\\ \\verb+#F00+ & \\color{#F00}{text} & \\verb+#F05+ & \\color{#F05}{text} & \\verb+#F0A+ & \\color{#F0A}{text} & \\verb+#F0F+ & \\color{#F0F}{text} \\\\ \\hline \\verb+#080+ & \\color{#080}{text} & \\verb+#085+ & \\color{#085}{text} & \\verb+#08A+ & \\color{#08A}{text} & \\verb+#08F+ & \\color{#08F}{text} \\\\ \\verb+#580+ & \\color{#580}{text} & \\verb+#585+ & \\color{#585}{text} & \\verb+#58A+ & \\color{#58A}{text} & \\verb+#58F+ & \\color{#58F}{text} \\\\ \\verb+#A80+ & \\color{#A80}{text} & \\verb+#A85+ & \\color{#A85}{text} & \\verb+#A8A+ & \\color{#A8A}{text} & \\verb+#A8F+ & \\color{#A8F}{text} \\\\ \\verb+#F80+ & \\color{#F80}{text} & \\verb+#F85+ & \\color{#F85}{text} & \\verb+#F8A+ & \\color{#F8A}{text} & \\verb+#F8F+ & \\color{#F8F}{text} \\\\ \\hline \\verb+#0F0+ & \\color{#0F0}{text} & \\verb+#0F5+ & \\color{#0F5}{text} & \\verb+#0FA+ & \\color{#0FA}{text} & \\verb+#0FF+ & \\color{#0FF}{text} \\\\ \\verb+#5F0+ & \\color{#5F0}{text} & \\verb+#5F5+ & \\color{#5F5}{text} & \\verb+#5FA+ & \\color{#5FA}{text} & \\verb+#5FF+ & \\color{#5FF}{text} \\\\ \\verb+#AF0+ & \\color{#AF0}{text} & \\verb+#AF5+ & \\color{#AF5}{text} & \\verb+#AFA+ & \\color{#AFA}{text} & \\verb+#AFF+ & \\color{#AFF}{text} \\\\ \\verb+#FF0+ & \\color{#FF0}{text} & \\verb+#FF5+ & \\color{#FF5}{text} & \\verb+#FFA+ & \\color{#FFA}{text} & \\verb+#FFF+ & \\color{#FFF}{text} \\\\ \\hline \\end{array} $$ (5) 添加删除线 使用删除线功能必须声明 $$ 符号。 (注意: katex 不需要\\\\require&#123;cancel&#125;) 在公式内使用 \\require&#123;cancel&#125; 来允许 片段删除线 的显示。 声明片段删除线后，使用 \\cancel&#123;字符&#125;、\\bcancel&#123;字符&#125;、\\xcancel&#123;字符&#125; 和 \\cancelto&#123;字符&#125; 来实现各种片段删除线效果。 12345678\\begin&#123;array&#125;&#123;rl&#125;\\verb|y+\\cancel&#123;x&#125;| &amp;amp; y+\\cancel&#123;x&#125;\\\\\\\\\\verb|\\cancel&#123;y+x&#125;| &amp;amp; \\cancel&#123;y+x&#125;\\\\\\\\\\verb|y+\\bcancel&#123;x&#125;| &amp;amp; y+\\bcancel&#123;x&#125;\\\\\\\\\\verb|y+\\xcancel&#123;x&#125;| &amp;amp; y+\\xcancel&#123;x&#125;\\\\\\\\\\verb|y+\\cancelto&#123;0&#125;&#123;x&#125;| &amp;amp; y+\\cancelto&#123;0&#125;&#123;x&#125;\\\\\\\\ (katex 不支持)\\verb+\\frac&#123;1\\cancel9&#125;&#123;\\cancel95&#125; = \\frac15+&amp;amp; \\frac&#123;1\\cancel9&#125;&#123;\\cancel95&#125; = \\frac15 \\\\\\end&#123;array&#125; $$ \\begin{array}{rl} \\verb|y+\\cancel{x}| & y+\\cancel{x}\\\\ \\verb|\\cancel{y+x}| & \\cancel{y+x}\\\\ \\verb|y+\\bcancel{x}| & y+\\bcancel{x}\\\\ \\verb|y+\\xcancel{x}| & y+\\xcancel{x}\\\\ \\verb+\\frac{1\\cancel9}{\\cancel95} = \\frac15+ & \\frac{1\\cancel9}{\\cancel95} = \\frac15 \\\\ \\end{array} $$ 二、矩阵使用参考1．如何输入无框矩阵在开头使用 begin&#123;matrix&#125;，在结尾使用 end&#123;matrix&#125;，在中间插入矩阵元素，每个元素之间插入 &amp; ，并在每行结尾处使用 \\ 。 使用矩阵时必须声明 $ 或 $$ 符号。 1234567$$ \\begin&#123;matrix&#125; 1 &amp; x &amp; x^2 \\\\\\\\ 1 &amp; y &amp; y^2 \\\\\\\\ 1 &amp; z &amp; z^2 \\\\\\\\ \\end&#123;matrix&#125;$$ $$ \\begin{matrix} 1 & x & x^2 \\\\ 1 & y & y^2 \\\\ 1 & z & z^2 \\\\ \\end{matrix} $$ 2．如何输入带边框的矩阵在开头将 matrix 替换为 pmatrix bmatrix Bmatrix vmatrix Vmatrix 。 123456$ \\begin&#123;matrix&#125; 1 &amp; 2 \\\\\\\\ 3 &amp; 4 \\\\\\\\ \\end&#123;matrix&#125; $$ \\begin&#123;pmatrix&#125; 1 &amp; 2 \\\\\\\\ 3 &amp; 4 \\\\\\\\ \\end&#123;pmatrix&#125; $$ \\begin&#123;bmatrix&#125; 1 &amp; 2 \\\\\\\\ 3 &amp; 4 \\\\\\\\ \\end&#123;bmatrix&#125; $$ \\begin&#123;Bmatrix&#125; 1 &amp; 2 \\\\\\\\ 3 &amp; 4 \\\\\\\\ \\end&#123;Bmatrix&#125; $$ \\begin&#123;vmatrix&#125; 1 &amp; 2 \\\\\\\\ 3 &amp; 4 \\\\\\\\ \\end&#123;vmatrix&#125; $$ \\begin&#123;Vmatrix&#125; 1 &amp; 2 \\\\\\\\ 3 &amp; 4 \\\\\\\\ \\end&#123;Vmatrix&#125; $ $$ \\begin{matrix} 1 & 2 \\\\\\\\ 3 & 4 \\\\\\\\ \\end{matrix} \\\\ \\begin{pmatrix} 1 & 2 \\\\\\\\ 3 & 4 \\\\\\\\ \\end{pmatrix} \\\\ \\begin{bmatrix} 1 & 2 \\\\\\\\ 3 & 4 \\\\\\\\ \\end{bmatrix} \\\\ \\begin{Bmatrix} 1 & 2 \\\\\\\\ 3 & 4 \\\\\\\\ \\end{Bmatrix} \\\\ \\begin{vmatrix} 1 & 2 \\\\\\\\ 3 & 4 \\\\\\\\ \\end{vmatrix} \\\\ \\begin{Vmatrix} 1 & 2 \\\\\\\\ 3 & 4 \\\\\\\\ \\end{Vmatrix} \\\\ $$ 3．如何输入带省略符号的矩阵使用 \\cdots , \\ddots , \\vdots 来输入省略符号。 12345678$$ \\begin&#123;pmatrix&#125; 1 &amp; a_1 &amp; a_1^2 &amp; \\cdots &amp; a_1^n \\\\\\\\ 1 &amp; a_2 &amp; a_2^2 &amp; \\cdots &amp; a_2^n \\\\\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\\\\ 1 &amp; a_m &amp; a_m^2 &amp; \\cdots &amp; a_m^n \\\\\\\\ \\end&#123;pmatrix&#125;$$ $$ \\begin{pmatrix} 1 & a_1 & a_1^2 & \\cdots & a_1^n \\\\ 1 & a_2 & a_2^2 & \\cdots & a_2^n \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & a_m & a_m^2 & \\cdots & a_m^n \\\\ \\end{pmatrix} $$ 4．如何输入带分割符号的矩阵12345678$$ \\left[ \\begin&#123;array&#125;&#123;cc|c&#125; 1&amp;2&amp;3\\\\\\\\ 4&amp;5&amp;6 \\end&#123;array&#125; \\right]$$ 其中 cc|c 代表在一个三列矩阵中的第二和第三列之间插入分割线。 $$ \\left[ \\begin{array}{cc|c} 1&2&3\\\\ 4&5&6 \\end{array} \\right] $$ 5．如何输入行中矩阵若想在一行内显示矩阵，使用\\bigl(\\begin&#123;smallmatrix&#125; ... \\end&#123;smallmatrix&#125;\\bigr)。 1这是一个行中矩阵的示例 $\\bigl( \\begin&#123;smallmatrix&#125; a &amp; b \\\\\\\\ c &amp; d \\end&#123;smallmatrix&#125; \\bigr)$ 。 这是一个行中矩阵的示例 $\\bigl(\\begin{smallmatrix} a &amp; b \\ c &amp; d \\end{smallmatrix}\\bigr)$ 三、方程式序列使用参考1．如何输入一个方程式序列人们经常想要一列整齐且居中的方程式序列。使用 \\begin&#123;align&#125;…\\end&#123;align&#125; 来创造一列方程式，其中在每行结尾处使用 \\\\ 。 使用方程式序列无需声明公式符号 $ 或 $$ 。 请注意 &#123;align&#125; 语句是 自动编号 的。 123456789$$\\left\\\\&#123; \\begin&#123;array&#125;&#123;c&#125; a_1x+b_1y+c_1z &amp;=d_1 \\\\\\\\ a_2x+b_2y+c_2z &amp;=d_2 \\\\\\\\ a_3x+b_3y+c_3z &amp;=d_3 \\\\\\\\ \\end&#123;array&#125;\\right. $$ $$ \\left\\{ \\begin{array}{c} a_1x+b_1y+c_1z &=d_1 \\\\ a_2x+b_2y+c_2z &=d_2 \\\\ a_3x+b_3y+c_3z &=d_3 \\\\ \\end{array} \\right. $$ 2．在一个方程式序列的每一行中注明原因在 &#123;align&#125; 中灵活组合 \\text 和 \\tag 语句。\\tag 语句编号优先级高于自动编号。 1234567$$\\begin&#123;align&#125; v + w &amp; = 0 &amp;\\text&#123;Given&#125; \\tag 1\\\\\\\\ -w &amp; = -w + 0 &amp; \\text&#123;additive identity&#125; \\tag 2\\\\\\\\ -w + 0 &amp; = -w + (v + w) &amp; \\text&#123;equations $(1)$ and $(2)$&#125; \\tag 3\\end&#123;align&#125;$$ $$ \\begin{align} v + w & = 0 &\\text{Given} \\tag 1\\\\\\\\ -w & = -w + 0 & \\text{additive identity} \\tag 2\\\\\\\\ -w + 0 & = -w + (v + w) & \\text{equations $(1)$ and $(2)$} \\tag 3 \\end{align} $$ 本例中第一、第二行的自动编号被 \\tag 语句覆盖，第三行的编号为自动编号。 四、条件表达式使用参考1．如何输入一个条件表达式使用 begin&#123;cases&#125; 来创造一组条件表达式，在每一行条件中插入 &amp; 来指定需要对齐的内容，并在每一行结尾处使用 \\\\，以 end&#123;cases&#125; 结束。 条件表达式无需声明 $ 或 $$ 符号。 1234567$$ f(n) = \\begin&#123;cases&#125; n/2, &amp; \\text&#123;if $n$ is even&#125; \\\\\\\\ 3n+1, &amp; \\text&#123;if $n$ is odd&#125; \\end&#123;cases&#125;$$ $$ f(n) = \\begin{cases} n/2, & \\text{if $n$ is even} \\\\\\\\ 3n+1, & \\text{if $n$ is odd} \\end{cases} $$ 2．如何输入一个左侧对齐的条件表达式若想让文字在 左侧对齐显示 ，则有如下方式： 123456789$$ \\left. \\begin&#123;array&#125;&#123;l&#125; \\text&#123;if $n$ is even:&#125;&amp;n/2\\\\\\\\ \\text&#123;if $n$ is odd:&#125;&amp;3n+1 \\end&#123;array&#125; \\right\\\\&#125; =f(n)$$ $$ \\left. \\begin{array}{l} \\text{if $n$ is even:}&n/2\\\\ \\text{if $n$ is odd:}&3n+1 \\end{array} \\right\\} =f(n) $$ 3．如何使条件表达式适配行高在一些情况下，条件表达式中某些行的行高为非标准高度，此时使用 \\\\[2ex] 语句代替该行末尾的 \\\\ 来让编辑器适配。 不适配[2ex] 1234567$$f(n) = \\begin&#123;cases&#125;\\frac&#123;n&#125;&#123;2&#125;, &amp; \\text&#123;if $n$ is even&#125; \\\\\\\\3n+1, &amp; \\text&#123;if $n$ is odd&#125;\\end&#123;cases&#125;$$ $$ f(n) = \\begin{cases} \\frac{n}{2}, & \\text{if $n$ is even} \\\\ 3n+1, & \\text{if $n$ is odd} \\end{cases} $$ 适配[2ex] 1234567$$f(n) = \\begin&#123;cases&#125;\\frac&#123;n&#125;&#123;2&#125;, &amp; \\text&#123;if $n$ is even&#125; \\\\\\\\[2ex]3n+1, &amp; \\text&#123;if $n$ is odd&#125;\\end&#123;cases&#125;$$ $$ f(n) = \\begin{cases} \\frac{n}{2}, & \\text{if $n$ is even} \\\\[2ex] 3n+1, & \\text{if $n$ is odd} \\end{cases} $$ 一个 [ex] 指一个 “X-Height”，即x字母高度。可以根据情况指定多个 [ex]，如 [3ex]、[4ex] 等。 其实可以在任何地方使用 \\\\[2ex] 语句，只要你觉得合适。 五、数组与表格使用参考1．如何输入一个数组或表格通常，一个格式化后的表格比单纯的文字或排版后的文字更具有可读性。数组和表格均以 begin&#123;array&#125; 开头，并在其后定义列数及每一列的文本对齐属性，c l r 分别代表居中、左对齐及右对齐。若需要插入垂直分割线，在定义式中插入 | ，若要插入水平分割线，在下一行输入前插入 \\hline 。与矩阵相似，每行元素间均须要插入 &amp; ，每行元素以 \\\\ 结尾，最后以 end&#123;array&#125; 结束数组。 使用单个数组或表格时无需声明 $ 或 $$ 符号。 123456789$$\\begin&#123;array&#125;&#123;c|lcr&#125;n &amp; \\text&#123;左对齐&#125; &amp; \\text&#123;居中对齐&#125; &amp; \\text&#123;右对齐&#125; \\\\\\\\\\hline1 &amp; 0.24 &amp; 1 &amp; 125 \\\\\\\\2 &amp; -1 &amp; 189 &amp; -8 \\\\\\\\3 &amp; -20 &amp; 2000 &amp; 1+10i\\end&#123;array&#125;$$ $$ \\begin{array}{c|lcr} n & \\text{左对齐} & \\text{居中对齐} & \\text{右对齐} \\\\ \\hline 1 & 0.24 & 1 & 125 \\\\ 2 & -1 & 189 & -8 \\\\ 3 & -20 & 2000 & 1+10i \\end{array} $$ 2．如何输入一个嵌套的数组或表格多个数组&#x2F;表格可互相嵌套 并组成一组数组&#x2F;一组表格。 使用嵌套前必须声明 $$ 符号。 123456789101112131415161718192021222324252627282930313233343536373839$$% outer vertical array of arrays 外层垂直表格\\begin&#123;array&#125;&#123;c&#125; % inner horizontal array of arrays 内层水平表格 \\begin&#123;array&#125;&#123;cc&#125; % inner array of minimum values 内层&quot;最小值&quot;数组 \\begin&#123;array&#125;&#123;c|cccc&#125; \\text&#123;min&#125; &amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\\\\\ \\hline 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\\\\\ 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1\\\\\\\\ 2 &amp; 0 &amp; 1 &amp; 2 &amp; 2\\\\\\\\ 3 &amp; 0 &amp; 1 &amp; 2 &amp; 3 \\end&#123;array&#125; &amp; % inner array of maximum values 内层&quot;最大值&quot;数组 \\begin&#123;array&#125;&#123;c|cccc&#125; \\text&#123;max&#125;&amp;0&amp;1&amp;2&amp;3\\\\\\\\ \\hline 0 &amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\\\\\ 1 &amp; 1 &amp; 1 &amp; 2 &amp; 3\\\\\\\\ 2 &amp; 2 &amp; 2 &amp; 2 &amp; 3\\\\\\\\ 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 \\end&#123;array&#125; \\end&#123;array&#125; % 内层第一行表格组结束 \\\\\\\\ % inner array of delta values 内层第二行Delta值数组 \\begin&#123;array&#125;&#123;c|cccc&#125; \\Delta&amp;0&amp;1&amp;2&amp;3\\\\\\\\ \\hline 0 &amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\\\\\ 1 &amp; 1 &amp; 0 &amp; 1 &amp; 2\\\\\\\\ 2 &amp; 2 &amp; 1 &amp; 0 &amp; 1\\\\\\\\ 3 &amp; 3 &amp; 2 &amp; 1 &amp; 0 \\end&#123;array&#125; % 内层第二行表格组结束\\end&#123;array&#125;$$ $$ % outer vertical array of arrays 外层垂直表格 \\begin{array}{c} % inner horizontal array of arrays 内层水平表格 \\begin{array}{cc} % inner array of minimum values 内层\"最小值\"数组 \\begin{array}{c|cccc} \\text{min} & 0 & 1 & 2 & 3\\\\\\\\ \\hline 0 & 0 & 0 & 0 & 0\\\\\\\\ 1 & 0 & 1 & 1 & 1\\\\\\\\ 2 & 0 & 1 & 2 & 2\\\\\\\\ 3 & 0 & 1 & 2 & 3 \\end{array} & % inner array of maximum values 内层\"最大值\"数组 \\begin{array}{c|cccc} \\text{max}&0&1&2&3\\\\\\\\ \\hline 0 & 0 & 1 & 2 & 3\\\\\\\\ 1 & 1 & 1 & 2 & 3\\\\\\\\ 2 & 2 & 2 & 2 & 3\\\\\\\\ 3 & 3 & 3 & 3 & 3 \\end{array} \\end{array} % 内层第一行表格组结束 \\\\\\\\ % inner array of delta values 内层第二行Delta值数组 \\begin{array}{c|cccc} \\Delta&0&1&2&3\\\\\\\\ \\hline 0 & 0 & 1 & 2 & 3\\\\\\\\ 1 & 1 & 0 & 1 & 2\\\\\\\\ 2 & 2 & 1 & 0 & 1\\\\\\\\ 3 & 3 & 2 & 1 & 0 \\end{array} % 内层第二行表格组结束 \\end{array} $$ 3．如何输入一个方程组使用 \\begin&#123;array&#125;…\\end&#123;array&#125; 和 \\left\\&#123;…\\right. 来创建一个方程组。 123456789$$\\left\\\\&#123; \\begin&#123;array&#125;&#123;c&#125; a_1x+b_1y+c_1z=d_1 \\\\\\\\ a_2x+b_2y+c_2z=d_2 \\\\\\\\ a_3x+b_3y+c_3z=d_3 \\end&#123;array&#125;\\right. $$ $$ \\left\\{ \\begin{array}{c} a_1x+b_1y+c_1z=d_1 \\\\ a_2x+b_2y+c_2z=d_2 \\\\ a_3x+b_3y+c_3z=d_3 \\\\ \\end{array} \\right. $$ 或者使用条件表达式组 \\begin&#123;cases&#125;…\\end&#123;cases&#125; 来实现相同效果： 1234567$$\\begin&#123;cases&#125;a_1x+b_1y+c_1z=d_1 \\\\\\\\a_2x+b_2y+c_2z=d_2 \\\\\\\\ a_3x+b_3y+c_3z=d_3\\end&#123;cases&#125;$$ $$ \\begin{cases} a_1x+b_1y+c_1z=d_1 \\\\ a_2x+b_2y+c_2z=d_2 \\\\ a_3x+b_3y+c_3z=d_3 \\end{cases} $$ 六、连分数使用参考1．如何输入一个连分式就像输入分式时使用 \\frac 一样，使用 \\cfrac 来创建一个连分数。 12345$$x = a_0 + \\cfrac&#123;1^2&#125;&#123;a_1 + \\cfrac&#123;2^2&#125;&#123;a_2 + \\cfrac&#123;3^2&#125;&#123;a_3 + \\cfrac&#123;4^4&#125;&#123;a_4 + \\cdots&#125;&#125;&#125;&#125;$$ $$ x = a_0 + \\cfrac{1^2}{a_1 + \\cfrac{2^2}{a_2 + \\cfrac{3^2}{a_3 + \\cfrac{4^4}{a_4 + \\cdots}}}} $$ 不要使用普通的 \\frac 或 \\over 来创建，否则会看起来 很恶心 。 12345$$x = a_0 + \\frac&#123;1^2&#125;&#123;a_1 + \\frac&#123;2^2&#125;&#123;a_2 + \\frac&#123;3^2&#125;&#123;a_3 + \\frac&#123;4^4&#125;&#123;a_4 + \\cdots&#125;&#125;&#125;&#125;$$ $$ x = a_0 + \\frac{1^2}{a_1 + \\frac{2^2}{a_2 + \\frac{3^2}{a_3 + \\frac{4^4}{a_4 + \\cdots}}}} $$ 当然，你可以使用 \\frac 来表达连分数的 紧缩记法 。 12345$$x = a_0 + \\frac&#123;1^2&#125;&#123;a_1+&#125; \\frac&#123;2^2&#125;&#123;a_2+&#125; \\frac&#123;3^2&#125;&#123;a_3 +&#125; \\frac&#123;4^4&#125;&#123;a_4 +&#125; \\cdots$$ $$ x = a_0 + \\frac{1^2}{a_1+} \\frac{2^2}{a_2+} \\frac{3^2}{a_3 +} \\frac{4^4}{a_4 +} \\cdots $$ 连分数通常都太大以至于不易排版，所以建议在连分数前后声明 $$ 符号，或使用像 [a0;a1,a2,a3,…] 一样的紧缩记法。 七、交换图表使用参考1．如何输入一个交换图表使用一行 \\require&#123;AMScd&#125; 语句来允许交换图表的显示。 声明交换图表后，语法与矩阵相似，在开头使用 begin&#123;CD&#125;，在结尾使用 end&#123;CD&#125;，在中间插入图表元素，每个元素之间插入 &amp; ，并在每行结尾处使用\\\\ 。 1234567$$\\begin&#123;CD&#125; A @&gt;a&gt;&gt; B \\\\\\\\ @VbVV @VVcV \\\\\\\\ C @&gt;&gt;d&gt; D\\end&#123;CD&#125;$$ $$ \\begin{CD} A @>a>> B \\\\ @VbVV @VVcV \\\\ C @>>d> D \\end{CD} $$ 其中，@&gt;&gt;&gt; 代表右箭头、@&lt;&lt;&lt; 代表左箭头、@VVV 代表下箭头、@AAA 代表上箭头、@= 代表水平双实线、@| 代表竖直双实线、@.代表没有箭头。 在 @&gt;&gt;&gt; 的 &gt;&gt;&gt; 之间任意插入文字即代表该箭头的注释文字。 1234567$$\\begin&#123;CD&#125; A @&gt;&gt;&gt; B @&gt;&#123;\\text&#123;very long label&#125;&#125;&gt;&gt; C \\\\\\\\ @. @AAA @| \\\\\\\\ D @= E @&lt;&lt;&lt; F\\end&#123;CD&#125;$$ $$ \\begin{CD} A @>>> B @>{\\text{very long label}}>> C \\\\ @. @AAA @| \\\\ D @= E @< F \\end{CD} $$","tags":["Markdown","mathjax"],"categories":["开发工具"]},{"title":"Cpp STL 与常见语法糖","path":"/post/C++/cpp-stl/","content":"刷题常见语法function｜auto&amp;&amp; dfs1️⃣ 关于 [572. 另一棵树的子树] 代码中的 auto dfs = [&amp;](auto&amp;&amp; dfs, TreeNode* node) -&gt; pair&lt;int, bool&gt; &#123;&#125; 传递 auto&amp;&amp; dfs 的解释。 1234567891011121314151617181920212223242526272829303132333435// 572. 另一棵树的子树class Solution &#123;public: int getHeight(TreeNode* root) &#123; if(root == nullptr) return 0; int left_h = getHeight(root-&gt;left); int right_h = getHeight(root-&gt;right); return max(left_h, right_h) + 1; &#125; bool isSameTree(TreeNode* p, TreeNode* q) &#123; if(p == nullptr || q == nullptr) &#123; return p == q; &#125; return p-&gt;val == q-&gt;val &amp;&amp; isSameTree(p-&gt;left, q-&gt;left) &amp;&amp; isSameTree(p-&gt;right, q-&gt;right); &#125; bool isSubtree(TreeNode* root, TreeNode* subRoot) &#123; int hs = getHeight(subRoot); auto dfs = [&amp;](auto&amp;&amp; dfs, TreeNode* node) -&gt; pair&lt;int, bool&gt; &#123; if(node == nullptr) return &#123;0, false&#125;; auto [left_h, left_found] = dfs(dfs, node-&gt;left); auto [right_h, right_found] = dfs(dfs, node-&gt;right); if(left_found || right_found) return &#123;0, true&#125;; int node_h = max(left_h, right_h) + 1; return &#123;node_h, node_h == hs &amp;&amp; isSameTree(node, subRoot)&#125;; &#125;; return dfs(dfs, root).second; &#125;&#125;; 🔥 为什么需要在调用 dfs 传递 dfs 自身：为了能够递归调用 dfs，我们需要在 lambda 的内部将其传递给自己。C++ 的 lambda 本身是不能直接递归的，因为它只是一个匿名函数对象，不知道如何调用自身。因此，我们显式地将 dfs 作为参数传递给它自身，以便在递归时能正确调用。 2️⃣ 如果要简化调用方式（即不重复传入 dfs），那可以这样定义： 12345auto dfs = [&amp;](this auto&amp;&amp; dfs, TreeNode* node) -&gt; pair&lt;int, bool&gt; &#123; ...&#125;// calldfs(root); 3️⃣ 当然也可以使用 function&lt;pair&lt;int, bool&gt;(TreeNode*)&gt;dfs = [&amp;](TreeNode* node) -&gt; pair&lt;int, bool&gt; &#123;&#125;; 这样就只需要传一个参数，但是也显得代码有些臃肿，看个人习惯，我比较习惯直接用 function 而不是 auto，也可以是：auto&amp;&amp; dfs = [&amp;](auto&amp;&amp; dfs, TreeNode* node) -&gt; pair&lt;int, bool&gt; &#123;&#125;; -&gt;，. 常见用处. 是结构体的成员运算符。用于通过对象或引用直接访问对象的成员。 12345678struct MyStruct &#123; int x; void func() &#123; /* ... */ &#125;&#125;;MyStruct obj;obj.x = 10; // 使用 . 来访问成员变量obj.func(); // 使用 . 来调用成员函数 -&gt; 是指针指向其成员的运算符。组合操作符，相当于先解引用指针，再通过 . 访问成员。 123MyStruct* ptr = &amp;obj;ptr-&gt;x = 20; // 使用 -&gt; 来访问成员变量ptr-&gt;func(); // 使用 -&gt; 来调用成员函数 其它用法： pair&lt;int, int&gt; p 使用 p.first 123456// 对象std::pair&lt;int, int&gt; p = &#123;1, 2&#125;;p.first = 10;// 指针std::pair&lt;int, int&gt;* pPtr = &amp;p;pPtr-&gt;first = 10; 迭代器通常是一个对象（例如容器的迭代器），但它通常表现为类似指针的行为，所以迭代器 iterator 使用 -&gt; 来解引用访问元素 1234567// 迭代器是对象it.operator++(); // 假设 it 是一个迭代器对象，可以直接调用成员函数// 但是访问元素需要使用 -&gt; 解引用auto it = mp.begin();it-&gt;first; // 访问 std::map 或 std::unordered_map 中的 pair 成员// *it 解引用迭代器后通常指向容器中的元素，-&gt; 是 (*it).member 的简写 关于 for 在 map 与 pair 中的遍历 1234567891011121314151617unordered_map&lt;int, int&gt; mp&#123;&#123;1, 2&#125;, &#123;3, 4&#125;&#125;;// iteratorauto it = mp.begin();cout &lt;&lt; it-&gt;first &lt;&lt; &quot;: &quot; &lt;&lt; it-&gt;second &lt;&lt; std::endl;// unordered_mapfor (auto &amp;p: mp) &#123; std::cout &lt;&lt; p.first &lt;&lt; &quot;: &quot; &lt;&lt; p.second &lt;&lt; std::endl;&#125;vector&lt;pair&lt;int, int&gt;&gt; vec&#123;&#123;1, 2&#125;, &#123;11, 22&#125;&#125;;// pairfor (auto &amp;p: vec) &#123; std::cout &lt;&lt; p.first &lt;&lt; &quot;: &quot; &lt;&lt; p.second &lt;&lt; std::endl;&#125; 常见数据结构数值大小size_t：是一种在 C 和 C++ 中常见的无符号整数类型，它用于表示某个对象或类型在内存中的大小，通常由 sizeof 操作符返回。size_t 的定义在标准头文件 &lt;stddef.h&gt;（C 中）或 &lt;cstddef&gt;（C++ 中）中。 无符号类型：size_t 是无符号整数，这意味着它不能表示负值（始终 &gt;&#x3D; 0）。 平台相关：size_t 的具体大小依赖于平台的架构。在32位系统上，size_t 通常为 4 字节（32 位）；在64位系统上，它通常为 8 字节（64 位）。 典型用途：size_t 主要用于数组索引、内存大小计算、malloc 和 calloc 等内存分配函数的返回值。 1234567// 像 STL 的容器 size() 函数返回值是 size_t，而 size_t 是一个与机器相关（32bit，64bit）的无符号整数类型，size_t size() const;// 死循环for (size_t i = N; i &gt;= 0; --i) &#123; // todo&#125; 其他常见数据结构类型 数据类型 字节大小 数值范围 char 1 -128 到 127 或 0 到 255（无符号） signed char 1 -128 到 127 unsigned char 1 0 到 255 short 2 $-2^{15}$ 到 $2^{15}-1$ int 4 $-2^{31}$ 到 $2^{31}-1$ long 4 或 8 … long long 8 $-2^{63}$ 到 $2^{63}-1$ wchar_t 2 或 4 … char16_t 2 0 到 $2^{16}-1$ char32_t 4 0 到 $2^{32}-1$ size_t 4 或 8（根据机器而定） 0 到 $2^{32}-1$ 或者 0 到 $2^{64}-1$ atoi(), stoi(), iota(), itoa() 与 c_str() c_str()：将 string 转为 char*，即把 C++ 字符串对象转换为 C 风格的字符串（以 \\0 结尾的字符数组） 123// const char* c_str() const noexcept;std::string str = &quot;hello&quot;;const char* cstr = str.c_str(); // cstr 现在为 &quot;hello&quot; itoa()：Integer to ASCII；将整数转换为 C 风格的字符串（即以 \\0 结尾的字符数组），返回指向转换后字符串的指针，即参数 str 的地址 iota()：Incremental Fill；将指定范围内的每个元素赋值为一个递增的值，通常用于生成序列 itoa() 为 C 库函数 1234567// char* itoa(int value, char* str, int base);char buffer[20];itoa(12345, buffer, 10); // 将整数 12345 转换为字符串 &quot;12345&quot;// void iota(ForwardIt first, ForwardIt last, T value);std::vector&lt;int&gt; vec(5);std::iota(vec.begin(), vec.end(), 10); // vec 现在包含 &#123;10, 11, 12, 13, 14&#125; atoi()：ASCII to Integer；将 char* 转为 int，因此对于一个字符串 str 我们必须调用 c_str() 的方法把这个 string 转换成 const char* 类型；不会做范围检查，如果超出范围的话，超出上界，则输出上界，超出下界，则输出下界。 atoi() 为 C 库函数 123// int atoi(const char* str);const char* str = &quot;123&quot;;int num = atoi(str); // num 现在为 123 stoi()：String to Int；将 string 转为 int，且会做范围检查，默认范围是在 int 的范围内的，如果超出范围的话则会 runtime error. stof()：String to Float；将 string 转为 float，同上 to_string() 1234567// int stoi(const std::string&amp; str, size_t* pos = 0, int base = 10);std::string str1 = &quot;456&quot;;int num1 = stoi(str1); // num 现在为 456// float stof(const std::string&amp; str, size_t* pos = 0);std::string str2 = &quot;3.14&quot;;float num2 = stof(str2); // num 现在为 3.14f *max_element() 与 *min_element()std::max_element() 和 std::min_element() 分别是取「最大值」和「最小值」的函数 C++ 20 也可以使用 ranges::max_element() 与 ranges::min_element() 1234567891011121314std::vector&lt;int&gt; v&#123;3, 1, -4, 1, 5, 9&#125;;// ForwardIt max_element( ForwardIt first, ForwardIt last );int mx_elem = *max_element(v.begin(), v.end());// ForwardIt min_element( ForwardIt first, ForwardIt last );int mn_elem = *min_element(v.begin(), v.end());// 自定义 compare 函数auto it = std::max_element(v.begin(), v.end(), [](int a, int b) &#123; return std::abs(a) &lt; std::abs(b); &#125;);std::cout &lt;&lt; *it &lt;&lt; std::endl; __builtin_popcount(nums[i])__builtin_popcount(nums[i]) 是 GCC 和 Clang 编译器中的内置函数，用于计算一个整数中二进制位为 1 的数量。 123456789101112131415161718192021// 3011. 判断一个数组是否可以变为有序class Solution &#123;public: bool canSortArray(vector&lt;int&gt;&amp; nums) &#123; // __builtin_popcount(num): GCC 和 Clang 编译器中的内置函数，用于计算一个整数中二进制位为 1 的数量 int n = nums.size(); int pre_max = 0; for (int i = 0; i &lt; n;) &#123; int mx = 0; int ones = __builtin_popcount(nums[i]); while (i &lt; n &amp;&amp; __builtin_popcount(nums[i]) == ones) &#123; if (nums[i] &lt; pre_max) &#123; return false; &#125; mx = max(mx, nums[i++]); &#125; pre_max = mx; &#125; return true; &#125;&#125;; resize() 知多少 ans.resize(n, avg) 多出的空间用 avg 补全，数组变短则直接截断。 ranges::nth_element()相关例题：1738. 找出第 K 大的异或坐标值 ranges::nth_element(vec, vec.end() - k) 求取第 k 大的数并放在对应位置，左边比其小，右边比其大，但顺序不保证。 1234567891011121314151617// 1738. 找出第 K 大的异或坐标值class Solution &#123;public: int kthLargestValue(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int k) &#123; int m = matrix.size(), n = matrix[0].size(); vector&lt;int&gt; ans; vector&lt;vector&lt;int&gt;&gt; s(m + 1, vector&lt;int&gt;(n + 1)); for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; s[i + 1][j + 1] = s[i][j] ^ s[i + 1][j] ^ s[i][j + 1] ^ matrix[i][j]; ans.push_back(s[i + 1][j + 1]); &#125; &#125; ranges::nth_element(ans, ans.end() - k); return ans[ans.size() - k]; &#125;&#125;; lower_bound() 与 upper_bound()lower_bound() 和 upper_bound() 都是利用「二分查找」方法在排序数组中进行查找。 lower_bound(nums.begin(), nums.end(), num)：找第一个大于或等于 num 的数字 upperer_bound(nums.begin(), nums.end(), num)：找第一个大于 num 的数字 123456789// 2529. 正整数和负整数的最大计数class Solution &#123;public: int maximumCount(vector&lt;int&gt;&amp; nums) &#123; int neg = ranges::lower_bound(nums, 0) - nums.begin(); int pos = nums.end() - ranges::upper_bound(nums, 0); return max(neg, pos); &#125;&#125;; 等价于 ranges::equal_range() 123456789class Solution &#123;public: int maximumCount(vector&lt;int&gt;&amp; nums) &#123; auto [left, right] = ranges::equal_range(nums, 0); int neg = left - nums.begin(); int pos = nums.end() - right; return max(neg, pos); &#125;&#125;; std::move() 与右值表达式推荐阅读：一文读懂 C++ 右值引用和 std::move 1. 什么是右值和左值？在 C++ 中，表达式的值可以分为两种类型：左值（lvalue） 和 右值（rvalue）。 左值（lvalue）： 左值表示一个具有持久存储（可以取地址）的对象，通常是变量或可以出现在赋值操作符左边的表达式。 例如：变量、数组元素、对象的成员等。 示例： 12int x = 10;x = 20; // x 是一个左值，可以赋值。 右值（rvalue）： 右值表示一个临时值或不持久存储的值，通常是表达式的结果，如常量、临时对象、运算结果等。右值通常无法取地址，也不能在赋值操作符的左边使用。 示例： 12int y = 10 + 20; // 10 + 20 是一个右值，只是一个计算结果。int z = 30; // 30 是一个右值。 2. 右值引用（rvalue reference）右值引用是 C++11 引入的一种新特性，它允许你通过引用操作右值。它的语法是在类型后面加上 &amp;&amp;，例如：int&amp;&amp; 表示一个右值引用。 右值引用的用途： 移动语义：允许通过移动（而不是复制）资源来优化性能，特别是对于涉及大量数据的对象（如大数组、字符串等）。 完美转发：在模板编程中使用，允许将函数参数完美转发给另一个函数。 右值引用的示例： 12int x = 10;int&amp;&amp; rvalueRef = 10; // 10 是右值，rvalueRef 是一个右值引用。 3. std::move() 的作用std::move() 是 C++ 标准库中的一个函数模板，用于将一个左值显式地转换为右值引用。这种转换允许开发者以右值引用的方式来处理本应是左值的对象，从而触发移动语义。 为什么需要 std::move()： 移动语义：在实现对象移动时（例如在 std::vector 中），你可以通过 std::move() 将资源从一个对象“移动”到另一个对象，而不是复制它们。这样可以避免不必要的资源分配和释放，极大提高性能。 避免复制：通过 std::move()，你可以明确告诉编译器，你不再需要某个对象的值，所以可以将其资源移动到另一个对象中。 std::move() 的示例： 123456789101112#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;utility&gt; // std::moveint main() &#123; std::string str = &quot;Hello, World!&quot;; std::string newStr = std::move(str); // str 的内容被移动到 newStr 中。 std::cout &lt;&lt; &quot;str: &quot; &lt;&lt; str &lt;&lt; std::endl; // str 现在可能为空。 std::cout &lt;&lt; &quot;newStr: &quot; &lt;&lt; newStr &lt;&lt; std::endl; // newStr 拥有 &quot;Hello, World!&quot;。 return 0;&#125; 输出： 12str: newStr: Hello, World! 在这个例子中，std::move(str) 将 str 转换为一个右值引用，这样 newStr 可以接管 str 的资源，而不需要复制字符串的内容。str 在移动后，其内部资源（如字符串数据）被转移到 newStr，因此 str 变为空或处于未定义状态。 4. 移动语义与对象的生命周期当对象的资源被移动后，原对象通常会被清空或置于一种安全的“空”状态。你不应再依赖或使用已移动的对象，除非明确知道它处于什么状态。 移动构造函数： 当一个对象被移动时，通常会调用它的移动构造函数。移动构造函数接受一个右值引用，并将资源从旧对象移动到新对象。 示例： 12345678910111213class MyClass &#123;public: MyClass() : data(new int[100]) &#123;&#125; ~MyClass() &#123; delete[] data; &#125; // 移动构造函数 MyClass(MyClass&amp;&amp; other) noexcept : data(other.data) &#123; other.data = nullptr; // 旧对象的指针设为 nullptr，表示资源已被转移。 &#125;private: int* data;&#125;; 5. std::move() 与右值引用的通俗理解 右值引用：你可以把右值引用看作是一个能够接管“临时对象”所有权的“特殊指针”，它可以直接操作这些临时对象而不会额外复制数据。 std::move()：它并不是真正“移动”了什么东西，而是“转换”了一个左值，使其变得可以被视为右值（临时对象），这样你就可以使用右值引用来操作它。其背后是为了优化性能，减少不必要的资源复制。 move 总结 右值引用（int&amp;&amp;）允许你捕获和操作临时对象，从而实现更高效的资源管理。 std::move() 是一种显式的类型转换工具，将左值转换为右值引用，告诉编译器可以“安全地”移动这个对象的资源。 使用 std::move() 和右值引用，可以避免不必要的复制操作，优化代码的执行效率，尤其是在处理大量数据的对象时。 C++ ranges 包 该包位于 #include &lt;algorithm&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;algorithm&gt;std::vector&lt;int&gt; vec = &#123;1, 2, 3&#125;;ranges::sort(vec);ranges::for_each(vec, [](int&amp; n) &#123; n *= 2; &#125;);ranges::find(vec, 1);int cnt = ranges::count_if(vec, [&amp;](int x) &#123; return x % 2 == 0; &#125;);// 原地去重: 移除范围内的重复连续元素， unique() 返回去重后最大值的指针位置auto it = std::ranges::unique(vec);//constexpr const T&amp; max( const T&amp; a, const T&amp; b, Comp comp = &#123;&#125;, Proj proj = &#123;&#125; );int mx = ranges::max(1, 9999);vector&lt;vector&lt;int&gt;&gt; nums;//constexpr T max( std::initializer_list&lt;T&gt; r, Comp comp = &#123;&#125;, Proj proj = &#123;&#125; );int max_end = ranges::max(nums, &#123;&#125;, [](const auto&amp; a) &#123; return a[1]; &#125;)[1];// fill 快速填充int min_d[26];ranges::fill(min_d, INT_MAX);ranges::lower_bound(nums, 0);ranges::upper_bound(nums, 0);ranges::reverse(vec);auto [left, right] = ranges::equal_range(nums, 0);ranges::nth_element(ans, ans.end() - k);bool isEmpty = ranges::empty(vec);auto size = ranges::size(vec);auto begin = std::ranges::begin(vec);auto end = std::ranges::end(vec);auto dist = std::ranges::distance(vec.begin() + 1, vec.end() - 1);auto distance = std::ranges::distance(vec); 关于 static auto x = []() 的用法解析 推荐阅读：关于 static auto x = []() 的用法解析 12345678910111213141516171819202122232425262728293031323334static const auto _ = []() &#123; ios::sync_with_stdio(false); cin.tie(nullptr); return nullptr;&#125;();class Solution &#123;public: // 官方题解 bool canThreePartsEqualSum(vector&lt;int&gt;&amp; arr) &#123; int s = accumulate(arr.begin(), arr.end(), 0); if(s % 3 != 0) return false; int target = s / 3; int n = arr.size(), i = 0, cur = 0; while(i &lt; n) &#123; cur += arr[i]; if(cur == target) break; ++i; &#125; if(cur != target) return false; int j = i + 1; // 满足最后两个数组非空 while(j + 1 &lt; n) &#123; cur += arr[j]; if(cur == target * 2) return true; ++j; &#125; return false; &#125;&#125;; ios::sync_with_stdio(false) 作用: 这行代码用于解除 C++ 标准流（cin, cout, 等）与 C 标准流（scanf, printf, 等）的同步。 原因: 在 C++ 中，cin 和 cout 默认与 scanf 和 printf 这类 C 的输入输出流同步，以确保它们可以混合使用而不会出现顺序问题。然而，这种同步会带来性能开销。 效果: 将 ios::sync_with_stdio(false) 设为 false 后，cin 和 cout 不再与 C 标准流同步，因此可以提高输入输出的效率，但这也意味着你不应再混用 C 和 C++ 的输入输出函数，否则可能会导致未定义行为。 cin.tie(nullptr) 作用: cin.tie(nullptr) 用于解除 cin 和 cout 之间的绑定关系。 原因: 默认情况下，cin 和 cout 是绑定在一起的，这意味着在每次使用 cin 进行输入操作前，cout 会自动刷新缓冲区，以确保输入输出顺序的正确性。然而，这种绑定关系在处理大量数据时会带来性能损失。 效果: 将 cin 的绑定关系设为 nullptr 后，cout 不会自动刷新缓冲区，从而提高了程序的运行效率。但这意味着你需要手动刷新输出缓冲区（通过 cout.flush() 或 endl 等方式），以确保输出顺序正确。 总结这两行代码通常用于竞赛编程或需要快速处理大量输入输出的程序中，能够显著提高输入输出的性能。然而，需要注意的是，它们可能会改变输入输出行为的某些细节，因此在启用这些优化时应确保不混用 C 和 C++ 的输入输出函数，并在需要时手动刷新输出缓冲区。 使用 #include&lt;bits/stdc++.h&gt; 指令，您可以轻松将大多数标准 C++ 头文件包含在代码中（面试中的 ACM 模式经常使用该标准库函数） bits/stdc++.h 是 GCC 专用的头文件，在使用 Clang 的 MacOS 上默认不可用。要修复“文件未找到”错误，您可以创建自己的 stdc++.h 文件并将其放在 Clang 可以找到的目录中。 类型转换 static_cast&lt;int&gt;(val)C++ 提供了几种不同的类型转换操作符，每种都有特定的用途和使用场景： static_cast：基本数据类型之间的转换（如 int 转 float） dynamic_cast：用于处理包含多态的类层次结构的类型转换 const_cast：修改变量的 const 或 volatile 修饰符，允许去除或增加这些修饰符 reinterpret_cast：最危险的类型转换操作符，主要用于在指针或引用之间进行非常规的、非安全的类型转换 push() 与 emplace()对于 map 也好，pair 也好，或者是对象，emplace 都能直接构造。 1234567std::map&lt;int, std::string&gt; myMap;// 使用 insert 和 std::make_pairmyMap.insert(std::make_pair(1, &quot;one&quot;));// 使用 emplace，直接传入构造 pair 的参数myMap.emplace(2, &quot;two&quot;); C&#x2F;C++ __builtin 超实用位运算库函数__builtin_ctz() &#x2F; __builtin_ctzll()返回括号内数字的二进制表示数末尾 0 的个数 12345678#include &lt;bits/stdc++.h&gt;using namespace std;int main() &#123; // 输出 3: 8 = 1000, 末尾 3 个 0 cout &lt;&lt; __builtin_ctz(8) &lt;&lt; endl ; return 0;&#125; __builtin_clz() &#x2F; __builtin_clzll()返回括号内数字的二进制表示数前导 0 的个数 1234567891011#include &lt;bits/stdc++.h&gt;using namespace std;int main() &#123; // 输出 28: // 8 = 0000 0000 0000 0000 0000 0000 0000 1000 // 整型(int)为 32 位, 有 28 个前导 0 // 如果换成 __builtin_clzll 则输出 60 cout &lt;&lt; __builtin_clz(8) &lt;&lt; endl ; return 0 ;&#125; __builtin_popcount()返回括号内数字的二进制表示数 1 的个数 12345678#include &lt;bits/stdc++.h&gt;using namespace std;int main() &#123; // 输出 4: 15 = 1111, 1 的个数有 4 个 cout &lt;&lt; __builtin_popcount(15) &lt;&lt; endl ; return 0 ;&#125; __builtin_parity()判断括号中数字的二进制表示数 1 的个数的奇偶数（偶数返回 0，奇数返回 1） 12345678#include &lt;bits/stdc++/h&gt;using namespace std;int main() &#123; // 输出 0: 15 = 1111, 1 的个数为 4 (偶数个) cout &lt;&lt; __builtin_parity(15) &lt;&lt; endl ; return 0 ;&#125; __builtin_ffs()返回括号中数字的二进制表示数的最后一个 1 在第几位（从后往前算） 12345678#include &lt;bits/stdc++.h&gt;using namespace std;int main() &#123; // 输出 4: 8 = 1000, 最后一个 1 在第四位 cout &lt;&lt; __builtin_ffs(8) &lt;&lt; Lendl ; return 0 ;&#125; STL 推荐阅读：https://www.apiref.com/cpp-zh/cpp/container.html 容器库是类模板与算法的汇集，允许程序员简单地访问常见数据结构，例如队列、链表和栈。 有三类容器： 顺序容器 关联容器 无序关联容器 容器管理为其元素分配的存储空间，并提供直接或间接地通过迭代器（拥有类似指针属性的对象）访问它们的函数。 C++ 标准模板库（STL）提供了一系列强大的容器，这些容器封装了常见的数据结构，支持各种操作和算法。 一旦 STL 容器中有 find() 方法，那么判断方法一般是 stl.find(val) != stl.end(). ⚠️ find 函数只有在「关联容器」和「string」中存在： 前者返回迭代器 iterator 后者 If no matches were found, the function returns string::npos. 顺序容器 顺序容器实现能按顺序访问的数据结构 array：静态的连续数组 vector：动态的连续数组 deque：双端队列 forward_list：单链表 list：双链表 关联容器 关联容器实现能快速查找「 $O(log n)$ 复杂度」的数据结构 set：唯一键的集合，按照键排序 map：键值对的集合，按照键排序，键是唯一的 multiset：键的集合，按照键排序 multimap：键值对的集合，按照键排序 无序关联容器 无序关联容器提供能快速查找「均摊 $O(1)$，最坏情况 $O(n)$ 复杂度」的无序（哈希）数据结构 unordered_set：唯一键的集合，按照键生成散列 unordered_map：键值对的集合，按照键生成散列，键是唯一的 unordered_multiset：键的集合，按照键生成散列 unordered_multimap：键值对的集合，按照键生成散列 容器适配器 容器适配器提供顺序容器的不同接口 stack：适配一个容器以提供栈（LIFO 数据结构） queue：适配一个容器以提供队列（FIFO 数据结构） 迭代器非法化 只读方法决不非法化迭代器或引用 修改容器内容的方法可能非法化迭代器和&#x2F;或引用 举个例子： 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;template&lt;typename T&gt;std::ostream &amp;operator&lt;&lt;(std::ostream &amp;s, const vector&lt;T&gt; &amp;v) &#123; s.put(&#x27;[&#x27;); char comma[3] = &#123;&#x27;\\0&#x27;, &#x27; &#x27;, &#x27;\\0&#x27;&#125;; for (const auto &amp;e: v) &#123; s &lt;&lt; comma &lt;&lt; e; comma[0] = &#x27;,&#x27;; &#125; return s &lt;&lt; &#x27;]&#x27;;&#125;int main() &#123; vector&lt;int&gt; vec&#123;1, 2, 3, 4, 5, 6&#125;; auto it = vec.begin(); vec.insert(it, 1); // success vec.insert(it, 666); // fail: 迭代器非法化(因为在上一步后容器扩容) cout &lt;&lt; vec.capacity() &lt;&lt; endl; // 扩容: 重新分配内存空间 it = vec.begin(); // 重新指向新内存地址 vec.insert(it, 666); // success vec.insert(it, 666); // success vec.insert(it, 666); // success cout &lt;&lt; vec &lt;&lt; endl; auto i = vec.begin(); vec.erase(i); // success vec.erase(i); // success i = vec.end() - 1; vec.erase(i); // success vec.erase(i); // fail: 迭代器非法化 cout &lt;&lt; vec &lt;&lt; endl; return 0;&#125; 迭代器非法化总结表格： 这里的插入指代任何添加一或多个元素到容器的方法： 因为插入过程可能会导致容器扩容（capacity 变化），扩容后会释放原有的空间，而迭代器依然指向原有空间中的位置，此时该迭代器变成野指针，导致无法访问！ insert push_back push_front operator[] 也算，因为也存在插入的可能性 而擦除指代任何从容器移除一或多个元素的方法： 擦除后迭代器失效是因为删除的是最后一个有效元素，然后删除后该迭代器指向容器的非有效位置！ erase pop_back pop_front clear 尾后迭代器需要特别留意。通常像指向未被擦除元素的正常迭代器一般非法化此迭代器。 故 std::set::end 决不被非法化，std::unordered_set::end 仅在重哈希时被非法化，std::vector::end 始终被非法化（因为它始终出现在被修改元素后），以此类推。 STL 成员函数 成员函数一览表 bitset｜位图std::bitset 也称「位图」，非常常用 12template &lt;size_t N&gt; class bitset bitset 的初始化方式： 12345678910111213std::bitset&lt;N&gt; bitset1; // 创建一个长度为 N 的 bitset，所有位都被初始化为 0std::bitset&lt;N&gt; bitset2(value); // 使用二进制整数 value 初始化一个长度为 N 的 bitsetstd::bitset&lt;32&gt; bitset21(0xffff); // bits 0 ... 15 are set to 1; 16 ... 31 are 0std::bitset&lt;128&gt; bitset22(0xffff); // bits 32 through 127 initialized to zero std::bitset&lt;N&gt; bitset3(string); // 使用二进制字符串 string 初始化一个长度为 N 的 bitsetstring str(&quot;1111111000000011001101&quot;);std::bitset&lt;N&gt; bitset31(str); //用整个字符串来初始化bitsetstd::bitset&lt;32&gt; bitset32(str, 5, 4); // 4 bits starting at str[5], 1100std::bitset&lt;32&gt; bitset33(str, str.size() - 4); // use last 4 characters std::bitset&lt;N&gt; bitset4(bitset); // 使用另一个 bitset 初始化一个长度为 N 的 bitsetstd::bitset&lt;n&gt; bitset5(bitset4, pos, n); //bitset5是bitset4中从位置pos开始的n个位的副本 方法： 方法 功能 b.any() b 中是否存在置为 1 的二进制位？ b.none() b 中不存在置为 1 的二进制位？ b.count() b 中置为 1 的二进制位的个数 b.size() b 中二进制位的个数 b[pos] 访问 b 中在 pos 处的二进制位 b.test(pos) b 中在 pos 处的二进制是否为 1？ b.set() 把 b 中所有二进制位都置为 1 b.set(pos) 把 b 中在 pos 处的二进制位置为 1 b.reset() 把 b 中所有二进制位都置为 0 b.reset(pos) 把 b 中在 pos 处的二进制位置为 0 b.flip() 把 b 中所有二进制位取反 b.flip(pos) 把 b 中在 pos 处的二进制位取反 b.to_ulong() 用 b 中同样的二进制位返回一个 unsigned long 值 os &lt;&lt; b 把 b 中的位集输出到 os 流 1234567std::bitset&lt;4&gt; b1(&quot;1100&quot;);size_t count = b1.count(); // count set bitssize_t size = b1.size(); // get number of bitsbool bit = b1.test(2); // test bit at position 2bool any = b1.any(); // check if any bit is setbool none = b1.none(); // check if no bit is setb1.flip(); // flip all bits 这些函数使得 std::bitset 成为处理位级别数据的强大工具。 std::bitset 还支持「位操作符」、「位移操作符」和「比较操作符」： 123456std::bitset&lt;4&gt; b1(&quot;1100&quot;);std::bitset&lt;4&gt; b2(&quot;1010&quot;);std::bitset&lt;4&gt; b3 = b1 &amp; b2; // bitwise ANDstd::bitset&lt;4&gt; b4 = b1 | b2; // bitwise ORstd::bitset&lt;4&gt; b5 = b1 ^ b2; // bitwise XORstd::bitset&lt;4&gt; b6 = ~b1; // bitwise NOT 123std::bitset&lt;4&gt; b1(&quot;1100&quot;);std::bitset&lt;4&gt; b2 = b1 &lt;&lt; 1; // left shiftstd::bitset&lt;4&gt; b3 = b1 &gt;&gt; 1; // right shift 123std::bitset&lt;4&gt; b1(&quot;1100&quot;);std::bitset&lt;4&gt; b2(&quot;1010&quot;);bool equal = (b1 == b2); // compare bitsets stringstr[i] 取到的是 char 字符 c_str()：const CharT* c_str() const; string 可以利用以下几个方法模拟 stack push_back() pop_back() erase() append() length() find()：finds the first occurrence of the given substring 1234567891011121314151617181920212223#include &lt;iomanip&gt;#include &lt;iostream&gt;#include &lt;string&gt;int main()&#123; std::string::size_type n; std::string const s = &quot;This is a string&quot;; /* ^ ^ ^ 1 2 3 */ // search from beginning of string n = s.find(&quot;is&quot;); // search from position 5 n = s.find(&quot;is&quot;, 5); // find a single character n = s.find(&#x27;a&#x27;); // find a single character n = s.find(&#x27;q&#x27;);&#125; rfind()：find the last occurrence of a substring string::npos：一般和 find() 搭配使用 1234// string search functions return npos if nothing is foundstd::string s = &quot;test&quot;;if (s.find(&#x27;a&#x27;) == s.npos) std::cout &lt;&lt; &quot;no &#x27;a&#x27; in &#x27;test&#x27; &quot;; 查找，包括前面 find 与 rfind find_first_of()：size_type find_first_of( const basic_string&amp; str, size_type pos &#x3D; 0 ) const; find_first_not_of() find_last_of() find_last_not_of() operations starts_with() [C++ 20] ends_with() [C++ 20] contains() [C++ 23] substr(size_type position = 0, size_type count = npos)：获取子串 int&#x2F;float 转为 string to_string to_wstring string 转为数值 stoi() stof() stod() stol() stoll() arrayarray 是一个固定大小的数组封装容器。 1234567891011121314151617181920std::array&lt;int, 5&gt; arr = &#123;1, 2, 3, 4, 5&#125;;// at(size_t index)int value1 = arr.at(2); // value = 3int value2 = arr[2]; // value = 3int first = arr.front(); // first = 1int last = arr.back(); // last = 5int* p = arr.data(); // p 是指向 arr 首元素的指针// size_t 一般用作 size() 的接收参数size_t size = arr.size(); // size = 5std::array&lt;int, 0&gt; ar; // 定义一个空的 std::arraybool isEmpty = ar.empty(); // isEmpty = truestd::array&lt;int, 3&gt; arr1 = &#123;1, 2, 3&#125;;std::array&lt;int, 3&gt; arr2 = &#123;4, 5, 6&#125;;arr1.swap(arr2); // arr1 现在是 &#123;4, 5, 6&#125;, arr2 现在是 &#123;1, 2, 3&#125; vector动态数组，支持随机访问，内存是连续的。 常用方法： push_back(value)：在末尾添加元素。 pop_back()：删除末尾元素。 insert(vec.begin(), value)：在指定位置插入元素。 erase(vec.begin())：删除指定位置的元素。 clear()：清空容器。 resize(n)：调整容器大小。 at(index)：访问指定位置的元素。 front()：访问第一个元素。 back()：访问最后一个元素。 empty()：检查容器是否为空。 size()：返回容器中元素的数量。 capacity()：返回容器的容量。 reserve(n)：预留至少 n 个元素的空间。 deque双端队列，支持在两端快速插入和删除。内存可能不连续，支持常数时间的随机访问。 push_back(value) push_front(value) pop_back() pop_front() front() back() erase(position) insert(position, value) at(index) empty() size() set [有序]集合，存储唯一元素，元素按顺序排列，底层通常是红黑树。 插入、删除、查找的时间复杂度为 $O(log n)$。 insert(value) emplace(value) erase(position) erase(value) find(value) count(value) empty() size() contains(value) [C++ 20] multiset [有序]允许存储重复元素的集合，元素按顺序排列，底层通常是红黑树。 插入、删除、查找的时间复杂度为 $O(log n)$。 滑动窗口 + multiset 1234567891011121314151617// 1438. 绝对差不超过限制的最长连续子数组class Solution &#123;public: int longestSubarray(vector&lt;int&gt;&amp; nums, int limit) &#123; multiset&lt;int&gt; ordered_set; int left = 0, ans = 0; for (int right = 0; right &lt; nums.size(); right++) &#123; ordered_set.insert(nums[right]); while (*ordered_set.rbegin() - *ordered_set.begin() &gt; limit) &#123; ordered_set.erase(ordered_set.find(nums[left])); left++; &#125; ans = max(ans, right - left + 1); &#125; return ans; &#125;&#125;; insert(value)：插入元素。 erase(position)：删除指定位置的元素。 erase(value)：删除与指定值相等的元素。 find(value)：查找指定值的元素。 count(value)：统计与指定值相等的元素数量。 clear()：清空容器。 empty()：检查容器是否为空。 size()：返回容器中元素的数量。 map [有序]键值对集合，按键排序，键唯一，底层通常是红黑树。 插入、删除、查找的时间复杂度为 $O(log n)$。 insert(&#123;key, value&#125;)：插入键值对。 erase(position)：删除指定位置的键值对。 erase(key)：删除指定键的键值对。 find(key)：查找指定键的键值对。 count(key)：统计指定键的键值对数量（返回 0 或 1）。 clear()：清空容器。 empty()：检查容器是否为空。 size()：返回容器中元素的数量。 at(key)：访问指定键的值（若键不存在则抛出异常）。 operator[](key)：访问或插入指定键的值。 multimap [有序]允许重复键的键值对集合，按键排序，底层通常是红黑树。 插入、删除、查找的时间复杂度为 $O(log n)$。 insert(&#123;key, value&#125;)：插入键值对。 erase(position)：删除指定位置的键值对。 erase(key)：删除指定键的键值对。 find(key)：查找指定键的键值对。 count(key)：统计指定键的键值对数量。 clear()：清空容器。 empty()：检查容器是否为空。 size()：返回容器中元素的数量。 unordered_map 无序容器使用哈希表实现，元素无序排列，插入和查找操作平均时间复杂度为 O(1)。 键值对集合，键唯一，元素无序排列，底层为哈希表。 插入、删除、查找的平均时间复杂度为 $O(1)$。 unordered_set集合，存储唯一元素，元素无序排列，底层为哈希表。 插入、删除、查找的平均时间复杂度为 $O(1)$。 unordered_multimap键值对集合，键唯一，元素无序排列，底层为哈希表。 插入、删除、查找的平均时间复杂度为 $O(1)$。 unordered_multiset允许存储重复元素的集合，元素无序排列，底层为哈希表。 插入、删除、查找的平均时间复杂度为 $O(1)$。 std::pair&lt;int, int&gt;将两个值组合在一起，常用于关联容器（如 std::map） p.first：第一个元素 p.second：第二个元素 make_pair(val_1, val_2)：创建一个 pair 对象 stack后进先出（LIFO）的栈，默认使用 std::deque 作为底层容器。 push(value) pop() top() empty() size() queue先进先出（FIFO）的队列，默认使用 std::deque 作为底层容器。 queue 为单端队列，deque 为双端队列 push(value) pop() front() back() empty() size() priority_queue top 访问队头元素 empty 队列是否为空 size 返回队列内元素个数 push &#x2F; emplace 插入元素到队尾（后者为 in-place insert） pop 弹出队头元素 swap 交换内容 123456789const auto data = &#123;1, 8, 5, 6, 3, 4, 0, 9, 7, 2&#125;;// 大顶堆(默认)priority_queue&lt;int&gt; max_priority_queue;// priority_queue&lt;int, vector&lt;int&gt;, less&lt;&gt;&gt; max_priority_queue;// 小顶堆priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; min_priority_queue(data.begin(), data.end()); 关于 swap 函数： 12345678910111213141516int main()&#123; std::vector&lt;std::string&gt; v1&#123;&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;&#125;, v2&#123;&quot;Ɐ&quot;,&quot;B&quot;,&quot;Ɔ&quot;,&quot;D&quot;,&quot;Ǝ&quot;&#125;; std::priority_queue s1(std::less&lt;&gt;(), std::move(v1)); std::priority_queue s2(std::less&lt;&gt;(), std::move(v2)); print(&quot;s1&quot;, s1); print(&quot;s2&quot;, s2); s1.swap(s2); print(&quot;s1&quot;, s1); print(&quot;s2&quot;, s2);&#125; Output: 1234s1 [4]: 4 3 2 1s2 [5]: Ǝ D Ɔ B Ɐs1 [5]: Ǝ D Ɔ B Ɐs2 [4]: 4 3 2 1 iteratorbegin() 与 end()：返回指向数组开头和末尾之后一个位置的迭代器 cbegin() 与 cend()：返回指向数组开头和末尾之后一个位置的常量迭代器 rbegin() 与 rend()：返回指向数组末尾和开头之前一个位置的反向迭代器 crbegin() 与 crend()：返回指向数组末尾和开头之前一个位置的常量反向迭代器 常量迭代器只读，不可以修改对应的元素值。","tags":["C++","STL","ranges","move","__builtin"],"categories":["C++"]},{"title":"Modern Cpp","path":"/post/C++/cpp-wiki/","content":"Link: Modern C++ (Lecture &amp; Tutorials, 2020, Vizzo &amp; Stachniss) - University of Bonn CMake｜Build System｜library✅ Modern C++: The Basics (Lecture 0, I. Vizzo, 2020)：简单的 Linux 和 Cpp 历史和教程 ✅ Modern C++: Build and Tools (Lecture 1, I. Vizzo, 2020)：学习了 cpp build system 整个流程（包括使用 cmake 生成 makefile 以及 CMAKE 的语法）、静态库&#x2F;动态库（lib*.a 与 lib*.so） 12345678# 可以自己写 library 然后自己追加# compile modulesc++ -std=c++17 -c tools.cpp -o tools.o# organize modules into libraries# &quot;ar rcs libname.a module.o module.o ...&quot;ar rcs libtools.a tools.o &lt;other_modules&gt;# link libraries when building codec++ -std=c++17 main.cpp -L . -ltools -o main 1234567891011121314151617181920# Use CMake to simplify the build# CMakeLists.txtcmake_minimum_required(VERSION 3.1)project(first_project)set(CMAKE_CXX_STANDARD 17)set(CMAKE_CXX_FLAGS &quot;-Wall&quot;)# 这个命令可以将构建系统的整个脚本过程输出到当前目录下set(CMAKE_EXPORT_COMPILE_COMMANDS ON) # important!# tell cmake where to look for *.hpp *.h filesinclude_directories(include/)# create library &quot;libtools&quot;add_library(tools src/tools.cpp) # create libtools.a# add executable mainadd_executable(main src/main.cpp) # main.o# tell the linker to bind these objects togethertarget_link_libraries(main tools) # ./main 12345# Build a CMake project (Build process)cd &lt;project_folder&gt;mkdir build &amp;&amp; cd buildcmake ..make strtok｜stringstream✅ Modern C++: Core C++ (Lecture 2, I. Vizzo, 2020) 123456789101112131415161718192021#include &lt;iomanip&gt;#include &lt;iostream&gt;#include &lt;sstream&gt;using namespace std;int main() &#123; stringstream filename(&quot;00205.txt&quot;); int num = 0; string ext; // Split the string stream using simple syntax // 而不是使用 strtok 来分割字符串 filename &gt;&gt; num &gt;&gt; ext; cout &lt;&lt; num &lt;&lt; endl; cout &lt;&lt; ext &lt;&lt; endl; return 0;&#125; int main(int argc, char const *argv[]); argc defines number of input parameters argv is an array of string parameters By default: argc &#x3D;&#x3D; 1 argv &#x3D;&#x3D; ““ C++ Functions✅ Modern C++: C++ Functions (Lecture 3, I. Vizzo, 2020) C++ 17 可以像 Python 返回多个类型一样，返回多种值了 —— tuple 123456789101112#include &lt;iostream&gt;#include &lt;tuple&gt;using namespace std;auto Foo() &#123; return make_tuple(&quot;Super Variable&quot;, 19);&#125;int main() &#123; auto [name, age] = Foo(); cout &lt;&lt; name &lt;&lt; &quot; is &quot; &lt;&lt; age &lt;&lt; &quot; years old.&quot; &lt;&lt; endl;&#125; WARNING: Never return reference to locally variables!!! 123456789101112131415#include &lt;iostream&gt;using namespace std;int&amp; MultiplyBy10(int num) &#123; // retval is created int retval = 0; retval = 10 * num; cout &lt;&lt; &quot;retval is &quot; &lt;&lt; retval &lt;&lt; endl; // 加上这行代码后，g++ -O3 test.cpp -o test 就可以正常工作；反之则输出乱数 return retval;&#125; // retval is destroyed, it&#x27;s not accesisble anymoreint main() &#123; int out = MultiplyBy10(5); cout &lt;&lt; out &lt;&lt; endl; return 0;&#125; 返回了一个指向已经被销毁的内存位置的引用，访问这个引用会导致未定义的行为。g++ -O3 test.cpp -o test 则会输出错误的值，不加 -O3 则正常，或者说在方法中加个 cout 输出则也正常。 Static：发生在「编译」时 Non-Static：发生在「运行」时 inline function function calls are expensive… If the function is rather small, you could help the compiler. inline is a hint to the compiler should attempt to generate code for a call. rather than a function call. 总结：当函数足够小的时候，可以用 inline 来内联函数，帮助编译器为你优化它 —— 即当函数调用时，直接将代码放（替换）到对应位置，而不是调用。 Check it out: https://godbolt.org/z/EGd6aG Good C++ Practices Break up complicated computations into meaningful chunks and name them. Keep the length of functions small enough. Avoid unecessary comments. One function shouldl achieve ONE task. If you can’t pick a short name, then split functionallity. Avoid macros: If you must use ig, use ugly names with lots of capital letters. C++ Namespace Helps avoiding name conflicts Group the project into logical modules Avoid using namespace ：好比写算法时总是使用 using namespace std;，这是需要避免的！ 12345678910111213141516171819#include &lt;cmath&gt;#include &lt;iostream&gt;// Avoiding!!!using namespace std; // std namespace is used// Self-defined function power shadows the std::powdouble pow(double x, int exp) &#123; double res = 1.0; for(int i = 0; i &lt; exp; i++) &#123; res *= x; &#125; return res;&#125;int main() &#123; cout &lt;&lt; &quot;2.0 ^ 2 = &quot; &lt;&lt; pow(2.0, 2) &lt;&lt; endl; return 0;&#125; C++ STL Library✅ Modern C++: The C++ STL Library (Lecture 4, I. Vizzo, 2020) Size of container (C vs. CPP)12int data[6];size_t data_size = sizeof(data) / sizeof(data[0]); 12std::array&lt;int, 6&gt; data_&#123;&#125;;cout &lt;&lt; data_.size() &lt;&lt; endl; Clear elements (C vs. CPP)12char letters[5] = &#123;&#x27;a&#x27;, &#x27;e&#x27;, &#x27;i&#x27;, &#x27;o&#x27;, &#x27;u&#x27;&#125;;memset(letters, 0, sizeof(letters)); 12std::string letters_&#123;&quot;aeiou&quot;&#125;;letters_.clear(); Iterating over maps New in C++17 1234std::map&lt;char, int&gt; _dict&#123;&#123;&#x27;a&#x27;, 17&#125;, &#123;&#x27;b&#x27;, 3&#125;&#125;;for(const auto&amp; [key, val] : _dict) &#123; cout &lt;&lt; key &lt;&lt; val;&#125; C++ Iterators C++ Algorithm sort(v.begin(), v.end()) find(v.begin(), v.end(), val) fill(v.begin(), v.end(), -1) count(v.begin(), v.end(), val) count_if(v.begin(), v.end(), [](int x) &#123;return x % 3 == 0;&#125;) for_each(v.begin(), v.end(), [](const int&amp; n) &#123;cout &lt;&lt; &quot; &quot; &lt;&lt; n;&#125;) rotate(v.begin(), v.begin() + 2, v.end()) transform(v.begin(), v.end(), [](char ch) &#123; return std::toupper(ch); &#125;) accumulate(v.begin(), v.end(), 0) max() min_element(v.begin(), v.end()): *min_element(v.begin(), v.end()) auto [min, max] = minmax_element(v.begin(), v.end()) … C++ Utilities✅ Modern C++: I&#x2F;O Files, Intro to Classes (Lecture 5, I. Vizzo, 2020) C++ includes a variety of utility libraries that provide functionality ranging from bit-counting to partial function application. These libraries can be broadly divided into two groups: language support libraries general-purpose libraries Language supportType support（std::size_t） Dynamic memory management（std::shared_ptr） Error handling（std::exception，assert） Initializer list（std::vector&#123;1, 2&#125;） Much more … General-purpose librariesProgram utilities（std::abort） Date and Time（std::chronologically::duration） Optional, variant and any（std::variant） Pairs and tuples（std::tuple） Swap, forward and move（std::move） Hash support（std::hash） Formatting library (coming in C++20) Much more … Much more utilitiesJust spend some time looking around: https://en.cppreference.com/w/cpp/utility Error handling 跳过，不建议使用 We can throw an exception if there is an error. std::exception To use exceptions: #include &lt;stdexcept&gt; An exception can be “caught” at any point of the program (try - catch) and even “thrown” further (throw) The constructor of an exception receives a string error message as a parameter. This string can be called through a member function what() Intuition Only used for “exceptional behavior” Often misused: e.g. wrong parameter should not lead to an exception. 🔥 GOOGLE—STYLE: Don’t use exceptions. Link: https://en.cppreference.com/w/cpp/error I&#x2F;O Libraryread&#x2F;write fileUse streams from STL Syntax similar to cerr, cout 12345678910111213#include &lt;fstream&gt;using std::string;using Mode = std::ios_base::openmode;// inputstd::ifstream f_in(string&amp; filename, Mode mode);// outputstd::ofstream f_out(string&amp; filename, Mode mode);// in_outputstd::fstream f_in_out(string&amp; filename, Mode mode); There are many modes under which a file can be opened. Mode Meaning ios_base::app append output ios_base::ate seek to EOF when opened ios_base::binary open file in binary mode ios_base::in open file for reading ios_base::out open file for writing ios_base::trunc overwrite the existing file 12345678910111213141516#include &lt;fstream&gt;#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main() &#123; int i; double a, b; string s; ifstream in(&quot;test_cols.txt&quot;, ios_base::in); while (in &gt;&gt; i &gt;&gt; a &gt;&gt; s &gt;&gt; b) &#123; // ... &#125; return 0;&#125; 12345678910111213#include &lt;iomanip&gt;#include &lt;fstream&gt;using namespace std;int main() &#123; string filename = &quot;out.txt&quot;; ofstream outfile(filename); if(!outfile.is_open()) &#123; return EXIT_FAILURE; &#125; double a = 1.23456789; outfile &lt;&lt; fixed &lt;&lt; setprecision(20) &lt;&lt; a &lt;&lt; endl; return 0;&#125; directory_iterator12345678910111213141516#include &lt;filesystem&gt;#include &lt;fstream&gt;#include &lt;iostream&gt;namespace fs = std::filesystem;int main() &#123; fs::create_directories(&quot;sandbox/a/b&quot;); std::ofstream(&quot;sandbox/file1.txt&quot;); std::ofstream(&quot;sandbox/file2.txt&quot;); for (auto&amp; p : fs::directory_iterator(&quot;sandbox&quot;)) &#123; std::cout &lt;&lt; p.path() &lt;&lt; &quot; &quot;; &#125; fs::remove_all(&quot;sandbox&quot;); return 0;&#125; 12# 必须指定 c++ 17 才可以编译g++ -std=c++17 test.cpp -o test 123&quot;sandbox/a&quot;&quot;sandbox/file1.txt&quot;&quot;sandbox/file2.txt&quot; 1234567891011121314#include &lt;filesystem&gt;#include &lt;fstream&gt;#include &lt;iostream&gt;namespace fs = std::filesystem;int main() &#123; std::cout &lt;&lt; fs::path(&quot;/foo/bar/txt&quot;).filename() &lt;&lt; &#x27; &#x27; &lt;&lt; fs::path(&quot;/foo/.bar&quot;).filename() &lt;&lt; &#x27; &#x27; &lt;&lt; fs::path(&quot;/foo/bar/&quot;).filename() &lt;&lt; &#x27; &#x27; &lt;&lt; fs::path(&quot;/foo/.&quot;).filename() &lt;&lt; &#x27; &#x27; &lt;&lt; fs::path(&quot;/foo/..&quot;).filename() &lt;&lt; &#x27; &#x27;; return 0;&#125; 12# 必须指定 c++ 17 才可以编译g++ -std=c++17 test.cpp -o test 12345&quot;txt&quot;&quot;.bar&quot;&quot;&quot;&quot;.&quot;&quot;..&quot; 1234567891011121314#include &lt;filesystem&gt;#include &lt;fstream&gt;#include &lt;iostream&gt;namespace fs = std::filesystem;int main() &#123; std::cout &lt;&lt; fs::path(&quot;/foo/bar.txt&quot;).extension() &lt;&lt; &#x27; &#x27; &lt;&lt; fs::path(&quot;/foo/bar.&quot;).extension() &lt;&lt; &#x27; &#x27; &lt;&lt; fs::path(&quot;/foo/bar.png&quot;).extension() &lt;&lt; &#x27; &#x27; &lt;&lt; fs::path(&quot;/foo/.&quot;).extension() &lt;&lt; &#x27; &#x27; &lt;&lt; fs::path(&quot;/foo/..&quot;).extension() &lt;&lt; &#x27; &#x27;; return 0;&#125; 1g++ -std=c++17 test.cpp -o test 12345&quot;.txt&quot;&quot;.&quot;&quot;.png&quot;&quot;&quot;&quot;&quot; 12const fs::path&amp; p = &quot;...&quot;;fs::(exists(p)); C++ Classesclass glossary Class Definition Class Implementation Class data members Class Member functions Class Constructors Class Destructor Class setters Class getters Class operators Class static members By default everything is private Access members with a “.” GOOGLE—STYLE: All data must be private What about structs?Definition starts with the keyword struct: 123456struct ExampleStruct &#123; Type value; Type value; Type value; // No functions!&#125; struct is a class where everything is public 🔥 GOOGLE—STYLE: Use struct as a simple data container, if it needs a function it should be a class instead. 🔥 Always initialize structs using braced initialization, such as: 123456struct namedInt &#123; int num; std::string name;&#125;;namedInt var&#123;1, std::string&#123;&quot;hello&quot;&#125;&#125;; Const correctnessconst after function states that this function does not change the object Mark all functions that should not change the state of the object as const Ensures that we can pass objects by a const reference and still call their functions. Substantially reduces number of errors. Typical const error 123456789101112131415161718#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;class Student &#123; public: Student(string name) : name_(name) &#123;&#125; // This function *might* change the object const string&amp; getName() &#123; return name_; &#125; // correct: const string&amp; getName() const &#123; return name_; &#125; private: string name_;&#125;;void Print(const Student&amp; student) &#123; cout &lt;&lt; student.getName() &lt;&lt; endl; &#125; 如果不在 getName() 后面加上 const，那么编译器不能保证你不会改变它，除了 setter，一般都需要加上 const吗，这能很大程度上避免错误。 std::Move() semantics c++11 引入 move() 所有权转移，用于将左值显示转换为右值，允许通过移动（而不是复制）资源来优化性能。 Smart pointers Smart pointers wrap a raw pointer into a class and manage its lifetime (RAII) Smart opinters are all about ownership Only use them with heap memory! #include &lt;memory&gt; C++ 11 Smart pointers types std::auto_ptr 🔥 std::unique_ptr 🔥 std::shared_ptr std::weak_ptr 因为使用的是 unique，不能直接用 &#x3D; 复制，但是可以转移所有权，那就使用 move()","tags":["C++"],"categories":["C++"]},{"title":"2025.04.12 饿了么笔试题","path":"/post/秋招指南/20250412-eleme/","content":"题解链接：https://mp.weixin.qq.com/s/uWZalLLGSpPh8HxLeUtQOA 测评链接：https://niumacode.com/training/68 1. 小红的小苯题小红拿到了一个正整数 x，小苯希望小红找到一个正整数 y，满足 x ⊕ y 既是 x 的因子，也是 y 的因子，你能帮帮小红吗? 在这里，⊕ 表示位运算中的按位异或操作。 输入描述 如果存在解，请输出一个正整数 y (1 ≤ y ≤ $10^{18}$)，代表询问的答案。如果无解，请输出 -1。 如果存在多个解决方案，您可以输出任意一个，系统会自动判定是否正确。注意，自测运行功能可能因此返回错误结果，请自行检查答案正确性。 示例 1 输入： 16 输出： 14 解释：对样例 1，由于 6⊕4 &#x3D; 2，而 2 同时是 4 和 6 两个数字的因数。 ⚠️ 注意，本题答案不唯一。 代码：脑筋急转弯 因为 1 是所有数字的因子，所以直接让 y=x^1，凑出 1 即可。 12345678910111213141516#include &lt;iostream&gt;using namespace std;int main() &#123; long x; cin &gt;&gt; x; if (x == 1) &#123; cout &lt;&lt; -1 &lt;&lt; endl; &#125; else &#123; long y = x ^ 1; cout &lt;&lt; y &lt;&lt; endl; &#125; return 0;&#125; 2. 音乐队列小红的播放器里一共有 n 首歌待放，歌单里第 $i$ 首歌的长度为 $a_i$ 秒。 小红会按顺序播放歌单里的歌，如果当前歌放完了，会自动插放下一首，两首歌曲之间没有缓冲的时间。 第 $i$ 首歌曲的等待时长为 $a_1 + … + a_{i-1}$ 秒，第一首歌曲等待时间为 0 秒。 小红想知道，如果她选择 $k$ 首歌移除播放队列，那么播放队列中剩下的歌曲的等待时长之和最小能达到多少? 输入描述 第一行输入两个整数 $n(1≤n ≤5000;0≤k≤n)$ 表示歌单里歌曲的数量、需要移除的歌曲数量 第二行输入 $n$ 个整数，表示每首歌的长度，其中 $1&lt;&#x3D;a_i&lt;&#x3D;10^9$ 输出描述 输出一个整数，表示插放队列中剩下的歌曲的等待时长之和的最小值。 示例 1 输入： 123 11 2 3 输出： 11 示例 2 输入： 123 01 2 3 输出： 14 代码：贪心算法 目标转换： 最小化移除 $k$ 首歌后的总等待时间，等价于最大化移除这 k 首歌所能减少的总等待时间。 计算单次移除收益： 对于原始列表中的每一首歌 $a_j$，计算如果只移除它，会使原始总等待时间减少多少。这个减少量 $R_j$ 等于 $a_j$ 原本的等待时间加上 $a_j$ 对其后面所有歌曲等待时间的贡献（即 $a_j$ 的长度乘以它后面歌曲的数量）。 贪心选择： 既然要最大化总减少量，并且移除每首歌的“收益” $R_j$ 是基于原始列表计算的，可以独立看待。因此，采用贪心策略：计算所有歌曲的 $R_j$，然后选择 $R_j$ 值最大的 $k$ 首歌进行移除。 计算结果：确定要移除的 $k$ 首歌的原始索引。构建一个只包含剩下 $n-k$ 首歌的新列表（保持它们的原始相对顺序）。直接计算这个新列表的总等待时间。核心思想是贪心，优先移除那些能最大程度降低总等待时间的歌曲。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;unordered_set&gt;using namespace std;// Class to store reduction value and original indexstruct ReductionInfo &#123; long long reduction; int originalIndex; // 1-based index ReductionInfo(long long r, int idx) : reduction(r), originalIndex(idx) &#123;&#125;&#125;;int main() &#123; int n, k; cin &gt;&gt; n &gt;&gt; k; vector&lt;int&gt; a(n); for (int i = 0; i &lt; n; i++) &#123; cin &gt;&gt; a[i]; &#125; if (k == n) &#123; cout &lt;&lt; 0 &lt;&lt; endl; // If all songs are removed, waiting time is 0 return 0; &#125; if (k == 0) &#123; // Calculate original waiting time directly if k=0 long long totalWait = 0; long long currentPrefixSum = 0; for (int i = 0; i &lt; n; i++) &#123; totalWait += currentPrefixSum; currentPrefixSum += a[i]; &#125; cout &lt;&lt; totalWait &lt;&lt; endl; return 0; &#125; // Calculate prefix sums vector&lt;long long&gt; prefixSum(n + 1, 0); for (int i = 0; i &lt; n; i++) &#123; prefixSum[i + 1] = prefixSum[i] + a[i]; &#125; // Calculate reduction for each song vector&lt;ReductionInfo&gt; reductions; for (int j = 1; j &lt;= n; j++) &#123; // R_j = P[j-1] + (n-j) * a[j-1] long long rj = prefixSum[j - 1] + (long long)(n - j) * a[j - 1]; reductions.emplace_back(rj, j); &#125; // Sort reductions in descending order sort(reductions.begin(), reductions.end(), [](const ReductionInfo&amp; r1, const ReductionInfo&amp; r2) &#123; // Sort by reduction descending. If reductions are equal, order doesn&#x27;t matter much, // but consistent sorting is good (e.g., by index ascending). if (r2.reduction != r1.reduction) &#123; return r2.reduction &lt; r1.reduction; // Descending reduction &#125; return r1.originalIndex &lt; r2.originalIndex; // Ascending index as tie-breaker &#125;); // Identify indices to remove unordered_set&lt;int&gt; removedIndices; for (int i = 0; i &lt; k; i++) &#123; removedIndices.insert(reductions[i].originalIndex); &#125; // Build the new list of songs (kept songs) vector&lt;int&gt; keptSongs; for (int i = 0; i &lt; n; i++) &#123; if (removedIndices.find(i + 1) == removedIndices.end()) &#123; // Check using 1-based index keptSongs.push_back(a[i]); &#125; &#125; // Calculate the total waiting time for the kept songs long long finalTotalWait = 0; long long currentPrefixSumNew = 0; for (int songLength : keptSongs) &#123; finalTotalWait += currentPrefixSumNew; currentPrefixSumNew += songLength; &#125; cout &lt;&lt; finalTotalWait &lt;&lt; endl; return 0;&#125; 3. 小红的加权三色数小红得到一棵树，该树有 $n$ 个节点。每个节点具有三种颜色之一，分别为 R、G 与 B。每个节点还拥有一个正整数权值，用 $w_i$ 表示第 $i$ 个节点的权值。 小红需要选择一个节点作为根节点。选定后，该根节点的颜色保持不变，不能被修改。对于其他非根节点，小红可以进行修改操作。每次修改操作的规则为： 选择一个非根节点，将以该节点为根的子树内所有节点的颜色统一修改为目标颜色，目标颜色为根节点的初始颜色 在一次修改中，该操作的代价为被修改子树内所有节点权值之和。 小红希望通过合理选择根节点并规划修改方案，使得最终全树所有节点均为根节点的颜色，同时使总代价最小。 名词解释 子树：对于树中的一个节点，其与所有后代节点构成的树称为该节点的子树。 输入描述 第一行输入一个整数 $(1&lt;&#x3D;n&lt;&#x3D;5*10^5)$，代表树的节点数量。 第二行输入一个长度为 $n$ 的字符串，该字符串仅由字符 R、G、B 组成，其中第 $i$ 个字符表示第 $i$ 个节点的初始颜色。 第三行输入 $n$ 个正整数 $w_1,w_2,…,w_n(1≤w_i≤10^9)$，表示各节点的权值。 随后输入 $n-1$ 行，每行包会两个整数 $u$ 和 $v(1≤u,v≦n,u≠y)$，表示节点 $u$ 与节点 $v$ 之间存在一条边。保证给定的 $n$ 个节点构成一棵树，即任意两个节点之问存在且仅存在一条简单路径。 输出描述 输出一个整数，代表使全树所有节点顿色统一为根节点初始颜色所需的最小总代价。 示例 1 输入： 123453RBB1 2 31 22 3 输出： 11 解释： 若选择节点 2 或节点 3 作为根节点，则目标颜色为 B。 以节点 2 为根时，仅需修改与其相连的非根节点（如节点 1），修改操作使节点 1 变为 B，代价为 1。 同理，以节点 3 为根时，方案类似，总代价亦为 1。 故最小总代价为 1。 代码：换根 DP（reroot） 题目要求尝试以每个节点 $r$ 为根，计算将整棵树染成 $r$ 初始颜色的最小代价，并求所有根选择中的最小代价。 暴力不可行： 对每个节点作为根都独立计算一次代价（需要 DFS 确定子树和计算代价）复杂度为 $O(N^2)$，太慢。 核心技术：换根 DP (Rerooting DP)。 这种技术适用于需要计算以每个节点为根时的某个树上属性的问题，能将复杂度优化到 $O(N)$。 第一遍 DFS（向下）：任选一个节点（如 0）作为临时根。 计算每个节点的子树权重和 subtreeSum[u]。 计算 DP 状态 dpDown[u][C]：表示在以 0 为根时，假设 u 的父节点颜色已经是目标色 C，将 u 的子树完全染成颜色 C 所需的最小代价。这个计算依赖于其子节点的 dpDown 值和 subtreeSum 值。 第二遍 DFS（向上&#x2F;换根）：计算最终 DP 状态 finalCost[u][C]：表示如果以 u 为真正的根，将整棵树染成目标色 C 的最小总代价。 这个计算利用 dpDown[u][C]（处理 u 子树部分的代价）和其父节点 p 的 finalCost[p][C] 以及 dpDown 值（推导出处理树上其他部分的代价）。 统计答案：遍历所有节点 r (0 到 N-1)。获取节点 r 的初始颜色 initial_color[r]。该节点作为根时的最小代价为 finalCost[r][initial_color[r]]。在所有 r 的这个代价中取最小值，即为最终答案。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;climits&gt;using namespace std;vector&lt;vector&lt;int&gt;&gt; adj;vector&lt;char&gt; colors; // 0-based node indexvector&lt;int&gt; weights; // 0-based node indexvector&lt;long long&gt; subtreeSum; // S[u]: sum of weights in subtree rooted at uvector&lt;vector&lt;long long&gt;&gt; dpDown; // dpDown[u][color_idx]: cost for subtree u if parent imposes target colorvector&lt;vector&lt;long long&gt;&gt; finalCost; // finalCost[u][color_idx]: total cost if u is root and target color is color_idxlong long totalWeightSum;const int R_IDX = 0;const int G_IDX = 1;const int B_IDX = 2;int n;// Helper to map color char to index 0, 1, 2int colorToIndex(char c) &#123; if (c == &#x27;R&#x27;) return R_IDX; if (c == &#x27;G&#x27;) return G_IDX; return B_IDX; // &#x27;B&#x27;&#125;// DFS1: Calculate subtree sums, starting from node 0void dfs_sum(int u, int p) &#123; subtreeSum[u] = weights[u]; for (int v : adj[u]) &#123; if (v != p) &#123; dfs_sum(v, u); subtreeSum[u] += subtreeSum[v]; &#125; &#125;&#125;void dfs_dp_down(int u, int p) &#123; for (int v : adj[u]) &#123; if (v != p) &#123; dfs_dp_down(v, u); // Calculate for child first int vColorIdx = colorToIndex(colors[v]); long long sv = subtreeSum[v]; // Subtree sum of child v for (int targetColorIdx = 0; targetColorIdx &lt; 3; targetColorIdx++) &#123; if (vColorIdx == targetColorIdx) &#123; // If child color matches target, add child&#x27;s dpDown cost for that target dpDown[u][targetColorIdx] += dpDown[v][targetColorIdx]; &#125; else &#123; // If child color differs, must modify child&#x27;s subtree, cost is S[v] dpDown[u][targetColorIdx] += sv; &#125; &#125; &#125; &#125;&#125;// Helper to get contribution of child x&#x27;s subtree when target is C, from parent&#x27;s viewlong long getContribution(int x, int targetColorIdx) &#123; int xColorIdx = colorToIndex(colors[x]); if (xColorIdx == targetColorIdx) &#123; // If x matches target, contribution is the cost calculated below x for that target return dpDown[x][targetColorIdx]; &#125; else &#123; // If x doesn&#x27;t match target, the whole subtree x must be modified, cost is S[x] return subtreeSum[x]; &#125;&#125;// DFS3: Rerooting to calculate finalCost[u][C] = cost if u is root and target is Cvoid dfs_reroot(int u, int p) &#123; for (int v : adj[u]) &#123; if (v != p) &#123; // Calculate cost contribution from the &#x27;parent&#x27; branch (everything except v&#x27;s subtree) for (int targetColorIdx = 0; targetColorIdx &lt; 3; targetColorIdx++) &#123; long long costParentBranch; // Cost of the tree excluding v&#x27;s subtree, assuming targetColorIdx long long contributionFromV = getContribution(v, targetColorIdx); // Weight sum of the parent branch (everything except v&#x27;s subtree) long long sumExcludingVSubtree = totalWeightSum - subtreeSum[v]; int uColorIdx = colorToIndex(colors[u]); if (uColorIdx == targetColorIdx) &#123; // If u matches target, the cost from parent branch is its calculated cost, // which is the total cost from u&#x27;s perspective minus v&#x27;s contribution. costParentBranch = finalCost[u][targetColorIdx] - contributionFromV; &#125; else &#123; // If u doesn&#x27;t match target, from v&#x27;s perspective, u must be modified. // The cost incurred by this modification is the sum of weights in that branch. costParentBranch = sumExcludingVSubtree; &#125; // Total cost for v = (cost below v) + (cost from parent branch) finalCost[v][targetColorIdx] = dpDown[v][targetColorIdx] + costParentBranch; &#125; // Recurse into child v dfs_reroot(v, u); &#125; &#125;&#125;int main() &#123; ios::sync_with_stdio(false); cin.tie(nullptr); cin &gt;&gt; n; colors.resize(n); for (int i = 0; i &lt; n; ++i) &#123; cin &gt;&gt; colors[i]; &#125; weights.resize(n); totalWeightSum = 0; for (int i = 0; i &lt; n; ++i) &#123; cin &gt;&gt; weights[i]; totalWeightSum += weights[i]; &#125; adj.resize(n); for (int i = 0; i &lt; n - 1; ++i) &#123; int u, v; cin &gt;&gt; u &gt;&gt; v; --u; --v; // Convert to 0-based adj[u].push_back(v); adj[v].push_back(u); &#125; subtreeSum.resize(n); dpDown.assign(n, vector&lt;long long&gt;(3, 0)); finalCost.assign(n, vector&lt;long long&gt;(3, 0)); // Step 1: Calculate subtree sums (rooted arbitrarily at 0) dfs_sum(0, -1); // Step 2: Calculate dpDown (cost from below, relative to root 0) dfs_dp_down(0, -1); // Step 3: Rerooting DP // Initialize root&#x27;s finalCost (cost if 0 is root = cost below 0) for (int c = 0; c &lt; 3; ++c) &#123; finalCost[0][c] = dpDown[0][c]; &#125; // Start rerooting DFS from root 0 to calculate finalCost for all nodes dfs_reroot(0, -1); // Step 4: Find minimum cost long long minTotalCost = LLONG_MAX; for (int r = 0; r &lt; n; ++r) &#123; int targetColorIdx = colorToIndex(colors[r]); // Target color is initial color of root r minTotalCost = min(minTotalCost, finalCost[r][targetColorIdx]); &#125; cout &lt;&lt; minTotalCost &lt;&lt; endl; return 0;&#125;","tags":["笔试","实习","饿了么"],"categories":["秋招指南"]},{"title":"2025.04.09","path":"/post/小吳日寄/2025-04-09/","content":"陆续一个月了，腾讯、阿里云、淘天、高德、拼多多、字节、美团… 能投的都投了。 项目：要么是让介绍项目难点时讨论下，要么就是基于项目去引申（相当于场景题和设计题），时间多的话，可以自己借助 GPT 和有些技术团队的博客&#x2F;沙龙去提升下项目。比如缓存一致性问题，遍地都是 Cache Aside 或者延时双删，可以调研下有没有其他成熟些的方案。 八股：少部分是八股盛宴，大多数情况问的都是些常规八股，偶尔是很细的八股 + 深挖。有的面试甚至没问八股。有些面试官会在你不了解某个八股的时候，会引导着思考。比如解决某个问题，我提到了可能要用本地缓存，面试官问我了解本地缓存不，不了解，然后就会问你觉得本地缓存该如何设计，有哪些功能。 手撕：简单题 + Hot 100 原题。遇到过多线程题：顺序打印 ABC、多线程计算数组和（future_task 最好会用），一次 sql 题（简单的 sql 还是最好掌握，如果面试官出了个简单的，写不出来就很尴尬了） 其他类型的题：大文件，小内存，排序&#x2F;去重&#x2F;统计次数等，这部分就看个人知识储备和思考能力了。 建议：多刷面经，可以快速积累场景题、设计题、多线程题，而且能快速 get 到高频八股，比如 oom、cpu 使用率高、慢查询治理… 找暑期哪有不疯的，运气也是非常重要（特指面试官）。 最后祝各位早日 oc（也祝我能 oc），无需过度焦虑，才四月初，正是发力期，过段时间一堆鸽穿的。","tags":["面经"],"categories":["小吳日寄"]},{"title":"2025.04.05 美团笔试题","path":"/post/秋招指南/20250405-meituan/","content":"题解链接：https://mp.weixin.qq.com/s/v5MeHD9ui8lPxRIoe0wD3Q 测评链接：https://oj.niumacode.com/training/59 1. 整数转变开始有一个整数 b，你需要经过若干次操作，使 n 的值不小于 m 。 操作一：将 $n$ 更改为 $2 * n$ ，花费为 $w_2$ 操作二：将 $n$ 更改为 $3 * n$ ，花费为 $w_3$ 请输出需要的最小花费。 输入描述 输入第一行一个整数 $T$，代表接下来有 $T$ 组测试数据。接下来 $T$ 行，每行有 4 个整数 $n,m,w_2,w_3$ $1&lt; T &lt; 10000$ $1&lt; n,m &lt; 2^{31}-1$ $1&lt; w_2,w_3 &lt; 1000$ 输出描述 对于每组测试数据，输出一行，一个整数代表最小花费 示例 1 输入： 1234541 6 2 34 32 3 42 1 1 21 2147483647 1 4 输出： 123458031 代码：动态规划（记忆化搜索 + 哈希表 memo） 记忆化搜索，这个题不可以使用迭代的动态规划来完成，会超时，记忆化搜索可以跳过非常多不必要考虑的状态（因为使用了 unordered_map 而非 vector，省去了逐个遍历的时间）。 12345678910111213141516171819202122232425#include &lt;bits/stdc++.h&gt;using namespace std;unordered_map&lt;long long, long long&gt; memo;long long dfs(long long i, long long m, long long w2, long long w3) &#123; if(i &gt;= m) return 0; if(memo.find(i) != memo.end()) return memo[i]; return memo[i] = min(dfs(i * 2, m, w2, w3) + w2, dfs(i * 3, m, w2, w3) + w3);&#125;int main() &#123; int T; cin &gt;&gt; T; while(T--) &#123; int n, m, w2, w3; cin &gt;&gt; n &gt;&gt; m &gt;&gt; w2 &gt;&gt; w3; memo.clear(); cout &lt;&lt; dfs(n, m, w2, w3) &lt;&lt; endl; &#125; return 0;&#125; 2. 漂亮数我们定义一个漂亮数是这样的数： 该数为正整数 设该数为 x，存在一个质数 p 使得 x mod p = 0 且 p * p &gt;= x 给你一个正整数 n，你能否求出有多少漂亮数小于等于 n？ 输入描述 输入一行一个正整数 $n(1 &lt; n &lt; 5 * 10^6)$ 输出描述 输出一行一个正整数，代表小于等于 n 的漂亮数的个数。 示例 1 输入： 110 输出： 18 解释：10 以内除了 1 和 8 都是漂亮数 代码：数论 筛质数 基于最小质因数，递推计算每个数的最大质因数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;int main() &#123; ios::sync_with_stdio(false); cin.tie(nullptr); int n; cin &gt;&gt; n; vector&lt;int&gt; min_prime(n + 1, 0); // 最小质因数数组 vector&lt;int&gt; primes; // 欧拉筛法预处理最小质因数 for (int i = 2; i &lt;= n; ++i) &#123; if (min_prime[i] == 0) &#123; min_prime[i] = i; primes.push_back(i); &#125; for (size_t j = 0; j &lt; primes.size(); ++j) &#123; int p = primes[j]; if (p &gt; min_prime[i] || i * p &gt; n) &#123; break; &#125; min_prime[i * p] = p; &#125; &#125; int count = 0; vector&lt;int&gt; max_prime(n + 1, 0); // 最大质因数数组 for (int x = 2; x &lt;= n; ++x) &#123; if (min_prime[x] == x) &#123; // x是质数 max_prime[x] = x; count++; &#125; else &#123; // x是合数 int p = min_prime[x]; int m = x / p; max_prime[x] = max(p, max_prime[m]); if (1LL * max_prime[x] * max_prime[x] &gt;= x) &#123; count++; &#125; &#125; &#125; cout &lt;&lt; count &lt;&lt; endl; return 0;&#125; 3. 最长路径游游很喜欢树，这一天他在研究树上的路径，他遇到了一个难题，现在邀请你帮助他解决该问题。 在一棵树上，两个点并不一定能确定一条链，但是可以找到一条经过这两个点最长的一条链。 你有一棵 n 个点的树，树上每条边都有一个权值，定义一条简单路径的长度为这条简单路径上的边权和，对于给定的两个点 x, y，你需要回答在树上经过这两个点的最长简单路径是多少。 树上的路径：从节点 u 到节点 v 的简单路径定义为从节点 u 出发，以节点 v 为终点，随意在树上走，不经过重复的点和边走出来的序列。可以证明，在树上，任意两个节点间有且仅有一条简单路径。 输入描述 第一行两个数 $n, m (1&lt; n, m &lt; 10^5)$ 接下来 $n - 1$ 行，每行 3 个数 $u_i, v_i, d_i (1 &lt; u_i, v_i &lt; n, 1 &lt; d_i &lt;10^9)$，表示树的第 $i$ 条边 接下来 $m$ 行，每行 2 个数 $x, y$，表示一次询问。 输出描述 共 m 行，每行一个整数 ans，表示你的答案 示例 1 输入： 123456784 41 2 11 3 21 4 12 14 31 42 4 输出： 12343332 代码：LCA（最近公共祖先） 路径由三部分组成： 起点 a 到 x：选一个能离 x 最远的点 a（不能往 y 方向走） x 到 y：这是唯一的固定路径 y 到终点 b：选一个能离 y 最远的点 b（不能往 x 方向走） 总长度就是这三段距离的和。核心是找到 a 和 b 这两个“最远端点”。 为了快速计算，需要提前准备三个重要信息： 向下最长路径（子树方向） 用深度优先搜索（DFS）从根节点出发，记录每个节点 u 的两个值： down1[u]：u 向下走到子树的最长路径（比如 u→ 子节点 v → … → 叶子） down2[u]：次长路径（必须走不同子节点） 同时记录 down1_child[u] 表示哪个子节点贡献了最长路径 向上最长路径（父节点方向） 第二次 DFS 计算 up[u]，表示从u向上走（经过父节点）的最长路径。这里要考虑两种情况： 如果父节点的最长路径经过 u → 只能用父节点的次长路径 否则 → 可以用父节点的最长路径 比如父节点 p 的最长路径是 p→q，而 u 是 p 的子节点但不是 q，则 up[u] = up[p] + 边权 LCA（最近公共祖先） 用倍增法预处理每个节点的 $2^k$ 级祖先，快速计算 x 和 y 的距离： dist(x,y) = 到根的距离x + 到根的距离y - 2 * 到根的距离(lca(x,y))：这能快速得到 x 到 y 的路径长度 对于每个查询 $(x,y)$，分情况处理： x 和 y 是同一个点：最长路径要么是向下走两条分支（down1 + down2），要么是向上走再向下（up + down1） x 和 y 不同 分三步计算： 确定路径方向： 找到 x 到 y 路径上的邻居节点 nx（如果 y 在 x 的子树里，nx 是 x 的子节点；否则是 x 的父节点） 同理找到 y 的邻居 ny 计算 max_dist_x（不经过 nx 的最远距离）： 如果 nx 是父节点 → 只能向下走，取 down1[x] 如果 nx 是子节点 → 比较向上（up[x]）和向其他子节点的路径（down1 或 down2） 同样计算 max_dist_y，最终总长度是这三部分的和 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;unordered_map&gt;#include &lt;algorithm&gt;#include &lt;cmath&gt;using namespace std;const int MAX_N = 200005;const int MAX_LOG_N = 20;unordered_map&lt;int, vector&lt;pair&lt;int, int&gt;&gt;&gt; adj;int parent[MAX_LOG_N][MAX_N];int dist_to_parent_pow2[MAX_LOG_N][MAX_N];int depth[MAX_N];int dist_from_root[MAX_N];int actual_parent[MAX_N];int edge_weight_to_parent[MAX_N];int down1[MAX_N], down2[MAX_N], down1_child[MAX_N], up[MAX_N];vector&lt;int&gt; results;void add_edge(int u, int v, int d) &#123; adj[u].emplace_back(v, d); adj[v].emplace_back(u, d);&#125;void dfs1(int u, int p, int d, int current_dist) &#123; depth[u] = d; dist_from_root[u] = current_dist; parent[0][u] = p; actual_parent[u] = p; int max1 = 0, max2 = 0, child1 = 0; for (auto&amp; [v, weight] : adj[u]) &#123; if (v != p) &#123; edge_weight_to_parent[v] = weight; dist_to_parent_pow2[0][v] = weight; dfs1(v, u, d + 1, current_dist + weight); int current_down_path = down1[v] + weight; if (current_down_path &gt;= max1) &#123; max2 = max1; max1 = current_down_path; child1 = v; &#125; else if (current_down_path &gt; max2) &#123; max2 = current_down_path; &#125; &#125; &#125; down1[u] = max1; down2[u] = max2; down1_child[u] = child1;&#125;void dfs2(int u, int p) &#123; int p_node = actual_parent[u]; if (p_node != 0) &#123; int weight_up = edge_weight_to_parent[u]; int down_from_parent_not_via_u; if (down1_child[p_node] == u) &#123; down_from_parent_not_via_u = down2[p_node]; &#125; else &#123; down_from_parent_not_via_u = down1[p_node]; &#125; up[u] = weight_up + max(up[p_node], down_from_parent_not_via_u); &#125; for (auto&amp; [v, weight] : adj[u]) &#123; if (v != p) &#123; dfs2(v, u); &#125; &#125;&#125;int get_lca(int u, int v) &#123; if (depth[u] &lt; depth[v]) swap(u, v); for (int k = MAX_LOG_N - 1; k &gt;= 0; --k) &#123; if (depth[u] - (1 &lt;&lt; k) &gt;= depth[v]) &#123; u = parent[k][u]; &#125; &#125; if (u == v) return u; for (int k = MAX_LOG_N - 1; k &gt;= 0; --k) &#123; if (parent[k][u] != parent[k][v]) &#123; u = parent[k][u]; v = parent[k][v]; &#125; &#125; return parent[0][u];&#125;int get_dist(int u, int v) &#123; int l = get_lca(u, v); return dist_from_root[u] + dist_from_root[v] - 2 * dist_from_root[l];&#125;int get_ancestor(int u, int k) &#123; int node = u; for (int i = 0; i &lt; MAX_LOG_N; ++i) &#123; if ((k &gt;&gt; i) &amp; 1) &#123; node = parent[i][node]; if (node == 0) break; &#125; &#125; return node;&#125;void solve() &#123; ios::sync_with_stdio(false); cin.tie(nullptr); int n, m; cin &gt;&gt; n &gt;&gt; m; for (int i = 0; i &lt; n - 1; ++i) &#123; int u, v, d; cin &gt;&gt; u &gt;&gt; v &gt;&gt; d; add_edge(u, v, d); &#125; int MAX_LOG_N = (n - 1) == 0 ? 1 : 32 - __builtin_clz(n - 1); dfs1(1, 0, 0, 0); for (int k = 1; k &lt; MAX_LOG_N; ++k) &#123; for (int i = 1; i &lt;= n; ++i) &#123; parent[k][i] = parent[k-1][parent[k-1][i]]; if (parent[k-1][i] != 0) &#123; dist_to_parent_pow2[k][i] = dist_to_parent_pow2[k-1][i] + dist_to_parent_pow2[k-1][parent[k-1][i]]; &#125; &#125; &#125; dfs2(1, 0); for (int i = 0; i &lt; m; ++i) &#123; int x, y; cin &gt;&gt; x &gt;&gt; y; if (x == y) &#123; int ans = max(down1[x] + down2[x], up[x] + down1[x]); results.push_back(ans); continue; &#125; int l = get_lca(x, y); int dist_xy = get_dist(x, y); int nx = 0; if (l == x) &#123; int target_depth = depth[x] + 1; int steps_up = depth[y] - target_depth; nx = get_ancestor(y, steps_up); &#125; else &#123; nx = actual_parent[x]; &#125; int ny = 0; if (l == y) &#123; int target_depth = depth[y] + 1; int steps_up = depth[x] - target_depth; ny = get_ancestor(x, steps_up); &#125; else &#123; ny = actual_parent[y]; &#125; int max_dist_x; if (nx == actual_parent[x]) &#123; max_dist_x = down1[x]; &#125; else &#123; if (nx == down1_child[x]) &#123; max_dist_x = max(up[x], down2[x]); &#125; else &#123; max_dist_x = max(up[x], down1[x]); &#125; &#125; int max_dist_y; if (ny == actual_parent[y]) &#123; max_dist_y = down1[y]; &#125; else &#123; if (ny == down1_child[y]) &#123; max_dist_y = max(up[y], down2[y]); &#125; else &#123; max_dist_y = max(up[y], down1[y]); &#125; &#125; int ans = max_dist_x + dist_xy + max_dist_y; results.push_back(ans); &#125; for (int res : results) &#123; cout &lt;&lt; res &lt;&lt; &quot; &quot;; &#125;&#125;int main() &#123; solve(); return 0;&#125;","tags":["美团","笔试","实习"],"categories":["秋招指南"]},{"title":"分布式系统中如何保证崩溃一致性？","path":"/post/系统与体系结构/how-to-ensure-crash-consistency-in-distributed-systems/","content":"面试官：你如何在系统中保证崩溃一致性？ 崩溃一致性的定义和重要性崩溃一致性是指系统在发生崩溃（例如服务器宕机、进程异常退出或断电）后，能够确保持久化的数据仍然处于一致的有效状态。也就是说，无论何时发生崩溃，系统存储上的数据要么保持崩溃前的完整更新，要么回退到崩溃前的稳定状态，不会出现部分更新导致的数据不完整或损坏。例如，在文件系统或数据库中，如果一次操作需要更新多个位置，崩溃一致性要求不能出现只更新了一部分就崩溃的情况，否则会造成数据结构的不一致。通过保证崩溃一致性，系统在重启恢复后可以正确地继续运行，数据不会因中途崩溃而处于混乱状态。这在分布式存储、数据库和后端服务中至关重要，直接关系到数据可靠性和系统健壮性。 常见的崩溃一致性保障方案在分布式系统和后端架构设计中，有多种机制用来保证崩溃一致性。实际设计中通常根据场景组合运用这些方案： 写前日志（Write-Ahead Logging，WAL）先将将要进行的更新记录到日志（预写日志）并持久化，再执行实际的数据更新。这样如果系统在更新过程中崩溃，重启时可以通过日志重放或回滚确保数据一致 (存储系统的崩溃一致性问题 (Crash Consistency))。WAL 广泛应用于数据库和文件系统（如 MySQL InnoDB 的 redo log，PostgreSQL 的 WAL，Ext4 文件系统的 journal 模式）。举例来说，在数据库事务中，先写事务日志并将其 fsync 到磁盘，再更新数据页；若中途崩溃，重启时根据日志完成未完事务或撤销部分更新，保证数据一致不丢失。 两阶段提交（2PC）&#x2F; 三阶段提交（3PC）这是分布式事务的经典协议，用于确保跨多个节点或资源的原子性提交。一致性通过一个协调者让所有参与者都准备就绪再统一提交。两阶段提交 (prepare&#x2F;commit) 确保所有节点要么都提交事务，要么都回滚，中间任一节点崩溃都不会导致部分节点提交。例如，在订单系统中，订单服务和支付服务需要同时更新，各服务在准备阶段预留资源，只有当所有服务都准备成功后才正式提交扣款和订单确认，否则全部撤销。2PC 的缺点是协调者崩溃或网络分区时会阻塞（出现脑裂风险）。三阶段提交在 2PC 基础上增加预提交阶段（CanCommit、PreCommit、DoCommit），减少单点故障导致的阻塞，但通信开销更大，且仍要求可靠网络条件。实际中原生 3PC 较少直接使用，更常用改进的一致性协议或结合其他机制来避免单点问题。 分布式一致性协议（如 Paxos &#x2F; Raft 等）这些是一致性算法，用于在多副本场景下保证数据副本之间的状态一致，进而保障崩溃后的系统一致性。Paxos 和 Raft 通过多数派投票达成共识，确保一旦某个操作被多数节点提交，整个集群最终都应用该操作，即使部分节点崩溃也不影响全局一致结果。它们通常用于实现复制日志和领导者选举。例如，Raft 协议通过由 Leader 将日志条目复制到 Follower，并要求超过半数节点写入确认后再认为提交成功，这样即使一个节点崩溃，已提交日志仍然存在于其他节点中，系统可以选举新 Leader 继续提供服务。很多分布式 KV 存储（如 Etcd、Consul）和分布式数据库利用 Raft&#x2F;Paxos 保证在崩溃或网络异常情况下数据不会不一致。此外，基于这些共识协议可以构建分布式事务：例如 Google Spanner 将 2PC 与 Paxos 结合，在每个分片组内用 Paxos 保证副本一致性，并用 2PC 跨分片提交全局事务，从而同时实现强一致和高可用的事务处理。 本地持久化与 fsync无论采用哪种高级协议，底层的持久化正确性都是基础。为了保证崩溃时数据已真正写入稳定存储，需要使用fsync或类似手段将数据刷盘。操作系统和硬件常有缓存，如果只写入内存缓冲区而不刷新到磁盘，崩溃会导致已写入的数据丢失。通过在关键步骤后调用 fsync 确保数据写入磁盘，可以提供持久化的崩溃一致性。例如，消息队列在写入消息日志后会调用 fsync（或根据配置定期刷盘）才确认消息“已持久化”，这样 Broker 宕机重启后，日志里的消息仍然可用，不会丢失或损坏。需要注意频繁 fsync 会影响性能，因此实际系统常结合批量写入或后台刷盘策略，在保证一定一致性的前提下平衡性能（例如 MySQL 的innodb_flush_log_at_trx_commit参数决定每次事务提交是否立即 fsync 日志）。 幂等性设计与重试机制在分布式系统中，失败重试是常见现象（例如网络超时后客户端重发请求，或者服务重启后重新处理消息）。为了保证在崩溃和重试场景下状态不乱，要求关键操作具有幂等性——同一操作执行一次和多次的效果相同，不会因重复执行产生副作用差异。例如，支付接口需要设计为幂等，以避免由于请求超时重复扣款；又如订单创建接口应防止创建重复订单。这通常通过在业务层引入唯一请求 ID 或事务 ID 来实现，每次操作前先检查是否已处理过该 ID，已处理则跳过，未处理才执行并记录结果。幂等设计配合重试机制，使系统在部分操作失败或崩溃恢复后可以安全地重放操作，达到“至少一次”投递但效果如“只执行一次”的一致性结果。例如，消息队列消费者在处理消息时，如果进程突然崩溃，下次重启后消息会被重新投递，此时消费者处理逻辑如果具备幂等（例如根据消息唯一键检查数据库中是否已应用），就能保证不会因重复消费导致数据错误。 实际项目经验与应用案例 面试中展示崩溃一致性的理解，最好结合自身经历或熟悉的系统案例，说明如何运用了上述机制： 分布式 KV 存储系统：举例来说，在设计分布式 Key-Value 存储时，会使用 WAL 日志 + 多副本复制来保证崩溃一致性。每次写操作先写入本地 WAL 并持久化，然后通过一致性协议（如 Raft）将该操作复制到其他节点。在我参与的一个存储引擎项目中，我们采用 Raft 保证各副本日志一致，同时每台节点本地使用 WAL 和定期快照。一次写入只有当多数节点写入日志成功并且主节点的日志 fsync 完成后才确认成功返回。这样，即便某个节点宕机，其恢复时可以通过重放本地 WAL 和从其他副本同步缺失日志将数据恢复到崩溃前的一致状态。这种方案在实践中确保了无单点故障的数据可靠性——如 etcd、ZooKeeper 也使用类似思路，保证配置数据在节点崩溃后依然一致。 订单和支付事务系统：在电商订单系统中，经常需要保证诸如“扣库存”和“扣款”这两个不同服务的操作要么都成功要么都不执行。我的经验是可以采用分布式事务或事务补偿机制来解决。例如，我们尝试过使用两阶段提交：订单服务作为协调者，通知库存服务和支付服务预留资源（准备阶段），如果都成功则发出提交指令，各自将最终状态持久化；如果中途任一失败则发出回滚指令撤销之前的操作。这保证了服务崩溃或网络异常时不会出现“扣了款但订单未创建”这类不一致结果。另外一种实践是使用 Saga（补偿事务）模式配合幂等设计，各服务先本地完成操作，如果后续步骤失败则通过调用补偿动作（如退款、加回库存）来最终达成一致。无论哪种方案，都需要在实际落地时注意持久化（写数据库事务日志或业务状态日志）以及操作的幂等性。例如，我们会为每个订单生成唯一事务 ID，在整个事务链路中传递，崩溃恢复后根据事务日志判断需要补偿还是继续未完成的步骤。通过这样的设计，订单系统在面临部分服务宕机重启时，仍然可以保证数据的最终一致性和正确性。 消息队列系统：以分布式消息队列为例（如 Kafka 或 RabbitMQ），崩溃一致性体现在不丢消息且不重复乱序。实际项目中，我部署过的 Kafka 集群采用持久化日志+副本同步：生产者发送的消息先写入领导者节点的磁盘日志（Kafka 提供多种 acks 级别确保消息写入持久化），Leader 将消息复制给 Follower 节点，等至少一个 Follower 也写入成功后再确认给生产者。每条消息有偏移量，消费者处理时按偏移顺序提交位移。若 Broker 崩溃，Zookeeper&#x2F;Raft 协调下会选出新的 Leader 继续未完成的日志追加，消费者可以从上次提交的偏移继续消费，保证顺序和一致性。而对于消费者重复消费的情况，我们在消费端通过幂等处理解决：例如消息携带唯一 ID，消费逻辑更新数据库前先检查记录是否已处理该 ID，以避免因消费者崩溃重启后重复消费导致的数据重复。通过这些措施，消息队列系统实现了崩溃后恢复不丢消息，并使得任何重复消息的影响可控，从而在分布式部署下依然保持数据一致可靠。 面试回答思路和结构化表达建议在技术面试中回答“如何保证崩溃一致性”这类问题时，可以按照有条理的结构来表达，确保面试官能清晰理解你的思路： 问题背景简介：首先简要说明什么是崩溃一致性，以及在什么背景下需要考虑它。可以点出崩溃场景（宕机、断电等）会导致部分写入丢失或数据结构不完整，从而引出需要机制保证一致性的重要性。 可选方案对比：接下来概述解决崩溃一致性的常见方案。可以按照从单机到分布式逐步展开，例如先介绍本地级别的方案（WAL 日志、Copy-on-Write、fsync 刷盘等），再说明分布式场景的方案（2PC&#x2F;3PC 分布式提交、Paxos&#x2F;Raft 一致性算法、幂等重试等） WAL 适合单节点多步骤原子更新 2PC 适合跨服务事务但有阻塞问题 Raft 适合多副本一致 实际方案选择及理由：然后重点描述你在实际项目中用到了哪些机制来保证崩溃一致性，以及为什么选择这些方案。结合具体案例谈更有说服力，比如说明“在某项目中我们遇到 XX 一致性要求，选择了 YY 方案，因为…”。阐述方案如何落地实施（比如如何实现日志持久化、如何协调多服务提交）。这一部分体现你将理论用于实践的能力，例如提到性能考量（为什么选 WAL 而不是每次直接写入，以及 WAL 带来的性能提升与一致性保障）、可靠性需求（为何采用 Raft 保证副本一致）等决策因素。 遇到的问题与优化：最后补充说明在实现崩溃一致性过程中遇到的挑战以及采取的优化措施。这显示你对细节和系统影响有深入理解。比如，你可以提到性能瓶颈和解决：“由于频繁 fsync 影响吞吐，我们采用了批量提交来优化磁盘 IO”。或者复杂性问题：“实现 2PC 时遇到了超时和协调难题，通过引入超时重试和事务日志监控来保证一致性”。再比如边缘情况处理：“考虑到网络分区导致的脑裂，我们引入了仲裁机制&#x2F;心跳检测来处理”。通过讲述如何发现问题、解决问题，表现出你对崩溃一致性机制有实战经验和思考。结束时可以强调经过这些努力，系统成功保证了在各种异常情况下数据的一致可靠。 推荐参考文献 《数据密集型应用系统设计（Designing Data-Intensive Applications）》 《操作系统原理与实现（Operating System Principle and Implementation）》","tags":["Linux","分布式系统","Paxos","Raft","Ceph","COW","WAL","崩溃一致性","幂等性"],"categories":["系统与体系结构"]},{"title":"Linux Kernel I/O","path":"/post/系统与体系结构/linux-kernel-io-path/","content":"前置知识｜页缓存 &amp; 零拷贝零拷贝技术（Zero-Copy）概念：在传统的数据传输过程中（比如读取文件发送给网络），数据通常会在内核空间和用户空间之间多次拷贝。零拷贝的目标是尽量减少或避免数据在内核空间与用户空间之间的拷贝操作，从而提升性能。 如果服务端要提供文件传输的功能，我们能想到的最简单的方式是：将磁盘上的文件读取出来，然后通过网络协议发送给客户端。 传统 I&#x2F;O 的工作方式是，数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的 I&#x2F;O 接口从磁盘读取或写入。 代码通常如下，一般会需要两个系统调用： 12read(file, tmp_buf, len);write(socket, tmp_buf, len); 首先，期间共发生了 4 次用户态与内核态的上下文切换，因为发生了两次系统调用，一次是 read() ，一次是 write()，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。 上下文切换到成本并不小，一次切换需要耗时几十纳秒到几微秒，虽然时间看上去很短，但是在高并发的场景下，这类时间容易被累积和放大，从而影响系统的性能。 其次，还发生了 4 次数据拷贝，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的，下面说一下这个过程： 第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。 第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。 第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。 第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。 这种简单又传统的文件传输方式，存在冗余的上文切换和数据拷贝，在高并发系统里是非常糟糕的，多了很多不必要的开销，会严重影响系统性能。 所以，要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数。 从 Linux 2.1 版本开始，Linux 引入了 sendfile 来简化操作。文件通过 sendfile() 直接发送到 socket，不经过用户空间。 12#include &lt;sys/socket.h&gt;ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count); 它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。 首先，它可以替代前面的 read() 和 write() 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。如下图： 多路复用技术（I&#x2F;O Multiplexing）概念：允许单个线程同时监听多个 I&#x2F;O 事件（如 socket 连接），只在有事件发生时才进行处理，避免阻塞等待每个 I&#x2F;O。 常见接口： select poll epoll（Linux 高效实现） 用途： 高并发服务器（如 Nginx、Redis） 网络编程中高效的 I&#x2F;O 模型 优势： 少量线程处理大量连接 减少线程切换开销 页缓存（Page Cache）技术 位于「程序内存分布」中的内核空间 概念：操作系统将磁盘中的数据缓存在内存中，以加快文件读写速度。缓存的单位是“页”（通常是 4KB）。 作用： 加快文件读取（命中缓存时无需访问磁盘） 写文件时先写到缓存，再异步刷到磁盘（提高写入性能） 相关命令： sync：强制把缓存写入磁盘 drop_caches：清除缓存，用于测试或释放内存 Linux 内核 I&#x2F;O 链路一览图 Linux I&#x2F;O 存储栈下的读写流程 应用程序通过系统调用访问文件（无论是块设备文件，还是各种文件系统中的文件）。可以通过 open 系统调用，也可以通过 memory map 的方式调用来打开文件。 mmap 与 read&#x2F;write 的区别可以参考文章：mmap 与 read&#x2F;write 对比 Linux 内核收到系统调用的软中断，通过参数检查后，会调用虚拟文件系统（Virtual File System，VFS），虚拟文件系统会根据信息把相应的处理交给具体的文件系统，如 ext2&#x2F;3&#x2F;4 等文件系统，接着相应的文件 I&#x2F;O 命令会转化成 bio 命令进入通用块设备层，把针对文件的基于 offset 的读&#x2F;写转化成基于逻辑区块地址（Logical Block Address，LBA）的读&#x2F;写，并最终翻译成每个设备对应的可识别的地址，通过 Linux 的设备驱动对物理设备，如硬盘驱动器（Harddisk Drive，HDD）或固态硬盘进行相关的读&#x2F;写。 用户态文件系统的管理。Linux 文件系统的实现都是在内核进行的，但是用户态也有一些管理机制可以对块设备文件进行相应的管理。例如，使用 parted 命令进行分区管理，使用 mkfs 工具进行文件系统的管理，使用逻辑卷管理器（Logical Volume Manager，LVM）命令把一个或多个磁盘的分区进行逻辑上的集合，然后对磁盘上的空间进行动态管理。 当然在用户态也有一些用户态文件系统的实现，但是一般这样的系统性能不是太高，因为文件系统最终是建立在实际的物理存储设备上的，且这些物理设备的驱动是在内核态实现的。那么即使文件系统放在用户态，I&#x2F;O 的读和写也还是需要放到内核态去完成的。除非相应的设备驱动也被放到用户态，形成一套完整的用户态 I&#x2F;O 栈的解决方案，就可以降低 I&#x2F;O 栈的深度。另外采用一些无锁化的并行机制，就可以提高 I&#x2F;O 的性能。例如，由英特尔开源的 SPDK（Storage Performance Development Kit）软件库，就可以利用用户态的 NVMe SSD（Non-Volatile Memory express）驱动，从而加速那些使用 NVMe SSD 的应用，如 iSCSI Target 或 NVMe-oF Target 等。 linux IO 存储栈分为 7 层: VFS 虚拟文件层: 在各个具体的文件系统上建立一个抽象层，屏蔽不同文件系统的差异。 PageCache 层: 为了缓解内核与磁盘速度的巨大差异。 映射层 Mapping Layer: 内核必须从块设备上读取数据，Mapping layer 要确定在物理设备上的位置。 通用块设备层: 通用块层处理来自系统其他组件发出的块设备请求，包含了块设备操作的一些通用函数和数据结构。 I&#x2F;O 调度层： IO 调度层主要是为了减少磁盘 IO 的次数，增大磁盘整体的吞吐量，队列中多个 bio 进行排序和合并。 块设备驱动层: 每一类设备都有其驱动程序，负责设备的读写。 物理设备层: 物理设备层有 HDD、SATA SSD、NVMe SSD 等物理设备。 PageCache 层 —— 两种策略 write back: 写入 PageCache 便返回，不等数据落盘。 write through: 同步等待数据落盘。 程序的内存分布，其中包括内核空间（Page Cache 在内存中） 读流程下面以一次文件读取操作为例，完整详细描述一次 I&#x2F;O 请求处理链路： 虚拟文件系统层（VFS，也是 Linux 一切皆文件的底层原因） 文件系统（Ext2&#x2F;3&#x2F;4、NFS、Btrfs、xfs） 通用块设备层（bio、request） I&#x2F;O 调度器（CFQ、Deadline、noop、BFQ） 设备驱动（块设备&#x2F;字符设备） 设备控制器（如 NVMe&#x2F;SCSI 控制器） 中断处理（IRQ 处理流程） 1️⃣ 用户进程调用标准库函数用户进程发起系统调用 read(fd, buf, count)，系统陷入内核态。 12// glibc 中封装的 read() 最终触发 syscallssize_t read(int fd, void *buf, size_t count); 内核获取调用参数，内核深入调用 sys_read，检查文件描述符的有效性并获取内核文件结构体，通过软中断（x86 上是 syscall 指令）进入内核态： 12345// 内核入口点（x86_64 架构）SYSCALL_DEFINE3(read, unsigned int, fd, char __user *, buf, size_t, count)&#123; return ksys_read(fd, buf, count);&#125; 2️⃣ 虚拟文件系统 VFS内核通过文件描述符定位 struct file *： 123456ssize_t ksys_read(unsigned int fd, char __user *buf, size_t count)&#123; struct fd f = fdget_pos(fd); // 从 fd 表中找到 struct file ... return vfs_read(f.file, buf, count, &amp;f.file-&gt;f_pos);&#125; VFS 提供统一的文件接口，不管是 ext4、xfs 还是设备文件，统一调用： 1234567ssize_t vfs_read(struct file *file, char __user *buf, size_t count, loff_t *pos)&#123; if (file-&gt;f_op-&gt;read) return file-&gt;f_op-&gt;read(file, buf, count, pos); // legacy else if (file-&gt;f_op-&gt;read_iter) return call_read_iter(file, buf, count, pos);&#125; 3️⃣ 文件系统层假设文件位于 ext4 文件系统，对应操作函数为： 12// ext4_file_operations.read_iter = ext4_file_read_iter 这最终会调用 generic_file_read_iter()，进入页缓存机制（page cache）。 页缓存流程： 在页缓存中查找页是否命中 命中则拷贝回用户态（零拷贝优化） 未命中则触发 page cache miss → 发起读取请求到块设备 12// mm/filemap.cfilemap_get_pages() → 调用 readpage(s) → 提交 bio 到块层 4️⃣ 通用块设备层页缓存 page miss 会创建对应的 bio 结构体表示一次 I&#x2F;O 请求并提交 submit_bio()，然后对 bio 进行进一步封装，形成更底层的 request 结构传入 I&#x2F;O 调度器队列。 ✅ request 是 I&#x2F;O 调度的最小单位，多个 bio 访问存储器件上相邻的区域数据并且是同种类型的（读&#x2F;写），则会被合并到一个 request 中，所以一个 request 可能包含多个 bio。 bio structure submit_io 1submit_bio(bio); // fs 层构造 bio，提交到底层设备 块层主要组件： bio：描述一次 I&#x2F;O 操作（起始扇区、长度、数据缓冲区等） request_queue：设备对应的请求队列 I&#x2F;O scheduler：调度多个 bio 的先后顺序 5️⃣ I&#x2F;O 调度器I&#x2F;O 调度器决定请求的先后顺序，进行排序和合并优化，以此优化磁盘&#x2F;硬盘访问。 12blk_mq_sched_insert_request()blk_mq_run_hw_queue() 常见调度器如： CFQ（完全公平队列） Deadline noop BFQ（新版本） 6️⃣ 块设备驱动调度器处理完后，接着将 request 分发给具体驱动，调用对应的驱动操作函数（例如 NVMe 驱动）： SATA 磁盘驱动 (ahci.ko) NVMe 驱动 (nvme.ko) 12// nvme driver: drivers/nvme/host/nvme-core.cnvme_queue_rq() → 调用控制器提交命令 驱动程序将 request 翻译成硬件控制器能理解的指令集 对于磁盘：ATA&#x2F;SCSI 命令 对于 NVMe：NVMe 命令 驱动程序将命令写入设备控制器寄存器，具体一些是控制器的 Submission Queue，并触发 DMA（直接内存访问）数据传输。 7️⃣ 设备控制器&#x2F;硬件接口层硬件控制器接收到 SQ 中的命令，解析命令 read 并读取数据到 DMA 缓存，通过 DMA 把数据传输到内存中的内核缓冲区（Page Cache），DMA 数据传输完成后，写入 Completion Queue，硬件设备发起硬件中断通知 CPU 操作完成。 8️⃣ 中断处理流程CPU 响应硬件中断，内核执行相应中断处理程序： 确认硬件完成状态； 根据 CQ 的完成项来找到并标记 request&#x2F;bio 已经完成； 唤醒被该 read 阻塞的上层等待进程（在 wait_on_page_locked() 阻塞）。 9️⃣ bio 回传用户空间唤醒进程后，内核从内核缓冲区（Page Cache）将数据拷贝到用户空间缓冲区。 系统调用返回，用户进程继续执行。 写流程write()—&gt;sys_write()—&gt;vfs_write()—&gt;通用块层—&gt;IO 调度层—&gt;块设备驱动层—&gt;块设备 mmap 与 read&#x2F;write 顺便复习下 mmap 与 read&#x2F;write 的区别：mmap 与 read&#x2F;write 对比 传统的 file I&#x2F;O 中 read 系统调用首先从磁盘拷贝数据到 kernel，然后再把数据从 kernel 拷贝到用户定义的 buffer 中。 而 mmap 直接由内核操刀，mmap 返回的指针指向映射内存的起始位置，然后可以像操作内存一样操作文件，而且如果是用 read&#x2F;write 将 buffer 写回 page cache 意味着整个文件都要与磁盘同步（即使这个文件只有个别 page 被修改了），而 mmap 的同步粒度是 page，可以根据 page 数据结构的 dirty 位来决定是否需要与 disk 同步。这是 mmap 比 read 高效的主要原因。对于那种频繁读写同一个文件的程序更是如此。 面试题：如何不使用库函数完成对底层设备的读写？用户态 I&#x2F;O 参考《操作系统 原理与实现》13.4.2 小节 —— 陈海波 无论是基于系统调用还是 I&#x2F;O 库接口，应用程序默认操作的设备对象都是操作系统提供的逻辑设备。用户态和内核态之间需要大量的拷贝，造成性能下降，有没有办法不使用库函数来达到直接对底层物理设备的读写呢？ 以网络 I&#x2F;O 为例，一种直观的思路是允许防火墙软件直接操作网卡的 DMA 缓冲区（应用程序直接操作设备控制器的 DMA 缓冲区），为了实现这一目标，Intel 联合其他网卡制造商共同开发了一套高性能的用户态网络 I&#x2F;O 框架 —— 数据平面开发套件（DPDK）。 DPDK 在设计上采用旁路内核的设计，即网络包的收发处理基本不需要 Linux 内核的参与，DPDK 的设计思路如下： 其底层原理同样适用于其他物理设备 用户空间驱动为了能在用户态同网卡设备进行交互，DPDK 需要在用户态直接执行网卡驱动代码。做法就是将设备寄存器直接映射到应用自身的进程地址空间中，进而让 DPDK 的用户态驱动通过 MMIO 操作设备。 正如操作系统为应用程序的开发提供统一设备文件系统的和 I&#x2F;O 使用接口一样，Linux 提供了用户态驱动开发框架，即 UIO (Userspace I&#x2F;O)。 Linux 将 UIO 设备抽象为路径为 /dev/uio [x] 的设备文件。应用程序通过打开 UIO 设备文件获取设备的 I&#x2F;O 空间和中断信息，同时自行决定如何操作和响应设备。 注意：UIO 用户驱动通常不使用 write 接口，而是从 uio_driver.h 中已经经过 mmap 处理的内存区间直接与设备交换数据。 更多详细内容可以查看 Linux Kernel 中的 include/linux/uio_driver.h. 系统调用的优化系统调用作为应用程序调用操作系统的入口，其性能也非常重要。然而不同于传统的函数调用，系统调用的过程复用了异常机制，因此不可避免地需要执行特权级切换、上下文保存等操作，导致其时延比普通函数调用高1～2 个数量级。对于需要频繁进行系统调用的应用来说，这是很大的性能开销。 Q：那么要怎样绕过费时的异常处理机制来实现系统调用呢？ A：可以通过在用户态和内核态之间共享一小块内存的方式，在应用与内核之间创建一条新的通道。 1️⃣ 方法 1：共享内核只读数据给应用内核将一部分数据通过只读的形式共享给应用，允许应用直接读取。 这种方法的缺点在于：如果系统调用需要修改内核中的变量，或者在运行过程中需要读取更多内核数据，该方法就不适用了。 2️⃣ 方法 2：允许应用以 “向内存页写入请求” 发起系统调用第二种方法就是允许应用（用户态）以 “向内存页写入请求” 的方式发起系统调用，并通过轮询来等待系统调用完成；内核（内核态）同样通过轮询来等待用户的请求，然后执行系统调用，并将系统调用的返回值写入同一块内存页以表示完成。 但应用和内核怎么同时轮询呢？ 这个设计的关键点在于：让内核独占一个 CPU 核心。 这个核心一直在内核态运行，而其他 CPU 核心则一直在用户态运行。这样从系统整体来看，对于任何一个 CPU 核心都不会发生从用户态到内核态的切换，大大降低系统调用的时延。在应用将请求写入内存页后的下一个时钟周期，处于轮询状态的内核立即可以读到这个请求，并开始运行处理函数；同样，当内核将返回结果写入内存页后，在另一个 CPU 核心处于轮询状态的应用立即可以读到结果并继续运行。 不过这种方式存在两个缺点： 第一个缺点在于，如果有多个应用同时发起请求，内核需要一个个顺序处理，则时延可能会比原来更长，因为没能充分使用多核。解决方法也很直接：让多个 CPU 核心同时运行在内核态并轮询用户的请求，当内核忙不过来时，占用的核心多一些，反之少一些（根据系统负载动态调整内核占用的 CPU 核心数）。 第二个缺点在于，如果整个系统只有一个 CPU 核心怎么办？可以将轮询改为批处理。当 CPU 运行在用户态时，应用程序一次发起多个系统调用请求，同样将请求和参数写入共享内存页。然后 CPU 切换到内核态，内核一次性将所有系统调用处理完，把结果写入共享内存页，再切换回用户态运行。由于特权级的切换次数变少了，所以整体吞吐率提升了。","tags":["计算机系统","Linux","VFS","Linux Kernel","DPDK","read","write","mmap","Zero Copy","Page Cache"],"categories":["系统与体系结构"]},{"title":"DuckDB 的 Adaptive Radix Tree 源码分析","path":"/post/系统与体系结构/duckdb's-adaptive-radix-tree-source-code/","content":"DuckDB 不同于其他数据库，并没有使用 B+ 树作为主要索引结构，而是使用 ART (Adaptive Radix Tree) 作为它内部的主要索引结构，本文介绍这一索引。 ART (Adaptive Radix Tree)ART 索引是由 Viktor Leis, Alfons Kemper, Thomas Neumann 等人提出，它相比于 B+ 树的主要区别在于 B+ 树是面向磁盘的，而 ART 则是面向内存的，即 ART 索引是需要全部加载到内存中的。DuckDB 之所以选择这个索引有以下几方面的考虑： 随着内存越来越大，并且价格也越来越便宜，我们可以使用纯内存的索引，从而避免磁盘 I&#x2F;O，提升性能 ART 索引可以很大程度上节省空间 ART 索引支持范围查询 ART 索引有着较高的性能 后续本文会先介绍 ART 这一数据结构，然后配合着 DuckDB 的代码描述 ART 是如何实现的。 Trie 数据结构在讲 ART 索引之前，我们先看一下 Trie 树🌲 如果你不知道 Trie 树，可以参考 Wikipedia：https://en.wikipedia.org/wiki/Trie ✅ LeetCode 上也有「206. 实现 Trie（前缀树）」算法题可供参考： 请你实现 Trie 类： Trie() 初始化前缀树对象。 void insert(String word) 向前缀树中插入字符串 word 。 boolean search(String word) 如果字符串 word 在前缀树中，返回 true（即，在检索之前已经插入）；否则，返回 false 。 boolean startsWith(String prefix) 如果之前已经插入的字符串 word 的前缀之一为 prefix ，返回 true ；否则，返回 false 。 假设字符串里面只有 a 和 b 两种字符。 insert：例如插入字符串 aab，相当于生成了一条移动方向为「左-左-右」的路径。标记最后一个节点为终止节点。再插入字符串 aabb，相当于生成了一条移动方向为「左-左-右-右」的路径。标记最后一个节点为终止节点。 search：例如查找字符串 aab，相当于查找二叉树中是否存在一条移动方向为「左-左-右」的路径，且最后一个节点是终止节点。 startsWith：例如查找前缀 aa，相当于查找二叉树中是否存在一条移动方向为「左-左」的路径，无其他要求。 推广到 26 种字母，其实就是一棵 26 叉树，对于 26 叉树的每个节点，可以用哈希表，或者长为 26 的数组来存储子节点。 1234567891011121314151617181920212223242526272829303132333435363738394041424344struct Node &#123; Node* son[26]&#123;&#125;; bool end = false;&#125;;class Trie &#123;private: Node* root = new Node(); int find(string word) &#123; Node* cur = root; for (char c : word) &#123; c -= &#x27;a&#x27;; if (cur-&gt;son[c] == nullptr) &#123; return 0; // not found &#125; cur = cur-&gt;son[c]; &#125; return cur-&gt;end ? 2 : 1; &#125;public: Trie() &#123;&#125; void insert(string word) &#123; Node* cur = root; for (char c : word) &#123; c -= &#x27;a&#x27;; if (cur-&gt;son[c] == nullptr) &#123; cur-&gt;son[c] = new Node(); &#125; cur = cur-&gt;son[c]; &#125; cur-&gt;end = true; &#125; bool search(string word) &#123; return find(word) == 2; &#125; bool startsWith(string prefix) &#123; return find(prefix) != 0; &#125;&#125;; 我们可以看到 Trie 树在检索时的优点是，它的检索时间仅与最长的字符串长度有关，而与存储的字符数量无关，这一特性在数据量极大的情况下十分优秀，但是它的缺点是浪费空间，即每个内部节点都需要保存固定数量的指针，即使它仅有极少的子节点。 比如图中的 root 节点，尽管它只有三个子节点，但是它仍然需要保存指向 a,b,c,d,e... 的空指针，这十分浪费空间，其次 Trie 树仅支持保存字符串。 ART 则是在 Trie 树的基础上，解决了它缺点的同时，保留了它的优点，下面来介绍 ART 索引。 对于一个索引而言，我们希望它有以下两个特点： 查询速度快 空间占用小 但是如果我们使用 Trie 树做索引（ART 是 Trie 的一个变种），我们就要面临取舍： 如果内部节点拥有的最大子节点越多（空间占据越多），那么它的高度也越低（速度越快） 如果内部节点拥有的最大子节点越少（空间占据越少），那么它的高度也越高（速度越慢） ART 树选择每个内部节点的大小为 8bit（子节点的数量为 256），刚好是一个 Byte。这样的好处是免去了内存对齐的问题，同时在空间与速度上取得了一个较好的平衡，我们称内部节点所占据的位宽为 span。 尽管如此，面对稀疏的数据时，每个节点有 256 个子节点仍然会浪费空间，为了解决这个问题，ART 将内部节点进一步细分为以下四类，我们分别来对其进行介绍： Node 4 Node 16 Node 48 Node 256 Node 4 从图中可以看出，Node 4 分为两个部分，一个是 key 数组，一个是 child 数组。 key 数组存放 key 的部分内容（也就是 key 的一个 Byte） child 数组则是保存对应的子节点的指针 注意，我们为了可以范围查询，key 数组要求顺序存储。 Node 16 Node 16 和 Node 4 几乎一样，区别只是从 4 个 slot 变成 16 个 slot。 Node 48 Node 48 和之前介绍的 Node 一样也是分为 key 数组和 child 数组，区别在于 Node 48 的 key 数组长度为 256，且内部 key slot 存放的是指针，指向对应子节点在 child 数组中的位置，这样我们就无需通过遍历找到对应的数组，而是可以直接通过 key 的二进制值作为下标直接定位到对应的 key slot。 实际查询仅需要 child_array[key_array[key]] 即可。 Node 256 Node 256 就是「Trie 树」原始的内部节点表示形式，仅需要一个数组，数组的下标即为 key，数组中存放的就是子节点的指针。 各种不同类型的 Node 可以相互转换，如果子节点数量超过限制容量就向上转换，如果节点数量相较于限制容量太小就向下转换。 LeafART 中的叶节点存放的就是 Key 对应的 Value 值，ART 的叶节点可以采用三种形式： 单独有一个叶节点类型专门保存 Value 和中间节点保持一致的类型，唯一区别则是 child 数组不保存指针而是保存值 如果值足够小可以通过位操作和指针一起保存，那么我们可以将值直接存放在内部节点中 🔥 DuckDB 采用的是第一种方式。 Optimization在解决了 ART 的空间问题，我们希望可以进一步优化查询速度，即减少树的高度。 论文链接：https://db.in.tum.de/~leis/papers/ART.pdf 论文中有两种方式，但实际上我们可以通过一种简单的做法同时获得这两种优化，每个节点加上 Prefix 标识。 1. Lazy Expansion 其实这个优化相当简单，我们只需 Leaf 可以保存多个 byte 即可，这样子对于多个只有一个子节点的路径来说，我们可以将其都保存在 Leaf 中，从而减少树的高度。 2. Path Compression这个优化和 Lazy Expansion 类似，我们只需让 内部节点 可以保存多个 byte 即可。即如果内部节点有相同的前缀，我们可以将其保存在 Prefix 中，key 数组仅仅只对 key 不同的部分作区分。这样也可以有效地减少树的高度。 如果这里没看懂也没关系，后续我会分析 DuckDB 的代码，那样会更加清晰。 数据转换对于 ART 来说，前面介绍的都是对于字符串类型 string，如果作为一个广泛使用的索引，也需要支持不同类型的数据。而 ART 索引实际上是把 Key 作为数据流进行处理的，也就是说如果想要通过 ART 进行范围搜索，我们需要让 Key 保持一个性质，即二进制的大小与该类型的语义大小相同：$$memcmp(binary(x),binary(y)) &lt; 0 \\Leftrightarrow x &lt; y \\memcmp(binary(x),binary(y)) &#x3D; 0 \\Leftrightarrow x &#x3D; y \\memcmp(binary(x),binary(y)) &gt; 0 \\Leftrightarrow x &gt; y$$因此我们需要对某些数字进行转换。 unsigned int无需转化，已经满足需求。 signed int将符号为 flip 即可。 float123456789101112131415161718192021222324252627282930static inline uint32_t EncodeFloat(float x) &#123; uint64_t buff; //! zero if (x == 0) &#123; buff = 0; buff |= (1u &lt;&lt; 31); return buff; &#125; // nan if (Value::IsNan(x)) &#123; return UINT_MAX; &#125; //! infinity if (x &gt; FLT_MAX) &#123; return UINT_MAX - 1; &#125; //! -infinity if (x &lt; -FLT_MAX) &#123; return 0; &#125; buff = Load&lt;uint32_t&gt;(const_data_ptr_cast(&amp;x)); if ((buff &amp; (1u &lt;&lt; 31)) == 0) &#123; //! +0 and positive numbers buff |= (1u &lt;&lt; 31); &#125; else &#123; //! negative numbers buff = ~buff; //! complement 1 &#125; return buff;&#125; charUCA 算法已经做出了定义。 Unicode Collation Algorithm (UCA) 是 Unicode 规定的如何比较两个字符串大小的算法。 null可以将该值设置为比最大位数仍多 1 位。 compound keys按照其包含的基本类型进行拼接即可。 DuckDB 源码分析 DuckDB 代码链接：https://github.com/duckdb/duckdb/tree/main/src/execution/index/art 其他参考： 论文 《The Adaptive Radix Tree: ARTful Indexing for Main-Memory Databases》 《SMART: A High-Performance Adaptive Radix Tree for Disaggregated Memory》 相关代码 [cpp] ART：https://github.com/rafaelkallis/adaptive-radix-tree [golang] ART：https://github.com/plar/go-adaptive-radix-tree 这一章通过阅读 DuckDB 的源码，来看一下 ART 索引的实现。 ART 索引的相关实现都在 art.cpp 和 art.hpp，我们主要关注 Insert 和 Find，其他函数留给读者自行了解。 Insert123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384bool ART::Insert(Node &amp;node, const ARTKey &amp;key, idx_t depth, const row_t &amp;row_id) &#123; if (!node.IsSet()) &#123; // node is currently empty, create a leaf here with the key Leaf::New(*this, node, key, depth, row_id); return true; &#125; if (node.DecodeARTNodeType() == NType::LEAF) &#123; // add a row ID to a leaf, if they have the same key auto &amp;leaf = Leaf::Get(*this, node); auto mismatch_position = leaf.prefix.KeyMismatchPosition(*this, key, depth); // identical equal if (mismatch_position == leaf.prefix.count &amp;&amp; depth + leaf.prefix.count == key.len) &#123; return InsertToLeaf(node, row_id); &#125; // example: // prefix : hello // key[depth] : heel; // mismatch_position = 2 // replace leaf with Node4 and store both leaves in it auto old_node = node; auto &amp;new_n4 = Node4::New(*this, node); // new prefix // new_n4&#x27;s prefix is he new_n4.prefix.Initialize(*this, key, depth, mismatch_position); // old_node&#x27;s prefix change to llo auto key_byte = old_node.GetPrefix(*this).Reduce(*this, mismatch_position); // add child Node4::InsertChild(*this, node, key_byte, old_node); Node leaf_node; Leaf::New(*this, leaf_node, key, depth + mismatch_position + 1, row_id); // add child Node4::InsertChild(*this, node, key[depth + mismatch_position], leaf_node); return true; &#125; // handle prefix of inner node auto &amp;old_node_prefix = node.GetPrefix(*this); if (old_node_prefix.count) &#123; auto mismatch_position = old_node_prefix.KeyMismatchPosition(*this, key, depth); if (mismatch_position != old_node_prefix.count) &#123; // prefix differs, create new node auto old_node = node; auto &amp;new_n4 = Node4::New(*this, node); new_n4.prefix.Initialize(*this, key, depth, mismatch_position); auto key_byte = old_node_prefix.Reduce(*this, mismatch_position); Node4::InsertChild(*this, node, key_byte, old_node); Node leaf_node; Leaf::New(*this, leaf_node, key, depth + mismatch_position + 1, row_id); Node4::InsertChild(*this, node, key[depth + mismatch_position], leaf_node); return true; &#125; depth += node.GetPrefix(*this).count; &#125; // recurse D_ASSERT(depth &lt; key.len); auto child = node.GetChild(*this, key[depth]); if (child) &#123; bool success = Insert(*child, key, depth + 1, row_id); node.ReplaceChild(*this, key[depth], *child); return success; &#125; // insert at position Node leaf_node; Leaf::New(*this, leaf_node, key, depth + 1, row_id); Node::InsertChild(*this, node, key[depth], leaf_node); return true;&#125; 参数含义： node 即为当前要进行插入的节点 key 即为要插入的 key depth：即当前已经处理到 key 的第几个 byte，举个例子，key 为 hello，depth 为 3，那么说明 he 已经保存在了 node 的祖先节点中，我们当前要处理的是 l row_id 即为 key 对应的 value 值 1234567bool ART::Insert(Node &amp;node, const ARTKey &amp;key, idx_t depth, const row_t &amp;row_id) &#123; if (!node.IsSet()) &#123; // node is currently empty, create a leaf here with the key Leaf::New(*this, node, key, depth, row_id); return true; &#125;&#125; 如果当前节点为空，那么直接设置该节点为叶节点，并且将 row_id 进行保存，注意这里我们会使用 lazy-expansion，即将 key 剩余未处理的字符全部保存在叶节点中。 123456789101112131415161718192021222324252627282930313233343536373839404142bool ART::Insert(Node &amp;node, const ARTKey &amp;key, idx_t depth, const row_t &amp;row_id) &#123; // .... skip if (node.DecodeARTNodeType() == NType::LEAF) &#123; // add a row ID to a leaf, if they have the same key auto &amp;leaf = Leaf::Get(*this, node); auto mismatch_position = leaf.prefix.KeyMismatchPosition(*this, key, depth); // identical equal if (mismatch_position == leaf.prefix.count &amp;&amp; depth + leaf.prefix.count == key.len) &#123; return InsertToLeaf(node, row_id); &#125; // example: // prefix : hello // key[depth] : heel; // mismatch_position = 2 // replace leaf with Node4 and store both leaves in it auto old_node = node; auto &amp;new_n4 = Node4::New(*this, node); // new prefix // new_n4&#x27;s prefix is he new_n4.prefix.Initialize(*this, key, depth, mismatch_position); // old_node&#x27;s prefix change to llo auto key_byte = old_node.GetPrefix(*this).Reduce(*this, mismatch_position); // add child Node4::InsertChild(*this, node, key_byte, old_node); Node leaf_node; Leaf::New(*this, leaf_node, key, depth + mismatch_position + 1, row_id); // add child Node4::InsertChild(*this, node, key[depth + mismatch_position], leaf_node); return true; &#125; //skip....&#125; 如果当前遇到的是叶节点，同时 key 完全相同，那么我们可以直接将 row_id 插入叶节点中。不然的话，我们需要将叶节点变成内部节点，同时将不同的部分作为该内部节点的叶节点，如下图所示。 123456789101112131415161718192021222324252627282930313233343536373839404142bool ART::Insert(Node &amp;node, const ARTKey &amp;key, idx_t depth, const row_t &amp;row_id) &#123; // skip .... // handle prefix of inner node auto &amp;old_node_prefix = node.GetPrefix(*this); if (old_node_prefix.count) &#123; auto mismatch_position = old_node_prefix.KeyMismatchPosition(*this, key, depth); if (mismatch_position != old_node_prefix.count) &#123; // prefix differs, create new node auto old_node = node; auto &amp;new_n4 = Node4::New(*this, node); new_n4.prefix.Initialize(*this, key, depth, mismatch_position); auto key_byte = old_node_prefix.Reduce(*this, mismatch_position); Node4::InsertChild(*this, node, key_byte, old_node); Node leaf_node; Leaf::New(*this, leaf_node, key, depth + mismatch_position + 1, row_id); Node4::InsertChild(*this, node, key[depth + mismatch_position], leaf_node); return true; &#125; depth += node.GetPrefix(*this).count; &#125; // recurse D_ASSERT(depth &lt; key.len); auto child = node.GetChild(*this, key[depth]); if (child) &#123; bool success = Insert(*child, key, depth + 1, row_id); node.ReplaceChild(*this, key[depth], *child); return success; &#125; // insert at position Node leaf_node; Leaf::New(*this, leaf_node, key, depth + 1, row_id); Node::InsertChild(*this, node, key[depth], leaf_node); return true;&#125; 如果是内部节点，那我们需要讨论： 如果前缀完全相同，即 “hello” 和 “hellopxxx”。那么我们仅需要找出子节点进行插入即可 如果前缀有不同之处，即 “hello” 和 “helopxxx”。那么我们需要创建一个新的节点，并将两个节点作为子节点进行插入 可以看到我们只需要在内部节点和叶节点中支持存储多个字符后，便天然支持上述的优化方案。 Find123456789101112131415161718192021222324252627282930313233343536373839Node ART::Lookup(Node node, const ARTKey &amp;key, idx_t depth) &#123; while (node.IsSet()) &#123; if (node.DecodeARTNodeType() == NType::LEAF) &#123; auto &amp;leaf = Leaf::Get(*this, node); // check if leaf contains key for (idx_t i = 0; i &lt; leaf.prefix.count; i++) &#123; if (leaf.prefix.GetByte(*this, i) != key[i + depth]) &#123; return Node(); &#125; &#125; return node; &#125; auto &amp;node_prefix = node.GetPrefix(*this); if (node_prefix.count) &#123; for (idx_t pos = 0; pos &lt; node_prefix.count; pos++) &#123; if (key[depth + pos] != node_prefix.GetByte(*this, pos)) &#123; // prefix mismatch, subtree of node does not contain key return Node(); &#125; &#125; depth += node_prefix.count; &#125; // prefix matches key, but no child at byte, does not contain key auto child = node.GetChild(*this, key[depth]); if (!child) &#123; return Node(); &#125; // recurse into child node = *child; D_ASSERT(node.IsSet()); depth++; &#125; return Node();&#125; 查找的代码相对来说比较简单： 查找到了 Leaf 节点，检查 Prefix 是否匹配，如果不匹配说明 Key 不存在，若匹配直接返回该叶节点即可 查找到了 内部节点，检查 Prefix 是否匹配，如果不匹配说明 Key 不存在，若匹配则继续搜索对应的子节点 最后本文介绍了 DuckDB 的 ART 索引，可以看到尽管 ART 索引的树会比 B+ 树更高，因此如果是面向磁盘的情况下，B+ 树会比 ART 索引优势更大，但是如果是内存索引的情况下，ART 索引更加紧凑，同时它的渐进时间复杂度仅与 key 的长度有关，可能也更加 Cache friendly？它的节点相较于 B+ 树更加的小，可以更多的保存在 Cache 中。从论文中的实验来看，它的性能会比 B+ 树更好。相较于 Hash table，它支持范围查询。基于此，DuckDB 将 ART 索引作为其的主要索引。","tags":["DuckDB","ART","Trie"],"categories":["系统与体系结构"]},{"title":"未来世界的幸存者","path":"/post/未来世界的幸存者/the-future-world/","content":"彻底了解你自己所有关于成长的书籍都告诉我们要扬长避短，做自己最擅长的事，但是了解自己长短这件事情并不容易。 你可能试过很多方法，比如心理学的各种人格与性格分类，甚至玄学中的星座、属相等等。你会从这些工具中得到各种各样结果，但不管你被归类为冷静理性的 intj，还是敏感细腻的 infp；是潇洒随意的射手座，还是完美主义的处女座。这些结论除了为你的自恋找到依据，或者为自我厌恶的部分做心理按摩以外，就只能增加些谈资，并没有什么实用价值，你的生活和事业并没有因为你知道这些而变好。 所以你需要一个科学的工具，这个工具叫回馈分析法。人类这种生物是没有多少自由意志的，所有的决策都被潜意识所影响。 卡尔·荣格曾说过，除非你意识到自己的潜意识，否则它会一直影响着你的生活，然后你说那是命运。 所以你必须扒开你的潜意识看看你的底色，而窥探潜意识最好的方式，就是用回馈分析法观察自己的决策。 你的潜意识如何影响你的人生，真实的你自己是什么样子，答案藏在你做的每一个决策里。 具体操作是：在你准备做一件事情之前，记录下你对结果&#x2F;效果的期望，在事情完成之后，将实际的结果&#x2F;效果与你的预期进行比较。 比如下面这样。 决策：我决定远离有毒的同事关系，跳槽到新公司重新开始。 预期结果：新公司的同事关系一定会很和睦，至少会和平相处。 实际结果：新公司的同事一样很坏，他们都针对我。 你记录的越多，你就对自己越了解，你会发现成功和失败的原因都极其类似，有些事情你很擅长，有些事情你就是死活也做不到。 你是怎么想的和怎么说的都不重要，重要的是怎么做的，你的决策和行为方式才是你最真实人格的体现，你所有的长项和缺陷都在其中一览无遗。 当然，你也不必花费数年的时间来记录自己的决策和结果，回忆过去所做的对人生有重大影响的决策，也可以达到同样的效果。 从这些记录中，你可以分析出你应该做什么，避免做什么，你最强的欲望和最深的恐惧都一目了然。 然后改变其中能改变的，接受并避免那些不能改变的，在以后的人生中充分发挥你的长项，而不是在缺陷里死循环，白白浪费时间。 等价交换你目前所拥有的一切都是来自你自身价值的交换，你的工作来自于你的技能；你的生意来自你掌握的资源；你的友情来自你所能提供的情绪价值；你的爱情来自物质和情绪价值的双重交换。 人在年轻的时候总是过于自我，觉得自己 “配得上这世间所有美好”，所以一旦不被领导赏识，难免会觉得 “怀才不遇”。你爱的人不爱你，你会觉得对方 “瞎了眼”，永远不会反思自己配不配，因为你觉得爱情不应该用物质来衡量，可是你试图用 “有趣的灵魂” 去交换别人的财富、地位、美貌这些硬通货，又高尚到哪里去了呢？ 短期内你的价值可能会被高估或者被低估，但生活就像投资品一样，是存在均值回归的，溢价终究会被时间抹平，最终每个人都只能过上自身实力能够匹配的生活。 所以你想要什么，必需要先掌握能够与之交换的筹码。 那么你有什么呢？ 如果你是一个普通人，那么你对世界的认知无非来自知乎、微博以及你平凡父母的言传身教；你的知识来自智商正常就能读的学校（毕业后大部分都还了回去）；你掌握的工作技能，任何一个应届生培训半个月就能胜任。 你想要怒放的生命，你想要不平凡的人生，又或者你没有别的愿望，只想和多个异性…..（季羡林先生语，此处省略） 就凭这些能交换到你想要的生活吗？ 所以你必须要增加你的筹码，如果你不名一文，那就应该用你的勤奋，去交换技能和知识，然后和这个世界做交易，在每一步交易中都获得自己想要的筹码，或者是钱，或者是人情，或者是信息。当你积攒的筹码足够多，最后你就可以给你的目标一个 “无法拒绝的条件”，过上你想要的人生。 这是一条极为艰苦的道路，爽片里的主角一旦下定决心奋斗，几个转场镜头，主角就脱胎换骨，走向人生巅峰。可是真实的奋斗不是这样，真实世界的奋斗是血与火的拼杀，是未知带来的恐惧，是无数个不眠之夜，你需要忍受焦虑和未知的煎熬。在这个过程中你会不断杀死 “自我”，从一个文艺小清新，变成一个 “油腻的生意人”，但这是一条正确的路。 你要有一门安身立命的手艺你必须要精通一门手艺，通过这门手艺你可以连接更高阶层的人，用帮助他们的方式种下友谊的种子，积累跨越阶层的人脉，从他们那里获取有价值的信息。 这门手艺将是你人生的下限，保证你过上至少中等水平的生活。这非常重要，假如你生活在社会底层，为了生活不得不精打细算，那么你将会因为生存资源匮乏养成 “稀缺头脑模式”，没有任何多余 “带宽” 来考虑如何学习提升，这叫贫穷的陷阱。陷入其中的人会因为缺乏改变现状的心力而长期贫困，甚至出现贫困的代际传递，他们的子女大概率也会继续贫困。 在学习手艺的过程中你还可以掌握把事情做成的方法论，不要小看这件事的价值，成功乃成功之母，这个社会大多数人都浑浑噩噩，没有体验过真正成功的滋味，多少都有点习得性无助，当你体验过为一件事专注到废寝忘食，最终把它做成，你将脱胎换骨。 得益于互联网的发展，我们学习一门手艺不需要像古时候一样磕头拜师（如果你看过白鹿原就知道那时候学手艺这事儿有多难），现今社会需要的大部分技术都可以从网络上学习，网上有丰富详细的各种教程，你可以学习任何你想学的东西，互联网时代不会埋没人才，也不会亏待勤奋的人，假如你是的话。 生理决定了你的精神状态你有没有想过，为什么有的人精力充沛，遇到紧急工作能连续熬夜，在巨大压力下，还能保持充足睡眠，该吃就吃，该喝就喝。而你整天精神萎靡，早上起不来，晚上睡不着，浑身散发负能量，遇难则退，“太难了”、“做不到” 是你的口头禅，饿、困、穷是你的日常抱怨内容。 有人觉得这是性格问题，但其实本质是个生理问题，人体分泌的各种神经递质会影响我们的情绪，而情绪又会外化为我们的各种日常行为。 大体上我们的情绪主要被三种神经递质影响： 多巴胺多巴胺应该是最为大众熟知的神经递质，多巴胺不生产快乐，它是一种 “承诺你这么做就能够获得快乐” 的物质，是人的心理动力源泉。没有了它就没有做任何事情的内在驱动力。 人们之所以会在周五工作效率特别高，是因为知道完成工作，就可以在周末愉快的玩耍。如果多巴胺分泌水平较低，就会缺乏这种奖赏机制下产生的动力，明明知道很多事情「很重要」「必须做」，但就是提不起精神，一再拖延。 血清素血清素最核心的作用是保持情绪和心情的稳定性。比如，别人对你发脾气，你心态很好，不容易生气。或者遇到挫折时抗压能力强，有点类似成功学说的 “逆商”。 另外，血清素还能抑制「厌烦」情绪的产生。有实验表明，当分泌血清素的神经元被激活，实验参与者会表现出更高的耐心和积极性。哪怕接连给他们制造困难，也不会失控和不耐烦。 同样的，当大脑缺乏血清素的时候，很容易导致情绪不稳定，感到抑郁、厌烦、悲观，觉得世界一片灰暗，动不动就发脾气烦躁，看什么都不顺眼。 皮质醇皮质醇又叫 “压力荷尔蒙”，听起来是一种不好的激素，实际上大有益处。人在运动锻炼和比赛之前身体会自然分泌皮质醇，可以短暂的改善记忆力和提高疼痛阈值。人体能进化并保留出皮质醇这种激素，是自然选择的结果。一个面对猛兽的原始人，不管他是选择战斗还是逃跑，适当的压力都会提升他的警惕性与战斗能力，生存概率也就会因此提高。也就是说，今天的人类都是那些能产生压力情绪的原始人的后代。 但是皮质醇过高则又变成了一件坏事，它会让我们过度悲观，导致什么也不想干，食欲大增，吃饱了还想吃。 最关键的，皮质醇高还会导致「延迟满足」能力变弱，所有让人进步的事情，都需要先苦后甜，你想英语流利，就必须忍受背单词的枯燥。但是皮质醇过高，会让人没办法集中精力做需要静下心才能做的事情，只想要当下的满足。 如果你多巴胺和血清素分泌水平低，皮质醇分泌水平高，你就会变成一个负能量黑洞或者高敏感人格，日日陷在心理内耗中不能自拔，学习、工作、事业就不要想了。 饮食｜冥想｜运动那么怎么改善这些神经递质的分泌水平呢？有三种经过科学检验的方法：饮食、冥想、运动。 1️⃣ 先说饮食，有些食物对改善神经递质的分泌有一定作用，但是我不建议用饮食调理，因为如果不能想吃什么就吃什么，人的情绪会受很大影响，饮食的调理功效会被对冲掉，所以饮食的作用可能不会太明显。 2️⃣ 其次是冥想，有研究表明，有规律的进行冥想可以直接影响大脑中关键神经递质的水平，能有效提高自控力、钝感力，促进睡眠。而且冥想的效果立竿见影，没有冥想经历的人，尝试一次冥想就能体验到久违的内心平静，对驱散焦躁情绪帮助极大。 3️⃣ 最后是运动，这是我比较推荐的一种方法，运动对提高多巴胺和血清素，降低皮质醇的作用非常显著，这和我们的印象大体上是一致的，运动能力好，身体素质好的人，通常元气满满，更乐观开朗。而身体素质差或者干脆就是亚健康的人抗压能力弱，遇到问题会更多抱怨，没有耐心，甚至脾气也更差。 当然冥想和运动都需要长期坚持，这对本身就充满负能量的人来说非常难。但是人生若不做成几件抓心挠肝的难事，基本不可能有阶级跃迁的机会。何况还是这种只要坚持就有效果，因果关系极为清晰的事。 完美主义害死人让一个完美主义者不出手的理由有很多，天气和心情都可以是原因，他们害怕失败，希望一出手就是完美状态。但这几乎是做不到的，很多事情都是在与现实的碰撞中一步一步完善的，不可能事先在脑海中想清楚每一个细节。 软件设计领域有一个著名的 “MVP” 原则，既最小可行产品，可以把它理解为一个软件的最简单版本，细节虽然不完善，甚至粗糙，但它是可以运行的，可以满足用户最核心的需求。把它快速推向市场，接受用户的检验，验证这个软件是否有市场，确定以后再快速迭代，加大投入。这样做可以用最小的成本，快速验证自己的创意，如果一开始就追求大而全，要么失了先机，让别人抢占市场，要么就是闭门造车，做的东西完全没人用，浪费时间和金钱。 很多人在学习上也是完美主义者，喜欢死抠细节，不搞明白绝不进入下一章节的学习。在学习上死磕精神是对的，但是对于初学者来说，过于抠细节往往会钻牛角尖，导致学习过程举步维艰。不是说细节不重要，而是初学阶段的细节问题，要么在以后的章节会讲到，要么就是初学者不了解基本概念，思考了一个不是问题的问题。 对于一个想要做点事儿的人来说，接纳一定程度的未知、混乱、瑕疵是常态，路是一步步走出来的。你需要在 “战争中学习战争”，让自己的想法和技能接受别人的检验和反馈。很多功成名就的人在成功以后都自夸当初如何运筹帷幄、高瞻远瞩，但实际上哪个不是一路如履薄冰，小心翼翼才走到今天。 你需要做一个副业这几年很多人都在尝试副业，但是我让你做的副业不是利用一项技能接私活，而是独立运营一门小生意。它可以是在朋友圈卖水果；在二手平台卖旧货；做外贸 soho；利用独立站做 drop shipping；做自媒体博主（文字、音频、视频，你对哪个感兴趣就做哪一种类型）。 做这些小生意你有百分之一的可能赚到超过你工资的钱，百分之十的可能赚点零花钱，更可能是亏几顿 KFC，但这些都不重要，重要的是培养商业能力和保持市场敏感度。你会学习如何引流获客，什么是投入产出比，什么是供应链。当你以一个商人的视角看待这个世界时，你会更加客观，你没有得到你想要的东西，只会是你错了，因为市场永远不可能出错，它只会给正确对待的它的人以回报。 读一百本商业书籍，在脑中设计一万个商业模式，不如自己亲自运营一个小生意，你只有身在其中才能保持对市场的敏感，在下一波浪潮到来时及时抓住机会，站上浪潮之巅。 做站长失败的伊光旭抓住了微博崛起的机会，运营出冷笑话精选等一批微博大号；在论坛博客时代就活跃的人，抓住了公众号的红利期，赚得盆满钵溢；在阿里巴巴把流量日益向大卖家倾斜时，一些活不下去的小卖家抓住了拼夕夕的机会；近几年火爆的跨境电商，从业者大多以前就在做传统外贸。 🌀没有人是横空出现的，你必须先进场 得到贵人帮助如果你研究过一些大佬的生平，你就会发现在大佬崛起的关键节点，往往都有贵人相扶。大佬得到的也许并不是直接的帮助，可能就是一个建议或者信息，但大佬从此就一飞冲天。 那么什么样的人才能得到贵人相助呢？ 首先你要有平均线以上的能力，这是别人给你机会的基础。一个团队中什么样的人会得到提拔呢？不一定是能力最好的人，但肯定不是能力最差的人。 其次，你要靠谱，这个品质非常重要，甚至比能力还重要。对一个领导来说，“可预期” 这件事非常重要，能力最好的人未必是可预期的，他可能心高气傲，受不了委屈随时撂挑子不干。如果你能做到 “凡事有交代，件件有着落，事事有回音”，成为领导心目中靠谱的人，那么领导就更有可能成为帮助你的贵人。 第三，你要真诚，懂得感恩（起码要表现的如此），因为没有人愿意帮助一个白眼狼。 除此以外，还有一种人必然会得到贵人相助，那就是真正的 “人中龙凤”，如果你惊才绝艳，才华突破天际，里里外外都表现出 “非池中物” 的品质，别人知道你迟早要出头，打压你也无济于事，就会给你提供帮助，提前在你这里攒下人情。 比如拼夕夕的创始人黄峥。在浙大期间黄峥就表现出了极客的品质，他热衷在网上发布技术文章，是学校的风云人物。网易的创始人丁磊有次遇到一个技术难题，在网上看到了黄峥的文章，于是联系到黄峥，在他的帮助下顺利解决了问题。丁磊非常希望黄峥能够加入网易，但是当时黄峥正要去美国留学，丁磊便介绍黄峥给退休在美国做投资的步步高创始人段永平认识，两人很快成为忘年之交。 段永平是黄峥重要的人生导师和贵人。黄峥在美国硕士毕业以后获得两个 offer，一个来自科技巨头微软，一个来自创立不久但发展迅速的谷歌。段永平建议他去当时规模还不大的谷歌。后来谷歌上市，黄峥持有的期权立刻让他实现财务自由。在谷歌工作两年后，黄峥回国创业，段永平又成为了他的投资人。 像黄峥这样的人万中无一，对于普通人来说，把自己修炼到具备水平以上的能力，并展现自己的靠谱和真诚，是获得贵人帮助的最好方式。","categories":["未来世界的幸存者"]},{"title":"2024 年终总结｜世界指向任何我想去的地方","path":"/post/年终总结/「2024」the-world-points-to-wherever-I-want-to-go/","content":"我总是习惯在跨年的时节，去回望过去的人生旅途，在无数次相遇和离别中，找回内心的平静。 往年的年终总结： [2023年终总结] 别急着赶路，去感受路 [2022年终总结] 人生是一片原野，而非轨道 [2021年终总结] 唯有热爱，可抵漫长岁月 今年真的要过去了，我始终觉得元旦不算新年，但真等到了除夕，又似乎和平时没有什么区别。2024 年仿佛一直都在路上，一直都在疲于奔命，社会节奏本就匆忙，互联网更是。为生活奔波的时候，没精力和大爷聊天，也没心情抬头看朝霞日落，连电梯上升的加速度都压得人腿软。 我总是期待着也祈祷着自己在路上，哪怕是周末了，我也希望自己可以从头忙到尾，兼顾学业、家庭、朋友，找时间读一本好书，听一场音乐会，看一场电影。似乎什么好事我都不愿意错过，好像身在一家自助餐厅，每样菜都很好吃，我都想尝试。我也确实很喜欢吃自助，但其实很快就吃饱了，已经不再是当年了。 对我个人来说，没有任何一件事情，像生病和生病造成的影响让我成熟得更快，它明确指出生命中到底什么最重要，我或许现在还没有找到，但一定不是屏幕上冗长的代码和无用的八股。 我最初写年终总结的初衷，仅仅是为了如果有一天 remake 了，能在互联网多留一些痕迹，所以当阅读人数从几十人到几万人，我就会很开心，这意味着世界上又多了一些看到了我痕迹的人。我写的这种不算小说，所以我写的很慢，一个作者哪能写尽世上的所有人呢，写来写去，写的还是自己和自己身边的人，无论孤独还是野心，都是自己人生某个侧面的写照，这是我的局限与浅薄，但也是我的真诚。 #01 我的学生时代春节那几天恰逢初高中学校的校友日，顺便约上朋友和老师一起回去看看，那六年的时间还历历在目。 我在高中的时候有人嫉妒我，我想大概是因为和哪个女生传过绯闻，被当成了情敌，我在本科的时候有人嫉妒我，我想是因为我当年是个卷王，对于卷王，大多数人都是恨得咬牙切齿然后一边痛骂一边怨恨为什么这个人不是自己，特别是人前显圣的时候，因为我也在心里骂过那个台上的卷王，这俩我都能理解。我不理解的是，怎么读了研究生，仍然会有人嫉妒我，嫉妒这样的一个卷了好些年后的衰仔。 有次看到个热搜是，一百万回到高三，问你愿不愿意，我其实挺想去的，可惜没钱，后来看了评论区才发现，原来是给我一百万。 图 1～图 3 分别是：小学、初中、高中 替我的化学老师带孩子哈哈哈，非常可爱 说实话我并不知道我为什么会疯狂的怀念学生时代，有时候一个画面，一段音乐，都可以勾起思绪，惆怅得不行，听说人喜欢怀旧是因为现实里过得并不好，我也不知道这是不是对的。那天我坐在曾经我们下课后聚众闲聊的走道边，脑海一路开始回想过去读书的日子，那时候阳光不是很大，暖暖的，温和的照在眼前，隔着树叶斑驳的影子在墙上晃动。也许我生来就是比较喜欢念旧的，不管过去有多好多差，总会去怀念那一段青涩的日子。怀念那个 12 人间的老旧寝室，晚上此起彼伏的鼾声；怀念偷偷看着喜欢的女孩子，然后她也会偶尔回头看自己一眼；怀念留下来默默的打扫卫生，然后听着广播里的不知名歌曲；怀念在图书馆用 MP3 听周杰伦的歌；怀念那条通往教学楼和寝室的小路；怀念那家经常去的奶茶店；怀念那辆通往学校的公交车… 在十七八岁或者更早的某天，我们像无数个往常一样和朋友说再见，很多年之后才意识到那是最后一见，却连那天的天气都记不起来了。相比之下，能认真告别就已经足够幸运了。 那天我拍了很多照片存手机里，好像这样就能留住我的学生时代一样。 可是人是会变的，大家都走了，没有人留在原地，我只是往过去多看了几眼。 很多年后，我还是会想起高考后的那个盛夏，大学，军训，正午，不知道哪里来的马蜂嗡嗡的穿过迷彩服的人群，人群快速的散开又聚合，在阴凉地看着未来的舍友和同学军训，呆呆的幻想着美好的大学生活。这时候还没有计算机，没有 Java，没有绩点，没有保研，也没有什么实习，什么秋招，什么天南海北的漂泊，聚散离合。 看到那些曾与我度过美好时光的人都已渐渐淡出我的人生时，我的心情 be like：🥺 #02 白日梦想家 分享一些我在 2024 年看过的文学作品，不限文体。 我们活在这样复杂的世界里，被其中如同圆周率一样从不重复也亳无规则的事情拉扯着，朝世界尽头盲目地跋涉而去。我们就是这样生活在如同圆周率般复杂而变化莫测的世界里，慢慢地度过了自己的人生，而文学把生命剥出新的层次，让人看见新的可能。它让我获得日常琐碎中感受不到的快乐，甚至是痛苦，但每感受一次，我就多活了一次。时间多珍贵啊，能多活一次，就要多活一次。活着，认真笃定地生活，要清醒，要思考，而不是长久地单薄地发笑。 0x01. 世界只有一个真相 黑塞的《悉达多》尽了最大的努力来缓解我们人生的空虚感，尤其是当你一无所有的时候，你依然可以拥有欲望和目标。 世界只有一个真相：原来我期待的圆满的人生，不会到来，换句话说，每一个当下就是圆满。所谓的我，就是过去一切体验的总和。我是我接触过的人、碰到过的物、感受过的情爱、迷失过的痛苦。所有的一切，才有此刻的我，少一点都不是。 我听便灵魂与肉体的安排，去经历罪孽，追逐肉欲和财富，去贪慕虚荣，以陷入最羞耻的绝望，以学会放弃挣扎，学会热爱世界。我不再将这个世界与我所期待的，塑造的圆满世界比照，而是接受这个世界，爱它，属于它。 0x02. 你想活出怎样的人生 四月份，和朋友一同去看了宫崎骏这部收官之作《你想活出怎样的人生》，是日本作家吉野源三郎的著作《你想活出怎样的人生》的同名电影。 在虚无主义无孔不入的时代，清醒观察思考，努力认真生活，无论时代如何困难、残酷，请始终作为一个“人”而活着 —— 也许这就是 83 岁的宫崎骏与内心的矛盾与伤痛纠葛一生后，想要告诉大家的活法。 0x03. 死亡不是终点，遗忘才是 强烈建议大家都去看看《寻梦环游记》，一部具有带有亡灵色彩与死亡教育的动画片。 人的一生，要死去三次： 第一次，当你的心跳停止，呼吸消逝，你在生物学上被宣告了死亡。 第二次，当你下葬，人们穿着黑衣出席你的葬礼，他们宣告，你在这个社会上不复存在，你悄然离去。 第三次，是这个世界上最后一个记得你的人，把你忘记。 这部电影不只是教会了我们应该如何在亲情与梦想之间做选择、如何去面对死亡，它更是一堂教育课，教会了我们如何成长，让我们明白活着的意义。我们是人类的一分子，而人类是充满激情的。医学、法律、商业、科技，这些都是崇高的追求，足以支撑人的一生。但音乐、诗歌、梦想、情感，这些才是我们活着的意义。 0x04. 自由，就是拥有被讨厌的勇气《被讨厌的勇气》一书中的阿德勒心理学其实就是个体心理学，把人当作一个独立的个体，也就是所谓的课题分离。我们要清楚的知道哪些是自己的课题，哪些是别人的课题，没必要为别人的期待而活，珍惜更多当下的时刻，去体验更多的事物，相见什么人就去见，去认识，去告别，做好自己的课题，被别人讨厌也没关系。人生是不断与理想的自己进行比较，不要把人生理解为一条线，而要理解成点的连续。人生就像是在每一个瞬间不停旋转起舞的连续的刹那。暮然四顾时常常会惊觉：已经来到这里了吗？ 在人际关系中面对困难时，应该先考虑 “倾听更大共同体的声音”，阿德勒用了一个更容易理解的比喻，当下的痛楚，如果比作杯中的风暴，那你应该跳出杯子，在太平洋这阵风暴完全不值一提，如果此刻难过，就用更宏大的视角去看待现在的困境。在读万卷书行万里路的过程中，找到更大的世界，去稀释当下的痛苦，当世界的分母变得足够大，痛苦的分子就无关紧要了。 0x05. 巴音布鲁克没有海 属实没想到《飞驰人生》还有续集，不管是第一部还是第二部，都给了我极佳的视觉震撼和观感体验。 影片中最击中我内心的一段对话： ​\t“我们努力了就一定有机会” ​\t“不是的，我努力过无数次了，但我明白，机会只存在于其中的一两次” 巴音布鲁克没有海，只有无尽的热爱，把你的全部奉献给你所热爱的一切。 0x06. 花束般的恋爱 不得不说，这部电影拍得很细腻，我在看的时候已经把我自己完全带入这个男主，我的心情随着麦跌宕起伏，体会到了学生时代恋爱的青涩，也感受到了成年后的爱情和生活多么不容易。 我也懂得了人生重要的一课：不要挽留所有要离开的人。你应该优先考虑你的神经系统，当远离某人可以让你的精神放松下来，给你带来平静时，你就知道是时候放弃这段关系了。 0x07. 等待戈多 《等待戈多》是爱尔兰现代主义剧作家塞缪尔·贝克特的两幕悲喜剧，1953 年首演。这是一个关于等待的故事，人生中那些名为等待的消磨，那些名为绝望的希望。戈多是你打不通的电话，是公交站未到的公车，是明天，是时间，是你现实生活中所有不可期的一切。 人生就是一场漫无目的的等待，生活是一个希望渺茫的困局，人是自己的救世主，等待戈多就是等待自己。 虚无的人生，荒诞的世界，每个人都在等待戈多。 #03 寻找人生的 25 号底片 中学的时候喜欢看意林之类的杂志，里面的作者用乱七八糟的理由跑去旅游，然后说 “阻碍你脚步的永远只有逃离的勇气和对生活的热爱”。 我觉得太对了，可惜 12306 付款方式里没有勇气和热爱，不知道是不是下了盗版。 Jan. 泉州年初和小伙伴们从厦门打车去泉州玩了一遭，刚好碰到大师在免费写春联，排了一晚上终于拿到了哈哈哈 晚上租了一个四人麻将房，锋哥（大师兄）的胜率高达 90%+，被虐惨了 有我这个地道的泉州人带路，狠狠地逛了西街、关岳庙、五店市，后面还深度体验了下蟳埔村的簪花（指偷拍🫤 清源山 May. 漳州五一：南靖土楼 + 长汀古城 Jun. 杭州六月，实验室一起去杭州开会，也算故地重游了。 参加学术会议最深的感受就是：全场四五个小时表现最具专业性的是摄影师。 除了开会，还抽空去灵隐寺、京杭大运河、西湖等各地游玩，体验了人生第一次剧本杀。此外还参观了浙大玉泉校区，和浙大的某实验室深入交流了一番，收获挺多的。 Jun. 西安六月底前往西安 · OPPO 公司结项，开启了长达两个月的实习。 记录人生第一次坐飞机 ✈️ 西安不愧是「碳水之都」 夕阳无限好 公司的健身房有点小，但是挺赞的，因为基本只有我在用 实习期间看到个帖子，说 xx 公司自己一入职就给自己花了 5w：笔记本 + 显示屏 + 一堆软件。下面有老哥锐评，你怎么不说公司还替你建了好几个亿的写字楼，非常真实。在 OPPO 实习的这段时间，只能用公司的电脑，而公司内电脑权限很小，你甚至不能下 QQ 和微信，也不能访问公网云盘，有时候觉得，不是给人配了个电脑，而是给电脑配了个人，人走了是耗材，电脑回到公司循环使用。 我之前一直用的 Windows，后来转向了 Mac，有朋友问我，Windows 和 Mac 怎么选，这个问题很难回答，就像大一暑期的时候问我 C++ 和 Java 这两门课应该怎么选择一样。之前觉得，用 Windows 让我还记得我是个学生，记得大一开学刚买第一个笔记本时的激动，而 Mac 给我的回忆只有极强的续航和轻便，以便我在不同的会议室奔波。 这两个月除了开不完的会议以及赶不完的进度，还投了一篇论文，好在是中了，会议需要作者 12 月到武汉开会，可惜我导不给报销，推掉了。 会议邀请函 奇險天下第一山 · 華山 落花时节又逢君 · 西安交大 Jul. 成都七月去成都找师兄玩！虽说刚毕业 1 个月，但还是迫不及待来见一面～ 这三天自驾游去「川西 · 毕棚沟」游玩，在成都街头走走，到熊猫谷看看国宝 🐼 成都美食真的顶哇！ 在成都的最后一天，恰逢附近有梵高展！ Jul. 银川抓住七月的尾巴，自己一人前往银川三天，其中一天跟了一个小团一日游：中卫 + 沙坡头 + 腾格里沙漠 + 66 号公路。 银川即是 “归雁入胡天” 的古来边关，更是 “大漠孤烟直” 的具像化，览山公园的风景让我着迷，我走过沙漠，骑骆驼 🐫，吹过旷野的风，这种无拘无束，自由掌握人生的感觉真美好。 生活的底片从来不是遥远的白日梦，而是热爱生活的自己。 Oct. 福州国庆节回了一趟福州，见了许久未见的朋友，每一刻都弥足珍贵。 约了本科两位亦师亦友的教授闲聊 感谢好朋友们的热情款待，顺带蹭了俩老师一顿饭哈哈哈 同时郑重的感谢我的好朋友思萍，来福州这段时间麻烦她不少 这次从福州回来，买了一等票，我之前觉得坐一等座是很不划算的行为，直到这时候我才明白，人为什么会去坐一等座，很简单：高铁上坐商务座的是有钱的，坐二等座是有票的，所以坐一等座的是没票而且没钱的。 每每返回福州，总会感伤和怀念那段时光和同学们。有一些东西要靠消失才能证明它的珍贵，如果这是无法返航的日子，那我祝你们一路向前，桥都坚固，隧道都光明，如果不能，那就祝你们曾经的理想能足够支撑当下的生活，等到未来偶然的一天回到这里，再聚的时候，我们能轻轻释怀所有的冷雨，微笑着轻描淡写地说：不过些许风霜罢了。 Oct. 东山岛计划了几月之久的东山岛旅游，工作日的短暂逃离💨 说好的一起看日出呢，就我醒了 Nov. 广州又是参会的一周，做不了学术大佬，就做学术蝗虫！ CCF China Storage’2024｜又见程老师！ 📷 广式早茶 #04 被审判的二十余岁人生 我总觉得，学生时代在大四那年就已经结束了，读研只是一场用来对前四年脱敏的短暂回光返照。每一根网线都在传递着焦虑的信息，只能靠逃避来抵制对未来的恐惧和怀疑。 有一次学长和我闲聊，问我最近学习怎样，我说我没学。他斟酌着措辞跟我隐晦的暗示：“额，有空闲时间不学习我会有内疚感的，你没有吗？” 我沉默了一会，然后不得不痛苦的承认了一个事实，是的，这可能就是我现阶段痛苦的根源。原来我傲慢的讨厌这讨厌那，讨厌世界，讨厌你们，我最讨厌的是我自己，那个傲慢又懒惰的自己。最痛苦莫过于清醒的摆烂。呵，不过话说回来，都是二十来岁，谁还没点儿理想啊。海边绚烂的烟花，路上美丽的夕阳，湖面晴朗的天空，益海楼前火烧的晚霞，落日，晚风，鲜花。这些浪漫与美好毋庸置疑装点了我的青春，但绝不能够成为我青春的全部意义，我要的是热血万丈，我要去的是英雄梦想，我要看的是天地奇观，我要拼尽全力拿到众望所归的成就，大大松一口气地听着别人的称赞，然后再谦虚的说，运气好而已。 有时候，我也会为一些无用的事情落泪，理想主义者的无畏坚持，改革者的魄力，权衡利弊者的仗义直言，已知悲剧结局的少年志气，或者仅仅是次元有壁。无病呻吟久了，有朝一日真得病了，我才突然发现，那些所谓挫折好像也就那么回事，太阳底下没有新鲜事。不过好像真到了需要验证某个成果的年纪了，生活热衷于打断理想主义者的脊梁，但永远有人撞破阻碍着理想主义者的屏障，也永远有人是理想主义者。看到被迫 gap 的同龄人困境，听到别人对他们或怜悯或嗤笑的高高在上的评价，我根本没办法庆幸自己逃过一劫。气愤和痛苦，夹杂着铺天盖地的焦虑将我包围，不是作壁上观，实属无奈，谁都一样。走在向上的钢丝上，越往上走，一旦踩空只会坠落得更加难看，泻水置平地，各自东西南北流。人们以为自己在追求幸福，但向下的自由不是自由，人类区别于一支芦苇，正是在于思维流动的光辉。 这一年，过得自信心全无，读研就像是某种无形的寄生虫，对人的侵蚀是无声无息、不温不火的，每天都透支一点点，一年后就消耗掉你所有的热情和活力。这一年我也终于理解了为什么工作的人越来越少发朋友圈，真的上纲上线倒也没有，但以前发是坦坦荡荡的分享快乐，现在发是如履薄冰，感觉像是在吸引炮火，真的丧失了很大一部分的自由。我也开始理解为什么有人会沉溺酒精、尼古丁、短视频，因为日子过到一定程度，有时候真的需要一点麻醉剂来饮鸩止渴。也许这时候有人又会说：年轻人就是吃不了苦、无病呻吟。辛苦就是辛苦，各有各的辛苦，并不是不如某某辛苦，就没有资格说出来。自嘲是为了不麻木，重视自己的感受。这一代的年轻人并非软弱，即使说了这么多丧气话，大家也一直在努力生活。只不过满腹牢骚者也可以把工作干得很好，胆怯者也可以颤颤巍巍的成为英雄。我开始意识到，解构才是对个体的真正尊重，人生无数次阅历的积攒，就只为在某个重要的时刻给予我们面对的勇气。 无所谓，每个人都有自己的南墙要撞！ 这一年，看着身边二十啷当岁的朋友。有的啤酒肚了，头发开始掉了，被女孩甩了。如果问我，生活会不会将当初的少年打趴，我不知道，但生活一定会将当初的少年打散。再聚首，再问起当年的少年意气，多数人都会不好意思地笑笑，然后说，那时候不懂事。而喝多的时候，就全成了让自己觉得矫情的眼泪。往往这个时候，我想不出来什么安慰的话。我确实没有什么话想讲，只觉得胸口像是春夏的雷雨天前那样发闷。人的心态会经历很多个奇妙的转变，这种转变甚至都不需要什么道理和铺垫，就好像你本来好好地在路上走着，然后一下子和路边的陌生人一起举着手，大声欢呼或者低着头默哀一样。 我们终于活到了小时候最羡慕的年纪，却没有成为小时候最想成为的人。毕业之后的我们都在害怕自己没出息，害怕自己买不起房子车子，遇不到喜欢自己的人，每次过年回家面对什么时候结婚，什么时候要孩子这种话题，其实更害怕的是面对许久不见的父母。我们都是普通的孩子，我们都想让自己的爸爸妈妈更自豪一些，更幸福一些。可我们自己的幸福都还像个石子，在生活的湖面上打着水漂。这么多年上学上过来，努力地学习，考试，可到最后才发现，普通的孩子只是聚光灯下的基石。想想这些年，我有很多以为近在咫尺的时候，我努力地抓啊抓，可就是什么都抓不到。再多的书也比不上导师满意的 PPT 和恰到好处的谄媚。我一边和自己的妈妈保证说，以后我一定会有出息的，一边成晚成晚的睡不着觉。这样的场景太多了，多到我觉得每一场跌宕起伏的人生经历总是会有个这样毫不意外的结局。 爬到山顶的时候，跑向海边的时候，以为我不再是我的时候。 我总以为山顶的石头不一样，升起的太阳不一样。 我总以为海边吹的风不一样，尽头的那边不一样。 我以为我不再是我，我爱她，她也爱我。 可惜，山还是山，海还是海。 我拥有很多人情绪崩溃的瞬间，他们有的在我身边，有的靠互联网奇缘。我没有和其中的任何一个人有过合照，有一起吃过一顿饭，没有听到过他们的声音，也没有听太多他们的故事。我只是短暂地让他们靠了一下岸。 而当生活的节奏反复无常，日历上的时间不断反转，我总是会在人生的重要时刻丧失无穷无尽的仪式感。我常觉得所有人都是被上了锁的自由花，偶尔被阳光照耀的时候会觉得自己配的上很多东西。像是野马找到了河边的水，牵牛爬上了缺角的屋檐。我很难分辨压在自己身上的到底是挡住眼睛的石头，还是粘住了后背的五指山。任何一种喘不过来气的定义都被他人掌控，我带着面罩，别人掐着氧气管。等到自己坚持不住的那一刻，很难说是呼吸的缺失，还是自己早就病入膏肓。 好多事情想不明白，只能先活着，看以后能不能想明白了。 人人都得活着，所以人人都得藏着。我偶尔就在这样沉默的冰河之下，悄悄探出头来，感受下有温度的太阳。然后再沉下去，告诉别人海面之上的故事。 #05 人生南北多歧路网上冲浪看到一个很有意思的话题：人一辈子，最重要的到底是什么？ 原回答如下，感触颇深 三岁那年，我紧握着手中的棒棒糖，坚定的认为那最重要。 五岁那年，我花了整整一个下午，逮住那只蜻蜓，那一刻，它好像是最重要的。 七岁那年，我看着同桌手中的奖状，带着羡慕和一点点嫉妒，觉得那也许是最重要的。 九岁那年，仰躺在树荫下，阳光斑驳的洒在脸上，一个悠闲的暑假于我而言是如此重要。 十三岁那年，我意识到，重点高中的录取通知书对我的人生很重要。 十六岁那年，坐在教室里，微风穿堂，盯着前排姑娘的马尾出了神，忽然觉得就这样一直下去也不错。 十八岁那年，我日夜苦读，求神拜佛，只为一张大学录取通知书。 二十二岁那年，告别校园，懵懂的踏进所谓社会，一份工作又成了最重要的。 二十四岁那年，迎来了我的婚礼，我看着满堂宾客和我的新娘，她当然不是我十六岁时的那个姑娘，心中只觉得有些遗憾，不过那一刻，我的新娘就成为了我最重要的人。 二十五岁那年，我和狐朋狗友推杯换盏，吹牛打屁，不谙世事的年纪，只觉得面子最重要。 二十六岁那年，我焦急的等在产房外，啼哭声打破了宁静，我知道，更重要的来了。 三十三岁那年，被房贷和车贷搞的焦头烂额的我觉得，钱可太重要了。 三十八岁那年，一生强硬的爸爸开始征求我的意见，那一刻我猛然意识到，他终于是老了。 还是三十八岁那年，妈妈再没有训斥过我，而是不厌其烦的念叨，还带着些小心翼翼，我知道，她也会老的。 又是三十八岁那年，儿子不再黏我，他有了自己的伙伴的生活，我知道，此后的一辈子，他只会不停的远离我。 那年，我恍然，可能时光才是这世上最重要的吧。 四十岁那年，看着乱七八糟的体检报告，我才想起，我从来没觉得自己重要。 四十五岁那年，浑浑噩噩度过了半生，挺着啤酒肚在工位摸鱼的时候，回想起年少的梦想，从未觉得梦想如此重要。 五十岁那年，看着儿子和一个还不错的姑娘步入婚姻殿堂，我眯着眼看着台上的儿子，不知道新娘是不是他十六岁时爱上的那个姑娘。但还是觉得儿子的幸福比我的幸福更重要。 五十五岁那年，我气喘吁吁的跟在孙子屁股后面，生怕他摔跤，那一刻，我从未给予孙子远大的希冀，他平安快乐便是最重要的。 六十岁那年，我将父母葬在了一起，年纪大了，很多事也便看开了许多，我没有流泪，只觉得，爸爸的责骂和母亲的絮叨在那一刻无比重要。 七十岁那年，妻子终是先走一步，儿子儿媳事业有成，孙子在外地读大学，我只能无所事事的在大街上闲逛，莫名觉得，妻子可比那广场舞的老太太重要的多。 七十五岁那年，在医院里，医生让我出去，单独留下我儿子的时候，我明白时间不多了，趁着这功夫我给孙子打了个电话，我想告诉他，如果你在十六岁的时候爱上过一个姑娘，可千万要握紧，就像握紧三岁那年手中的棒棒糖。思来想去，又觉得多少有些为老不尊，电话接通后，只说了一句爷爷想你了，有空来看看我。医生宽慰我问题不大，我笑着告诉医生，人生没有大问题，其实把日子过下去是最重要的。 七十六岁那年，孙子回来看我了，让他看到我奄奄一息的样子心里多少还有点别扭，儿子儿媳守在床边，泣不成声，我没有多余的精力思考什么最重要了，我只想着后事从简，儿子儿媳年纪也不小了，身体遭不住，孙子刚刚参加工作不久，请假不好请，别给领导留下坏印象。 正想着，不知哪里吹来一阵风，迷了我的眼，睁开眼，爸爸妈妈牵着手，脸上挂着我最熟悉的笑容，他们都是年轻的样子，张开双臂示意我抱抱，我好想他们啊，所以我毫不犹豫跳下床，向他们飞奔而去，奔跑中，我变成了六十岁的样子，五十岁的样子，四十岁的样子，三十岁的样子，直到变成三岁的样子，他们终于又能抱起我了，我向他们点点头，他们也笑着点头，带着我转身离开。我回望一眼儿子儿媳和孙子，他们抱着七十六岁的我，嚎啕大哭，虽然不舍，不过没关系，我知道他们依然可以过的很好。 所以，什么最重要？什么都重要，但又不是非有不可。初中的亲戚小孩问我寒假作业不写有什么后果吗。我说有的，比如你会拥有一个没有作业的寒假。当然，你也会失去一些什么，比如寒假作业。 你曾经认为最重要的，总有失去的那天。 时间改变了太多东西了。 遗憾才是人生的常态。 年少的标志之一，就是对人生的旷野感到恐惧。 这不稀奇，当然也不值得去忧虑，因为它来源于一种与现实之间轻飘飘的，遥远的疏离。 我完全无法想象当我的生命趋于麻木，当我困守在一间窄窄的房子里，开始为钱发起了愁，为生计开始了奔波，那是怎样一副光景。 而这样的一生到底有什么意义呢。 不要恐惧，不要害怕你的自由和浪漫会失去。 我说了人生就如同一片旷野，当那漫长且潮湿的雨季来临以后，你就会发现浅小的水洼成为了汪洋，萤火虫成了海上的月亮，蝉也化作挥动着翅膀的鲸。 去赋予生活意义，也赋予生活爱和有趣。 一个人思虑太多，就会失去做人的乐趣，一直往前走吧，会有你想要的答案的。 年轻嘛，未妨惆怅是清狂，但我知道，人不能永远过着打球、唱歌、夜宵这样放纵的日子，一方面，岁月无情，另一方面，美丽的东西往往也太过单薄，成为一个好的人就是要有一种对于世界的开放性、一种信任自己难以控制的无常事物的能力… 这种生活的根基就在于愿意被暴露在世界中，就在于更像一株植物，而不是一颗宝石。 现代人格外接受不了不确定性，于是热衷于相信存在一套稳定的秩序，费尽千辛万苦地找一个尽可能高的位置把自己放进去，高塔当然辉煌，高的位置当然可以很好的安放一个人，可是转头看，凡有日月星辰照耀之地，又何处不可寄此一生？天地广阔，四季春秋，等年华老去，明天的我们也许会去找一些更厚重的东西来承担更长久的人生，比如去祖国的宏大叙事里做一枚齿轮，不管你信不信，朋友，对于齿轮来说，运转不是致命的，生锈才是。 所以，困住你脚步的到底是什么？ 我的意思是，当你意识到生命只有一次的时候，你的第二次生命就开始了。 #06 这江湖没什么好的，也就酒还行似乎本科时候也没那么难熬，可能是因为当时在乎的人都在身边吧，我是个贼念旧的人，这点其实不好，也不适合互联网。 2019 年以前腾讯放弃了电商，默认了自己没有电商基因、京东在 3C 电子做着防守、字节跳动正准备发布一款叫 “抖音” 的音乐社交软件、那家叫拼多多的初创公司还在农村里乱转，卖点可怜的水果拼团生意，那会的耀子还和华子绑在一起，大家还觉得是个低端品牌，至于比亚迪，绝大多数人连简历都不曾投递过，当然，从 2020 年开始一切都变了。 正如公司所信仰的拥抱变化一样，其实我们也拥抱了不少变化，比如还没出生的时候就遇到了计划生育，刚出生赶上了非典，到了喝奶粉的年纪遇到了三鹿毒奶粉，没安分几年又来了多种版本的禽流感，小学爱吃校门口大锅炸的辣条，后来发现用的全是地沟油，玩游戏的时候赶上了防沉迷，好不容易混进大学被疫情封了三年，毕业了发现大学生比狗都多，想吃外卖了到了发现是国潮包装。 我们这一代人绝大多数都看过考试周破防，对我来说是大二的暑期，我喜欢去买一瓶热带风味冰红茶，这是我本科过得最开心的一个暑假之一了，下学期的课很少很少，然后要保研啦，保研去哪里不知道呢，反正有很多很多的可能性，我到时候一定要选一个喜欢的学校，喜欢的城市，冰红茶的瓶盖上有时会写着再来一瓶，我总是不着急兑换，因为觉得来日方长，未来有一天我收拾东西提桶跑路的时候发现了当年的瓶盖，才意识到好像我的青春只剩下了谢谢惠顾。 忘了在哪里看到的鸡汤：“不要谩骂以前的自己，TA 当时一个人站在雾里也很迷茫”。 但我从不骂，因为我他丫的现在还在雾里。 政治老师曾说过：“这个选项没有错，只是它不符合题意”，我想，在这个时代，我们也是。 我一直是个很悲观的人，也没什么安全感，我走在一直变强的路上，我现在有能力屏蔽掉许多坎坷，但终有一天，我会遇到迈不过去的门槛，压抑不了的负面情绪。我始终会想，这时候，谁还会在我身边，我希望大家都在，但这个显然太过天真了，我现在给不出答案，但其实与人的每一次相遇我都在想，TA 会怎么做。我厌恶欺骗，相对于欺骗别人，我更厌恶被别人欺骗。所以我是个很慢热的人，我的很多值得交心的朋友，在我决定敞开心扉的时候，早就不在我身边了。 在此声明一下哥们不是回避型人格，哥们是逃难型人格，每次感觉到别人一丁点冷落，哥们都会屁滚尿流地收拾包袱跑路。 我这人从很小的时候就争强好胜，我一直以为是我自己赢了，直到有一天看着镜子，才知道自己输了。在我最美好的时候，我最在意的人都不在我身边。从认识我到对我失望，到底需要多长时间，我每认识一个朋友，就会在心里想一遍这个问题。如果几年前你问我会不会害怕失去而逃避未来的相遇，我会回答是的，但现在不会是。因为我已经失去过很多了，不再差这点了。 以我的能力和意志力，永远不会迎来把过往的错误和懊悔全部弥补的那一天，但以我的记忆力和心态，一定有毫无内疚把他们全部抛之脑后的那一天。人的烦恼就是记性太好，如果可以把所有事都忘掉，以后每一天都是个新开始，你说多好。因为我总是很擅长把一个可以花精力解决的问题，变成一个需要时间接受的事实。 学计算机的总有种错觉，仿佛自己穷举出所有的可能性，然后选取一个不会太差的决定，也有时会觉得，很多事靠卷或是努力可以解决，这几年发现并不是。朋友问我的人生是贪心还是动态规划，我说我只会暴力，但我很喜欢 KMP 算法：一个人能走多远不取决于在顺境中能走多快，而在于他在逆境中能否找到曾经的自己。 有时候会觉得，命运不公平。人和人是不一样的，有的人生下来就和开了挂一样，有钱开朗，家庭温馨，一路上会遇到很多有趣的人，很多朋友，老了跟人吹牛都有很多故事可讲，成为别人眼中酷酷的老头或者老婆婆，对这样的人来说，每件往事都很珍贵，但也都没那么珍贵，就像她可能会在意这周的演唱会，会激动的好几天睡不着抢票，做规划，要是抢不到也没有什么大不了，她可以飞到另一个城市去看下周的演唱会，但有些人不一样，他们一辈子就呆在一片很小很小的地方，一共认识不了几个人，没有几个人会真正在乎他，也没有几件他真正在乎的事。 有时候又会觉得，命运挺公平，至少过程，是独一无二的，是有开心的时刻的。 我始终觉得，人非草木，人活一世，更多的只是活几个瞬间。 反正这个世界挺没意思的，要是没了我那几个朋友，就更没意思了。 我很重感情，这是优点也是弱点。 我由衷感谢那些还陪在我身边的朋友们。 于道各努力，千里自同风！ 还有许多朋友遗失了合照和相片，找了一晚上实在没找到 😭 #07 UNICEF｜联合国儿童基金会这一年，也可以尽自己所能做一些慈善活动，为什么会有这个想法呢。我想借用中科院黄国平博士的一段话：人情冷暖，生离死别，固然让人痛苦与无奈，而贫穷则可能让人失去希望。我的理想不伟大，只愿年过半百，归来仍是少年，希望还有机会重新认识这个世界，不辜负这一生吃过的苦。最后如果还能做出点让别人生活更美好的事，那这辈子就赚了。 大爱壁纸 #08 超级全满贯｜Fan Z.D.从小学一年级我就开始打乒乓球了，打了 12 年的球，至今已经二十余年的间隔了。 今年奖励自己新买了一副乒乓球拍，作为球迷也见证了樊振东的夺冠之路，心满意足。 奥运会男单那两场比赛我已经看了无数次，但是我还是会选择点进来： 七局死斗，一个人就是千军万马；巴黎奥运会：樊振东 VS 张本智和 巴黎奥运会：樊振东 4-1 莫雷高德，实现超级全满贯伟业 我非常喜欢的几位乒乓球运动员： 张继科：抢班夺朝，这么多年只有张继科一人做到了，真正意义上的天赋型选手 马龙：GOAT 无需多言 樊振东：16 岁横空出世，天降紫薇星，17 岁成为男乒史上最年轻世界冠军，三剑客时代后我唯一爱看的选手 简单介绍下东哥的职业生涯 2013 年樊振东横空出世，在队内选拔赛中原本并没有获得参赛资格，而是赛后教练组动用机动名额给了樊振东，这才让他第一次参加巴黎世乒赛，但是在第三轮比赛中就输给了张继科，此时樊振东年仅 16 岁。 2015 年樊振东再次参赛，成功打进苏州世乒赛半决赛，尽管此刻的他技术进步明显，但遇到了巅峰发胶龙，还是被 4 : 1 带走，止步半决赛。 之后樊振东又打进世界杯决赛与马龙会师，没想到被马龙横扫夺冠。 2016 年里约奥运会樊振东当时世界排名第二，却最终以 P 卡参赛，那一年是龙队横扫张继科夺冠，划时代的决赛。 2016 年樊振东成功打进世界杯决赛，并且以 4 : 1 的大比分战胜许昕，夺得首个三大赛男子单打冠军。 2017 年杜塞尔多夫世乒赛，樊振东首次打入决赛，但是以两分之差遗憾输给龙队，赛后也成为了他的意难平。 2018 年世界杯在马龙出局的情况下，樊振东顶住压力战胜波尔再夺世界杯冠军。 2019 年布达佩斯世乒赛，此时樊振东世界排名第一，却爆冷输给梁靖崑。 2019 年成都世界杯，马龙意外被张本智和打败无缘决赛，而后樊振东在主场战胜了张本智和蝉联冠军。 2020 年世界杯决赛，樊振东时隔五年决赛再遇马龙，决胜局以两分之差险胜马龙成为世界杯四冠王！ 2021 年东京奥运会男单决赛，樊振东首次奥运单打便以 4 : 2 的比分遗憾输给马龙摘银。 2021 年休斯顿世乒赛樊振东再一次打进决赛，这也是罕见的决赛外战，樊振东不出意外 4 : 0 横扫小莫拿下首个世乒赛冠军。 2023 年德班世乒赛决赛，樊振东战胜王楚钦蝉联世乒赛单打冠军，再一次捧起圣伯莱杯。 2024 年巴黎奥运会，樊振东的 last dance 表明了自己的决心，并成功击败小莫拿下自己生涯的首个奥运单打冠军。 从 13 年看小胖崭露头角，到乒坛 11 年的角逐，他乒乓球生涯的大部分时间，都和巅峰张继科以及巅峰马龙重叠，一拍一拍从三剑客的时代打出自己的时代。三大赛单打拥有四个世界杯冠军，两个世乒赛冠军，一个奥运会冠军，三大赛团体冠军更是数不胜数。 解说口中的樊振东是普通人一生的缩影，其实不是的，他是天才，但是大满贯这条路他走了十一年，但未来不止于此，一个时代的到来，它不会轻易落下帷幕！ Fan Z.D. #09 2024 东成西就一年前的我，略带期待地向未来发出诘问，一字一句：“一年后的你，生活有答案了吗？” 人类常常如此，有时候连自己的问题是什么都没弄清楚，就敢执着地去索要答案。 于是我开始复盘，在飞驰的时光里，努力筛选一些拿得出手的成绩。不得不说，每当复盘的时候，数据还是挺能安慰到人的，如非为了申请或吹嘘，我大概很少会主动想起所谓加身的荣誉，这些其实只占珍贵时光中的很少一部分。 GitHub LeetCode Apple Music 集满 Jay Chou 所有专辑 Netease Cloud Music 高德地图 知乎 专利 花各有期 手机相册里的 2024 #10 你看，每个人都在闪闪发光点开了很久没看的朋友圈，当初想的是打着防止被骚扰的理由换账号，实际上是接受不了和身边朋友的落差，很多人去名校读研，或者留学，每个学校都赫赫有名，许多人也都有自己的归宿。 “你看，每个人都在闪闪发光。“ 我对自己说。就像烟花一样，我好喜欢烟花，恨不得在每个句子里都上一颗火星，这样整篇文章就看起来熠熠生辉。 我知道，应该接受过去、享受当下、期待未来， 可我永远只会后悔过去、浪费当下、焦虑未来。 我们总是把自己未经历或者已经经历过的时光称作最美好的时光，我突然开始怀疑，其实从来没有哪段时光是美好的，所有时光都是痛苦的，所谓美好，只是大脑编出来的一个美妙幻梦，让我们在尘世间有所寄托。我开始怀疑，会不会所有对过去的怀念，全部来自于不用真的再去经历那些事情，本质上只是旁观者的幸灾乐祸。我想不是的，起码过年放烟花的日子，是实实在在的开心的。不论春晚有多无聊，当主持人的倒数淹没在鞭炮声里，火树银花凌空绽放，整座城市隆隆作响，震颤从天空传到大地，极尽所能地宣告我们又活过一年，捂住耳朵又不舍得错过满天绚烂，仰起头，眼底惊喜和火光交相辉映。 这一年我的心态也转变了不少，以前我总是想着追寻那个所谓的成功，所谓的万事求全，但回过头来你会发现和伙伴一起被现实打得满地找牙的过程，似乎才是最美妙的。我很喜欢我朋友和我说过的一句话，他说巅峰的快乐总是短暂的，你知道人生最美好的感受是什么吗？虚惊一场，对吧！最美好的感觉就在这一张一弛之间。 当你看尽人类所有的历史，悲欢离合，英雄小人，爱恨情仇，都只在这么一颗小小的蓝色星球之上，你会不会有这种感觉，最终我们都会化为尘土，那为什么要做所谓的好事，还有难的事呢？如果这个宇宙的结局是注定、是消亡、是归于死寂，那或许更说明，过程才是最重要的，这是我们能够改变的唯一的事。 2024 年在漫长的折磨中，带着无尽苦涩，终究也是结束了，有人欣喜雀跃，有人遗憾痛悔，更多人在平淡艰巨的日子里，朝着更大的光荣彼岸无声努力着。 如果未来变得更糟，也没关系，我们有的是时间去变成更好的人。 关于离别，是制造羁绊需要承担的掉眼泪的风险。 关于未来，是做该做的事并承担它的事与愿违。 新的一年里，我只希望趁着自己还有劲儿，多笑一笑，百年需笑三万六千场，一日一笑，此生快哉！ 今天这个日落真的很完美，我就在此刻为这篇文章画上句号，尽情享受这一刻。 我们明年再见👋","categories":["年终总结"]},{"title":"A Study of Linux File System Evolution","path":"/post/系统与体系结构/a-study-of-linux-file-system-evolution/","content":"Virtual File System (VFS)上图解构如下： 应用层指用户编写的程序，如我们的 hello.c GNU C 库（glibc）即 C 语言标准库，例如在编译器章节介绍的 libc.so.6 文件，它 包含了 printf、malloc，以及本章使用的 fopen、fread、fwrite 等文件操作函数 用户程序和 glibc 库都是属于用户空间的，本质都是用户程序 应用层的程序和 glibc 可能会调用到 “系统调用层（SCI）” 的函数，这些函数 是 Linux 内核对外提供的函数接口，用户通过这些函数向系统申请操作。例如，C 库 的 printf 函数使用了系统的 vsprintf 和 write 函数，C 库的 fopen、fread、fwrite 分别 调用了系统的 open、read、write 函数，具体可以阅读 glibc 的源码了解。 由于文件系统种类非常多，跟文件操作相关的 open、read、write 等函数经过虚 拟文件系统层，再访问具体的文件系统。 总的来说，为了使不同的文件系统共存， Linux 内核在用户层与具体文件 系统之前增加了虚拟文件系统中间层，它对复杂的系统进行抽象化，对用户提供了统一的文件操作接口。无论是 ext2&#x2F;3&#x2F;4、FAT32、NTFS 存储的文件，还是 &#x2F;proc、&#x2F;sys 提供 的信息还是硬件设备，无论内容是在本地还是网络上，都使用一样的 open、read、write 来访问，使得 “一切皆文件” 的理念被实现，这也正是软件中间层的魅力。 Linux System Calls从上图可了解到，系统调用（System Call）是操作系统提供给用 户程序调用的一组“特殊”函数接口 API，文件操作就是其中一种类型。实际 上，Linux 提供的系统调用包含以下内容： 进程控制：如 fork、clone、exit 、setpriority 等创建、中止、设置进程优先级的操作。 文件系统控制：如 open、read、write 等对文件的打开、读取、写入操作。 系统控制：如 reboot、stime、init_module 等重启、调整系统时间、初始化模块的系统操作。 内存管理：如 mlock、mremap 等内存页上锁重、映射虚拟内存操作。 网络管理：如 sethostname、gethostname 设置或获取本主机名操作。 socket 控制：如 socket、bind、send 等进行 TCP、UDP 的网络通讯操作。 用户管理：如 setuid、getuid 等设置或获取用户 ID 的操作。 进程间通信：包含信号量、管道、共享内存等操作。 从逻辑上来说，系统调用可被看成是一个 Linux 内核与用户空间程序交互的中间人，它把用户进程的请求传达给内核，待内核把请求处理完毕后再将处理结果送回给用户空间。它的存在就是为了对用户空间与内核空间进行隔离，要求用户通过给定的方式访问系统资源，从 而达到保护系统的目的。 也就是说，我们心心念念的 Linux 应用程序与硬件驱动程序之间，就是各种各样的系统调用，所以无论出于何种目的，系统调用是学习 Linux 开发绕不开的话题。 接下来通过「文件操作」的两个实验，来演示使用「C 标准库」与「系统调用」方式的差异。 File Ops｜C Standard Lib本小节讲解使用通用的 C 标准库接口访问文件，标准库实际是对系统调用再次进行了封装。使用 C 标准库编写的代码，能方便地在不同的系统上移植。 例如 Windows 系统打开文件操作的系统 API 为 OpenFile，Linux 则为 open，C 标准库都把它们封装为 fopen，Windows 下的 C 库会通过 fopen 调用 OpenFile 函数实现操作，而 Linux 下则通过 glibc 调用 open 打开文件。用户代码如果使用 fopen，那么只要根据不同的系统重新编译程序即可，而不需要修改对应的代码（代码可移植性）。 在开发时，遇到不熟悉的库函数或系统调用，要善用 man 手册，而不要老是从网上查找。C 标准库提供的常用文件操作简介如下： 1. fopen()12#include &lt;stdio.h&gt;FILE *fopen(const char *pathname, const char *mode); pathname 参数用于指定要打开或创建的文件名。 mode 参数用于指定文件的打开方式，注意该参数是一个字符串，输入时需要带双引号： “r”：以只读方式打开，文件指针位于文件的开头。 “r+”：以读和写的方式打开，文件指针位于文件的开头。 “w”：以写的方式打开，不管原文件是否有内容都把原内容清空掉，文件指针位于文件的开头。 “w+”： 同上，不过当文件不存在时，前面的“w”模式会返回错误，而此处的“w+”则会创建新文件。 “a”：以追加内容的方式打开，若文件不存在会创建新文件，文件指针位于文件的末尾。与“w+”的区别是它不会清空原文件的内容而是追加。 “a+”：以读和追加的方式打开，其它同上。 fopen 的返回值是 FILE 类型的文件文件流，当它的值不为 NULL 时表示正常，后续的 fread、fwrite 等函数可通过文件流访问对应的文件。 2. fread()123456#include &lt;stdio.h&gt;size_t fread(void *ptr, size_t size, size_t count, FILE *stream);// usagechar buffer[1024] = &#123;0&#125;;fread(buffer, sizeof(char), sizeof(buffer), p); stream 是使用 fopen 打开的文件流，fread 通过它指定要访问的文件，它从该文件中读取 count 项数据，每项的大小为 size，读取到的数据会被存储在 ptr 指向的数组中。fread的返回值为成功读取的项数（项的单位为 size）。 3. fwrite()12#include &lt;stdio.h&gt;size_t fwrite(void *ptr, size_t size, size_t count, FILE *stream); 它的操作与 fread 相反，把 ptr 数组中的内容写入到 stream 文件流，写入的项数为 count，每项大小为 size，返回值为成功写入的项数（项的单位为 size）。 4. fclose()fclose 库函数用于关闭指定的文件流，关闭时它会把尚未写到文件的内容都写出。因为标准 库会对数据进行缓冲，所以需要使用 fclose 来确保数据被写出。 12#include &lt;unistd.h&gt;int close(int fd); 5. fflush()fflush 函数用于把尚未写到文件的内容立即写出。常用于确保前面操作的数据被写 入到磁盘上。fclose 函数本身也包含了 fflush 的操作。 12#include &lt;stdio.h&gt;int fflush(FILE *stream); 6. fseek()fseek 函数用于设置下一次读写函数操作的位置。 12#include &lt;stdio.h&gt;int fseek(FILE *stream, long offset, int whence); 其中的 offset 参数用于指定位置，whence 参数则定义了 offset 的意义，whence 的可取值如下： SEEK_SET：offset 是一个绝对位置。 SEEK_END：offset 是以文件尾为参考点的相对位置。 SEEK_CUR：offset 是以当前位置为参考点的相对位置。 7. Usage12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;stdio.h&gt;#include &lt;string.h&gt;//要写入的字符串const char buf[] = &quot;filesystem_test:Hello World! &quot;;//文件描述符FILE *fp;char str[100];int main(void)&#123; //创建一个文件 fp = fopen(&quot;filesystem_test.txt&quot;, &quot;w+&quot;); //正常返回文件指针 //异常返回NULL if(NULL == fp)&#123; printf(&quot;Fail to Open File &quot;); return 0; &#125; //将buf的内容写入文件 //每次写入1个字节，总长度由strlen给出 fwrite(buf, 1, strlen(buf), fp); //写入Embedfire //每次写入1个字节，总长度由strlen给出 fwrite(&quot;Embedfire &quot;, 1, strlen(&quot;Embedfire &quot;),fp); //把缓冲区的数据立即写入文件 fflush(fp); //此时的文件位置指针位于文件的结尾处，使用fseek函数使文件指针回到文件头 fseek(fp, 0, SEEK_SET); //从文件中读取内容到str中 //每次读取100个字节，读取1次 fread(str, 100, 1, fp); printf(&quot;File content: %s &quot;, str); fclose(fp); return 0;&#125; File Ops｜System CallsLinux 提供的文件操作系统调用常用的有 open、write、read、lseek、close 等。 1. open()1234567891011121314151617#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;int open(const char *pathname, int flags);int open(const char *pathname, int flags, mode_t mode);// usage-1fd = ::open(filename, O_RDWR | O_DIRECT | O_CREAT, 0666);// usage-2#include &lt;fcntl.h&gt;...int fd;mode_t mode = S_IRUSR | S_IWUSR | S_IRGRP | S_IROTH;char *filename = &quot;/tmp/file&quot;;...fd = open(filename, O_WRONLY | O_CREAT | O_TRUNC, mode);... Linux 使用 open 函数来打开文件，并返回该文件对应的文件描述符。函数参数的具体说明如下： pathname：要打开或创建的文件名； flag：指定文件的打开方式，具体有以下参数，见下表 flag 参数值。 标志位 含义 O_RDONLY 以只读的方式打开文件，该参数与 O_WRONLY 和 O_RDWR 只能三选一 O_WRONLY 以只写的方式打开文件 O_RDWR 以读写的方式打开文件 O_CREAT 创建一个新文件 O_APPEND 将数据写入到当前文件的结尾处 O_TRUNC 如果pathname文件存在，则清除文件内容 除此之外，还有 O_DIRECT 之类的，可以查 man 手册： C 库函数 fopen 的 mode 参数与系统调用 open 的 flags 参数有如下表中的等价关系。 fopen 的 mode 参数 open 的 flags 参数 r O_RDONLY w O_WRONLY | O_CREAT | O_TRUNC a O_WRONLY | O_CREAT | O_APPEND r+ O_RDWR w+ O_RDWR | O_CREAT | O_TRUNC a+ O_RDWR | O_CREAT | O_APPEND ⚠️ mode：当 open 函数的 flag 值设置为 O_CREAT 时，必须使用 mode 参数来设置文件 与用户相关的权限。mode 可用的权限如下表所示，表中各个参数可使用 “|” 来组合；或者直接用数字表示更快，比如 0666。 \\ 标志位 含义 当前用户 S_IRUSR 用户拥有读权限 \\ S_IWUSR 用户拥有写权限 \\ S_IXUSR 用户拥有执行权限 \\ S_IRWXU 用户拥有读、写、执行权限 当前用户组 S_IRGRP 当前用户组的其他用户拥有读权限 \\ S_IWGRP 当前用户组的其他用户拥有写权限 \\ S_IXGRP 当前用户组的其他用户拥有执行权限 \\ S_IRWXG 当前用户组的其他用户拥有读、写、执行权限 其他用户 S_IROTH 其他用户拥有读权限 \\ S_IWOTH 其他用户拥有写权限 \\ S_IXOTH 其他用户拥有执行权限 \\ S_IROTH 其他用户拥有读、写、执行权限 2. read()123456789101112#include &lt;unistd.h&gt;ssize_t read(int fd, void *buf, size_t count);// usage#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;char buf[20];size_t nbytes;ssize_t bytes_read;int fd;nbytes = sizeof(buf);bytes_read = read(fd, buf, nbytes); read 函数用于从文件中读取若干个字节的数据，保存到数据缓冲区 buf 中，并返 回实际读取的字节数，具体函数参数如下： fd：文件对应的文件描述符，可以通过 fopen 函数获得。另外，当一个程序运行时，Linux 默认有 0、1、2 这三个已经打开的文件描述符，分别对应了标准输入、标准输出、标准错误输出，即可以直接访问这三种文件描述符 buf：指向数据缓冲区的指针 count：读取多少个字节的数据 3. write()12345678910111213#include &lt;unistd.h&gt;ssize_t write(int fd, const void *buf, size_t count);// usage#include &lt;sys/types.h&gt;#include &lt;string.h&gt;char buf[20];size_t nbytes;ssize_t bytes_written;int fd;strcpy(buf, &quot;This is a test &quot;);nbytes = strlen(buf);bytes_written = write(fd, buf, nbytes); write 函数用于往文件写入内容，并返回实际写入的字节长度，具体函数参数如下： fd：文件对应的文件描述符，可以通过 fopen 函数获得 buf：指向数据缓冲区的指针 count：往文件中写入多少个字节 4. close()1234567891011121314int close(int fd);// usage#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#define LOCKFILE &quot;/etc/ptmp&quot;int pfd;FILE *fpfd;if ((fpfd = fdopen (pfd, &quot;w&quot;)) == NULL) &#123; close(pfd); unlink(LOCKFILE); exit(1);&#125; 5. lseek()lseek 函数可以用与设置文件指针的位置，并返回文件指针相对于文件头的位置。 1off_t lseek(int fd, off_t offset, int whence); 它的用法与 flseek 一样，其中的 offset 参数用于指定位置，whence 参数则定义了 offset 的意义，whence 的可取值如下： SEEK_SET：offset 是一个绝对位置。 SEEK_END：offset 是以文件尾为参考点的相对位置。 SEEK_CUR：offset 是以当前位置为参考点的相对位置。 Usage1234567891011121314151617181920212223242526272829303132333435363738#include &lt;sys/stat.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdio.h&gt;#include &lt;string.h&gt;//文件描述符int fd;char str[100];int main(void)&#123; //创建一个文件 fd = open(&quot;testscript.sh&quot;, O_RDWR|O_CREAT|O_TRUNC, S_IRWXU); //文件描述符fd为非负整数 if(fd &lt; 0)&#123; printf(&quot;Fail to Open File &quot;); return 0; &#125; //写入字符串pwd write(fd, &quot;pwd &quot;, strlen(&quot;pwd &quot;)); //写入字符串ls write(fd, &quot;ls &quot;, strlen(&quot;ls &quot;)); //此时的文件指针位于文件的结尾处，使用lseek函数使文件指针回到文件头 lseek(fd, 0, SEEK_SET); //从文件中读取100个字节的内容到str中，该函数会返回实际读到的字节数 read(fd, str, 100); printf(&quot;File content: %s &quot;, str); close(fd); return 0;&#125; Common header files我们常常会用到以下头文件，此处进行简单说明，若想查看具体的头文件内容，使用 locate 命令找到该文件目录后打开即可： 头文件 stdio.h：C 标准输入与输出（standard input &amp; output）头文件，我们经常使用的打印函数 printf 函数就位于该头文件中。 头文件 stdlib.h：C 标准库（standard library）头文件，该文件包含了常用的 malloc 函数、free 函数。 头文件 sys&#x2F;stat.h：包含了关于文件权限定义，如 S_IRWXU、S_IWUSR，以 及函数 fstat 用于查询文件状态。涉及系统调用文件相关的操作，通常都需要用到 sys&#x2F;stat.h 文件。 头文件 unistd.h：UNIX C 标准库头文件，unix，linux 系列的操 作系统相关的 C 库，定义了 unix 类系统 POSIX 标准的符号常量头文件，比如 Linux 标准的输入文件描述符（STDIN），标准输出文件描述符（STDOUT），还有 read、write 等系统调用的声明。 头文件 fcntl.h：unix 标准中通用的头文件，其中包含的相关函数有 open，fcntl，close 等操作。 头文件 sys&#x2F;types.h：包含了 Unix&#x2F;Linux 系统的数据类型的头文件，常用的有 size_t，time_t，pid_t 等类型。 示例代码中的开头包含了一系列 Linux 系统常用的头文件。今后学习 Linux 的过程中，我们可能会接触各种各样的头文件，因此了解一下 Linux 中头文件的用法十分有必要。 在 linux 中，大部分的头文件在系统的 “&#x2F;usr&#x2F;include” 目录下可以找到，它是系统自带的 GCC 编译器默认的头文件目录，如下图所示，如果把该目录下的 stdio.h 文件删除掉或更改名字（想尝试请备份），那么使用 GCC 编译 hello world 的程序会因为找不到 stdio.h 文件而报错。 locate 查找 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091$ locate sys/stat.h/usr/include/x86_64-linux-gnu/sys/stat.h$ ls -al /usr/include/x86_64-linux-gnu/systotal 496drwxr-xr-x 3 root root 12288 Jun 11 2023 .drwxr-xr-x 12 root root 4096 Dec 11 06:30 ..-rw-r--r-- 1 root root 3302 Jul 6 2022 acct.h-rw-r--r-- 1 root root 1260 Jul 6 2022 auxv.h-rw-r--r-- 1 root root 86 Jul 6 2022 bitypes.h-rw-r--r-- 1 root root 26600 Jul 6 2022 cdefs.h-rw-r--r-- 1 root root 3576 Jul 6 2022 debugreg.h-rw-r--r-- 1 root root 922 Jul 6 2022 dir.h-rw-r--r-- 1 root root 1024 Jul 6 2022 elf.h-rw-r--r-- 1 root root 5076 Jul 6 2022 epoll.h-rw-r--r-- 1 root root 19 Jul 6 2022 errno.h-rw-r--r-- 1 root root 1400 Jul 6 2022 eventfd.h-rw-r--r-- 1 root root 1292 Jul 6 2022 fanotify.h-rw-r--r-- 1 root root 19 Jul 6 2022 fcntl.h-rw-r--r-- 1 root root 1675 Jul 6 2022 file.h-rw-r--r-- 1 root root 1188 Jul 6 2022 fsuid.h-rw-r--r-- 1 root root 6210 Jul 6 2022 gmon.h-rw-r--r-- 1 root root 2577 Jul 6 2022 gmon_out.h-rw-r--r-- 1 root root 3901 Jul 6 2022 inotify.h-rw-r--r-- 1 root root 2027 Jul 6 2022 ioctl.h-rw-r--r-- 1 root root 5086 Jul 6 2022 io.h-rw-r--r-- 1 root root 1462 Jul 6 2022 ipc.h-rw-r--r-- 1 root root 1112 Jul 6 2022 kd.h-rw-r--r-- 1 root root 1204 Jul 6 2022 klog.h-rw-r--r-- 1 root root 5552 Jul 6 2022 mman.h-rw-r--r-- 1 root root 5706 Jul 6 2022 mount.h-rw-r--r-- 1 root root 2623 Jul 6 2022 msg.h-rw-r--r-- 1 root root 11111 Jul 6 2022 mtio.h-rw-r--r-- 1 root root 3149 Jul 6 2022 param.h-rw-r--r-- 1 root root 923 Jul 6 2022 pci.h-rw-r--r-- 1 root root 1127 Jul 6 2022 perm.h-rw-r--r-- 1 root root 2723 Jul 6 2022 personality.hdrwxr-xr-x 2 root root 4096 Jun 11 2023 platform-rw-r--r-- 1 root root 3025 Jul 6 2022 poll.h-rw-r--r-- 1 root root 1795 Jul 6 2022 prctl.h-rw-r--r-- 1 root root 4338 Jul 6 2022 procfs.h-rw-r--r-- 1 root root 1959 Jul 6 2022 profil.h-rw-r--r-- 1 root root 6282 Jul 6 2022 ptrace.h-rw-r--r-- 1 root root 19539 Jul 6 2022 queue.h-rw-r--r-- 1 root root 5173 Jul 6 2022 quota.h-rw-r--r-- 1 root root 1471 Jul 6 2022 random.h-rw-r--r-- 1 root root 1182 Jul 6 2022 raw.h-rw-r--r-- 1 root root 1633 Jul 6 2022 reboot.h-rw-r--r-- 1 root root 1827 Jul 6 2022 reg.h-rw-r--r-- 1 root root 4034 Jul 6 2022 resource.h-rw-r--r-- 1 root root 6715 Jul 6 2022 rseq.h-rw-r--r-- 1 root root 5039 Jul 6 2022 select.h-rw-r--r-- 1 root root 2660 Jul 6 2022 sem.h-rw-r--r-- 1 root root 1806 Jul 6 2022 sendfile.h-rw-r--r-- 1 root root 2131 Jul 6 2022 shm.h-rw-r--r-- 1 root root 1714 Jul 6 2022 signalfd.h-rw-r--r-- 1 root root 20 Jul 6 2022 signal.h-rw-r--r-- 1 root root 1182 Jul 6 2022 single_threaded.h-rw-r--r-- 1 root root 12382 Jul 6 2022 socket.h-rw-r--r-- 1 root root 141 Jul 6 2022 socketvar.h-rw-r--r-- 1 root root 29 Jul 6 2022 soundcard.h-rw-r--r-- 1 root root 2094 Jul 6 2022 statfs.h-rw-r--r-- 1 root root 13767 Jul 6 2022 stat.h-rw-r--r-- 1 root root 2821 Jul 6 2022 statvfs.h-rw-r--r-- 1 root root 1593 Jul 6 2022 swap.h-rw-r--r-- 1 root root 1256 Jul 6 2022 syscall.h-rw-r--r-- 1 root root 1518 Jul 6 2022 sysinfo.h-rw-r--r-- 1 root root 7777 Jul 6 2022 syslog.h-rw-r--r-- 1 root root 2103 Jul 6 2022 sysmacros.h-rw-r--r-- 1 root root 74 Jul 6 2022 termios.h-rw-r--r-- 1 root root 1155 Jul 6 2022 timeb.h-rw-r--r-- 1 root root 9139 Jul 6 2022 time.h-rw-r--r-- 1 root root 2583 Jul 6 2022 timerfd.h-rw-r--r-- 1 root root 1597 Jul 6 2022 times.h-rw-r--r-- 1 root root 2839 Jul 6 2022 timex.h-rw-r--r-- 1 root root 2499 Jul 6 2022 ttychars.h-rw-r--r-- 1 root root 3568 Jul 6 2022 ttydefaults.h-rw-r--r-- 1 root root 5713 Jul 6 2022 types.h-rw-r--r-- 1 root root 5842 Jul 6 2022 ucontext.h-rw-r--r-- 1 root root 6796 Jul 6 2022 uio.h-rw-r--r-- 1 root root 1453 Jul 6 2022 un.h-rw-r--r-- 1 root root 20 Jul 6 2022 unistd.h-rw-r--r-- 1 root root 5208 Jul 6 2022 user.h-rw-r--r-- 1 root root 2481 Jul 6 2022 utsname.h-rw-r--r-- 1 root root 161 Jul 6 2022 vfs.h-rw-r--r-- 1 root root 1880 Jul 6 2022 vlimit.h-rw-r--r-- 1 root root 1199 Jul 6 2022 vm86.h-rw-r--r-- 1 root root 22 Jul 6 2022 vt.h-rw-r--r-- 1 root root 6233 Jul 6 2022 wait.h-rw-r--r-- 1 root root 4275 Jul 6 2022 xattr.h Linux File System Evolution｜FAST’13 Paper研究涉及六个主要的Linux文件系统：Ext3、Ext4、XFS、Btrfs、ReiserFS和JFS。这些文件系统在功能、设计、实现和开发团队上都有所不同。研究团队检查了Linux 2.6系列中每个文件系统的每个补丁，通过理解每个补丁的意图并对其进行分类，从而深入量化地洞察文件系统开发过程。研究结果回答了诸如“大多数补丁是什么？”“常见的错误类型是什么？”等问题，并提供了对当前文件系统开发和维护中常见方法和问题的新的见解。 主要观察结果包括： 近50%的补丁是维护补丁，反映了保持代码简单和可维护所需的持续重构工作。 剩余的主要类别是错误修复（近40%，约1800个错误），显示了实现“正确”版本所需的努力。 错误数量并没有随时间减少，即使对于稳定的文件系统也是如此。 进一步分析错误类别，语义错误（需要理解文件系统语义才能找到或修复的错误）是主导错误类别（超过50%的所有错误）。 并发错误是第二常见的（约占错误总数的20%），比用户级软件更为普遍。 内存错误和错误代码处理错误也较为常见，大多数错误代码错误完全忽略了错误。 此外，研究还发现，大多数错误（研究中的错误）会导致崩溃或数据损坏，这些结果在语义、并发、内存和错误代码错误中都成立。研究还发现，B树（许多文件系统中用于可扩展性的结构）的错误数量相对较少。大约40%的错误发生在错误处理路径上，文件系统在尝试响应失败的内存分配、I&#x2F;O错误或其他意外情况时，很容易犯下进一步的错误，如状态更新不正确和资源释放遗漏。 性能和可靠性补丁也占有一定比例，分别占8%和7%。性能技术相对常见和广泛，例如去除不必要的I&#x2F;O或降低写锁到读锁。约四分之一的性能补丁减少了同步开销。与性能技术相比，可靠性技术的添加似乎更加随意。 研究的另一个成果是一个公开的文件系统补丁注释数据集，供文件系统开发者、系统语言设计者和错误检测工具构建者进一步研究。研究通过一个案例研究展示了这个数据集的实用性，特别是搜索数据集以找到所有文件系统中异常常见的错误、性能修复和可靠性技术。 A look at the dark history of Linux file systemsLinus 又发飙了，这一次是 ext4如果你订阅了 Linux Kernel 的 maillist，你一定发现最近 Linus 又爆粗口了，而这次的对象是 ext4 文件系统。 On Sun, Aug 6, 2017 at 12:27 PM, Theodore Ts’o tytso@mit.edu wrote:&gt;&gt; A large number of ext4 bug fixes and cleanups for v4.13 A couple of these appear to be neither cleanups nor fixes. And a lotof them appear to be very recent. I’ve pulled this, but if I hear about problems, ext4 is going to be onmy shit-list, and you’d better be a lot more careful about pullrequests. Because this is not ok. Linus 而这已经不是 Linus 第一次对 ext4 文件系统表达不满了。 尽管 ext4 文件系统已经发布了多年，也被广泛应用于桌面及服务器，但关于 ext4 存在可能丢数据的 Bug 报告就一直没有中断过。例如在 2012 年的一封邮件中，Theodore Ts’o 报告了一次严重的 Bug，已经影响了部分 Linux 稳定版本的内核。 如果你持续关注文件系统或内核技术，你一定注意过这样一篇文章：Fuzzing filesystem with AFL。Vegard Nossum 和 Quentin Casasnovas 在 2016 年将用户态的 Fuzzing 工具 AFL（American Fuzzing Lop）迁移到内核态，并针对文件系统进行了测试。 结果是相当惊人的：Btrfs，作为 SLES（SUSE Linux Enterprise Server）的默认文件系统，仅在测试中坚持了 5 秒钟就挂了。而 ext4 坚持时间最长，但也仅有 2 个小时而已。 这个结果给我们敲响了警钟，Linux 文件系统并没有我们想象中的那么稳定。而事实上，在 Fuzz 测试下坚持时间长短仅仅体现出文件系统稳定性的一部分。数据可靠性，才是文件系统中最核心的属性。然而 Linux 文件系统社区的开发者往往都把注意力放在了性能，以及高级功能的开发上，而忽略了可靠性。 带大家回顾一下 Linux 文件系统的黑历史，希望能够警醒大家，不要过分相信和依赖文件系统。同时，在使用文件系统构建应用时，也需要采用正确的“姿势”。 POSIX，一个奇葩的标准谈到 Linux 文件系统，不得不提到 POSIX（Portable Operating System Interface），这样一个奇葩的标准。而开发者对于 POSIX 的抱怨，可谓是罄竹难书。 作为一个先有实现，后有标准的 POSIX，在文件系统接口上的定义，可谓是相当的“简洁”。尤其当系统发生 crash 后，对于文件系统应有的行为，更是完全空白，这留给了文件系统开发者足够大的“想象空间”。也就是说，如果一个 Linux 文件系统在系统发生崩溃重启后，整个文件系统的内容都不见了，也是“符合标准”的。 而事实上，类似的事情确实发生过：在 2015 年，ChromeOS 的开发者曾报告了一个 ext4 的问题，有可能导致 Chrome 发生崩溃。而来自 ext4 开发者的回答是，“Working As Intended”。 在历史上，不断有人尝试给文件系统提供更加严谨的 Consistency（一致性）定义，尤其是 Crash-Consistency（故障后的一致性）。到目前为止，尽管 POSIX 也经历了几个版本，但关于文件系统接口的定义，还是那个老样子。而 POSIX 标准，也是造成了文件系统各种问题的一个很重要的因素。关于各种一致性的定义，我们后面也会有文章专门进行介绍。 文件系统的黑历史 《A Study of Linux File System Evolution》 文件系统一直有着光辉的发展历史，也孕育了许多伟大的 Linux 内核贡献者。从最早的 FFS，到经典的 ext2&#x2F;ext3&#x2F;ext4，再到拥有黑科技的 Btrfs，XFS，BCacheFS 等。 然而软件开发的过程，当然不是一帆风顺的。威斯康辛大学麦迪逊分校的研究者曾在 FAST ‘13 上发表过一篇著名的论文《A Study of Linux File System Evolution》。文章对 8 年中，Linux 社区与文件系统相关的 5079 个 Patch 进行了统计和分析。从其数据中可以看出，有将近 40% 的文件系统相关的 Patch 属于 Bugfix 类型。换句话说，每提交两个 Patch，就有可能需要一个 Patch 用于 Bugfix。 而文件系统的 Bug 数量并没有随着时间的推移而逐渐收敛，随着新功能不断的加入，Bug 还在持续不断的产生。而 Bug 的集中爆发也往往源于大的功能演进。 而从上图中可以看出，在所有的 Bug 中，有接近 40% 的 Bug 可能导致数据损坏，这还是相当惊人的。 可以想象，在 Linux 文件系统的代码库中，还隐藏着许多 Bug，在等待着被人们发现。 哥伦比亚大学文件系统领域著名的专家 Junfeng Yang，曾经在 OSDI ‘04 上发表了一篇论文《Using Model Checking to Find Serious File System Errors》，该论文也是当年 OSDI 的 Best Paper。在这篇论文中，Junfeng Yang 通过 FiSC，一种针对文件系统的 Model Checking 工具，对 ext3，JFS，ReiserFS 都进行了检查，结果共发现了 32 个 Bug。而不同于 AFL，FiSC 发现的 Bug 大部分都会导致数据丢失，而不仅仅是程序崩溃。例如文章中指出了一处 ext3 文件系统的 Bug，该 Bug 的触发原因是在通过 fsck 进行数据恢复时，使用了错误的写入顺序，在 journal replay 的过程中，journal 中的数据还没有持久化到磁盘上之前，就清理了 journal，如果此时发生断电故障，则导致数据永久性丢失。 对应用程序开发的影响对于大部分应用程序开发者来说，并不会直接使用文件系统。很多程序员都是面向数据库进行编程，他们的数据大多是存在数据库中的。我们经常想当然的认为，数据库的开发者理应会理解文件系统可能存在的问题，并绕过文件系统的 Bug，帮助我们解决各种问题。然而这只是一种侥幸心理罢了，由于文件系统过于复杂，标准不清晰，即使是专业的数据库的开发人员，也往往无法避开文件系统中所有的问题。 以 LevelDB，我们最常用的一种单机 Key-Value Store 举例。研究人员分别对 LevelDB 的两个版本，1.10 和 1.15 进行了测试，分别发现了 10 个和 6 个不同程度的漏洞。其中 1.10 版本有 1 个漏洞可能导致数据丢失，5 个漏洞导致数据库无法打开，4 个漏洞导致数据库读写错误。而 1.15 版本分别有 2 个漏洞导致数据库无法打开，2 个漏洞导致数据库读写错误。 这些问题，大部分源自应用开发者对文件系统错误的假设。也就是说，他们以为文件系统可以保证的特性，而事实上并不能得到保证。而这些特性，也都是 POSIX 标准中未曾明确定义的。 这里举个例子：Append atomicity，追加写原子性。 向文件中追加写入，并不意味着是原子性的。如前文 ChromeOS 开发者遇到的 ext4 的问题，其根本原因，就是假设 ext4 文件系统是保证追加写原子性的。在这封邮件中，开发者提供了一个可以复现问题的步骤。假设文件中已经有 2522 字节的数据，再追加写入 2500 字节的数据，文件大小本应为 5022 字节。而如果在追加写的过程中，遇到系统崩溃，在系统恢复后，文件的大小可能是 4096 字节，而非 5022 字节，而文件的内容，也可能是垃圾数据，无法被程序正确识别。 LevelDB 同样也假设了文件系统具有追加写的原子性，前面提到的一些漏洞就源于此。 而这仅仅是冰山一角。单单关于文件系统写入数据的原子性，就有包括：单 sector 覆盖写，单 sector 追加写，单 block 覆盖写，单 block 追加写，多 block 追加写等等。而对于不同类型的文件系统，甚至同一个文件系统的使用不同参数，对于原子性都可能具有不同范围的支持。再考虑到 POSIX 提供的其他接口，包括 creat，rename，unlink，truncate 等等。这使得开发应用系统，尤其是数据库系统，变得非常复杂。 开发者的正确姿势是什么这里我们提供一些建议，希望能够帮助大家尽量少的踩坑。 首先，对于大部分应用程序员来说，应尽可能选择使用成熟的数据库，而非直接操作文件。尽管如前文所说，在复杂的文件系统面前，数据库也无法幸免于难，但数据库开发者掌握的关于文件系统的知识，还是远远强于普通开发者的。数据库也通常提供了数据恢复工具，以及备份工具。这避免了开发者重新造轮子，也极大的减轻了灾难发生后可能带来的影响。 而对于单机数据库，分布式数据库，以及分布式存储的开发者来说，我们的建议是尽量避免直接使用文件系统，尽可能多的直接使用裸设备，这避免了很多可能引起问题的接口，例如 creat，rename，truncate 等。例如 SmartX 在设计和实现分布式存储时，就直接使用裸设备。 如果必须要使用文件系统，也要使用尽量简单的 IO 模型，避免多线程，异步的操作。同时，一定要在设计的过程中，把对于文件系统操作的模型抽象出来，并画成步骤图，这里我们推荐 draw.io，一个非常不错的免费画图工具。要假设每一个步骤都可能失败，每一个步骤失败后，都可能产生垃圾数据，要提前设计好数据校验以及处理垃圾数据的方式。如果步骤之间有存在依赖关系，一定要在执行下一步之前，调用 fsync()，以保证数据被持久化到磁盘中。 最后，设计和实现完成后，在单元测试和集成测试的过程中，也一定要增加故障测试。例如在单元测试中，通过 mock 的方式模拟 IO 故障，在集成测试中，可以加入随机 kill 进程，随机重启服务器的测试用例，也可以通过 dm-delay，dm-flakey 等工具进行磁盘故障模拟。 看了这么多黑历史，真的是三观都毁掉了。而事实上，我们每天确实都生活在这些危机中。 这里要强调的是，我并不是想诋毁 Linux 文件系统，相反，我们非常感谢 Linux 内核开发者在文件系统方面做出的贡献。但同时，由于系统的复杂度所带来的严重问题也是无法回避的。在 Linux 文件系统的代码中，必然还存在着很多未被发现的严重 Bug，开发者和研究人员也从来没有停止过寻找 Bug 的努力。而随着新功能不断地加入，新的 Bug 也在不断的产生。我们多一些这方面的思考和谨慎，并不是什么坏事。","tags":["File System","Linux","VFS","Syscall","EX4","POSIX"],"categories":["系统与体系结构"]},{"title":"全闪存阵列｜mdadm 实操","path":"/post/系统与体系结构/madam-for-all-flash-array/","content":"全闪存阵列搭建｜mdadm 实操用以下 4 个 SSD 组全闪存阵列（All-Flash Array），与组 raid 同法，简单记录下。 123456789101112$ lsblk -fNAME FSTYPE LABEL UUID FSAVAIL FSUSE% MOUNTPOINTloop0 squashfs 0 100% /snap/core20/2379loop1 squashfs 0 100% /snap/lxd/24061loop2 squashfs 0 100% /snap/snapd/21759loop3 squashfs 0 100% /snap/core20/2434loop4 squashfs 0 100% /snap/lxd/29619loop5 squashfs 0 100% /snap/snapd/23258sda ext4 a35cd456-e07a-4d50-8118-1556a18a6971 sdb ext4 e2a3bb45-0b9b-4d0c-b9db-192dbc1b507e sdc ext4 39a9734c-bfc2-4a6e-99b5-de18082385f8 sdd ext4 5f8065ab-88e5-47a5-9729-c1b3c286bf73 要将 4 个 SSD 组成一个 All-flash Array，可以通过 RAID 技术来完成，常见的方式是使用 Linux 软件 RAID（mdadm）来配置一个 RAID 阵列。这些 SSD 可以通过不同的 RAID 模式（如 RAID 0、RAID 1、RAID 5、RAID 10 等）组合在一起，具体选择哪种 RAID 取决于你对性能、冗余和容错的需求。 步骤 1：安装 mdadm 工具mdadm 是用于创建和管理 Linux 软件 RAID 阵列的工具。如果你的系统上没有安装 mdadm，可以使用以下命令进行安装： Ubuntu&#x2F;Debian 系列 12sudo apt updatesudo apt install mdadm 步骤 2：清除磁盘上的现有数据在创建 RAID 阵列之前，你需要确保所有磁盘上没有任何分区或者已有数据。可以使用 wipefs 命令清除磁盘上的任何现有文件系统和分区信息： 1234sudo wipefs --all /dev/sdasudo wipefs --all /dev/sdbsudo wipefs --all /dev/sdcsudo wipefs --all /dev/sdd 步骤 3：创建 RAID 阵列决定你需要哪种 RAID 级别（0、1、5、10）。以下是几种常见 RAID 阵列的说明： RAID 0（条带化）：提供最高性能，但没有冗余，任何磁盘故障都会导致数据丢失。 RAID 1（镜像）：提供数据冗余，但只使用两个磁盘，容量是最小磁盘大小的两倍。 RAID 5（带奇偶校验的条带化）：提供冗余和良好的性能，至少需要 3 个磁盘。 RAID 10（1+0，镜像 + 条带化）：提供较好的性能和冗余，至少需要 4 个磁盘。 创建 RAID 0（条带化）阵列如果你的目标是最大化性能，可以选择 RAID 0： 1sudo mdadm --create /dev/md0 --level=0 --raid-devices=4 /dev/sda /dev/sdb /dev/sdc /dev/sdd 这将创建一个包含 4 个磁盘的 RAID 0 阵列，设备名为 /dev/md0 创建 RAID 1（镜像）阵列如果你希望有更高的冗余（需要两对磁盘进行镜像），你可以选择 RAID 1： 12sudo mdadm --create /dev/md0 --level=1 --raid-devices=2 /dev/sda /dev/sdbsudo mdadm --create /dev/md1 --level=1 --raid-devices=2 /dev/sdc /dev/sdd 这会创建两个 RAID 1 阵列，每对磁盘形成一个镜像。 创建 RAID 5（带奇偶校验的条带化）阵列如果你希望实现性能和冗余的平衡，RAID 5 是一个不错的选择，它提供奇偶校验，能够承受一个磁盘故障： 1sudo mdadm --create /dev/md0 --level=5 --raid-devices=4 /dev/sda /dev/sdb /dev/sdc /dev/sdd 创建 RAID 10（镜像 + 条带化）阵列RAID 10 提供了较好的性能和冗余，适合需要较高性能和数据保护的应用： 1sudo mdadm --create /dev/md0 --level=10 --raid-devices=4 /dev/sda /dev/sdb /dev/sdc /dev/sdd 步骤 4：查看 RAID 阵列状态创建 RAID 阵列后，使用以下命令来检查阵列的状态： 1sudo mdadm --detail /dev/md0 这将显示 /dev/md0 阵列的详细信息，包括阵列的健康状态、磁盘的状态等。 步骤 5：格式化 RAID 阵列创建 RAID 阵列后，你需要为其创建文件系统。通常使用 ext4 或 xfs 文件系统。以下是格式化 RAID 阵列的命令： 1sudo mkfs.ext4 /dev/md0 步骤 6：挂载 RAID 阵列创建并格式化 RAID 阵列后，你需要将其挂载到文件系统中。 12sudo mkdir /mnt/raidsudo mount /dev/md0 /mnt/raid 步骤 7：自动挂载 &#x2F;etc&#x2F;fstab如果你希望在每次启动时自动挂载 RAID 阵列，可以将其添加到 /etc/fstab 文件中。 12# 首先，获取阵列的 UUIDsudo blkid /dev/md0 然后编辑 /etc/fstab 文件并添加以下行： 1UUID=&lt;uuid_from_blkid&gt; /mnt/raid ext4 defaults 2 0 步骤 8：监控和管理使用 mdadm 来监控 RAID 阵列的状态，并检查是否有任何磁盘故障或阵列问题。 1sudo mdadm --detail /dev/md0 针对 AFA 的读写放大问题，可以采用以下这条流程测试和监控： ✍️ 番外篇：iostat 监测磁盘 I&#x2F;O｜fio 压测1️⃣ 使用 iostat 监控磁盘 I&#x2F;Oiostat 可以显示磁盘的读写性能，但它并不直接提供写放大倍数。不过你可以通过 总写入量 和 实际写入量 来间接推算。例如： 1iostat -x 1 详细信息解释： avg-cpu：显示 CPU 使用情况的平均值： %user：用户空间的 CPU 使用率 %nice：以较低优先级运行的进程使用的 CPU 时间百分比 %system：内核空间的 CPU 使用率 %iowait：等待 I&#x2F;O 操作完成时的 CPU 空闲时间百分比 %steal：虚拟化环境中，被虚拟机监控程序抢占的 CPU 时间百分比 %idle：CPU 空闲时间百分比 磁盘 I&#x2F;O 信息： r&#x2F;s：每秒读取的请求数（I&#x2F;O 操作次数） w&#x2F;s：每秒写入的请求数 rkB&#x2F;s：每秒读取的数据量（KB） wkB&#x2F;s：每秒写入的数据量（KB） rrqm&#x2F;s: 每秒合并读操作的次数 wrqm&#x2F;s: 每秒合并写操作的次数 r_await：每个读操作平均所需要的时间，不仅包括硬盘设备读操作的时间，也包括在内核队列中的时间 w_await：每个写操平均所需要的时间，不仅包括硬盘设备写操作的时间，也包括在队列中等待的时间 svctm：I&#x2F;O 服务时间（毫秒），表示请求处理的平均时间 %util：设备的利用率，表示磁盘 I&#x2F;O 操作的占用程度，如果值接近 100%，说明磁盘已经达到饱和 这个命令会每秒输出一次磁盘的读写性能，包括每个磁盘的读写 I&#x2F;O 操作次数和每秒的字节数 iostat 命令的主要功能是展示每个磁盘（包括 RAID 阵列的虚拟磁盘）以及 CPU 的利用情况，显示磁盘设备的 I&#x2F;O 性能指标，如每秒的读写字节数、I&#x2F;O 请求数、等待时间等。 常用的 iostat 参数 -c：显示 CPU 使用情况 -d：显示磁盘设备的 I&#x2F;O 统计信息 -x：显示磁盘设备的扩展统计信息（如磁盘的响应时间、队列长度等） -k：以 KB 为单位显示数据（默认单位为字节） -m：以 MB 为单位显示数据 -t：显示时间戳 -p：显示分区的统计信息 -z：仅显示有 I&#x2F;O 操作的设备，不显示没有活动的设备 interval：更新统计信息的时间间隔，单位为秒 1$ iostat [options] [interval] [count] interval：统计的更新频率，单位为秒。例如，每 5 秒刷新一次统计信息。 count：显示多少次统计信息。例如，iostat 5 3 表示每隔 5 秒输出一次统计信息，总共输出 3 次。 2️⃣ 使用 fio 进行基准测试fio 可以用来生成 I&#x2F;O 工作负载，测试不同类型的读写模式，从而间接估算 RAID 阵列和 SSD 的性能表现。 你可以通过特定的测试配置来模拟写操作，并计算写放大，比如： 123456789101112131415161718192021# 全盘顺序写sudo fio \\ --name=seq_write_test \\ --filename=/dev/md0 \\ --size=100% \\ --bs=4k \\ --rw=write \\ --iodepth=64 \\ --numjobs=4 \\ --direct=1# 全盘随机写sudo fio \\ --name=rand_write_test \\ --filename=/dev/md0 \\ --size=100% \\ --bs=4k \\ --rw=randwrite \\ --iodepth=64 \\ --numjobs=4 \\ --direct=1 3️⃣ 使用 smartctl 检查磁盘&#x2F;硬盘状态smartctl 检查和控制硬盘驱动器（HDD）和固态硬盘（SSD）SMART（Self-Monitoring, Analysis, and Reporting Technology）状态，smartctl 工具可以提供磁盘的健康状况、温度、错误信息等，通常用于监控单个硬盘的健康状况。 不过 smartctl 只能查看单个磁盘&#x2F;硬盘的 SMART 数据，无法直接查看整个 RAID 阵列（如 /dev/md0）的读写放大（Write Amplification）情况。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107wyk 20:20:37 ~$ sudo smartctl -a /dev/sdasmartctl 7.1 2019-12-30 r5022 [x86_64-linux-5.4.0-198-generic] (local build)Copyright (C) 2002-19, Bruce Allen, Christian Franke, www.smartmontools.org=== START OF INFORMATION SECTION ===Device Model: Fanxiang S103Pro 1TBSerial Number: 2036E4AD5054LU WWN Device Id: 5 00a075 1e4ad5054Firmware Version: 22Z4VBNDUser Capacity: 1,000,204,886,016 bytes [1.00 TB]Sector Sizes: 512 bytes logical, 4096 bytes physicalRotation Rate: Solid State DeviceForm Factor: 2.5 inchesDevice is: Not in smartctl database [for details use: -P showall]ATA Version is: ACS-3 T13/2161-D revision 5SATA Version is: SATA 3.3, 6.0 Gb/s (current: 6.0 Gb/s)Local Time is: Fri Dec 27 20:21:44 2024 UTCSMART support is: Available - device has SMART capability.SMART support is: Enabled=== START OF READ SMART DATA SECTION ===SMART overall-health self-assessment test result: PASSEDGeneral SMART Values:Offline data collection status: (0x80) Offline data collection activity was never started. Auto Offline Data Collection: Enabled.Self-test execution status: ( 0) The previous self-test routine completed without error or no self-test has ever been run.Total time to complete Offline data collection: ( 0) seconds.Offline data collectioncapabilities: (0x7b) SMART execute Offline immediate. Auto Offline data collection on/off support. Suspend Offline collection upon new command. Offline surface scan supported. Self-test supported. Conveyance Self-test supported. Selective Self-test supported.SMART capabilities: (0x0002) Does not save SMART data before entering power-saving mode. Supports SMART auto save timer.Error logging capability: (0x01) Error logging supported. General Purpose Logging supported.Short self-test routine recommended polling time: ( 2) minutes.Extended self-test routinerecommended polling time: ( 30) minutes.Conveyance self-test routinerecommended polling time: ( 2) minutes.SCT capabilities: (0x0031) SCT Status supported. SCT Feature Control supported. SCT Data Table supported.SMART Attributes Data Structure revision number: 16Vendor Specific SMART Attributes with Thresholds:ID# ATTRIBUTE_NAME FLAG VALUE WORST THRESH TYPE UPDATED WHEN_FAILED RAW_VALUE 1 Raw_Read_Error_Rate 0x0000 100 100 000 Old_age Offline - 0 5 Reallocated_Sector_Ct 0x0000 100 100 000 Old_age Offline - 0 9 Power_On_Hours 0x0000 100 100 000 Old_age Offline - 575 12 Power_Cycle_Count 0x0000 100 100 000 Old_age Offline - 52148 Unknown_Attribute 0x0000 100 100 000 Old_age Offline - 37557149 Unknown_Attribute 0x0000 100 100 000 Old_age Offline - 302150 Unknown_Attribute 0x0000 100 100 000 Old_age Offline - 78151 Unknown_Attribute 0x0000 100 100 000 Old_age Offline - 146159 Unknown_Attribute 0x0000 100 100 000 Old_age Offline - 0160 Unknown_Attribute 0x0000 100 100 000 Old_age Offline - 0161 Unknown_Attribute 0x0000 100 100 000 Old_age Offline - 93163 Unknown_Attribute 0x0000 100 100 000 Old_age Offline - 23164 Unknown_Attribute 0x0000 100 100 000 Old_age Offline - 16394165 Unknown_Attribute 0x0000 100 100 000 Old_age Offline - 14166 Unknown_Attribute 0x0000 100 100 000 Old_age Offline - 1167 Unknown_Attribute 0x0000 100 100 000 Old_age Offline - 5168 Unknown_Attribute 0x0000 100 100 000 Old_age Offline - 3000169 Unknown_Attribute 0x0000 100 100 000 Old_age Offline - 100177 Wear_Leveling_Count 0x0000 100 100 050 Old_age Offline - 3751181 Program_Fail_Cnt_Total 0x0000 100 100 000 Old_age Offline - 0182 Erase_Fail_Count_Total 0x0000 100 100 000 Old_age Offline - 0192 Power-Off_Retract_Count 0x0000 100 100 000 Old_age Offline - 7194 Temperature_Celsius 0x0000 100 100 000 Old_age Offline - 25195 Hardware_ECC_Recovered 0x0000 100 100 000 Old_age Offline - 0196 Reallocated_Event_Count 0x0000 100 100 016 Old_age Offline - 0199 UDMA_CRC_Error_Count 0x0000 100 100 050 Old_age Offline - 0232 Available_Reservd_Space 0x0000 100 100 000 Old_age Offline - 100241 Total_LBAs_Written 0x0000 100 100 000 Old_age Offline - 144248242 Total_LBAs_Read 0x0000 100 100 000 Old_age Offline - 102956245 Unknown_Attribute 0x0000 100 100 000 Old_age Offline - 172137SMART Error Log Version: 1No Errors LoggedSMART Self-test log structure revision number 1No self-tests have been logged. [To run self-tests, use: smartctl -t]SMART Selective self-test log data structure revision number 1 SPAN MIN_LBA MAX_LBA CURRENT_TEST_STATUS 1 0 0 Not_testing 2 0 0 Not_testing 3 0 0 Not_testing 4 0 0 Not_testing 5 0 0 Completed [00% left] (0-65535)Selective self-test flags (0x0): After scanning selected spans, do NOT read-scan remainder of disk.If Selective self-test is pending on power-up, resume after 0 minute delay.","tags":["fstab","mdadm","SSD","RAID","All-Flash Array","iostat","wipefs","fio","smartctl"],"categories":["系统与体系结构"]},{"title":"PMDK Programming Guidelines","path":"/post/系统与体系结构/pmdk-programming-guidelines/","content":"libpmemobj在使用 libpmemobj 库时，不需要直接使用 mmap。libpmemobj 提供了高级的 API 来管理持久内存池和分配内存。mmap 通常用于更底层的内存映射操作，而 libpmemobj 封装了这些操作，使得管理持久内存更加方便和安全。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;libpmemobj.h&gt;#include &lt;iostream&gt;#include &lt;cassert&gt;#include &lt;cstring&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;void init_pmem() &#123; // create pool const char *pool_name = &quot;/mnt/pmem0/matianmao/fast_fair.data&quot;; const char *layout_name = &quot;fast_fair&quot;; size_t pool_size = 64LL * 1024 * 1024 * 1024; // 16GB if (access(pool_name, 0)) &#123; pmem_pool = pmemobj_create(pool_name, layout_name, pool_size, 0666); if (pmem_pool == nullptr) &#123; std::cout &lt;&lt; &quot;[FAST FAIR]\\tcreate fail &quot;; assert(0); &#125; std::cout &lt;&lt; &quot;[FAST FAIR]\\tcreate &quot;; &#125; else &#123; pmem_pool = pmemobj_open(pool_name, layout_name); std::cout &lt;&lt; &quot;[FAST FAIR]\\topen &quot;; &#125; std::cout &lt;&lt; &quot;[FAST FAIR]\\topen pmem pool successfully &quot;;&#125;// 函数通过 pmemobj_zalloc 从持久内存池中分配指定大小的内存，并返回分配的内存地址// 如果分配失败，输出错误信息并终止程序void *allocate(size_t size) &#123; // 用于存储分配的内存地址 void *addr; // 用于存储持久内存对象的标识符 PMEMoid ptr; // 调用 pmemobj_zalloc 函数从持久内存池 pmem_pool 中分配大小为 size 字节的内存，并将分配的内存对象标识符存储在 ptr 中 int ret = pmemobj_zalloc(pmem_pool, &amp;ptr, sizeof(char) * size, TOID_TYPE_NUM(char)); if (ret) &#123; std::cout &lt;&lt; &quot;[FAST FAIR]\\tallocate btree successfully &quot;; assert(0); &#125; // 将持久内存对象标识符 ptr 转换为直接指针，并将其存储在 addr 中 addr = (char *)pmemobj_direct(ptr); // 返回分配的内存地址 return addr;&#125; 1️⃣ 使用 libpmemobj 库函数读写持久内存的示例代码 libpmemobj_pmem.cpp（without mmap —— 封装📦好了）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#include &lt;libpmemobj.h&gt;#include &lt;iostream&gt;#include &lt;cassert&gt;#include &lt;cstring&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;// 持久内存池的全局变量PMEMobjpool *pmem_pool;// 定义持久对象的类型编号#define TOID_TYPE_NUM_CHAR 1// 初始化持久内存池void init_pmem() &#123; // 持久内存池的名称和布局名称 const char *pool_name = &quot;/mnt/pmem1/libpmemobj_pmem&quot;; const char *layout_name = &quot;fast_fair&quot;; // 持久内存池的大小（16GB） size_t pool_size = 16LL * 1024 * 1024 * 1024; // 检查持久内存池文件是否存在 if (access(pool_name, 0)) &#123; // 创建持久内存池 pmem_pool = pmemobj_create(pool_name, layout_name, pool_size, 0666); if (pmem_pool == nullptr) &#123; std::cout &lt;&lt; &quot;[FAST FAIR]\\tcreate fail &quot;; assert(0); &#125; std::cout &lt;&lt; &quot;[FAST FAIR]\\tcreate &quot;; &#125; else &#123; // 打开持久内存池 pmem_pool = pmemobj_open(pool_name, layout_name); if (pmem_pool == nullptr) &#123; std::cout &lt;&lt; &quot;[FAST FAIR]\\topen fail &quot;; assert(0); &#125; std::cout &lt;&lt; &quot;[FAST FAIR]\\topen &quot;; &#125; std::cout &lt;&lt; &quot;[FAST FAIR]\\topen pmem pool successfully &quot;;&#125;// 分配指定大小的持久内存，并返回分配的内存地址void *allocate(size_t size) &#123; // 用于存储分配的内存地址 void *addr; // 用于存储持久内存对象的标识符 PMEMoid ptr; // 调用 pmemobj_zalloc 函数从持久内存池 pmem_pool 中分配大小为 size 字节的内存，并将分配的内存对象标识符存储在 ptr 中 int ret = pmemobj_zalloc(pmem_pool, &amp;ptr, sizeof(char) * size, TOID_TYPE_NUM_CHAR); if (ret) &#123; std::cout &lt;&lt; &quot;[FAST FAIR]\\tallocate fail &quot;; assert(0); &#125; // 将持久内存对象标识符 ptr 转换为直接指针，并将其存储在 addr 中 addr = pmemobj_direct(ptr); // 返回分配的内存地址 return addr;&#125;int main() &#123; // 初始化持久内存池 init_pmem(); // 分配 1024 字节的持久内存 void *pmem_addr = allocate(1024); std::cout &lt;&lt; &quot;[FAST FAIR]\\tallocated 1024 bytes at &quot; &lt;&lt; pmem_addr &lt;&lt; &quot; &quot;; // 使用分配的持久内存（例如，写入数据） strcpy((char *)pmem_addr, &quot;Hello, Persistent Memory!&quot;); std::cout &lt;&lt; &quot;[FAST FAIR]\\tdata written: &quot; &lt;&lt; (char *)pmem_addr &lt;&lt; &quot; &quot;; // 关闭持久内存池 pmemobj_close(pmem_pool); std::cout &lt;&lt; &quot;[FAST FAIR]\\tpmem pool closed &quot;; return 0;&#125; 编译命令： 12$ g++ -o libpmemobj libpmemobj_pmem.cpp -lpmemobj$ ./libpmemobj mmap2️⃣ 如果不使用 libpmemobj 库函数来读写持久内存（PM），你可以直接使用 mmap 函数将持久内存映射到虚拟地址空间，然后通过指针操作进行读写。以下是一个示例代码 mmap_pmem.cpp，展示了如何使用 mmap 来读写持久内存： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include &lt;fcntl.h&gt;#include &lt;sys/mman.h&gt;#include &lt;unistd.h&gt;#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cassert&gt;#define PMEM_FILE_PATH &quot;/mnt/pmem1/mmap_pmem&quot;#define PMEM_FILE_SIZE (16LL * 1024 * 1024 * 1024) // 16GBvoid* pmem_addr = nullptr;int pmem_fd = -1;// 初始化持久内存void init_pmem() &#123; // 打开或创建持久内存文件 pmem_fd = open(PMEM_FILE_PATH, O_RDWR | O_CREAT, 0666); if (pmem_fd &lt; 0) &#123; std::cerr &lt;&lt; &quot;Failed to open or create PMEM file&quot; &lt;&lt; std::endl; exit(1); &#125; // 设置文件大小 if (ftruncate(pmem_fd, PMEM_FILE_SIZE) != 0) &#123; std::cerr &lt;&lt; &quot;Failed to set PMEM file size&quot; &lt;&lt; std::endl; close(pmem_fd); exit(1); &#125; // 将文件映射到内存 pmem_addr = mmap(nullptr, PMEM_FILE_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, pmem_fd, 0); if (pmem_addr == MAP_FAILED) &#123; std::cerr &lt;&lt; &quot;Failed to mmap PMEM file&quot; &lt;&lt; std::endl; close(pmem_fd); exit(1); &#125; std::cout &lt;&lt; &quot;PMEM initialized successfully&quot; &lt;&lt; std::endl;&#125;// 关闭持久内存void close_pmem() &#123; if (pmem_addr != nullptr) &#123; munmap(pmem_addr, PMEM_FILE_SIZE); pmem_addr = nullptr; &#125; if (pmem_fd &gt;= 0) &#123; close(pmem_fd); pmem_fd = -1; &#125; std::cout &lt;&lt; &quot;PMEM closed successfully&quot; &lt;&lt; std::endl;&#125;int main() &#123; // 初始化持久内存 init_pmem(); // 分配 1024 字节的持久内存 void* data_addr = static_cast&lt;char*&gt;(pmem_addr) + 1024; std::cout &lt;&lt; &quot;Allocated 1024 bytes at &quot; &lt;&lt; data_addr &lt;&lt; std::endl; // 使用分配的持久内存（例如，写入数据） strcpy(static_cast&lt;char*&gt;(data_addr), &quot;Hello, Persistent Memory!&quot;); std::cout &lt;&lt; &quot;Data written: &quot; &lt;&lt; static_cast&lt;char*&gt;(data_addr) &lt;&lt; std::endl; // 关闭持久内存 close_pmem(); return 0;&#125; pmem_map_file3️⃣ 调用 pmem_map_file 函数来映射 PM，pmem_map_file 是 libpmem 库中的一个函数，用于将持久内存文件映射到虚拟地址空间。示例代码 pmem.c 如下： 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;fcntl.h&gt; // for open, O_RDWR, O_CREAT, O_TRUNC#include &lt;unistd.h&gt; // for close, ftruncate#include &lt;sys/types.h&gt; // for types#include &lt;sys/stat.h&gt; // for ftruncate#include &lt;libpmem.h&gt; // for PMDK functions#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define PMEM_SIZE 1024#define PMEM_FILE &quot;/mnt/pmem1/pmem_file&quot;int main() &#123; // 创建持久内存文件 int fd = open(PMEM_FILE, O_RDWR | O_CREAT | O_TRUNC, 0666); if (fd &lt; 0) &#123; perror(&quot;open&quot;); return EXIT_FAILURE; &#125; ftruncate(fd, PMEM_SIZE); // 映射持久内存 void *pmem_addr = pmem_map_file(PMEM_FILE, PMEM_SIZE, PMEM_FILE_CREATE, 0666, NULL, NULL); if (pmem_addr == NULL) &#123; perror(&quot;pmem_map_file&quot;); return EXIT_FAILURE; &#125; // 写入数据 sprintf(pmem_addr, &quot;Hello, Persistent Memory!&quot;); // 刷新持久内存 pmem_persist(pmem_addr, PMEM_SIZE); // 读取数据 printf(&quot;%s &quot;, (char *)pmem_addr); // 清理 pmem_unmap(pmem_addr, PMEM_SIZE); close(fd); return EXIT_SUCCESS;&#125; pmem_map_file 底层封装的也是 mmap，以下是 pmem_map_file 实现的一个简化示例，具体实现可能会有所不同： pmdk&#x2F;src&#x2F;libpmem&#x2F;pmem.c 代码库中对 pmem_map_file 的定义 – create or open the file and map it to memory 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;libpmem.h&gt;#include &lt;sys/mman.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;void *pmem_map_file(const char *path, size_t len, int flags, mode_t mode, size_t *mapped_lenp, int *is_pmemp) &#123; int fd = open(path, flags, mode); if (fd &lt; 0) &#123; perror(&quot;open&quot;); return NULL; &#125; if (len == 0) &#123; len = lseek(fd, 0, SEEK_END); if (len == (size_t)-1) &#123; perror(&quot;lseek&quot;); close(fd); return NULL; &#125; &#125; void *addr = mmap(NULL, len, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); if (addr == MAP_FAILED) &#123; perror(&quot;mmap&quot;); close(fd); return NULL; &#125; close(fd); if (mapped_lenp) *mapped_lenp = len; if (is_pmemp) *is_pmemp = 1; // Simplified, actual implementation may check if it&#x27;s true PMEM return addr;&#125;","tags":["mmap","PMDK","libpmemobj"],"categories":["系统与体系结构"]},{"title":"浅析 trace 的处理","path":"/post/系统与体系结构/analysis-of-trace-processing/","content":"由于作者见识有限，本文仅对 WebSearch2.spc 这一 trace 进行讲解分析。 What is tracetrace 这个词有着很多的含义，在英文维基中计算机科学分类中就有 5 个代指。而实验室平常所说到的 trace 应该是特指 I&#x2F;O trace。说来惭愧，一直在网上找不到实验室用的 I&#x2F;O trace 的权威定义，根据之前跟诸位学长的探讨，自己的拙见如下： I&#x2F;O trace 就是一些真实在线系统的运行数天的磁盘所接受的 I&#x2F;O 请求记录。 而 I&#x2F;O trace 也有着许多格式，例如本文提到的 WebSearch2 就来自于一个流行的搜索引擎，是真实的工作实际负载，它的格式定义遵循 SPC trace 文本规范$^{[1]}$。厂商之所以将其真实的负载公布出来，也是为了让学术界对这些数据进行分析科研，让学术界和工业界紧密的结合，达到双赢的目的。 Download12$ wget http://skuld.cs.umass.edu/traces/storage/WebSearch2.spc.bz2$ bunzip2 WebSearch2.spc.bz2 这样，我们就得到本文要分析的 trace 文件 WebSearch2.spc Cognize 拿到一个 trace，首先要了解它的基本格式1234567891011121314$ head WebSearch2.spc0,21741712,24576,R,0.0007741,18960512,24576,R,0.0009381,32558896,8192,R,0.0081172,21841504,24576,R,0.0082522,21841568,8192,R,0.0083880,18600896,8192,R,0.0111780,30860080,8192,R,0.0127030,30503312,8192,R,0.0168011,32558944,8192,R,0.0207481,20802624,8192,R,0.025710$ wc -l WebSearch2.spc4579809 WebSearch2.spc 可以看到 trace 由 400w 多行的数据构成，每一行都反映了一次 I&#x2F;O 请求。每行用 , 号作为分隔符构成 5 个自然域。 将每个自然域以 $i 来标识，则每个自然域分别代表： $1 Application specific unit (ASU) 设备号 $2 Logical block address (LBA) 逻辑块地址 $3 Size 请求的数据长度 $4 Opcode 读请求或者写请求，WebSearch2 中只有读请求 $5 Timestamp 请求下达的时间戳 Analysis对 trace 及其格式有了基本的认识之后，我们再来做进一步的分析探讨： 我们研究的意义是对 trace 进行重播，让我们研究的系统模拟真实负载下的性能 那么原先的 trace 并不一定适合我们想要测试研究的系统，我们要使用这一 trace 的时候就要对其进行重新组织 就让我们一步步的从每个自然域来分析下 WebSearch2.spc 这一 trace 文件吧。首先来看下这个 trace 访问设备的频率： 1234567$ awk &#x27;BEGIN&#123;FS=&quot;,&quot;&#125;;&#123;print $1&#125;&#x27; WebSearch2.spc | sort | uniq -c1544375 01517218 11515918 2 765 3 795 4 738 5 可以看到这个 trace 的 I&#x2F;O 请求主要集中于前三个设备，而且请求是均匀分布的。至于后 3 个设备那稀疏的请求次数，跟具体的系统有关，我们便不得而知了。 第二个作用域我们需要关心的是每个设备系统的请求的最大的逻辑块地址，这关系到我们 trace 重播的设计： 123456789101112$ awk &#x27;BEGIN&#123;FS=&quot;,&quot;;max=0&#125;;&#123;if($1==0&amp;&amp;$2&gt;max)&#123;max=$2&#125;&#125;;END&#123;print max&#125;&#x27; WebSearch2.spc34967808$ awk &#x27;BEGIN&#123;FS=&quot;,&quot;;max=0&#125;;&#123;if($1==1&amp;&amp;$2&gt;max)&#123;max=$2&#125;&#125;;END&#123;print max&#125;&#x27; WebSearch2.spc34662560$ awk &#x27;BEGIN&#123;FS=&quot;,&quot;;max=0&#125;;&#123;if($1==2&amp;&amp;$2&gt;max)&#123;max=$2&#125;&#125;;END&#123;print max&#125;&#x27; WebSearch2.spc25949392$ awk &#x27;BEGIN&#123;FS=&quot;,&quot;;max=0&#125;;&#123;if($1==3&amp;&amp;$2&gt;max)&#123;max=$2&#125;&#125;;END&#123;print max&#125;&#x27; WebSearch2.spc25949312$ awk &#x27;BEGIN&#123;FS=&quot;,&quot;;max=0&#125;;&#123;if($1==4&amp;&amp;$2&gt;max)&#123;max=$2&#125;&#125;;END&#123;print max&#125;&#x27; WebSearch2.spc34643200$ awk &#x27;BEGIN&#123;FS=&quot;,&quot;;max=0&#125;;&#123;if($1==5&amp;&amp;$2&gt;max)&#123;max=$2&#125;&#125;;END&#123;print max&#125;&#x27; WebSearch2.spc34951264 ⁉️可以看到最大的 LBA 为 3kw 多，我们至少需要 35000000×512B 的磁盘空间才能满足 trace 的需求。 第三个作用域是请求块的大小： 12345$ awk &#x27;BEGIN&#123;FS=&quot;,&quot;&#125;;&#123;print $3&#125;&#x27; WebSearch2.spc | sort | uniq -c 495744 16384 406838 24576 912770 327682764457 8192 根据 SPC 文档的规范，size 的单位是 byte，于是可以看到请求块的大小只有 4 种分别是： 8KB 16KB 24KB 32KB 而 8KB 的请求占大多数，32KB 紧随其后 第四个作用域是读请求或者写请求，WebSearch2 的 trace 大部分为读请求，固不做分析处理。 第五个作用域是时间戳： 12345$ awk &#x27;BEGIN&#123;FS=&quot;,&quot;;max=0&#125;;&#123;if($5&gt;max)&#123;max=$5&#125;&#125;;END&#123;print max&#125;&#x27; WebSearch2.spc15395.556800$ tail -1 WebSearch2.spc2,25487520,8192,R,15395.556800 时间戳是按照请求到达的顺序排列的，最大的时间也是最后一条请求到达的时间。根据 SPC 文档的规范，时间的单位为 s，可以看到这个 trace 实际上只是系统运行 4 个多小时的记录。 Refactoring我们对 trace 君的百般玩弄主要的目的是在于在我们自己的系统下重放 trace 的负载（replay trace），分析系统的性能，主要是其平均响应时间。 但是我们的系统几乎不太可能与原先 trace 的工作系统一致，于是我们就需要对 trace 进行重构处理：即处理 trace 的格式 Single Disk如果仅对单盘进行 trace 重放，有两种方法。 第一种方法，直接忽视设备号，每个请求都视为访问同一设备。 优点：实现简单 缺点：丧失了原先的局部性，可以造成性能下降 第二种方法，将磁盘扩展，第二个设备视为直接第一个设备的衍生，并依次类推。即新的逻辑块地址&#x3D;块设备号×总块数+旧逻辑块地址 优点：可能保留了局部性 缺点：需要进行换算，实现会比较复杂，需要比较大的磁盘 Multiple Disk对于多盘进行 trace 重放，如果盘数恰好相等，则无用多说。 如若不等，则类似 Single Disk 的第二种方法，先将磁盘扩展为单盘，再进行切分。 Question 如果想要测试磁盘的容量比 trace 的最大偏移地址大很多呢？ 类 RAID5 的测试：盘内存在校验块 Replay trace 的重放也有着两种方式 第一种，压力重放，无视时间戳的存在，直接循环中无间断执行每条请求 第二种，守时重放，控制每条请求不能早于时间戳的时间执行 Future Work 多种 trace 的对比 tools: disksim etc.. Rant 实验室的文档，传承 引用出处，参考文献","tags":["trace"],"categories":["系统与体系结构"]},{"title":"Linux 磁盘配置文件 /etc/fstab 详解","path":"/post/系统与体系结构/linux-disk-automatic-mounting/","content":"&#x2F;etc&#x2F;fstab 文件的作用磁盘被手动挂载之后都必须把挂载信息写入 /etc/fstab 这个文件中，否则下次开机启动时仍然需要重新挂载。 系统开机时会主动读取 /etc/fstab 这个文件中的内容，根据文件里面的配置挂载磁盘。这样我们只需要将磁盘的挂载信息写入这个文件中我们就不需要每次开机启动之后手动进行挂载了。 挂载的限制在说明这个文件的作用之前我想先强调一下挂载的限制。 根目录是必须挂载的，而且一定要先于其他 mount point 被挂载。因为 mount 是所有目录的根目录，其他都是由根目录 / 衍生出来的 挂载点必须是已经存在的目录 挂载点的指定可以任意，但必须遵守必要的系统目录架构原则 所有挂载点在同一时间只能被挂载一次 所有分区在同一时间只能挂在一次 若进行卸载，必须将工作目录退出挂载点（及其子目录）之外。 &#x2F;etc&#x2F;fstab 文件中参数123456789101112131415161718# 查看当前系统已经存在的挂载信息$ cat /etc/fstab# /etc/fstab: static file system information.## Use &#x27;blkid&#x27; to print the universally unique identifier for a# device; this may be used with UUID= as a more robust way to name devices# that works even if disks are added and removed. See fstab(5).## &lt;file system&gt; &lt;mount point&gt; &lt;type&gt; &lt;options&gt; &lt;dump&gt; &lt;pass&gt;# / was on /dev/sda1 during installation/dev/disk/by-uuid/dbe45dcb-0a04-428d-816d-ae4c004599d8 / ext4 defaults 0 1# /boot/efi was on /dev/nvme1n1p1 during curtin installation/dev/disk/by-uuid/8EC3-92ED /boot/efi vfat defaults 0 1/swap.img none swap sw 0 0UUID=cf0c96db-89d0-41d9-bdc9-0dd5cb67bcde /mnt/pmem0 ext4 defaults 0 1/dev/sda1 /mnt/sda1/zz_data ext4 defaults 0 2/mnt/sda1/zz_data /home/zz/data_new/Nomad/src none bind 0 0UUID=526d14d2-dbcc-4100-8cb5-85579eefae94 /home/lj ext4 defaults 0 2 在文件中我已经把每一列都做出来表示方便识别，我们可以看到一共有六列。 第 1 列 [Device] 磁盘设备文件或者该设备的 Label 或者 UUIDLabel 就是分区的标签，在最初安装系统时填写的挂载点就是标签的名字。 UUID-Universally Unique IDentifiers 全局唯一标识符 可以通过查看一个分区的 superblock 中的信息找到 UUID 和 Label name。 123456# 切换 root$ sudo -i# 查询 /dev/nvme0n1 的 UUID$ blkid /dev/nvme0n1/dev/nvme0n1: UUID=&quot;36df5186-24a0-4dad-9b4e-664a4230b7f1&quot; TYPE=&quot;ext4&quot; 使用设备名称（/dev/sda)来挂载分区时是被固定死的，一旦磁盘的插槽顺序发生了变化，就会出现名称不对应的问题。因为这个名称是会改变的。 不过使用 label 挂载就不用担心插槽顺序方面的问题。不过要随时注意你的 Label name。至于 UUID，每个分区被格式化以后都会有一个 UUID 作为唯一的标识号。使用 uuid 挂载的话就不用担心会发生错乱的问题了。 第 2 列 [Mount Point] 设备挂载点，就是你要挂载到哪个目录下第 3 列 [File System] 磁盘文件系统的格式，包括 ext2、ext3、ext4、nfs…第 4 列 [Parameters] 文件系统的参数 参数 说明 Async&#x2F;sync 设置是否为同步方式运行，默认为 async auto&#x2F;noauto 当下载 mount -a 的命令时，此文件系统是否被主动挂载。默认为 auto rw&#x2F;ro 是否以以只读或者读写模式挂载 exec&#x2F;noexec 限制此文件系统内是否能够进行”执行”的操作 user&#x2F;nouser 是否允许用户使用 mount 命令挂载 suid&#x2F;nosuid 是否允许 SUID 的存在 Usrquota 启动文件系统支持磁盘配额模式 Grpquota 启动文件系统对群组磁盘配额模式的支持 Defaults 同时具有 rw,suid,dev,exec,auto,nouser,async 等默认参数的设置 第 5 列 [能否被 dump 备份命令作用] dump 是一个用来作为备份的命令，通常值为 0 或 1 参数 说明 0 代表不要做 dump 备份 1 代表要每天进行 dump 的操作 2 代表不定日期的进行 dump 操作 第 6 列 [是否检验扇区] 开机的过程中，系统默认会以 fsck 检验我们系统是否为完整（clean） 参数 说明 0 不要检验 1 最早检验（一般根目录会选择） 2 1级别检验完成之后进行检验 Linux 磁盘分区 UUID 获取及其作用获取 UUID 的方法123456# 方法一$ sudo ls -l /dev/disk/by-uuid/# 方法二$ sudo blkid /dev/sda1/dev/sda1: UUID=&quot;f0d9b5f8-24ef-4aba-b3ce-f4bf0a0c231a&quot; TYPE=&quot;ext4&quot; PARTUUID=&quot;e3d6d3a9-01&quot; 原因 1：它是真正的唯一标志符UUID 为系统中的存储设备提供唯一的标识字符串，不管这个设备是什么类型的。如果你在系统中添加了新的存储设备如硬盘，很可能会造成一些麻烦，比如说启动的时候因为找不到设备而失败，而使用UUID则不会有这样的问题。 原因 2：设备名并非总是不变的自动分配的设备名称并非总是一致的，它们依赖于启动时内核加载模块的顺序。如果你在插入了 USB 盘时启动了系统，而下次启动时又把它拔掉了，就有可能导致设备名分配不一致。 使用 UUID 对于挂载移动设备也非常有好处──例如我有一个 24 合一的读卡器，它支持各种各样的卡，而使用 UUID 总可以使同一块卡挂载在同一个地方。 原因 3：ubuntu 中的许多关键功能现在开始依赖于 UUID例如 grub ──系统引导程序，现在可以识别 UUID，打开你的 /boot/grub/menu.lst，你可以看到类似如下的语句： 123456$ cat /boot/grub/menu.lsttitle Ubuntu hardy (development branch), kernel 2.6.24-16-genericroot (hd2,0)kernel /boot/vmlinuz-2.6.24-16-generic root=UUID=c73a37c8-ef7f-40e4-b9de-8b2f81038441 ro quiet splashinitrd /boot/initrd.img-2.6.24-16-genericquiet","tags":["Linux","fstab","grub","mount"],"categories":["系统与体系结构"]},{"title":"Linux 分区更改 fdisk、格式化 mkfs、检查 fsck、挂载 mount","path":"/post/系统与体系结构/linux-partition/","content":"Linux 系统下与磁盘分区相关的有 fdisk、fsck、mkfs、mount 等这些命令： fdisk 是用来操作磁盘分区表相关的更改，比如更改分区表格式，创建分区表，新建&#x2F;删除分区等 mkfs 则是在创建分区之后负责将分区格式化的工具 mount 则是将分区挂载到 Linux 的文件树中（与之对应的卸载是 umount） 我以向 Linux 系统添加了一块全新的磁盘以拓展存储空间为例。各种命令的详细使用方法使用 man 查看，此处不再翻译。 fdisk使用 fdisk 命令对硬盘进行分区，创建分区表和分区。可以创建主分区、扩展分区和逻辑分区等。 分区完成后，每个分区都会被赋予一个设备节点（例如：/dev/sda1，/dev/sdb2 等）。 接下来，需要使用 mkfs 命令对每个分区进行格式化，例如 mkfs.ext4、mkfs.xfs 等。 最后，将格式化后的分区挂载到指定的挂载点（目录）上，使其可以被访问和使用。 在添加磁盘之前，先执行 fdisk -l 列出系统中的物理磁盘，记录下来，方便与添加磁盘之后做对比，找到新添加的磁盘设备号。 1234567891011root@linux:~$ fdisk -lDisk /dev/sda: 20 GiB, 21474836480 bytes, 41943040 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0x25241c74Device Boot Start End Sectors Size Id Type/dev/sda1 * 2048 25165823 25163776 12G 83 Linux/dev/sda2 25167870 41940991 16773122 8G 5 Extended/dev/sda5 25167872 41940991 16773120 8G 82 Linux swap / Solaris 可以看到，目前系统只安装了一块硬盘 sda，有三个分区，现在可以关机加硬盘了。加完硬盘后开机再执行 fdisk -l 12345678910111213141516root@linux:~$ fdisk -lDisk /dev/sda: 20 GiB, 21474836480 bytes, 41943040 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0x25241c74Device Boot Start End Sectors Size Id Type/dev/sda1 * 2048 25165823 25163776 12G 83 Linux/dev/sda2 25167870 41940991 16773122 8G 5 Extended/dev/sda5 25167872 41940991 16773120 8G 82 Linux swap / SolarisDisk /dev/sdb: 10 GiB, 10737418240 bytes, 20971520 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytes 可以看到，新添加的硬盘的设备号为 sdb，没有分区表，没有分区。接下来就用 fdisk /dev/sdb 来创建分区表和分区。 1234567root@linux:~$ fdisk /dev/sdbWelcome to fdisk (util-linux 2.27.1).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Device does not contain a recognized partition table.Created a new DOS disklabel with disk identifier 0x95942ae2.Command (m for help): 不知道怎么操作的此时可以按 m 调出帮助界面 123456789101112131415161718192021222324252627282930Command (m for help): mHelp: DOS (MBR) a toggle a bootable flag b edit nested BSD disklabel c toggle the dos compatibility flag Generic d delete a partition F list free unpartitioned space l list known partition types n add a new partition p print the partition table t change a partition type v verify the partition table i print information about a partition Misc m print this menu u change display/entry units x extra functionality (experts only) Script I load disk layout from sfdisk script file O dump disk layout to sfdisk script file Save &amp; Exit w write table to disk and exit q quit without saving changes Create a new label g create a new empty GPT partition table G create a new empty SGI (IRIX) partition table o create a new empty DOS partition table s create a new empty Sun partition table 先创建一个 GPT 分区表，按 g 12Command (m for help): gCreated a new GPT disklabel (GUID: F4A12897-62F7-4ABA-9BC3-88BF53550DE3). 分区表创建后创建分区，按 n 回车，Partition number、First sector、Last sector 参数不清楚的可以直接回车使用默认参数。 指定起始扇区：按回车使用默认值，通常是第一个可用扇区。 指定结束扇区或分区大小，你可以手动指定结束扇区，也可以通过输入大小来自动计算结束扇区。例如： 输入 +50G 创建一个 50 GiB 的分区。 输入 +200G 创建一个 200 GiB 的分区。 12345Command (m for help): nPartition number (1-128, default 1):First sector (2048-20971486, default 2048):Last sector, +sectors or +size&#123;K,M,G,T,P&#125; (2048-20971486, default 20971486):Created a new partition 1 of type &#x27;Linux filesystem&#x27; and of size 10 GiB. 此时已经在这块新加的 10GB 的硬盘中创建了一个 10GB 的分区。 最后按 w 将更改信息写入硬盘。 1234Command (m for help): wThe partition table has been altered.Calling ioctl() to re-read partition table.Syncing disks. mkfs常见的 File System ext2 ext3 ext4 btrfs xfs 虽然说文件系统的种类很多，但大部分 linux 下文件系统都有着类似的结构，包括超级块、inode、数据块、目录块等。 超级块包括了文件系统的总体信息，是文件系统的核心，所以磁盘中会有多个超级块，即使某一些超级块坏了，文件系统依然可用。 inode 存储着所有与文件有关的数据，比如文件的权限等，并不包括文件内容和文件名。 数据块是真实存储数据的，一个数据块默认的大小为 4KB。 目录块包括文件内容和文件名，以及 inode 的信息。 注意：如果设备上没有分区，或者设备分区上没有文件系统，也会导致挂载失败。你可以检查设备是否已经被格式化或有文件系统。 1234567891011121314151617181920212223242526$ sudo blkid /dev/nvme0n1# 为空表示没有文件系统/还没被格式化过$ sudo mkfs.ext4 /dev/nvme0n1mke2fs 1.45.5 (07-Jan-2020)Discarding device blocks: done Creating filesystem with 122096646 4k blocks and 30531584 inodesFilesystem UUID: 36df5186-24a0-4dad-9b4e-664a4230b7f1Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000, 7962624, 11239424, 20480000, 23887872, 71663616, 78675968, 102400000Allocating group tables: done Writing inode tables: done Creating journal (262144 blocks): doneWriting superblocks and filesystem accounting information: done$ sudo blkid /dev/nvme0n1/dev/nvme0n1: UUID=&quot;36df5186-24a0-4dad-9b4e-664a4230b7f1&quot; TYPE=&quot;ext4&quot;$ sudo mount &lt;设备&gt; &lt;挂载点&gt;# 已经被格式化过$ sudo blkid /dev/nvme1n1/dev/nvme1n1: PTUUID=&quot;8e912df5-211c-45ea-a422-6a0f83c045c3&quot; PTTYPE=&quot;gpt&quot; 接下来 mkfs.ext4 /dev/sdb1 格式化该分区（mkfs 后面跟着 . 与文件系统的格式表明要将目标分区格式化成什么文件系统） 12345678910root@linux:~$ mkfs.ext4 /dev/sdb1mke2fs 1.42.13 (17-May-2015)Creating filesystem with 2621179 4k blocks and 655360 inodesFilesystem UUID: 886f1d1a-a3ad-4bdf-89b3-54ee0c9238f2Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632Allocating group tables: doneWriting inode tables: doneCreating journal (32768 blocks): doneWriting superblocks and filesystem accounting information: done mount在文件系统中创建一个空目录作为挂载点，并将分区挂载到挂载点 12root@linux:~$ mkdir /mnt/new_mountpointroot@linux:~$ mount -t ext4 /dev/sdb1 /mnt/new_mountpoint/ 此时 /mnt/new_mountpoint/ 下面的存储空间就是此次新添加的10GB磁盘的存储空间，可以用 df -h 查看 1234567891011root@linux:~$ df -hFilesystem Size Used Avail Use% Mounted onudev 3.9G 0 3.9G 0% /devtmpfs 799M 9.1M 790M 2% /run/dev/sda1 12G 4.5G 6.7G 40% /tmpfs 3.9G 188K 3.9G 1% /dev/shmtmpfs 5.0M 4.0K 5.0M 1% /run/locktmpfs 3.9G 0 3.9G 0% /sys/fs/cgrouptmpfs 799M 24K 799M 1% /run/user/108tmpfs 799M 0 799M 0% /run/user/1000/dev/sdb1 9.8G 23M 9.2G 1% /mnt/new_mountpoint 在使用 mount 命令时，设备（source）和挂载点（target）的顺序很重要。设备应该在前面，挂载点在后面。具体的语法格式如下： 1$ mount [选项] &lt;设备&gt; &lt;挂载点&gt; 具体说明 设备：指的是你要挂载的块设备或文件系统的路径，比如 /dev/sda1 或 /dev/nvme0n1p1。 挂载点：指的是挂载该设备的目录路径，比如 /mnt/nvme0n1。 示例 挂载设备： 假设你有一个设备 /dev/sda1，你想挂载到 /mnt/data 目录下，使用如下命令： 1sudo mount /dev/sda1 /mnt/data 挂载文件系统类型： 如果你想指定文件系统类型（例如 ext4），可以使用 -t 选项： 1sudo mount -t ext4 /dev/sda1 /mnt/data 卸载设备： 卸载挂载的设备使用 umount 命令： 1sudo umount /mnt/data 常用选项 -t &lt;type&gt;：指定文件系统类型，如 ext4、xfs 等。 -o &lt;options&gt;：指定挂载选项，如 ro（只读）、rw（读写）、noatime（不更新访问时间）等。 总结fdisk 分区挂载更加灵活，可以将磁盘划分为多个分区，每个分区可以有不同的文件系统类型，分区完后仍然需要对每个分区 mkfs 格式化文件系统，或者也可以直接 mkfs 选择对整个磁盘格式化，但整个磁盘将只能使用一个文件系统类型，无法将磁盘分割为多个独立的区域。 常用命令 lsblk、df、du123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263wyk 09:20:49 ~$ lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTSloop0 7:0 0 79.9M 1 loop /snap/lxd/22923loop1 7:1 0 62M 1 loop /snap/core20/1587loop3 7:3 0 38.8M 1 loop /snap/snapd/21759loop4 7:4 0 63.9M 1 loop /snap/core20/2318loop5 7:5 0 87M 1 loop /snap/lxd/28373sda 8:0 0 447.1G 0 disk ├─sda1 8:1 0 1G 0 part └─sda2 8:2 0 446.1G 0 part /old8003-2sdb 8:16 0 1.8T 0 disk /home/cyf/hddnvme4n1 259:0 0 894.3G 0 disk /home/lzh/ssdnvme3n1 259:1 0 894.3G 0 disk /home/wyk/ssdnvme2n1 259:2 0 894.3G 0 disk ├─nvme2n1p1 259:3 0 1G 0 part /boot/efi└─nvme2n1p2 259:4 0 893.2G 0 part /nvme0n1 259:5 0 894.3G 0 disk /home/cyf/ssd0nvme1n1 259:6 0 894.3G 0 disk /home/cyf/ssd1wyk 09:21:02 ~$ df -hFilesystem Size Used Avail Use% Mounted ontmpfs 13G 3.3M 13G 1% /run/dev/nvme2n1p2 879G 308G 527G 37% /tmpfs 63G 0 63G 0% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/lock/dev/nvme2n1p1 1.1G 6.1M 1.1G 1% /boot/efi/dev/sda2 439G 336G 81G 81% /old8003-2/dev/nvme3n1 880G 28K 835G 1% /home/wyk/ssdwyk 09:17:50 ~$ sudo du -h --max-depth=1 /old8003-2/home/30G /old8003-2/home/ymx6.4G /old8003-2/home/cjh72G /old8003-2/home/cyf15G /old8003-2/home/zzh2.1G /old8003-2/home/jyc525M /old8003-2/home/astl2.7G /old8003-2/home/lcc1.1G /old8003-2/home/whs1.6G /old8003-2/home/olh6.4G /old8003-2/home/wyk95G /old8003-2/home/lzh8.0G /old8003-2/home/zyu239G /old8003-2/homewyk 09:24:37 ~$ lsblk -d -o name,rotaNAME ROTAloop0 0loop1 0loop3 0loop4 0loop5 0sda 0sdb 1nvme4n1 0nvme3n1 0nvme2n1 0nvme0n1 0nvme1n1 0wyk 09:24:44 ~ lsblk -d -o name,rota 对于其返回值，看 ROTA 值来判断： 若 ROTA&#x3D;1，则意味该硬盘旋转，则其为机械硬盘； 若 ROTA&#x3D;0，则意味着该盘为固态硬盘； 对于上述打印结果，sdb 为固态硬盘，sda 为机械硬盘。 执行 sudo umount /old8003-1 不会擦除 SSD 上的数据。 umount 命令只是卸载文件系统，意味着它将断开挂载点和设备的关联，让该挂载点不再可访问。数据仍然保留在 SSD 上的分区中，没有被删除。 简单来说： umount: 只断开文件系统，不会对数据产生任何影响。 数据还在磁盘上，只是暂时不可通过该挂载点访问。 要删除数据，通常需要格式化磁盘或者手动删除文件。 某个 ssd&#x2F;hdd 还挂载在某个目录下，如果要清除上面的数据并挂载到自己指定目录下要怎么做（全流程） 这将显示所有在 /old8003-1 目录下活动的文件和进程。如果有进程正在使用该目录，可以终止它们或手动关闭它们：sudo lsof /old8003-1 格式化前先取消磁盘的挂载 sudo umount /old8003-1 可以选择 sudo fdisk /dev/nvme3n1 对磁盘进行分区，也可以不分区， 直接把整个磁盘格式化（就没有 nvme3n1p1、nvme3n1p2 这类分区了） 指定分区的格式化文件系统类型 sudo mkfs.ext4 /dev/nvme3n1 最后挂载上去即可 sudo mount ~/ssd /dev/nvme3n1","tags":["Linux","mount","fdisk","mkfs","fsck","lsblk","df","du"],"categories":["系统与体系结构"]},{"title":"广东·广州","path":"/post/摄影日志/guangzhou_2024-11-29/","content":"CCF 中国存储大会 廣州 take a .jpg when you pass by 广式早茶","tags":["摄影","广州"],"categories":["摄影日志"]},{"title":"NVM 存储系统领域比较厉害的实验室","path":"/post/系统与体系结构/nvm-top-lab/","content":"步入研究生，开始了 NVM 方向的科研，近半年来逐渐探索到了一些在 NVM 方向上做的比较不错的团队，方便对 NVM 方向感兴趣的同学关注大佬团队的最新论文，也希望可以帮助想申请 NVM 方向 Ph.D 的同学，如有不足的地方，希望大家多多补充。 International Lab 美国 佐治亚理工 Joy Arulraj ，研究方向是 NVM上的database，毕业于CMU，导师是数据库大神 Andy Pavlo，个人网站 https://www.cc.gatech.edu/~jarulraj&#x2F; 美国 UCSD大学 Non-Volatile Systems Lab 负责人Steven Swanson ，主要研究NVM上的软件，论文发表在体系结构领域的顶会上，个人网站 https://swanson.ucsd.edu/ 加拿大 Simon Fraser大学 Tianzheng Wang，主要研究NVM上的数据库索引，论文主要发表在数据库领域的顶会上，Dash 论文获得了vldb2020 的 best paper ，个人主页 https://www2.cs.sfu.ca/~tzwang&#x2F;pubs.html 美国 Virginia Tech 大学的 Changwoo Min，主要研究NVM上的索引和存储，论文发表在操作系统领域，个人网站 https://multics69.github.io/ 美国 UC,merced大学的 Dong Li，主要研究NVM上高性能应用，Dong Li老师主要是做高性能和并行计算的，近几年开始研究将高性能计算和NVM结合起来，文章都发在了体系结构和超算的顶会上，个人网站 https://faculty.ucmerced.edu/dong-li/ 新加坡第四范式 Chen Cheng ,主要研究NVM上的database ,设计基于NVM的系统，个人网站https://sites.google.com/site/chencheng1560/home 韩国 KAIST 的 Myoungsoo Jung，主要研究 flash、SSD和NVM存储方面的工作，还有并行计算、异构计算方面的高性能计算工作，论文发表在体系结构领域和高性能计算领域顶会上，个人网站 http://camelab.org/ Domestic Lab 清华 舒继武老师团队 http://storage.cs.tsinghua.edu.cn/~jiwu-shu&#x2F;，感觉陆游游老师在团队中很出色，年轻有为，主要研究NVM上的存储系统和 Flash 存储系统，个人主页 Home - Youyou Lu (tsinghua.edu.cn) 清华 武永卫老师团队 http://madsys.cs.tsinghua.edu.cn/~yongweiwu&#x2F;，研究NVM上的数据结构和应用，他们组里图计算的工作也很出色，工作发表在数据库，存储和并行计算领域 上交 陈海波老师团队https://ipads.se.sjtu.edu.cn/zh/members/，将NVM和RDMA结合做研究，陈老师组里的文章可谓是 操作系统领域、体系结构领域、高性能计算领域顶会大满贯了，很厉害 计算所 陈世敏老师团队 https://www.shimin-chen.com/，研究NVM上的数据库索引和NVM上的系统，文章发表在数据库和存储领域； 华科 金海老师团队 http://grid.hust.edu.cn/index.htm，金老师的组里还有很多老师，有的老师在NVM上搞研究，具体文章可以看他们的团队官网 华科 华宇老师团队 https://csyhua.github.io/csyhua/index.html，天才少年 Pengfei Zuo就是华老师的学生，他们在NVM上的研究很多，发表在体系结构、系统、存储、数据库等领域","tags":["NVM"],"categories":["系统与体系结构"]},{"title":"持久性内存｜Persistent Memory","path":"/post/系统与体系结构/persistent-memory-research-report/","content":"分层存储学过计算机原理的人都知道，计算机系统的存储采用分层的结构（如上图所示 ）。其中，CPU regiesters、CPU Caches 和 DRAM 都是易失性的（volatile），SSD、HDD、Tape 是非易失性的（non-volatile）。 企业级 SSD 可以提供 10 微秒级别的响应时间，DRAM 的响应时间大约是 100 纳秒这个级别。SSD 的响应时间和 DRAM 有着差不多 100 倍的差距。而 DRAM 和最后一级 CPU Cache 的响应时间只有 8~10 倍的差距。 很明显，DRAM 和 SSD 之间存在比较巨大的性能鸿沟。所以在设计应用程序的时候，需要特别注意 I&#x2F;O 相关的操作，避免 I&#x2F;O 成为系统的性能瓶颈。 持久化内存持久化内存（Persistent Memory，简称 PMEM），也叫非易失性内存（Non-Volatile Memory，简称 NVM），是指一类支持字节寻址（Byte-Addressable）、可以通过 CPU 指令直接进行操作、断电后数据不丢失的存储硬件。 计算机系统的分层存储 PMEM 提供亚微秒级别的延迟时间。从成本、性能、容量上看，PMEM 是位于 DRAM 和 SSD 之间的一层存储。PMEM 的出现，填补了 DRAM 和 SSD 之间的性能鸿沟，同时也将影响存储软件的架构设计。 Optane DIMMs「学术界」在很早以前就开始了对持久化内存的研究，比如： NOVA: A Log-structured File System for Hybrid Volatile&#x2F;Non-volatile Main Memories Bztree: A High-performance Latchfree Range Index for Non-volatile Memory Let’s talk about storage: Recovery methods for nonvolatile memory database systems …… 但以前没有真实的持久化内存硬件，只能基于软件模拟器进行仿真测试。直到 2019 年 4 月，Intel 发布了第一款企业级的持久化内存 —— Intel Optane DC Persistent Memory（下面简称 Optane DIMMs）。 由于模拟器没法百分之百模拟硬件，之前通过模拟器仿真出来的研究结果和真实硬件下的测试结果还是有一些差别的。在 FAST’20 上，有人发表了一篇论文，介绍 Intel Optane DC Persistent Memory 的使用特点 —— An Empirical Guide to the Behavior and Use of Scalable Persistent Memory。 Intel Optane DC Persistent Memory 是目前唯一一款量产的持久化内存，同时目前也只有 Intel 的 Cascade Lake 处理器支持这款持久化内存。 Intel Optane DC Persistent Memory 如上图所示，Optane DIMMs 采用和 DRAM 一样的 DIMM 接口。这意味着，Optane DIMMs 可以直接插在内存插槽上，通过内存总线和 CPU 通信，而 CPU 也可以通过指令直接操作 Optane DIMMs。 Optane DIMMs 的持久化Optane DIMM 有两种工作模式：Memory Mode 和 App Direct Mode。 Memory Mode 简单说就是把 Optane DIMMs 当成易失性内存使用，把 DRAM 当作 CPU 和 Optane DIMMs 之间的 cache，并且 DRAM 对外不可见（就像 CPU 的多级 cache 对外也不可见）。基于 Memory Mode 的工作模式，可以通过应用无感知的方式，解决一些内存数据库（比如 Redis、Memcached）单机 DRAM 容量不足或成本过高的问题。 App Direct Mode 将 Optane DIMMs 当成一个持久化设备来使用，直接通过 CPU 指令读写 Optane DIMMs，不需要经过 DRAM。应用可以使用能够感知持久化内存的文件系统（比如 EXT4-DAX、XFS-DAX、NOVA）或其他组件（比如 PMDK）来管理、操作持久化内存设备。 Memory Mode 由于不考虑持久化问题，一般情况下将其当做一块更大的 DRAM 使用即可。 在 App Direct Mode 工作模式下，尽管 Optane DIMMs 设备本身是非易失的，但是由于有 CPU Cache 的存在，当设备掉电时，“还没写入” Optane DIMMs 的数据还是会丢失。 Asynchronous DRAM Refresh 为了数据的持久化，Intel 提出了 Asynchronous DRAM Refresh（ADR）机制。ADR 机制保证，一旦写请求达到 ADR 中的 WPQ（Write Pending Queue），就能保证数据的持久性。除了 WPQ，Optane DIMMs 上也有缓存数据，ADR 机制同样会保证这部分数据的持久化。 但是，ADR 机制无法保证 CPU Cache 中的数据的持久化。为了保证 CPU Cache 上的数据持久化，可以调用 CLFLUSHOPT 或 CLWB 指令，将 CPU Cache Line Flush 到 Optane DIMMs 中： CLFLUSHOPT 指令执行完成后，CPU Cache 中的相关数据被逐出。 CLWB 指令执行完成后，CPU Cache 中的相关数据依然有效。 由于，CLFLUSHOPT 和 CLWB 指令都是异步执行的，所以一般需要跟随一个 SFENCE 指令，以保证 Flush 执行完成。 CPU 还提供了 NTSTORE（Non-temporal stores）指令可以做到数据写入的时候 bypass CPU Cache，这样就不需要额外的 Flush 操作了。 Optane DIMMs 的读写延迟 从论文中的测试数据看，Optane DIMMs 的读延迟是 DRAM 的 2~3 倍。另外，Optane DIMMs 顺序读的速度是随机读的 1.8 倍，相比之下，DRAM 顺序读的速度只有随机读的 1.2 倍。 由于写入 Optane DIMMs 的数据只需要到达 ADR 的 WPQ 即可，DRAM 和 Optane DIMMs 的写入延迟接近。 图正上方的三个数字的含义是：load 线程数 &#x2F; ntstore 线程数 &#x2F; store + clwb 线程数 DRAM 的读写带宽几乎不受数据大小和并发线程数的影响，速度很快并且非常稳定。对 DRAM 来说，读带宽大约是写带宽的 1.3 倍，但是 Optane DIMMs 读带宽是写带宽的 2.9 倍。 Optane DIMMs 的读写带宽在读写数据大小为 256B 时达到最大值。这是因为 Optane DIMMs 虽然支持字节寻址，但是每次读写的最小粒度是 256B。当一次读操作小于 256B 时，会浪费一些带宽。当一次写操作小于 256B 时，就会被转换成一次 read-modify-write，造成写放大（这点和 SSD 很像，只不过粒度更小，SSD 一般是大于等于 4KB）。 最后，根据上图的最右所示，Optane DIMMs 在并发线程数较多且访问数据为 4KB 时，带宽掉了个大坑 —— 这和 Optane DIMMs 内部结构有关。主要原因有两个： 对内部 buffer&#x2F;cache 和内存控制器（iMC） 的争用。 由于多条 Optane DIMMs 采用 4KB 交叉的方式组织成一个完整的持久化内存地址空间。每次访问对齐的 4 KB，请求都只能落在一条 Optane DIMMs 上，无法发挥多条 Optane DIMMs 通道并行执行的能力。 ✅论文的最后总结了 4 条 Optane DIMMs 的最佳实践： Avoid random accesses smaller than &lt; 256 B. 避免小于 256 字节的随机读写。 Use non-temporal stores when possible for large transfers, and control of cache evictions. 大内存操作时，使用 ntstore 指令绕过 CPU Cache。 Limit the number of concurrent threads accessing a 3D XPoint DIMM. 限制一个 Optane DIMMs 通道的并发数。 Avoid NUMA accesses (especially read-modify-write sequences). 避免 NUMA 访问。其实内存也一样，远端内存比本地内存要慢不少，这个问题在 Optane DIMMs 表现更突出，需要特别注意。 更具体的内容，建议大家去看论文。 Basic Performance Measurements of the Intel Optane DC Persistent Memory Module 这一篇也比较有代表性，数据更详细。 PMDK 简介前面说了，为了保证数据的持久化，需要在合适的地方用一些底层的 CPU 指令来保证。这样做有两个明显的缺点： 太过于底层，代码写起来麻烦。 可移植性差，不同 CPU 的指令是不一样的。 为了简化基于持久化内存的应用开发，Intel 开发和维护了 Persistent Memory Development Kit 这个开源组件。虽然这个组件目前由 Intel 开发和维护，但是理论上 PMDK 是与具体的硬件平台无关的——虽然现在依然只有 Intel 的一款持久化内存量产了。 PMDK 中的库可以分成两大类： Volatile libraries。如果不关心数据的持久化，只想通过 persistent memory 扩展内存，可以使用这一类库。 Persistent libraries。如果想要保证数据的 fail-safe，需要使用这一类库。 Volatile libraries libmemkind 提供 malloc 风格的接口，可以将持久化内存当成 DRAM 使用。 libvmemcache 是一个针对持久化内存的特点优化的易失性 LRU 缓存。 Persistent libraries libpmem 提供比较底层的操作持久化内存的接口，比如 pmem_map 类似 mmap、pmem_memcpy 类似 memcpy，具体可以参考官方文档。 libpmemobj 提供基于持久化内存的对象存储能力。 libpmemkv 是一个基于持久化内存的嵌入式 Key-Value 引擎，基于 B+ 树实现，针对读优化（libpmemkv 的内部实现）。 libpmemlog 提供 append-only 的日志文件接口。 libpmemblk 提供块存储接口，简单说就是将持久化内存抽象成一个数组。 除此之外，PMDK 还提供了一些工具和命令用于辅助开发和部署基于持久化内存的应用，具体参考 PMDK 官方文档。","tags":["NVM","PMDK","Optane DIMMs","Storage"],"categories":["系统与体系结构"]},{"title":"关于 mmap 与 read/write","path":"/post/系统与体系结构/mmap-vs-read-write/","content":"原文链接：https://nineright.github.io/2014/03/12/mmap-io.html 前几天在看 malloc 实现资料的时候，看到 mmap，发现自己并不是非常理解 mmap 的作用，于是查了一些资料，顺便把以前的知识梳理一下，于是就有了这篇博文。 Linux 下对文件的访问主要有两种方式。一种是 read&#x2F;write&#x2F;seek，而另外一种是利用 mmap 系统调用将整个文件映射到内存中。$[8][9]$对比两种方式的性能，测试结果如图 1、2 所示。 图1：mmap 读写文件测试 图2：mmap 图像处理性能测试 (scale 是测试程序的一个参数) mmap 的优势Stackoverflow 上$[2]$有一个很好的讨论，对比 read 和 mmap。总结一下，通常使用 mmap() 的三种情况最终目的其实都一样：提高效率。 🔥提高 I&#x2F;O 效率：传统的 file I&#x2F;O 中 read 系统调用首先从磁盘拷贝数据到 kernel，然后再把数据从 kernel 拷贝到用户定义的 buffer 中（可能是 heap 也有可能是 stack 或者是全局变量中$[6]$）。而 mmap 直接由内核操刀，mmap 返回的指针指向映射内存的起始位置，然后可以像操作内存一样操作文件，而且如果是用 read&#x2F;write 将 buffer 写回 page cache 意味着整个文件都要与磁盘同步（即使这个文件只有个别 page 被修改了），而 mmap 的同步粒度是 page，可以根据 page 数据结构的 dirty 位来决定是否需要与 disk 同步。这是 mmap 比 read 高效的主要原因。对于那种频繁读写同一个文件的程序更是如此。 匿名内存映射：匿名内存映射有点像 malloc()，其实 Heap 和 BSS 段就可以看成是一个 anonymous mmap [图 4]。有些 malloc 的实现中，当要分配较大的内存块时，malloc 会调用 mmap 进行匿名内存映射，此时内存操作区域不是堆区，内存释放后也会直接归还给 OS，不像 heap 中的内存可以再利用。匿名内存不是 POXIS 的标准，但是几乎所有的 OS 实现了这个功能。一个目前功能最好的 malloc 实现 dlmalloc 就是采用这种方式$[4][5][6]$。dlmalloc 有三种分配方式： (1) 小于 64B 的 exact-size quicklist； (2) 小于 128KB 的 coalesce quicklist； (3) 对于较大请求直接调用 mmap。 共享内存进程通信：相对于管道、消息队列方式，通过内存映射的方式进程通信效率明显更高，它不需要任务数据拷贝。说到共享内存，还有一种 System V 保留下来的内存共享方法就是 shmget 相关系统调用。两者相比 mmap 更加简单易用一些，而 shmget 提供的功能更全面一些。 mmap 的一些限制当然 mmap 也有一定的限制。 mmap 的对齐方式是 page 为大小的，有存在内存内部碎片的可能（调用的时候 length 没有对齐)，所以 mmap 不适合小文件。 mmap 后的内存大小不能改变。当一个文件被 mmap 后，如果其他程序要改变文件的大小，要特别留意[8]。 mmap 不能处理所有类型的文件，例如 pipes、tty、网络设备文件就不能处理。 mmap 要求进程提供一块连续的虚拟内存空间，对于大文件（1G）的内存映射。有时候会失败。尽管空闲内存大于 1G，但是很有可能找不到连续的 1G 的内存空间。 mmap 对于那种批量写 (write-only) 的情景并没有优势。 $[1]$讨论了在传统的数据库中对数据库文件的相关操作“为什么不用 mmap？”。传统数据库对 datafile 的读写大部分是通过 open 系统调用加 O_DIRECT 标志。使用 O_DIRECT 标志可以跳过 kernel 的 page cache 而直接与 block device（如磁盘）打交道，与普通的 read&#x2F;write 相比少了一层缓存 (page cache)，数据库开发者通过实现在用户层的高效缓存来达到提高效率目的。但是这带来很大的复杂性问题，首先使用 O_DIRECT 的话，就必须以页为单位进行 I&#x2F;O，而且既然放弃 kernel 的提供 page cache 以及相关的缓存策略，那么意味着是想通过 O_DIRECT 提供自己的更好的缓存策略，这个往往是很困难的。在 Linus 看来$[12]$，“O_DIRECT 是一个非常糟糕的接口，目前只为数据库开发者保留，其他人使用都属于脑残的行为”。数据库开发者想通过直接与 device 打交道（简单说，他们觉得能比 OS 干得更好），来提高 I&#x2F;O 性能，例如提供更适合数据库的缓存策略（如 LIRS 缓存算法$[13]$）。例如 Innodb 中通过配置文件的形式提供了两种方式读写数据文件，一种是传统的 read&#x2F;write 读写，一种是 O_DIRECT 访问。一般情况下 O_DIRECT 的性能要高$[11]$。 处理高并发的方案在作者看来，用 mmap 管理是一个可行的方案：使用 mmap 可以减少 kernel 与 user space 之间的 context switch；kernel 提供了 page cache 高效的缓存管理；内存被共享时 kernel 提供了同步功能。除了 mmap，配合 mlock()、madvise()、msync()，开发者能够更自由的控制缓存策略。像 MongoDB 就是使用 mmap 来读写数据文件的。但是由于使用 madvise 的人不多，kernel 好像并没有利用 madvise 信息，或者效果不是很好$[12]$。 文中最后提了这种方式如何应对高并发的请求，并提了一些解决方案。 Coroutine，用户级的协程的好处就是比 thread 的开销更小，但是有一个很大的问题，一旦一个协程调用系统调用阻塞时（如等待 I&#x2F;O），协程所属的线程就会阻塞，也就意味着其他协程也要跟着阻塞。这里有几种解决方案： 如果能够容忍阻塞对性能的影响，就不做处理。 为阻塞的协程新建一个内核线程专门等待系统调用完成，这样其他协程就可以继续， Goroutine 采用的就是这种机制。 使用 NonblockingIO，文中提到了 epoll+eventfd$[14]$。Epoll 是 linux 下的一种多路复用技术，功能与 select，poll 一样，eventfd 则与 pipe 有点像，它通过创建的事件对象来读写一个 64 位的整数计数器，线程之间通过协商好事件对应的数值来协调通信。 对于 O_DIRECT 访问 Disk，使用异步 IO，当然也可一配合 epoll 使用。 $[1]$文中的评论给出了一些不同看法： 频繁的使用 mmap 会很容易耗尽内存的资源，特别对于 32 位的机器。作者提出可以使用 cgroups$[15]$来控制资源的使用。 mmap 并不适合那种 write-only 的场景，或者说这个时候没什么性能优势，而 database 的 commit log 就属于这一类型。 mmap 不能提供一些灵活的控制缓存的需求，例如控制不同缓存块的写入顺序等等。 图3：Linux虚拟内存空间（截图自 CSAPP 第二版） 图4：Linux 虚拟内存空间对应的重要数据结构$[16]$ Page Cache上文的讨论中，涉及到一个很重要的概念——Page Cache，简单概括，就是磁盘的数据以页式缓存的形式保存在内存中。可以从两个方面去理解 Page 和 Cache。 Cache：缓存存在的最主要目的为了解决设备读写速度不均横的问题。例如内存可以理解为 Disk 等设备的缓存，CPU Cache 可以理解为内存的缓存。图 5 给出了传统计算机各个部件的速度，非常的直观。简单说一个好的缓存设计可以大大提高系统 IO 的性能。 Page：Page 是 Disk block 在内存中的缓存结构，类似的 Cache Line 是内存数据在 CPU Cache 中的缓存单元。一般 Page 大小是可配置的，一般是 Disk block 的倍数，但是一个 Page 对应的多个 block 在 Disk 中不一定是连续的。 一个高效的缓存，必然会涉及到几个问题。 缓存替换算法：最有名莫过于 LRU (Least Recently Used) 算法，但是 LRU 在批量读写大文件的时候，会清空当前缓存，而如果读取的大文件只是读取一次，那么意味着之前缓存的数据又要从磁盘重新读取，为了避免这种情况 Kernel 使用两条链表，一条 Hot 链表，存的是被访问一次以上的数据，而另一个链表存放第一次读取的 Page，两个链表都使用 LRU 算法。 数据写回侧策略：主要两种：write through 和 write back。Kernel 为了效率使用 write back。后台使用 flush 线程将 page cache 与磁盘等设备同步。有三种情况会触发这个同步线程： 内存空闲（未与磁盘同步）页表数低于系统设定阈值； dirty 的页在内存中存在超过系统设置的时间； 用户调用 sync()，fsync() 系统调用。Linux Kernel 中 flush 的线程数目等于系统磁盘（持久化设备）的个数，其实同步线程有一个演化的过程，从 bdflush 和 kupdated 配合使用到动态个数的 pdflush 线程再到现在的与外部设备等个数的 flush 线程。具体可参考$[17]$。 如何高效判断数据已在缓存中：Kernel 中使用 Radix Tree 进行索引，在 2.6 版本以前使用全局的 Hash Table 效率较低。现在是每个文件都会有一个 radix tree。提供一个文件的偏移值（偏移值对应 radix tree 的 key），可以在常数（与偏移值的位数有关）时间内找到对应的 page 项，如果没有，则先分配一个，再返回，并且每个 page 项表明了是否 dirty 等信息。Radix Tree 是 Trie 的压缩版本，Trie 是一个节点一个字符，Radix Tree 允许多个字符。 有关 Page Cache 的更细节的东西，可以参考《Linux kernel development》$[17]$第13 章。 图5：一个典型 X86 架构各个部件的速度$[16]$","tags":["Linux","Linux Kernel","read","write","mmap","mmaloc"],"categories":["系统与体系结构"]},{"title":"漳州·东山岛","path":"/post/摄影日志/dongshandao_2024-10-30/","content":"工作日的短暂逃离💨 东山岛 东山岛","tags":["摄影","漳州"],"categories":["摄影日志"]},{"title":"福建·福州","path":"/post/摄影日志/fuzhou_2024-10-01/","content":"有一些东西要靠消失才能证明它的珍贵，如果这是无法返航的日子，那我祝你们一路向前，桥都坚固，隧道都光明，如果不能，那就祝你们曾经的理想能足够支撑当下的生活，等到未来偶然的一天回到这里，再聚的时候，我们能轻轻释怀所有的冷雨，微笑着轻描淡写地说：不过些许风霜罢了。 自是聚少离多","tags":["旅游","摄影"],"categories":["摄影日志"]},{"title":"宁夏·银川","path":"/post/摄影日志/yinchuan_2024-07-27/","content":"银川即是 “归雁入胡天” 的古来边关，更是 “大漠孤烟直” 的具像化，览山公园的风景让我着迷，我走过沙漠，骑骆驼 🐫，吹过旷野的风，这种无拘无束，自由掌握人生的感觉真美好。 宁夏·银川","tags":["摄影","银川"],"categories":["摄影日志"]},{"title":"四川·成都","path":"/post/摄影日志/chengdu_2024-07-14/","content":"和我在成都的街头走一走，直到所有灯都熄灭了也不停留 成都 川西·毕棚沟 成都美食 梵高展","tags":["旅游","摄影"],"categories":["摄影日志"]},{"title":"陕西·西安","path":"/post/摄影日志/xi'an_2024-06-24/","content":"人生首飞 厦航 西安·碳水之都 Shot on iPhone 13 OPPO 健身房 奇險天下第一山·華山 落花时节又逢君·XJTU","tags":["摄影","西安"],"categories":["摄影日志"]},{"title":"浙江·杭州","path":"/post/摄影日志/hangzhou_2024-06-15/","content":"第 26 届中国计算机系统研讨会 Shot on LumixS5-50mm 浙江大学·玉泉校区","tags":["摄影","杭州"],"categories":["摄影日志"]},{"title":"漳州·南靖土楼","path":"/post/摄影日志/zhangzhou_2024-05-01/","content":"田螺坑土楼群 🫡 Shot on iPhone 13","tags":["摄影","漳州"],"categories":["摄影日志"]},{"title":"福建·泉州","path":"/post/摄影日志/quanzhou_2024-01-28/","content":"泉州烟火气 清源山","tags":["摄影","泉州"],"categories":["摄影日志"]},{"title":"2023 年终总结｜别急着赶路，去感受路","path":"/post/年终总结/「2023」feel-the-journey/","content":"前两年的年终总结在这： 「2021 年终总结」唯有热爱，可抵漫长岁月 「2022 年终总结」人生是一片原野，而非轨道 0x01. 毕业季🎓临近毕业答辩的前两月，我的课题方向在哲哥的指导下才有了一定的形状，于是年后的 2 月初，我紧赶慢赶地回到实验室继续完成我的毕设，可算在 2 月底完成这篇学术垃圾。别人都在想着怎么降重，我倒好，论文查重率为 0%，要么开天辟地，要么学术垃圾，我这篇就不一样了，是属于开天辟地的学术垃圾。 知网查重 来自我哥的锐评 论文答辩、毕业典礼、毕业合照、寄行李、转档案、退宿舍，在一条条通知的催促下完成最后的 ddl，既没有真实的别离痛苦，也没有休息的闲情逸致，忙起来就觉得烦躁，闲下来又感到空虚。如果非要用一个词来形容的话，那就是“仓促”，仓促到没有多留下几张合照。我总计划着在毕业前和所有小伙伴们单独都拍一张合照，但总觉得时间很长，机会还有很多，于是一拖再拖。拖着拖着，临近毕业我才发现，原来上次瞥过的那一眼，已经是最后一面了。 那些年学校的活动 报复性消费那些年错过的食堂 临近毕业那几天的晚霞格外瑰丽，那个时候，跑步比其他任何事都来得快乐，骑着小电驴觉得怎么会有这么轻便的工具，在深夜的操场上尽情感受风的形状。送别的时候，我们都约着再见，约着回来，其实大家心里都清楚，再怎么强买桂花同载酒，也终不似，少年游。毕业的那段时光，我们都爱说“毕业快乐”，其实毕业一点都不快乐，可明知是没有人会一直在舞台上，怎么这么多人都舍不得大步迈向自己的人生。也许是太过于珍视某些人、某些事，珍视过去的快乐，以至于大家试图通过各种方式想要延续大学这段时光，可惜镜花水月，江中央已经再也回不去了。 其实，人与人之间，一个 moment 就足够了。 美好的不只是我的 22 岁，还有 22 岁的我。 毕业快乐 也许人生最大的遗憾，是一个人无法同时拥有青春和对青春的感受。我不知道未来会是一帆风顺，还是人海浮沉，但起码我可以在照片里留住这些瞬间，对我数年来的学海泛舟，做个了结。感谢所有的遇见，祝好，在未来的每一个瞬间！ ✍️毕业论文写下的致谢，共勉 0x02. 武汉｜樱花时节🌸2022 年末参加的一场比赛，让我有幸得到主办方邀请前去武汉 HUST 参加颁奖典礼。 依稀记得三天的武汉之旅，两天半的时间在下着大雨，好在亲眼目睹了武汉樱花园里盛开的樱花。 Sakura 武汉的汉口江滩去了、汉口码头去了、武汉美术馆去了、吉庆街去了、黎黄陂路去了、黄鹤楼去了、长江大桥去了、粮道街去了、户部巷去了、昙华林去了。唯一遗憾的就是没有提前预约湖北省博物馆，没有亲眼见一见那被誉为“天下第一剑”的越王勾践剑、改写世界音乐史的曾侯乙编钟。 武漢 plog 0x03. 杭州｜之江实习🧑🏻‍💻 2023 年 4 月 28 日，完成毕设答辩后，我即刻飞往杭州，开启了在「之江实验室」长达 3 个月的实习生活，下面分享一下我这三个月的实习体验、租房经历以及杭州的风景，算是给这段实习画上一个圆满的句号。 杭州租房小记到达杭州前，我提前联系好了一个中介帮忙租房，押金付了，人也到了，中介半天都联系不上，就这样一个人在酒店楼下坐到了傍晚。当时真以为自己被骗了，还求助前台小哥直接联系房东，问题才得以解决。 人生建议：真的不要摆脱中介找房，如果真的需要，也找一个靠谱点的中介。 房子在杭州「临安区」青山湖附近，属于杭州的郊区了，但是户型我很喜欢，房间很大，空间够容纳两个人。月租也只需要 ¥1400 而已，实习的住房补贴能够完全 cover，房东人也非常好。要说唯一的槽点，那就是住在 15 楼真的很不方便，每每上班坐电梯，总要遭受非人的折磨。 租房日记 在杭州待到了 8 月，随后转租出去，按理说我提前结束租房，房东完全可以依据合同条款不偿还剩余的租金和违约金，房东人美心善，见我还是学生，不仅给我退租金和押金，还给我额外的💰，着实感动。 转租 房东退租金 上有天堂，下有苏杭入职那会正好赶上 5.1 放假，匆匆忙忙办好入职手续后，就又放了一个小长假，正巧又碰上师兄来杭州找我玩，便开始攻略杭州各大旅游景点。 正所谓东南形胜，三吴都会，钱塘自古繁华。西湖的美自然不必多说，除此外，我还走过京杭大运河，游过良渚古城遗迹，进过灵隐寺，见过雷峰塔，打卡过一块钱人民币背面同款的三潭印月，经历过武林夜市的繁华… 这期间我也走到过「影视飓风」的基地，可惜只能远远眺望，这是我非常喜欢的一位 up，或者说，一个创作团队，看着他拍出那么多优秀的作品，总能被感染到，一次又一次点燃我摄影的激情。 江南 · 杭州 不过杭州不愧被誉为“美食荒漠”，兜兜转转找不出什么比较有亮点的美食，但我那几个月确实胖了不少，匪夷所思，也许一方水土养一斤肉吧。当然这偌大的杭州也不是我短短几月能逛完的，毕竟我都是抽空出去旅游，感觉还有许多有趣的地方都没来得及参观，就这样离开了，心里还是有一点点遗憾的。 真 · 美食荒漠 ZHEJIANG Lab · 之江实验室 · 实习 以下记录仅代表个人观点，存在较强的主观性，每个研究院、每个中心的情况都不一样，仅供参考。 之江实验室是「浙江省」创建的开放协同的混合所有制新型研发机构，依托「浙江大学」和「阿里巴巴」为主要研究力量，坐落在浙江杭州余杭区。 地理位置公司的位置超级偏僻，在余杭区南湖那里，地图导航搜索 “之江实验室新园区”，而不是人工智能小镇那里。每天早上公司都有专门的班车，大概 5 分钟就到了，但是我住临安区，上班通勤时间差不多要 40 分钟。 工作时间初到杭州，给我的第一感受就是，大城市的节奏是会快一些，这里的人脚步快、做事也快，比如下电梯基本不会站立等待，会加快脚步跟着走，显得我有一丝丝格格不入。之江实验室反倒有些许不同，你在这里可以慢下来，慢慢生活，慢慢工作，不过这一切后面改变了，因为绩效考核越来越严格，公司采用阿里赛马制，但这都是针对正式员工而言，实习生倒是没什么过多要求。 这里有最真实的 “955” 工作时间，不用加班而且双休，早上 9 点开工，到中午 11:30 即可去恰饭，中午午休 2 小时，然后从 13:30 干到 17:30 就可以下班了，每一天都是如此，除了有时开会可能会拖到 18 点，其他时候准时准点走人，不存在任何隐性加班的问题，实习生或正式员工都是如此。 之江团队我所在的组是「之江-燧原联合创新研究中心」下的「新型通用智能计算芯片与定向加速芯片研究任务组」，程老师是我的组长，人特别好，也非常有耐心的带我，关照有加。 工牌 🪪 组内的学历全是博士和博士后，整个之江实验室「硕士:博士」的比例为 3:7，不过我是组内唯一一个 00 后大学生，估计也是之江屈指可数的 00 后了，这边的称呼都是以“老师”为称，所以当别人知道我的年龄，我听得最多的反应就是：“这么年轻”。 之江实验室对员工的学历要求很高，这边遍地都是 985 本硕博，211 学历都会被卡。最夸张的不过当时听说有一位老师内推应聘，见他们在分析简历，发了 7 篇顶会，可以在浙大当个教授了都，但是因为第一学历不是 985 被卡在之江实验室的门外，当时深受震撼。当然我是走「项目聘用」的通道进来的，不然也不会有这个机会在这里实习。 在这里我认识了很多很厉害的老师，也有幸能和他们打成一片，虽然我不擅长交际，但是和每位老师都能时不时说上几句，甚至认识不少燧原中心的其他老师和同在实习的小伙伴们。中间甚至有一位老师来求助我一些问题，大概是想考中科大非全日制在职博士，但是他很多年没参加这种考试了，拿着提纲就来问我复习哪些内容，给些推荐，最后他也如愿考上了，还特地线下感谢我了一波，当然也请我搓了一顿。还有三年博士海归、高考探花等等优秀的，就不一一说了，总之在这里、在他们身上，我学到了很多在学校学不到的知识和眼界。 工作日记我以时间线的形式分享一下我在之江的一天。 早上基本都将近 8 点起床，然后从青山湖站坐地铁🚇，接着到南湖站后等公交车🚌。 差不多 8:40 左右到达园区，然后刷卡&#x2F;刷脸进入。 电梯不错，但是感觉这边的电梯调度算法有点问题🙋‍♂️ 公司食堂在主楼，并不算大，但是早餐种类很多，我最喜欢的就是这边的早餐了，便宜又好吃😋。 9:00 左右吃完早餐就去工位上， 9:10 开晨会汇报近两天的工作。虽说是九点上班，但很多员工都是九点后才到工位上，mentor 说这边打卡时间还是比较灵活的，毕竟从刷脸进园区那一瞬间就已经算上班了。 关于会议： 周一、周三、周五晨会：主要讲讲自己这两天的进展 周二晚论文分享会：每一两月一次即可 周四晚技术分享会：中心分享，相对重量级 有幸在组内做过一次分享，给大家介绍了我的科研工作，并得到较为客观的指导： 我的工位 后期工位（从小到大都喜欢坐到角落位置） 预订会议室、厦大实验室组会｜I like this feel 上午 11:30 就可以去食堂吃午饭了，正式员工有自动扣款的档口，实习生只能去刷卡的档口。食堂菜色还可以，整体价格大概是学校的 1.5 倍。 食堂餐饮｜比看上去的还要好吃 超市 11:30 ~ 13:30 属于自由时间，午餐、睡觉或健身房都可，老师们一般是吃完午饭在园区内散散步然后回去午休。很多员工都会买折叠床，也可以在主楼（我所在的那栋楼）的客厅沙发上睡午觉。 之江园区 13:30 开始下午的工作（实习过我才发现午休的重要性），工作到 17:30 就可以下班了，可以选择在食堂吃晚餐，也可以回宿舍吃，我一般选择健身完吃饭后再回去。每周一、周三、周五下午，我基本都会和各位老师一起去打羽毛球🏸、打乒乓球🏓、打篮球🏀或者去健身房🏋️锻炼，这边的设施都很齐全。我特别喜欢羽毛球双打，自我感觉虽然打球不够专业，但是跑动能力和反应力还是挺强的。 羽毛球馆 健身房 图书馆和健身房 除了健身房、图书馆、咖啡店等常规配套设施外，园区内还有舞蹈协会、书法室、绘画室，还蛮新颖的。 ZHEJIANG Lab · plog 之江团建入职不久后，我刚好赶上公司半年一次的团建活动，地点在「杭州云上草原国际山地旅游度假区」，懂不懂周五团建的快乐啊😎 福利待遇正式员工有五险一金，12% 左右的公积金，生日福利，节日福利。 正式员工每个月有 600 餐补，硕士 2000 房补，博士 2500 房补。 年假 10 天左右，孕假更久，基本都是和国企对齐的，毕竟省政府创建。 正式员工会有免费公寓，普通员工 40~50 平，职位高些能有 100+ 平米。 不过有利有弊，我觉得有以下的缺点： 财务部效率不高，首先是住房补贴，发票审核太久而且过于注重细枝末节，导致我入职一个月后才拿到住房补贴，而且发放实习工资的速度较慢 不论正式员工还是实习生，工资水平相对不高，实习工资按照考核标准来的，优（3500）、良（3000）、合格（2500）、不合格（0），这还只是税前工资，到手工资扣税 20% 左右，第一个月我到手 ¥2950；至于正式员工，毋庸置疑肯定是比私企少的 园区位置相当偏僻，属于郊区中的郊区，周围很荒芜，外卖都送不进来，也许这就是科研氛围吧 之江实验室属于省属单位，所以拿不到杭州市人才补贴（硕士 5w，博士 10w） 末位淘汰制度：这是我入职不久后在会议上听中心主任说的，我所处的部门更是核心部门，做芯片的，预计短期不会裁员，还在扩招 博士生、大厂跳槽的人很多，硕士的晋升有限，以科研成果评估 能学到的东西比较有限，如果你想提升代码水平，还是建议往私企大厂那边靠 工作氛围这边很多的员工都是从阿里、腾讯、华为等大厂跳过来的，基本没有应届生，员工的年龄基本都是 35 岁以下的。我问过 mentor，他说一般只招 3~5 年工作经验的硕士，而且这两年不怎么招硕士了，招博士为主，毕竟研究所。 工作的时候不会有人巡视，很自由，工作内容上主打科研，论文、专利、申请项目，也会有项目落地的工作，整体压力都不大，论文可以慢慢看，代码可以慢慢敲，工作时间内都能完成相应的任务。 周围同事也都很友好，素养很高，完全不会有电视剧里出现的 “职场霸凌”、“勾心斗角”、“死气沉沉”、“PUA” 的情况，感觉每一天都有盼头，大家都很热爱自己的工作。 三个月的实习经历在 8 月落幕了，故事的结尾也是该说再见了，期待下一次相遇👋 人只有在举目无亲的地方才算真正活着不知道你有没有过这种想法，一个人居住在没人认识我的城市，我不需要帮助，也不想总是被问收入。一直以来，好像大家得到的很多爱都是以责备的方式表现出来的，爱使人愧疚，责备使人害怕，但这都不是什么好情绪，所以我真心实意地觉得：长大真好。虽然我的父母、亲人朋友们并不对我苛求，也不会干涉我的人生，但这并不影响我向往自由。 长大之后，衣服脏了可以自己洗，杯子打碎了可以重新买，感冒发烧了就吃药睡一觉，去动车站只需拿出手机打一辆滴滴，就像自己孑然一身去杭州实习，自己能决定 ”天塌下来当被盖“ 的感觉真的很好，我可以很有底气的大手一挥说一句 “没事，我可以摆平”，这种自由掌控人生的状态让我着迷。原来打一辆车真的花不了多少钱，原来问题出现只需要解决问题本身，万万不用上升到道德层面，自己给自己兜底。 不过开头说的住进孤岛的想法只是开个玩笑，并不是没有勇气，而是在世上有着割舍不掉的羁绊，因为这个世界上有在意的人，这同样也是我长大的意义，但偶尔人也要为自己而活一活，人只有在举目无亲的地方才能真正活着，也许这就是出发的意义。 义无反顾实在是一个很美好的词，原来我爱的少年气，是对这些美好不愿意放下的追逐，我真的需要一点鲜活的、自由的、沸腾的、张扬的东西，只要一点点，真的就足够支撑我走很远的路。我知道大家都已经在生活中拼尽全力，但偶尔也想把世界从肩膀上卸下来，去做你喜欢的事吧，不要等到成年某刻再去宴请年少的自己，时间错位一切都将失去意义。 去奔跑，去唱歌，去摔倒，去大声哭，就是趁我鲜活，不允许任何人熄灭我。我爱我的家乡，我可以生在这里，也可以死在这里，但我不能从生到死都在这里。 而此刻，我将出发，我还要万里路要行。 0x04. 深圳｜CLKs 会议🌀10 月份报名参加了「Linux 内核开发者大会」，导师报销车费住宿费，那我不得狠狠去深圳涨涨见识。 此次去深圳有 7 人，10.27 都一块住深圳维也纳酒店，大概 ¥600 左右一晚，我的评价是不如厦门 ¥300 一晚。 记录记录📝 三天的行程安排大致如下： 10.27：到达深圳，参观腾讯公司 10.28：早上参加 CLKs 主场会议，下午参加内存管理分会场（参会人最多的一场，除此之外还有 “云和服务器”、“调试&#x2F;eBPF&#x2F;调度”、“Arch&amp;虚拟化&amp;I&#x2F;O” 这几个分会场） 10.29：打道回府 不过这只是我导安排，我们还四处逛了逛，原本 28 号打算去欢乐谷玩，还好提前调研了一下，欢乐谷前一天刚好出了过山车碰撞🎢重大事故，已经闭园两个多月了，最近这几天才重新开园。还好晚到一天，逃过一劫，不然进 ICU 的就是哥几个了。 后面兜兜转转，酒吧基本都有低消（2k左右），还是选择了性价比最高的网咖，不得不说深圳的网咖是真的贵，价格我忘了，但我忘不了下单时的不舍。我们几人在网吧开黑到凌晨 3 点左右，就玩了俩游戏：「英雄联盟」和「求生之路」，开黑还得是后面这款游戏有意思。 打车回酒店的路上，🚖师傅说这栋楼的 3 楼是深圳最有名最大的同性恋交友互动酒吧，好家伙，我回去还搜了一下，这酒吧叫 BONBON CTR，感兴趣的小伙伴可以去看看，反正是震撼到我了，深圳不愧是大城市，包容性就是强。 我们这几天在深圳基本都吃自助餐，早餐自助，晚餐自助，午餐就吃披萨和会议提供的盒饭🍱。 伙食（简） 深圳 plog · 随手拍📷 0x05. 厦门大学｜生活 · 工作🌈2023 年 9 月，我来到了厦大。 短短 30 公里，我走了 8 年才到… 厦大没有宵禁，任你几点回寝室都可以，给予学生最大限度的自由。 校园生活也挺丰富，时不时会有一些大型活动。 至于餐饮方面，我觉得厦大唯一的优势就是便宜，价格比你想象中的还要低，所以这里的生活成本并不高。但是质量方面，我觉得和师大还是有一定差距的，难怪被誉为 “福建吃饭大学“，时至今日我才彻底明白，那些优质的饮食，是我回不去的青春😭 翔安校区很静也很偏僻，缺少了一丝文化底蕴，不像思明校区那般，仅仅走在芙蓉隧道你就可以深切感受到厦大的人文气息。毕竟人文思明，理工翔安。 实验室里的生活也没有我想象中的枯燥，氛围十分融洽。偶尔学累了还可以打打羽毛球、乒乓球、台球、网球，也可以去健身房撸铁，去游泳馆放空自我，或者回寝室弹弹吉他，学会放松也是挺重要的，持续高压的环境下，弦是会断的。 22 年 8 月进入实验室以来，我都觉得自己的研究生生涯离不开圣哲、子航、佳泓及锋哥等等的帮助，其中受益最深的莫过于哲哥，感激之情溢于言表。 23 年下旬那段时间压力真的很大 2023 年末，学校开办的讲座接踵而至，我最没想到的是陈海波老师竟然来到厦大开讲座，学术界的大咖，讲座当天像极了粉丝见面会和新书发布会，我也很荣幸地得到了波哥的专属签名，浓墨重彩的一笔✍️ 哲哥说名字怎么自己写的，给我笑拥了 怕你们看得不清楚👀 不过看到海波就会联想到自己的华为 P30 手机寿终正寝，鸿蒙系统没我想得那么强大，至少站在消费者的角度来说。 12 月 20 日，我发现自己的手机会无限重启，进入系统后是紧急备份模式，无法正常使用。调查了下，发现是鸿蒙系统升级的锅，导致主板发热严重，主板虚焊脱落导致无法启动。当天去线下维修店，老板说可以维修，但是这种 CPU 烧坏了的情况，维修也就可以支撑几个月，还需要 ¥500 的维修费，所以我果断换把新机。也就是这种机缘巧合下，我凑齐了简约版的 “苹果全家桶”： iPhone 13 iPad Air 4 MacBook Air M2 全家桶合照 除此之外，我挺想拥有一台属于自己的相机，我热爱摄影，热爱记录生活中每个值得纪念的瞬间。读书让我了解世界，而摄影能让我把世界按照自己的想法具像化。 咔嚓 📷 厦门印象 XMU 0x06. 读研是当代年轻人的青春疼痛文学🌓2023 出现一个新名词 “孔乙己的长衫”，大概意思就是说，高学历不仅是块敲门砖，也是我下不来的高台，更是那孔乙己脱不下的长衫。如果我没上过大学，我就可以心安理得的去做任何工作。 我听说过一种说法，从经济学方面来解释所谓的结构性失业，感到非常有意思，和大家分享一下。把问题放在时空的大背景下，这个原因，其实要追溯到当年为了应对 98 金融危机促进消费而进行的高校扩招。因为这样，大家就回把大量的钱放在教育投资上，当时预计扩招一倍，但事实上没能控制住，扩招了 6 倍。由此，我们迎来了长达十几年的繁荣发展，代价是直接导致了高中教育的内卷，而由于初中是义务教育无法直接内卷，于是高中内卷达到顶峰之后，接下来就是研究生学历的内卷。从这个角度来说，我们目前面临的困境，其实只是历史开了一个玩笑，道理就好像小时候，世界给了你一个承诺：“只要读好大学，就有好工作”，你相信了并且为之付出很多努力，然而现在毕业了，发现世界并没有兑现这个承诺，这只是一个时代的恶作剧。而读研就好像 10 年后，你要去取存在银行里的钱，但银行没钱，所以给你办个业务让你再存 3 年，3 年之后这些钱就按照约定给你了吗，没有人知道答案。 提到读研，我猜测大部分同学对此的执着追求，并非是为了学术梦想，而是为了更高的工资更高的起点，我们从小接受的知识改变命运，大部分人理解的是学历改变命运。然而这套逻辑在 20 年前行得通，在今天却遇到了困难。所以在这种时代背景下，教育被拉下神坛，学习的意义被质疑，我们会感到非常痛苦、愤怒、无力，甚至走向虚无，认为一切都没有意义。 我们不难发现，所谓孔乙己的长衫，本质其实是另一种形式的读书无用论，不过我想表达的是，大家总是要向前走的，即使世界没有兑现承诺，即使高学历成为泡沫，那我们就只能回归最朴素的 “价值决定价格”。这个 3 年之后会好的银行业务，到 3 年之后会不会兑现，仍然是个未知数，我们能做的只有摒弃 “等到什么什么之后就好了” 这种想法，不管是本科还是研究生，都认真提高自己真实的能力，或者我也可以称之为 “理解这个世界运作规律的能力”。从上往下看的话，高学历的价值本身就是外界赋予的，不管是 985 还是研究生，只是个人能力的货币体现，并非个人能力的铁碗保障，出于学历的傲慢，更是非常荒谬。就好比岳阳楼为什么出名呢？因为岳阳楼记。滕王阁为什么出名呢？因为滕王阁序。荷塘月色为什么出名呢？因为朱自清先生他写过荷塘月色。景观都是人文赋予的意义，景观唯一能自己给自己带来的意义，只能是珠穆朗玛峰它是世界第一高峰。因为美是人发现的，审美的主体不把情绪转移到审美的客体上，它也不会有什么附加价值，学历也是如此。 当然这样讲可能是不公平而无奈的，因为在过去相当长一段时间，有太多人靠学历的光环，得到了远超自己能力的回报。然而现在，我们难以凭借单纯的学历而获得这些，很容易会有一种被骗了的感觉，但控诉时代意义甚微，看到很多人焦虑，其实还是在焦虑一些世俗的成功，而从世俗层面来说，作为个人能做的只有尽量在游戏规则里打出好战绩罢了。我只能像丁玲笔下的陆萍那样：“失望和颓丧都是她所怕的，所以不管遇着怎样的环境她都好好的，替它做一个宽容的恰到的解释”。 我还没想好自己的价值，人也不是非要读研不可，其次如果读研，也要给学历祛魅，抛弃莫须有的研究生的傲慢，不寄希望于研究生学历给我带来什么额外的东西，尽量努力做到，这 3 年本身比最后的学历更重要吧。考研也好，保研也好，读研也好，读完研找工作也好，除了真正醉心于学术的诸公，剩下的被逼着走上这套流程的人里，没有谁能从头到尾笑着走出来，「研究生」这三个字好像成了当代年轻人的青春疼痛文学，甚至一经提起，都使人沉默郁然，人人都有满腹苦水兀自吞下，大家一直说 “直接工作也没关系”，心里却不是这么想的，在淘汰制的考试中，注定只有少部分人胜出，每往上走一层，就有大批留在下面一层的人。考试让太多人成了牺牲品，但是 “早知道去送外卖，就不用这么辛苦读书了“ 这个逻辑就完全是对的吗？我想也不尽然，高等教育的普及，就像鲁迅在暗室里的一声呐喊。学历改变命运有限，但我从不怀疑知识的珍贵性。 这个世界，沉默的终究是大多数。 0x07. 罹患甲流😷21 年以前是哮喘，22 年是新冠，23 年是甲流，未来不知道还有什么等着我。 甲流症状还是比较明显的，刚开始体温迅速升高，通常会达到 38~40 度，我有幸刷到了 40 多度，同时会出现肌肉的酸痛，头疼和乏力，它和新冠有类似的症状，但是潜伏期要短一点。接着就是反复发烧、头疼、喉咙疼、流鼻涕，我发烧了 5 天左右，具体症状强度因人而异，反正我是进急诊了，个人感觉强度和 22 年得新冠差不多，但起码新冠才 39.6 度😭 每逢大病初愈，我都会感叹道：活着真好！ 那你如果要问我活着的意义是什么，恕我难以告诉你，众生皆苦，活着很难，不是吗？ 很残酷的现实是，生命的意义是个经不起推敲的问题，因为我们的生命都没什么意义。 站在时光的巨大尺度上，我们微小得令人恐惧，我们珍爱的人，所罹患的病，所背负的包裹，所经历过的喜悦与悲伤，所承受的爱与被爱的重量，都像被秋风扫落的枯叶一样脆弱，不会在世界上留下多少痕迹。 包括我们所经历过的痛苦，也是毫无意义的。就如余华所说的，其实是你的情绪进入了死胡同，而不是你的人生进入了死胡同。 我是说，生命是自己的，如果你觉得承受不住了，我尊重你的选择，也会祝你下辈子做个快乐的人。但如果你仍然有一丝留念值得你再坚持下去，我相信，对死亡已经不再有畏惧的你，一定会是个既坚强，又温柔的人。 你会悄然改变自己甚至别人的生活。那时候你可能会觉得，有你活着，真是件好事。 这段话送给此刻正在阅读文章的你，也送给曾经的那个自己。 0x08. 还好这个世界有音乐🎶平日里非常喜欢听 Jay Chou 和雷子的歌曲，热爱民谣，也把玩着一把民谣吉他，最近迷上了 Eason Chan，应该没有人不喜欢粤语歌吧。我也尝试抢过 jay 和 eason 的演唱会，根本抢不到，希望有机会能去现场感受音乐，如果有价格合适的「杰伦 &#x2F; 奕迅」演唱会门票 🎫 可以 call 我。 NetEaseMusic 年度报告 跟风测了测 mbti，不然都跟不上时代的说 [doge] 0x09. 在繁花深处，遇见梵高🌻第一次见到梵高的画是在高一美术课上，在临摹过程中偶然瞥见两幅画，一幅是蒙克画笔下的「呐喊」，还有一幅便是梵高的「星空」，二者都给我留下很深的印象，似乎是从那一刻见识到了艺术，孤独而伟大。 23 年 8 月，在泉州举办了一场「致敬梵高」的会展，我抓住最后的时间去参观了一趟，很幸运那是最后几天，整个艺术展里只有我和我朋友，像是只属于我们的艺术展，踏进场馆的那一刻仿佛置身于梵高的星空中，我在那里坐了一下午，我很喜欢这种放空的感觉。 致敬梵高展 Van Gogh 梵高的伟大在于，即使一生命运坎坷、穷困潦倒，仍对绘画保持着极为纯粹的热爱，对劳动者和大自然有着无比的热忱。他如火般炙热骄傲的内心，如同阿尔勒的向日葵，让我们在相隔百年之后，仍可以感受到他笔下传递出来的美。 0x0A. 节选自阿兰德波顿的「爱情笔记」☘️我不想和你聊世俗，我想和你聊你的童年记忆，你的幸福时光和至暗时刻。 想和你聊你是怎么一步一步走到今天，有哪些遗憾，错过了什么人，谁保护了你你又感激谁，想和你聊你的故作坚强：你的谎言和逃避，你为了自保而不得已的小阴暗。 想知道是哪句话给你力量支撑你走到今天，想和你聊你对未来的期盼。 至此，我才算浅薄地认识了你，了解了一点点你的来路和去处。 我喜欢有深度和真诚的你，不喜欢没有瑕疵的你，我讨厌早安晚安式的闲谈，我想和你谈论大自然、死亡、性、世界、人类、智慧、生命意义、隐秘想法和你想过的理想人生、让你想跳舞的音乐、有趣的回忆。你说过的谎言、你的缺点、你最喜欢的气味、你的童年、让你彻夜难眠的东西、你的不安全感和恐惧。 我喜欢你带着真实的情感说话，因为那是我要的有趣和血肉，而不是一直借助一些美好的事物和话语，装真实的自己从而表现得完美。 这才是我关于爱你的详细备注。 0x0B. 别急着赶路，去感受路⛵️非要找一个 2023 年的关键词，我会说是 “力所能及”。 他们说，考上大学就好了，考过四六级就好了，考上教资就好了，考上研究生就好了。读研前我以为从此人生就会变好，但踏进新校园的那一刻，世界安安静静，什么都没发生，我恍然意识到，路的尽头还是路，那些我们以为重要的，甚至连转折点都算不上。莫名的我想起了前辈说的一句话，他说，你不要害怕失败，你可以试着去失败一次看看，你会发现，什么都不会发生。 2023 年，我毕业了，我经历了很多分别，搞砸了很多关系，遇到了很多困难，痛苦的发现，很多自以为是的努力原来没有意义，曾经坚信的东西原来行不通，花费了很多精力去刻意避免的事，最终还是宿命般的发生。我只能在自己的能力范围内，做一些力所能及的东西， 力所能及的意思是太多因素无法控制，太多结果充满未知，但我仍然可以做点什么，虽然不多，终究是有可为之。 2023 年，我体验过许多不同的人生，战战兢兢，倒也没从薄冰上掉下去，仍然会愤怒，也仍然会心软，我是没有办法改变什么，但我好像也没有被改变，甚至很多我的痛苦，正是来源于我没有被改变。我知道很多期待和想法在现实里并不可行但是，要是我放弃了它，我便不再是我。我是不太适应，但我也不太想适应，我们会遇到形形色色的人，会遇到无法理解的恶意，会感到失望，会感到委屈，但是只要过去了你就会发现，其实这些都是在提醒你：不要成为那样的人。同时我们也会遇到猝不及防的善意，会发自内心的喜悦，而这些都是在告诉我们：如果生活把你的门关上了，那你就再打开，这就是门，门就是这样用的。虽然有时会害怕，但我不想因为担心失败的风险，就停止出发。船停在港口是最安全的，但这不是造船的意义。 最难忘的永远是无用的大笑，一群人凑一块聊两个钟头，拣不出一句有用的，做许许多多的傻事，然后迅速忘记它们，像风在晚霞里飞驰，什么都没有发生，如果生命力足够旺盛的话，我愿意一直坚持对生活的孜孜不倦。到底什么才是永远适用于未来的答案，生如寄，死能归吗？轻舟已过万重山，但彷徨未减，求仁得仁，但冷暖自知。我只是越来越发觉到，好像不必非要等到什么时候再，我们似乎可以在人生的任何一个坐标上，放置里程碑，没有什么差别。 打球的最常说的一句话就是：“没事，再来”。这是由回合制的游戏规则决定的，一旦站到球场上，失误一个球之后，必须快速调整心态，否则下一个球也会丢。比起安全的推挡防守，我宁愿选择去拧拉刁钻的球，我想过那种非常值得回忆的人生，尽管我还没找到一个为之奋斗一生的目标，但我想这并不是一件很急的事情，一路一路，一年一年，一直走下去，终有一天，我会找到我存在的价值。人生路万条，成功和失败是每个人都要面对的命题，上一颗球没接好，是我的问题，我也知道我不可能接好每一颗球，但不用让着我，我会反复练习，我下一球一定会接得更好。 2023 年，我一直在出发，一直在路上。这也许就是旅行的意义，相比直观的风景，更有意义的往往是预料之外的相遇，同样是一座城，每个人都有自己能讲的故事，只要我还没走到终点，就还有新的山水可以期待。所以别急着赶路，去感受路！ 故事到这里就结束了，很感谢你能看到这里，那我们，明年再见！","categories":["年终总结"]},{"title":"福建·厦门","path":"/post/摄影日志/xiamen_2023-12-24/","content":"📷 中国·厦门 XMU","tags":["摄影","厦门"],"categories":["摄影日志"]},{"title":"Hexo Stellar Deployment Guide","path":"/post/博客开发/hexo-stellar-deployment-guide/","content":"博客常见语法$$\\sum_{i&#x3D;0}^n i^2 &#x3D; \\frac{(n^2+n)(2n+1)}{6}$$ 使用 iPhone 12 Pro Max 拍摄。 支持多彩标记，包括：默认 红 橙 黄 绿 青 蓝 紫 亮 暗 警告 错误 一共 12 种颜色。 Stellar Hexo GitHub 适合居中且醒目的引用：Stellar 是迄今为止最好用的主题支持自定义引号： 热门话题 特别引用 这是一个 icons.yml 配置的示例 这是一个 url 的示例 游山西村陆游莫笑农家腊酒浑，丰年留客足鸡豚。山重水复疑无路，柳暗花明又一村。箫鼓追随春社近，衣冠简朴古风存。从今若许闲乘月，拄杖无时夜叩门。诗词节选 文言文出师表先帝创业未半而中道崩殂，今天下三分，益州疲弊，此诚危急存亡之秋也。然侍卫之臣不懈于内，忠志之士忘身于外者，盖追先帝之殊遇，欲报之于陛下也。诚宜开张圣听，以光先帝遗德，恢弘志士之气，不宜妄自菲薄，引喻失义，以塞忠谏之路也。后出师表先帝深虑汉、贼不两立，王业不偏安，故托臣以讨贼也。以先帝之明，量臣之才，固知臣伐贼，才弱敌强也。然不伐贼，王业亦亡。惟坐而待亡，孰与伐之？是故托臣而弗疑也。诸葛亮三国节选 滕王阁序王勃时维九月，序属三秋。潦水尽而寒潭清，烟光凝而暮山紫。俨骖騑于上路，访风景于崇阿。临帝子之长洲，得天人之旧馆。层峦耸翠，上出重霄；飞阁流丹，下临无地。鹤汀凫渚，穷岛屿之萦回；桂殿兰宫，即冈峦之体势。重九日节选 这&nbsp;是标题这是正文 哈哈。 一共支持12种颜色，可以满足几乎所有的需求了。color 可设置 red、orange、amber、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。 一共支持12种颜色，可以满足几乎所有的需求了。color 可设置 red、orange、amber、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。 不带摘要的样式： https://xaoxuu.com/blog/20221029/https://xaoxuu.com/blog/20221029/ 带摘要的样式： https://xaoxuu.com/blog/20221029/https://xaoxuu.com/blog/20221029/ 12345&#123;% link href [title] [icon:src] [desc:true/false] %&#125;# href: 链接# title: 可选，手动设置标题（为空时会自动抓取页面标题）# icon: 可选，手动设置图标（为空时会自动抓取页面图标）# desc: 可选，是否显示摘要描述，为true时将会显示页面描述 O1 2024年的小目标：完成 Volantis 6.0 并发布上线 来自2025年的复盘：已《基本》实现目标 正常 44% KR1 重构 tag-plugins 和 wiki 系统 当 KR 进度为 100% 时，标签默认显示为 已完成当 KR 未设置进度时，默认为 0%当 O 未设置进度时，则显示所有 KR 进度平均值 已完成 100% KR2 完成主要页面设计稿 小提示1小提示2您可以在 _config.yml 文件中修改标签的颜色和文案您可以在 _config.yml 文件中增加任意的标签配置 延期 90% KR3 完成前置准备工作（如果你知道答案，请在留言区帮帮我！🥹） 在咸水和海滩之间找一亩地求出圆周率后15位找出宇宙的终极逻辑去地狱里走两步 未完成 -12% KR-4 开发、测试和发布 支持嵌套插入图片等其它简单组件 风险 0% $ 没有勾选的单选框 已勾选的单选框 普通的没有勾选的复选框 普通的已勾选的复选框 显示为加号的绿色的已勾选的复选框 显示为减号的黄色的已勾选的复选框 显示为乘号的红色的已勾选的复选框 Your browser does not support the audio tag. Your browser does not support the video tag. 文章项目留言GitHub 这是 密码 标签 这是 下划线 标签 这是 着重号 标签 这是 波浪线 标签 这是 删除线 标签 这是 上角标 标签 这是 下角标 标签 这是 键盘样式 标签，试一试：⌘ + D 2021 年 2 月 16 日主要部分功能已经开发的差不多了。2021 年 2 月 11 日今天除夕，也是生日，一个人在外地过年+过生日，熬夜开发新主题，尽量在假期结束前放出公测版。 动态数据是从 GitHub Issues 中拉取的，使用方法为： 建一个仓库 创建一个 issue 并添加一个 label 进行测试 写 timeline 标签时加上 api:https://api.github.com/repos/your-name/your-repo/issues 这条内容为静态数据这条内容为静态数据，静态数据在 deploy 时就已经确定了。 推荐的写法123func test() &#123; // ...&#125; 不推荐的写法123func test() -&gt; () &#123; // ...&#125; 图文混排示例代码个人电脑作为办公设备时，我们该如何保护隐私？公司一般都会强制安装安防软件，这些软件要求开机自启动，要求有屏幕录制权限、完全的磁盘访问权限包括相册图库。因此如果使用自己的 MacBook 作为办公设备，必须要把生活区和工作区完全独立开，安装在两个磁盘分区，并且对磁盘分区进行加密。 默认打开的代码折叠框代码块 Unsplash PhotoThe Galactic Center is the rotational center of the Milky Way galaxy. Its central massive object is a supermassive black hole of about 4 million solar masses, which is called Sagittarius A*. Its mass is equal to four million suns. The center is located 25,800 light years away from Earth.Ōwhiro Bay, Wellington, New ZealandPublished on May 31, 2022SONY, ILCE-6000Free to use under the Unsplash License 普通 Box 样式： cell 1 cell 2 cell 3 cell 4 可浮起的卡片样式： cell 1 cell 2 cell 3 cell 4 @tianhao_wang@eberhard@eberhard@eberhard@eberhard@vklemen 博客进阶：自动化部署本文讲了如何利用脚本和 GitHub Actions 简化博客搭建和部署流程，提高效率。 瀑布流布局（原图比例） @Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu 12345678&#123;% gallery layout:flow %&#125;![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202310142119069.jpg)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202310142119069.jpg)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202310142119069.jpg)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)&#123;% endgallery %&#125; 网格布局（接近原图比例） @Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu 12345678&#123;% gallery layout:grid ratio:origin size:xl %&#125;![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)&#123;% endgallery %&#125; 网格布局（正方形） @Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu 123456789101112131415161718&#123;% gallery layout:grid ratio:square size:l %&#125;![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)&#123;% endgallery %&#125; 网格布局（正方形 + 混搭）：一般 6 的倍数张 @Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu@Yikun Wu 12345678&#123;% gallery %&#125;![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)![@Yikun Wu](https://cdn.jsdelivr.net/gh/Wu-yikun/OSS/PicGo/202506120421998.JPG)&#123;% endgallery %&#125; Hexo 常用指令1234567891011121314151617181920212223# 启动本地服务器$ hexo s# 清理缓存文件$ hexo clean# 生成静态文件 public/$ hexo g# 部署网站$ hexo d# 新建文章 _posts/$ hexo new [layout] &quot;&lt;title&gt;&quot;# 新建页面 source/xxx/index.md$ hexo new page &quot;&lt;page&gt;&quot;# 新建草稿 _drafts/$ hexo new draft &quot;&lt;title&gt;&quot;# 发布草稿 _drafts/ -&gt; _posts/$ hexo publish draft &quot;&quot; 自动化部署 可以参考「配置 Hexo 的自动推送」 也可以参考官方方法：在 GitHub Pages 上部署 Hexo 还在用 hexo d 来推送你的 Blog 到 GitHub 上吗？应该使用 Github Actions 自动推送！具体细节参考文章！ 当每次要删除文章时（新建文章同理，但最好使用 hexo new &quot;title&quot;），直接把文章从 📂*_post* 文件夹中删除，再执行 add、commit、push 三连 source repo，会自动触发 Action 部署 public 文件夹到 target repo ! 强烈建议：❌不要使用 hexo 自带的命令进行手动部署！ source repo: https://github.com/Wu-yikun/wu-yikun.github.io-source target repo: https://github.com/Wu-yikun/wu-yikun.github.io","tags":["GitHub","Hexo","Stellar"],"categories":["博客开发"]},{"title":"广东·深圳","path":"/post/摄影日志/shenzhen_2023-10-27/","content":"深圳 伙食","tags":["摄影","深圳"],"categories":["摄影日志"]},{"title":"福州·毕业季","path":"/post/摄影日志/fjnu_2023-06-14/","content":"欲买桂花同载酒，终不似，少年游 人与人之间，一个 moment 就足够了 FJNU 毕业快乐 下一站，梦想","tags":["摄影","福州"],"categories":["摄影日志"]},{"title":"浙江·杭州","path":"/post/摄影日志/hangzhou_2023-04-28/","content":"我爱我的家乡，我可以生在这里，也可以死在这里，但我不能从生到死都在这里。 而此刻，我将出发，我还要万里路要行。 杭州影像 江南 荒漠美食 之江实验室 租房日记 Zhejiang Lab 之江团建","tags":["摄影","杭州"],"categories":["摄影日志"]},{"title":"湖北·武汉","path":"/post/摄影日志/wuhan_2023-04-04/","content":"🌸 武汉","tags":["摄影","武汉"],"categories":["摄影日志"]},{"title":"2022 年终总结｜人生是一片原野，而不是轨道","path":"/post/年终总结/「2022」life-is-a-field-not-a-track/","content":"🌀前言分享下毛姆所著小说《刀锋》中的一段文字： 我并不怕犯错，搞不好会在其中一条冤枉路上，找到人生的目标，人生从来就没有白走的路，每一步都算数。 我们这一生，都怕走冤枉路，都想找到一条捷径，好用最快的速度接近自己的目标。 但事实上，当你并不清楚自己内心最真实的声音的时候，你只有不断尝试，才可能知道什么是适合自己的，就算尝试过后你还是不清楚自己想要什么，但你最起码知道一点，这不是自己喜欢的。 时间来到 2022 年的尾巴，如果没有笔耕不缀地记录着自己所体验、所尝试过的每一种生活，我大抵忘了这一年是怎么过来的了… 不确定自己是否做好准备迎接 2023 年的到来，但 2022 已经接近尾声了，是该做个了结了… ❤️掘金 · 优秀创作者 这一年凭借掘金掘力值改版以及文章的输出，终于达到 Lv.5 并获得了「优秀创作者」一称，来之不易，继续努力。 2022 年撰写的文章主要围绕以下关键词： Vue Golang LeetCode 设计模式 Spring Boot Spring Cloud … 很荣幸，「手撕设计模式」专栏得到了大家的赏识，至今的关注数已达 79 人，我不确定什么时候会再继续往下补充未完成的部分，但我保证一定会回来填坑的。 2021 年数据概览 2022 年数据概览 对比往年的数据，今年的数据较为可观，毕竟万事开头难，只要坚持下去，迟早都会收到正向的反馈。 不过距离最新发布的文章，时间也已经过去小半年了，这半年没有持续输出文章，实属一大憾事，相信来年我会继续创作的。 回望我这一年 GitHub 的提交信息，频率下降了不少，值得反思。 🔥冬令营2022 年初有幸参与过一次「大学生冬令营」活动，这是由「教育改变晋江」联合「灵源街道教育发展促进会」以及企业举办的活动，虽然为期短短四天，但是我从实践中收获不少知识，积攒了或多或少的经验，见识到了许多敢打敢拼的老一辈晋江企业家… 最重要的是结识了一群伙伴，我很难用语言去形容这样一次奇妙的相遇，还有那些我亲身参与过的活动： 👋再见了，班长数不清的打卡、核酸检测以及班上一些大大小小的事务，基本都由班长包揽了。 有次在朋友圈无意看到这样一段文字，让我笑麻了，这就是班长： 没错就是我，担任一年班长，其实蛮辛苦的，不过在其位、谋其职，一切也似乎很合理。虽然呢，我没有做出什么卓有成就的贡献，但我问心无愧的做好了每一件事，不过迫于毕业季的压力，我也是顺其自然在大三结束后卸任班长一职。 辅导员却是找了我（班长）和我舍友（团支书）来了一场近 30 分钟的交流，她希望我们能够继续连任，但我却从言语中感受到了 “我们担任班长&#x2F;团支书就是为了思政分，为了谋取利益，目的达成便逃之夭夭”。 存粹偏见，思政分尚且不至于让我耗费一年时间去争取，我本可以去做更多更有意义的事，那为什么当班长呢？我想，也许对于我而言，本身就是一件很有意义并且值得为此付诸精力的事情。 退一万步说，在不损害他人利益的前提下，每个人为了自己的前途谋取利益，我认为这无可厚非。 人生从来都是由自己定义的，我有权选择一种生活，也有权拒绝另一种生活。 一些工作 🌏党员转正 | 再谈入党动机其实去年 12 月份我俨然已经是一位（预备）党员，目前我只是满足了预备期满一年的条件，党员转正这个说法其实还不太准确，受疫情影响，「党员转正大会」推迟到下学期，还需要「党员转正大会」顺利召开后才能算是正式转正。 转正申请书 为什么要在年终总结提起这个问题，这还得回到暑假期间对面试的准备，那时候总感觉会对该问题进行提问，但提笔作答之时，我发现自己并没有给 2 年前「入党动机」一个准确的答复，或者说那时候我的回答没有掺杂自己的主观思考。我思绪万千，为什么要入党？现在，我要重新认识下这个问题。 如果我的认识肤浅，那我也要寻找一个答案，这不是为了宏伟的目标，是为了给自己内心一个交代。 也许当年写入党申请书的时候，我没有真切怀有人民公仆的情怀，但是担任一年的班长加之疫情防控管理，我真的体会到一种居庙堂之高的责任感，我只是一个普通人，但我也希望通过自己薄弱的一份力为集体散发光和热。 我知道，入党不会让我有更多的特权和优越感，而是让我内心更加踏实，更有一种无形的约束感；或者说，这是一种信仰。 如果大家能认同这样的观点，那就不只是我，而是我们。 一百多年前开始，党庇护一代又一代年轻人的成长，而如今，这崛起的一代又一代的党员是否能成就党和国家。 💪身体和灵魂，总有一个要在路上今年的运动量可以说是微乎其微了，运动主要集中在上半年，相比去年少了不少健身的时间。 锻炼量骤减有两个原因，一方面是下半年疲于奔命，另一方面是锻炼过量导致左右手受伤（如图），休养了小半年时间。 Keep · 2022 Keep Running 3 公里用时突破 13 分钟！ 部分器械 小半年没运动，四肢有些退化了，至于下阶段的训练计划，已经在酝酿了，「这是计划的一部分」😏 😷疫情时代下的我们大学才 4 年，疫情占 3 年，于是这段青春有了网课，打卡，封校；还有发不完的健康码和行程码，填不完的表格，回复不完的群接龙… 其实不论高考、择校、上课、考研、就业，大学生的人生轨迹都受了疫情很大影响。 奥密克戎时期弥足珍贵的物资 这轰轰烈烈的三年疫情管控慢慢地将要落下帷幕。从 2019 年 12 月 8 日武汉疫情爆发，到广州打响最后一枪，再到北京红码赋绿码和 2022 年 12 月 7 日「新十条」为标志，象征着「防疫工作」的结束。这三年的疫情，三年的艰难跋涉，有多少悲壮，就有多少欣慰与向往。 遗憾吗？挺遗憾的。大学期间没能去更多的地方看看山水，还未踏足祖国大好河山。 遗憾吗？也没什么遗憾的，我才 22 岁，我还有一只手数不过来的三年。 希望大家能明白结束的仅仅是防疫工作，并不是疫情！并且感谢这三年疫情所有无私奉献的人，山高路远，各自珍重。 待疫情稳定，我也希望能再度到泉州这座充满岁月的古城逛逛，走在满城都是闽南红的街道，逛在几十座各类的宗教寺院中，享受地道的闽南风味… 👻助导 | 迎新季的新身份早在七月份便接手了助导这个支线任务，导致八、九月份的工作应接不暇。 八月份主要是在线上给新生答疑，我一人对线近 200 名软件工程专业的新生，键盘侠本人。 九月份则是奔波于各个场合：新生宿舍、辅导员办公室、学生街… 那段期间手上总有工作需要处理：发布不完的表格，统计不完的数据，开不完的会议，布置不完的场所，检查不完的宿舍，熬不完的夜… 但不得不说，我的抗压能力又得到了进一步的提升。 许许多多繁杂的材料需要整理和汇总 迎新日 🥳夏令营 &amp; 保研下一站，厦大大三结束后，我便一头扎进「夏令营」的备考当中，期间准备了一大摞材料，在投递简历的过程给我提供了很大的便利，不过准备这些资料也花费了我非常多的心血… 夏令营面试材料 &amp; 推免材料 一轮初筛后，我拿到了厦大、中南和中科院的面试机会，简要说说这三个院校的面试： [x] 中科院我途中退出了，Pass [x] 厦大是最早参加的，所以我基本的心思都在备战 XMU 夏令营，笔试面试各占 50% [x] 面试：英语口语有备而来轻松化解，个人介绍部分发挥稳定，不过问答环节稍显逊色【20 分钟】 [x] 笔试：操作系统 + 计算机网络 + 数据结构 + 数据库 + JAVA【2.5 小时】 [x] 中南是最后发的二轮面试，花了一个晚上草草准备了一下：个人介绍部分较为随意，较难的是「英语自我介绍」和「口语问答」，因为距离上次英语自我介绍已经过去一个月了，我脑子里已经没有任何英语口语相关的内容了，好在自由发挥比较出色，还被面试官表扬英语口语不错，口语问答也是临场发挥，有惊无险的通过了，整体面试下来只花了 15 分钟不到就结束了 🌈有趣的是，在这次夏令营中我的编号是 No.1，而且也是软工系第一位报道的，同时我在 GitHub CS 保研仓库中唯一提交的信息也是厦大夏令营招生简章，最后就是夏令营舍友全部放鸽子了；只能说「天时·地利·人和」优势尽在我 [doge] 备战 XMU 夏令营 夏令营：中南大学 &amp; 中科院 &amp; 厦门大学 在 5 月至 7 月挣扎的这段期间内，很感谢「林老师」和「毛老师」的鼎力支持，让我有幸能够在厦大夏令营拿到「优秀营员」！夏令营结束后，本着躺平的心态也没打算继续参与「九推」。 接下来就是静候本科保研名单的公示，如果不出意外的话，那应该是不出意外了😏 推免名单公示（仅截取部分） 这算是给大学生涯的一个答复，至于我能以专业第一的名次保研，三年前我便深信不疑。你要想做成一件事，首先要相信这件事。 值得一提的是，我们专业今年的保研率只有 4%（6&#x2F;150），我们班级的保研率在 6%（3&#x2F;50），我们宿舍的保研率在 50%（2&#x2F;4），有意思的一组数据。 一切尘埃落定，当我在「研招网」接受厦大录取通知后，更多的不是喜悦，而是释怀，六年前的问题终于有了一个答案。 初中毕业相册 | 2016 年写下… XMU 番外篇：推免名场面 🏆世界杯 | 阿根廷夺冠世界杯中「阿根廷」的每一场比赛我都有看，虽然我不赌球，但是心里早已把冠军投给了阿根廷队，今年非常希望能看到「梅西」捧杯！ 遥看 2014 年阿根廷在「巴西世界杯」决赛中惨遭德国绝杀，赛后梅西凝望着大力神杯的一幕令人动容。 一步之遥 2018 年阿根廷对上了法国，可惜阿根廷 3 : 4 不敌法国。 又一届世界杯，同样是阿根廷对战法国，这决赛的剧本属实把气氛拉满——下半场姆巴佩 97s 追平 2 球，加时赛 1 比 1 平拖入点球大战。 迪马利亚破门 加时赛梅老板再进一球！ 绝杀！ 历史没有重蹈 4 年前的覆辙，历史唯一不变的事实，就是一切都会改变，最终梅西也是如愿以偿捧起大力神杯。 那天凌晨 2 点有幸见证阿根廷夺冠，现场的气氛真是燃炸了！ 「烧烤店 · 阿根廷主场」又是哲哥请客的一天（哭死 ⚽除了阿根廷夺冠的画面，「贺炜」在世界杯决赛的解说也令人印象深刻： “卢赛尔体育场绚烂的烟火，是在为阿根廷人欢呼！同样也为所有参加此次世界杯的人而送上祝福与敬意！冠军只有一个，但是所有人都有为自己的梦想去努力的机会。” “四年一度的世界杯，就像年轮一样，一圈一圈的镌刻着历史的脚步，讲述着巨星的叱咤风云或者黯然神伤，也讲述着我们自己生命的推演。” “要知道，梅西这一代的运动员，在上一次阿根廷队夺冠的时候，他们都还没有出生，但是他们给阿根廷整个国家带来的关于世界杯的美好记忆却是传承了下来。” “电视机前的观众朋友们，问问我们自己，四年前陪你看球的人现在还在联系吗？四年后看球的自己许过的愿望都实现了吗？” “我们为什么深爱着足球这项运动？因为它不仅展现了球员们励志的奋斗故事，还寄托了我们普通人平凡生活中的英雄梦想。” “我们恭喜阿根廷，我们也向法国队送上祝福。无论今晚你支持的球队是胜是负，都希望今天晚上的感悟能够帮助你勇敢面对明天早上推开门之后真实的生活，这才是这项运动真正的魅力。” “我爱足球，我想你们也是。” “波斯湾的故事讲完了，四年之后，让我们相约在落基山，尼亚加拉瀑布，尤卡坦半岛，让我们一起去玛雅文明曾经存在过的地方。观众朋友们，四年之后，让我们在美加墨世界杯再见。” 😂家庭教师 | 有点东西但不多今年在闲暇之余也是接手了一个支线任务「家教」： 家教对象：初三学生 家教课程：中考数学 &amp; 中考物理 家教时长：每周末 4 小时 家教价格：100 &#x2F; hour 教材（还有许多习题集就不展示了） 在家教期间，我看到了很多学生时代我所犯过的错误，也接触到了我从未犯过的错误，并了解到了我以后可能会犯的错误——包括学习，不止学习。 其实兜兜转转说了这么多，我只想说一点，不要害怕犯错，尤其是年轻时代的犯错成本是很低的。你犯过的错，吃过的亏，那都是一剂疫苗，防止这些龃龉烂入骨髓腐蚀你的生活。以无声无息的形式温水煮青蛙，可比犯错一时揭伤疤来得狠戾。 故事的结尾 对方家里甚至有一位在上幼儿园的孩子已经在学习「少儿编程」了，我想听到这在座的各位心里多少都会有点感触。其实也不用过于焦虑，每个时代有每个时代的基准线，对于我们而言，做好当下每一件事，走好当下每一步路，就足够了。 😎升级打怪的实习期身处互联网行业的我们，今年应该都能感受到「春招和秋招」的岗位明显缩减。强监管、反垄断、疫情扰动、消费不振等诸多不利因素钳制下，中国互联网流量红利已近枯竭，下沉市场的故事偃旗息鼓。 2022 年互联网影响最深的一件事莫过于“一波接一波的裁员大潮”。从年初的大厂“毕业季”到年末的裁员大潮，还有硅谷的大裁员，国内外很多小伙伴都离开了自己的岗位，需要重新找工作，却又四处碰壁。 这个行业实在变化太快，“一招鲜，吃遍天”这种事情是不存在的，我们总会遇到从未接触过的新挑战，怎么办？ 学习！ 就如同一个优秀的企业，它最有价值的地方在于它有无限的发展前景。那么一个优秀的互联网从业者，最有价值的地方就在于拥有无限的潜力。 抛开远的不谈，对我来说值得庆幸的是，学校将实习时长从 4.5 个月降到了 3 个月~ 未完成的实习报告手册 租房那些事我前后居住的 2 个宿舍分别是「民宿」和「客栈」，房租大概都在￥1500 左右，但我导报销。 简单聊聊这几个月的居住感受。 三星民宿⭐⭐⭐居住在民宿三楼，房东在一二楼，房顶晾晒衣物。 民宿外观还行，但房间内部较为朴素，隔音较差，那段期间正好赶上周遭装修，体验可想而知，其次是洗衣晾晒不太方便，不过这都是些小问题，整体居住的感觉还行。 民宿 四星客栈⭐⭐⭐⭐十月份结束后，从民宿转到客栈，只能说客栈完美的弥补了手洗衣服的缺点——洗衣机！除了房东不允许我凌晨 0~5 点洗衣服以外，感觉都还行，哈哈哈。 虽然房间可以放置物品的空间不大，哑铃也只能随意堆在角落，双人间的装修可以说是很有观赏性（其实我有得住就知足了。 客栈 Massive Storage · 挑战赛年末参与了一场「存储比赛」，那时候带着好奇加入飞哥的团队，闯一把，不过从头到尾我的贡献微乎其微，充当着重在参与的角色 [doge] 「华为」和「华科」联合举办，奖金有点诱人 Coding…（99.99% 的代码都是飞哥码下的） 初赛 Rank 15th，决赛加油 飞哥一路上带我闯进决赛，这个比赛过程中我也学到不少知识，不论最后结果如何，我这把比赛躺了😎 来到华科领奖啦 新手村培训实习期内，哲哥牺牲个人的时间出了一期有针对性的培训，同时对我的问题知无不言言无不尽，二者都使我受益良多😭 完成任务期间还求助过许多朋友，大家对我都很耐心，包容性极强。 不过，我还是需要不断提升自己才行，毕竟编码能力菜就是原罪，现在的水平还是让人堪忧。 口语录制今年也尝试了许多以前没有踏足的领域，比如给 PPT 录制视频并配上英文讲解（定稿）。 原本以为只是简简单单的口语短文小测，可惜我错了。录制 15 分钟的口语汇报，耗费了我 8 小时持续不停的口语朗读，就是一个在失败中不断尝试，再在尝试中不断失败的过程。 心凉了半截 原本想以普通人的身份和大家相处，没想到换来的却是疏远，不装了，我摊牌了。 躺在邮箱中的邮件自从不怎么使用 QQ 这个玩意儿，我基本都在各大论坛和开源社区闲逛，交流工具基本剩下「微信」和「邮件」，以前感受不到为什么都喜欢使用邮件，现在能明白了，前人发明的一切交流工具都是为了传递基本的信息，在表达清楚自己意图的基础上，怎么简单怎么来！ 偶尔我也会向大牛咨询一些问题或者索要代码（大牛基本都用邮件交流多一些，有别于我用邮件纯粹因为它简单） 索要代码 咨询问题 勇于尝试，大胆尝试，就算被拒绝了也不见得是坏事。 周报真的是互联网最糟糕的发明写了将近 4 个月的周报，我对周报的厌恶感不断攀升，虽然很痛苦，但还是要写。 老板也很焦虑，进展不快的第一反应往往就是抓人效，首当其冲就是检查周报是否完成、尽善尽美。 那么问题来了，周报写得好，真的能提升我们的成果吗？ 答案肯定是否定的。 周报充其量是个人总结的一种方式，有别于会议，它并不具备实时性和快速性。有人会认为周报是组织交流、上传下达的重要渠道。但事实上，一次好的周报应该是有反馈的，但反馈的效果往往由你的 leader 决定，问题就出在这里，你可以是一个非常努力完成周报的人，但你不能要求你的 leader 跟你一样认真，这也是我前期周报认真完成，后期直接开摆的原因，因为我逐渐意识到了这个问题并且无法从根源上去解决。 周报存在的意义是什么？单单从务实的角度讲，无非就两点： 复盘过去的工作 明确未来的工作 既然如此，不如直接简单开个短会来得明朗，不过每周的组会已经让我有点喘不过气了，所以建议能省就省。 夜猫子生活白天不起，晚上不睡，在 11~12 月已成为我的常态。 当代年轻人熬夜报告，是我没错了 通宵除了思考人生，还可以等一轮日出（About 6 o ’clock） 深夜创作者 我 de 工位 Desktop 1 Desktop 2 必须得给大家伙秀一把新到的服务器，只能说太顶了！ 开黑之夜平安夜 5 人齐聚开黑，「2本科 + 1硕士 + 2博士」，这阵容一晚上赢不了一把游戏，哈哈哈 除了一把没赢，我觉得整个过程都挺轻松愉快的，毕竟游戏有游戏的玩法，无关输赢，开心就好。 上手体验 ChatGPT最近 ChatGPT 很火，如果你在互联网圈子里就应该听说过或者见过它的身影。简单的说，这是一个 AI 聊天工具，无聊的时候真的可以自顾自的聊一天。 接下来聊聊怎么上手。 1. 注册 OpenAI 账号进入 OpenAI 主页，点击「Sign Up」进入注册流程。 在这一步，你需要填写注册邮箱和密码，还需要完成一个简单的验证。 注意，输入的邮箱必须是非内地邮箱，我用的是 Gmail 邮箱，也就是谷歌邮箱。 填写完邮箱之后系统会提示你登录邮箱做一个验证，进入邮箱，点击验证链接就完成了账号创建。 接下来，你会来到填写手机号码的步骤，这也是难住很多人的一步，因为我们大多数人都没有国外手机号。 别着急，凡事都有办法。 2. 注册虚拟手机号并获取验证码前往 SMS-ACTIVATE 并注册一个账号，这一步同样需要使用邮箱验证（内地邮箱即可）。 这个网站提供国外虚拟手机号注册功能，目的是获取可用的短信验证码。 如果你英文不好的话，可以切换为中文模式。 注册成功后，需要先给账号充值。点击网站右上角的「余额」并进入「充值」模块。 这里购买一个虚拟手机号接收一次验证码大概需要 11 卢布——俄罗斯货币。 不过没关系，我们可以充值美元并兑换成卢布，而充值美元可以直接用支付宝支付。 我算了下，只接收一次验证码的话充值 0.2 美元就够了，也就是说你需要花费大概 1.4 元人民币（我充值了 1 美元，有需要注册的小伙伴可以联系我，免费让你体验） 充值成功后，就可以选择对应的服务商来使用虚拟手机号接收验证码了。 这里我选择的是印度的服务商，接着在服务项目里输入 OpenAI 并选择买入一个。 购买成功后，你会被分配一个虚拟手机号，下图中那一长串数字就是手机号。 此时，复制这串号码回到 OpenAI 的注册现场，然后点击获取验证码。 这里要注意，你在 OpenAI 注册手机号选择的归属地和在这里注册的虚拟号码归属地要保持一致。 大概几秒钟过后，你会在上面这个页面看到刷新出来一个 6 位数的数字，这就是你的验证码。 复制这个验证码填写到 OpenAI 的注册页面，点击提交，此时账号就创建成功了。 至此，你就可以正式开始使用 ChatGPT 了。 3. ChatGPT 初体验 抛开内容不谈，你就说它回复了没 [doge] 不过在我看来，使用 ChatGPT 最高的门槛不是上面这些步骤，而是如何向他提出一个好问题，也就是「提问的艺术」。 此外，ChatGPT 目前并没有达到人机自如的理想状态，有些回答略显生涩和模板化，甚至会有纰漏。 不过这不要紧，因为这只是一个开端，未来它的进化速度会很快，就像当初 AlphaGo 的进化能力一样。 如果你有一些疑问，或者有关于人生的终极思考，又或者郁闷想找人聊聊天，不妨试试。 ChatGPT 让我感受到了一种未来，就是某些职业可能会失业，比如新闻报道记者，比如通稿写作者。 虽然这些影像还很模糊，但未来真实地在向我们靠近。 未来已来，你还不来？ 🍂又是一年 | 春夏与秋冬须臾之间，又是一年，春夏与秋冬。 以往本着「活在当下」的态度碌碌无为、自得其乐地度过了一年又一年的四季，未曾想记录生活又何尝不是一种自由。 知乎 &amp; 飞书：用文字记录生活 网易云音乐 · 年终总结 📸Snapshot 有点东西，但不多 🍀我的摆烂文学其实这一年走来，刻苦努力的那些日子里，总是让我百感交集。 我赶过夜晚近 23 点的末班车，也进过凌晨 2 点的粥铺，目睹过凌晨 4 点空旷无垠的大街，等待着 6 点初升的太阳，更在熬了一夜过后的 8 点懒洋洋地回到宿舍… 几乎在每一个不合理的时间点，我都存在过，在码字、在阅读、或者在思考，或许没意义，但是我乐意。 除了精力充沛外，我知道那时候的自己想要什么，需要做点什么。 不过有一点值得说明，我从未认为自己的行径算得上内卷，一方面可能是我努力的程度远远不及「内卷」，另一方面可能是我对于内卷的理解有所偏驳。 我在知乎上曾看到一句话，曾经，并没有内卷这个词汇，每个人都只是为自己的前途而努力着，自始至终。记得高中的时候，为了考大学，我每天都抓紧各种零散时间努力学习，比别人更努力，即使结果不如愿，我从不觉得羞耻。我喜欢「山本耀司」的那句 “我从来不相信什么懒洋洋的自由，我向往的自由是通过勤奋和努力实现的更广阔的人生，那样的自由更加珍贵、更有价值”。 第一次接触内卷，是在 2 年前，那时候内卷一词流行于各个角落，起初并不懂它的含义，书本将其定义为人类社会在一个发展阶段达到某种确定的形式后，停滞不前或无法转化为另一种高级模式的现象。 好比一个流量很大的地铁站，早高峰很难挤上地铁，有一天，一个人决定先反向坐一站，提前上地铁，防止挤不上来。后来越来越多的人这样效仿，大家耗费了更多的时间和精力，却得到一样的结果。 我从不认为谁的努力如“内卷”的释义一般。 同时我也时常庆幸，在我的十二年寒窗里，内卷一词并未泛滥。我怀念高中的时候，我们在纸条上写下各自的理想大学，朝着各自目标努力着，简单、自由且纯粹。 不过，这种自由的状态也仅仅占有我生命中的少部分时候，我更多时候的状态是一如既往的「安于现状、得过且过」，我没有部分人认为的那般拼命和聪慧，却也是大部分人所认为的那般懒惰与笨拙。 我也时常停下脚步，不知道为什么前进，那些超出预期的差池总是令我徘徊在常规性的自我厌弃之中，并不断靠着游戏和短视频等迷幻药短暂性的捕捉虚无的快乐。又或者是天一黑夜已深，网易云一开，气氛一到位，我就开始思考一些平时不假思索的问题，科技伦理，人类进化，宇宙边缘，生命尽头… 十年前大家都在看「成功学」，现在大家都在看「摆烂学」，但大部分人却又处于「摆了又没完全摆，躺平又没完全躺，摸鱼又没完全摸」的处境。我能体会到为什么，因为烂的感觉并不好，搁在图书馆偷懒躺平摸鱼，躺在床上刷 b 站的滋味并不好受，它总是在清醒过后唤醒我灵魂深处最虔诚的忏悔和鄙视。 摆烂又或许是害怕失败的一种逃避手段。不确定性的存在是无解的，机会成本的产生是必然的，没有人愿意承担失败带来的代价，成功学的理念在大家 DNA 里刻得太深，不能失败的观念始终是悬在我们头顶的「达摩克里斯之剑」，把人压得喘不过气来，这一套对于高考来说是行得通的，因为这个社会的规则便是如此。但它并不适用于我们的人生，人生太长了，大家又不是只活二三十年。 但那个把全部的生活过成竞争，把所有的悲欢都取决于排名，把每一次失败都反求诸己的你，一定很累吧。 你当然足够倔强，足够拼命，足够努力，足够优秀； 但你真的足够自信，足够乐观，足够快乐，足够善良吗？ 还是说。 其实你对父母充满愧疚，对名利充满贪婪，对自己充满怀疑，对同窗充满嫉妒，对社会充满怨言，对竞争充满恐惧，对成功沾沾自喜，对失败无所适从，对未来一片迷茫？ 也许这个社会并不需要所有人都成功，这并不是要宣传摆烂文学，只是想提醒自己保持一颗平常心。万事记得，来日方长。 🌗人生最重要的一课：感谢他人致谢与铭记他人的恩情，从来都不是人生的选修课，而是必修课。 2022 结束前，我还要感谢那些一而再，再而三，千千万万次救我于水深火热困境中的人们。 感谢我「爸妈」的无私奉献，2022 以及以往的每一年里，都是你们用「物质和精神」默默支持着我的每一个决定 感谢陪我耍过大学四年的舍友 感谢「鑫杰」，我永远不会忘记我们为了保研共同奋斗过的那些日子，我们有许多共通的爱好和相似的经历，也各自怀揣着不同的理想主义和现实眼光，也许是这样一种羁绊，才让我更加珍惜这段友谊无可替代。这一年里，不，或者说是这三年里，我从你身上不断学习到许多前所未闻的认知和视野，你始终站在我的知识盲区内，未来希望还能一起努力，一起进步 感谢「鑫欣」给我上了一课又一课，三观和认知都凌驾在我之上的退伍军人，从你身上我见识到了军人般的自律，也让涉世未深的我学到不少深刻的道理，尤其是暑假独处的那段时间，我都默默看在眼里 感谢「品庚」和「灿阳」一直以来的帮助，在我最需要的时候总是会义无反顾的出手帮我 还有大一舍友——「光箭、健业、强钵、文杰」，虽然我们五人帮见面的机会少了，但一有时间我们总能无话不谈，事实证明，五个人的友情并不拥挤 感谢我的「大学同学和朋友们」，你们的存在点缀了我短暂的大学生活 大学期间犯了不少错，自知给辅导员带去了不少麻烦，所以很感谢「黄导」和「张导」的包容 感谢「展鹏学长」、「寿铭学长」、「泓浩学长」、「冠钞学长」、「良宽学长」以及本科期间一直以来不吝赐教的各位学长们 感谢「慧怡学姐」和「王玲学姐」一直以来的耐心指导 感谢「成双成队」的各位小伙伴给我这一年留下浓墨重彩的一笔 还得狠狠感谢下「若珩」，这一年给了我不少帮助，不愧是心理学高材生。百忙中还给我送来了一些药物，同时谢谢一些关心我的小伙伴们 还有就是当然要感谢实验室的 XDM，来自华科、华南理工、厦门、武大等众多高校的你们都比我优秀太多了，有太多值得我学习的地方了，我作为实验室的下水道级别，以后还请大家多多指教（说说这段时间以来的感悟） 在我融入实验室节奏的过程中，「哲哥」总是不厌其烦地给我讲解我所咨询的问题，懂得换位思考，简单的交流也能让我受益匪浅，以至于现在都有些许依赖性，遇到不顺的事会为我们打抱不平，甚至牺牲自己的时间来提升大家的水平，不愧是实验室的天花板选手；除此之外，生活中对我（们）都很包容和大度，心思缜密，双商拉满。总之我对哲哥的感激之情无法言喻。不过几个月的相处，我想就足以让我永远铭记于心了，令我感到可惜的是，我们相处的时间可能所剩无几了💔 也很感谢「锋哥」，作为实验室科研的扛把子，你总能提出独到的见解和发人深省的问题，在科研理解上和生活中你都给予了我不少的帮助，今年更是直指顶会，预计 2023 年你便可驰骋于各大顶会带我们起飞。令我不解的是你总认为我有点东西，可惜我真没有哈哈哈，还有至今都还没有让你看得上的异性，也许是一心科研吧。 认识「芝豪师兄」源于某次偶然的询问“我是谁”，虽然当时我在后座来着哈哈。芝豪师兄是软硬件都精通的大佬，平时服务器出现了点什么问题总会去麻烦和请教一下，虽然平时交流并不频繁，但都有问必答，而且一针见血。 学累了怎么办？无所谓，「飞哥」会出手。最早熟悉的当属飞哥了，8 月份便和你一同居住，我能感受到，你将灵活科研的理念贯彻到底，「”休闲” &amp; 麦麦 &amp; 大骨」是提升你科研效率的三件套，耳濡目染下我也能熟练地运用你的三件套来融入我的学习中，而且作为网易和字节出来的人才，假以时日，你也能杀进各大顶会，于你而言简直是信手拈来。当然除了比赛带飞我，对于学习上不懂的问题，飞哥也总是能三两下帮我解决，突出一个醍醐灌顶。不过有一说一，体重该减就得减，明年带你一起减肥 [doge] 从 8 月份开始，我就开始请教「子航师兄」了，关于我所研究的方向，如果没有子航师兄的指点，想必我又要走不少弯路，真的十分感谢。尽管素未谋面，但是子航师兄总是会竭尽所能给我讲解我不懂的知识，纠正我的认知偏差，悟性和学习能力极强的人大概就是如此了。不过在师兄看来较为简单的问题，但我总需要花费较多时间去学习，没办法我的悟性和学习能力较差，望谅解。同时我也为自己这段期间的打扰说一声抱歉。还有子航师兄总是能在我压力很大的时候开导我，不然可能真顶不住这跨越式的压力而崩溃，总之呢很期待之后师兄的回归，一定要注意身体，以后一起坐着把鱼摸嘻嘻。 我觉得最有缘分的应该得算「佳泓师兄」了，6 月份凑巧有机会和泓哥取得联系，也很耐心地给我介绍了实验室的大体情况，我学习到不少。之后换宿舍也很巧地和泓哥一同居住，这一住便是 2 个月，只能说相处得十分融洽。佳泓师兄的每一句话都能很好的给我减压，平日里也很谦让我，还教会了我不少科研生存法则，有时总能和泓哥聊到了凌晨 5、6 点，堪比人生导师。有时也能约着一块打篮球，不得不说，你的篮球很有东西还能教会我不少技巧。让我难受的估计就是今年一别，不知道还有没有机会再见。 然后得说到实验室的谐星（估计以后是我了）——「宇轩师兄」，估计是实验室最快乐的人了，初来乍到宇轩也很照顾我，在生活某些方面总能给予我帮助（比如餐卡），我很羡慕你那无忧无虑的生活，成功的人生也不过如此吧。你也教会了我不少的道理，让我明白了做人不能太自私，以后我也会多站在对方的角度去思考问题的。 同时非常非常感谢「河山」，平日里很热情的解答我的问题，有困难你是真上。给我的感觉就是河山一出手，就知有没有（ACM 银不是开玩笑的）。学习上基本没有难得住你的问题，不仅游戏玩得好，主要是平易近人很玩得来。除了摸鱼水平能和你一较高低以外，感觉没有什么可以和你相提并论了 还有要谢谢「张宇」抽空陪我摸鱼，当然对于我不懂的问题你也是知无不言，相信未来的某一天，你一定能给老师调整调整科研方向。 虽然今年没机会见到「立瀚」，但没关系，线上该出手就出手，明年见。 再次感谢「林老师」的推荐和支持以及「毛老师」和「吴老师」的帮助 如果可以，我还要感谢一位朋友，让我真正的明白了我所拥有的一切都是侥幸，er 失去的才是人生，未来还多需努力。只不过，遗憾终究是遗憾。 以及感谢那个未曾放弃且笃定前行的自己！ …（此处省略 1W 字） 总之，感谢在这一年里对我如此包容的大家，我会永远铭记于心的。 💖未来世界上每个人本来就有自己的发展时区。 身边有些人看似走在你前面，也有人看似走在你后面。 但其实每个人在自己的时区有自己的步程。 不用嫉妒或嘲笑他们。 他们都在自己的时区里，你也是。 生命就是等待正确的行动时机。 所以，放轻松。你没有落后，你没有领先。 在命运为你安排的属于自己的时区里，一切都准时。 至于未来，是极乐，是悬崖，还是围城？反正都是未知，不如索性期待。 以上！","categories":["年终总结"]},{"title":"Golang Wiki","path":"/post/Golang/golang-wiki/","content":"👨‍💻本文中的源码地址：https://github.com/wangkechun/go-by-example 学习目录 1. Go 简介介绍下 Go 语言的特性以及目前 Go 语言在市场上的 “帝位”。 1.1 Go 语言特性 高性能 &amp; 高并发：Go 语言天生支持高并发（goroutine &amp; channel &amp; 调度器），不像很多语言通过库的形式支持；Go 像一些低级别的语言 (C&#x2F;C++) 一样是一门编译型语言，这意味着它的性能足以媲美 C&#x2F;C++！ 语法简洁易懂：语法类似 C 语言，比如：同时去掉了不需要的 ()，循环也只简化成 for 循环这一种表示… 该特点使得用 Go 编写的代码易于维护。 丰富的标准库：Go 语言带有极其丰富与完善的标准库，无需再借助第三方库完成便可以应对日常的开发，而且能持续享受到语言迭代带来的性能优化。 完整的工具链：编译、代码格式化、错误检查、包管理、代码补全等都有相应的工具，Go 语言还内置了单元测试框架（单元测试、性能测试、代码覆盖率、性能优化）。 静态链接：所有的编译结果默认都是静态链接的，只需要拷贝编译后唯一的可执行文件即可部署运行，线上发布的体积可以控制得很小。 快速编译：Go 语言一开始设计就考虑到快速编译。它能像其他解释型语言一样（Python &amp; JavaScript），你不会注意它正在编译。 跨平台：Go 语言能在 Linux、MacOS、Windows 等操作系统下运行，还能用于开发 Android、iOS 软件，甚至能运行在路由器、树莓派等等设备；同时具备交叉编译特性。 垃圾回收：Go 无需考虑内存的分配与释放，因为其内存由 Go 自身进行管理，不同于 C&#x2F;C++，和 Java 类似。 简洁的 Go 语法 1.2 拥抱 Go 语言目前字节跳动已全面拥抱 Go 语言。除此之外，哔哩哔哩、七牛云、腾讯、百度、美团、Facebook、Google、Twitter、滴滴、深信服、知乎、去哪儿、360、微博等公司也在大量使用 Go 语言。 Go 语言在云计算、微服务、大数据、区块链、物联网等领域蓬勃发展，Docker、Kubernetes、etcd 等几乎所有的云原生组件全都是用 Go 语言实现。 2. Go 入门😆这部分简单概括下如何搭建 Go 的开发环境，浏览下 Go 语言的基础语法 &amp; 标准库。 2.1 搭建开发环境2.1.1 下载安装 Golang https://go.dev/ : Golang 官网 https://studygolang.com/dl : Golang 中国镜像（Golang 官网无法打开的情况可用） https://goproxy.cn/ : 七牛云 Go 模块代理，配置 go mod proxy 并按网站提示进行操作可助力提升下载第三方包的速度（优化访问 GitHub 较慢的情况） 2.1.2 配置 Golang IDE⭐首选目前市场上使用最广泛的两款 IDE : VSCode &amp; GoLand VSCode：由微软公司开发，免费。能运行在 MacOS、Windows、Linux 上的跨平台开源代码编辑器（功能齐全的 IDE），需要在扩展市场中安装 Go 插件才能支持 Golang 开发。 GoLand：由 JetBrains 公司开发，付费 (学生可申请免费使用)。 2.1.3 云上开发环境我们还可以使用基于 GitHub 的 Gitpod 在线编程环境来使用 golang，只需在你的开源仓库 URL 的 https:// 替换成 https://gitpod.io/# 即可。 2.2 基础语法 &amp; 常用标准库这部分开始正式学习 Golang 的语法以及常用标准库的使用。 2.2.0 从 Hello World 见证 Go 程序的运行123456789package mainimport ( &quot;fmt&quot;)func main() &#123; fmt.Println(&quot;hello world&quot;)&#125; 有 2 种方式运行该段程序： go run 命令可直接运行程序 go build 可将程序编译成二进制，编译完成后直接执行 ./main 即可运行 2.2.1 变量 &amp; 常量Golang 是一门强类型语言（每个变量都有其对应的类型），变量 var 如果没有标注类型会自动推导，常量 const 默认没有确定类型（自动推导）。 注意：如果定义了变量，必须得使用，否则编译不通过 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package mainimport ( &quot;fmt&quot; &quot;math&quot;)// 全局变量var x string = &quot;global&quot; // 可以// x := &quot;global&quot; // 不可以, := 仅可以在函数内部使用const ( A = iota // iota=0, 值为 0 B // iota=1, 值为 1 C = iota // iota=2, 值为 2 D = &quot;test&quot; // iota=3, 值为&quot;test&quot; E // iota=4, 值为&quot;test&quot; F = 9 // iota=5, 值为 9 G // iota=6, 值为 9)func main() &#123; /* ------------ 变量 ------------ */ // 声明并赋值 var a = &quot;掘了&quot; // 类型推导 var b = true // 多变量定义 &amp; 类型推导 var c, d int = 1, 9 var e, f = 6, &quot;F&quot; var ( g = 666 h = false ) // 简短定义(另一声明变量的方式 :=) i := 1.9 // 类型转换: float64=&gt;float32 j := float32(i) // 字符串可通过 + 拼接 k := &quot;掘金&quot; + a // 匿名变量 _ y, _ := 1, 2 // Go 易于实现两数 c, d = d, c /* ------------ 常量 ------------ */ const l string = &quot;constant&quot; const m = 10 const n = 2e3 / m // &quot;global&quot; &quot;掘了&quot; true 9 1 6 &quot;F&quot; 666 false 1.9 1.9 &quot;掘金掘了&quot; &quot;constant&quot; 10 200 1 fmt.Println(x, a, b, c, d, e, f, g, h, i, j, k, l, m, math.Abs(n), y) // 0 1 2 &quot;test&quot; &quot;test&quot; 9 9 fmt.Println(A, B, C, D, E, F, G)&#125; 2.2.2 数据类型 &amp; 占位符🌗Go 语言基本数据类型较多，主要有以下这些： byte、int、int8、int16、int32、int64、uint… float32、float64 error string bool rune 🌓Go 语言囊括的复合数据类型范围较广 (下文慢慢介绍) ： 数组 array 切片 slice 字典 map 函数 func 结构体 struct 通道 channel 接口 interface 指针 * 🚀根据数据特点又可分为值传递 &amp; 引用传递： 值传递：int、float、string、bool、array、struct 引用传递：slice、map、chan、* ⭐至于运算符（算法运算符、关系运算符、逻辑运算符、位运算符、赋值运算符）和其他语言基本一致，这里不再赘叙。 2.2.3 if-else 条件判断Go 语言中的 if 判断语句不需要 ()；同理，switch 和 for 也不需要。 Go 语言中的 if 语句存在一种特殊的写法： err 是 myFunc() 的返回值，执行后再对 err==nil 语句进行判断。 123456789101112131415161718192021package mainimport &quot;fmt&quot;func main() &#123; // Golang 的 if、for、switch 均无需 () if 5%2 == 0 &#123; fmt.Println(&quot;5 is even&quot;) &#125; else &#123; fmt.Println(&quot;5 is odd&quot;) &#125; // 特殊的 if 分支: if 执行语句; 判断语句 &#123; &#125; if num := 9; num &lt; 0 &#123; fmt.Println(num, &quot;is negative&quot;) &#125; else if num &lt; 10 &#123; fmt.Println(num, &quot;has 1 digit&quot;) &#125; else &#123; fmt.Println(num, &quot;has multiple digits&quot;) &#125;&#125; 2.2.4 for 循环Go 语言中没有 while、do while 这类循环，仅仅只有 for 这一种循环。 123456789101112131415161718192021package mainimport &quot;fmt&quot;func main() &#123; // while i := 1 for i &lt;= 3 &#123; fmt.Println(i) i = i + 1 &#125; for j := 7; j &lt; 9; j++ &#123; fmt.Println(j) &#125; // 死循环 for &#123; fmt.Println(&quot;endless loop&quot;) &#125;&#125; 2.2.5 switch 分支相比 C&#x2F;C++，Go 语言的 switch 分支略有不同，也更加强大。 不同之处：case 中不需要再显式加 break，执行完对应 case 就会退出，不像 C&#x2F;C++ 没加 break 会跑完余下所有 case；同时 switch 后也不再需要 ()。 强大之处：Go 语言中 switch 后能跟任意变量类型；也可不跟任何变量，然后在 case 中写条件分支，这样就将 switch-case 分支结构简化为 if-else 条件判断结构了。 123456789101112131415161718192021222324252627282930313233package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main() &#123; // switch-case 标准结构 a := 2 switch a &#123; case 1: fmt.Println(&quot;one&quot;) case 2: fmt.Println(&quot;two&quot;) // 控制台只输出 &quot;two&quot; case 3: fmt.Println(&quot;three&quot;) case 4, 5: fmt.Println(&quot;four or five&quot;) default: fmt.Println(&quot;other&quot;) &#125; // switch 后不跟变量 t := time.Now() switch &#123; case t.Hour() &lt; 12: fmt.Println(&quot;It&#x27;s before noon&quot;) default: fmt.Println(&quot;It&#x27;s after noon&quot;) &#125;&#125; 2.2.6 数组 array数组是一个长度固定的元素序列，可利用索引取值&#x2F;存值。 1234567891011121314151617181920212223242526272829303132package mainimport &quot;fmt&quot;func main() &#123; // 一维数组 var a [5]int a[4] = 100 fmt.Println(&quot;get:&quot;, a[2]) // get: 0 fmt.Println(&quot;len:&quot;, len(a)) // len: 5 // 3 种数组初始化方式 (1) b := [3]int&#123;1, 2, 3&#125; // 或 var b = [3]int&#123;1, 2, 3&#125; fmt.Println(b) // [1 2 3] // 3 种数组初始化方式 (2) c := [...]int&#123;1, 3, 2&#125; // 或 var c = [...]int&#123;1, 2, 3&#125; fmt.Println(c) // [1 3 2] // 3 种数组初始化方式 (3) d := [...]int&#123;1: 3, 6: 5&#125; // 或 var d = [...]int&#123;1: 3, 6: 5&#125; fmt.Println(d) // [0 3 0 0 0 0 5] // 二维数组 var twoD [2][3]int for i := 0; i &lt; 2; i++ &#123; for j := 0; j &lt; 3; j++ &#123; twoD[i][j] = i + j &#125; &#125; fmt.Println(&quot;2d: &quot;, twoD) // [[0 1 2] [1 2 3]]&#125; 🚫不过在真实的业务场景中，我们很少直接使用定长的数组，更多使用的是切片。 2.2.7 切片 slice数组是定长的，所以 Go 推出可扩容的切片。与数组不同的是，切片不需要指定 [] 里的长度。 12345678910// 1.声明空切片var slice1 []string// 2.创建一个带默认长度的切片var slice2 = make([]int, 3)// 3.声明并初始化切片slice3 := []string&#123;&quot;g&quot;, &quot;o&quot;, &quot;o&quot;, &quot;d&quot;&#125;// 4.最常用切片创建方式slice4 := make([]int, 3)// 5.创建带有长度和容量的切片slice5 := make([]int, 3, 5) 通常情况下，我们会使用 make 函数来创建一个切片；使用 append 来追加元素，注意要将其结果赋值给原切片；然后可以像数组一样去取值；还可以通过 [a:b] 来获取切片中指定范围的值。 1234567891011121314151617181920212223242526272829303132333435363738394041package mainimport &quot;fmt&quot;func main() &#123; // 创建切片 —— 长度:3; 容量:5 s := make([]string, 3, 5) s[0] = &quot;a&quot; s[1] = &quot;b&quot; s[2] = &quot;c&quot; fmt.Println(&quot;get:&quot;, s[2]) // c fmt.Println(&quot;len:&quot;, len(s)) // 3 fmt.Println(&quot;cap:&quot;, cap(s)) // 5 // append 追加元素 s = append(s, &quot;d&quot;) s = append(s, &quot;e&quot;, &quot;f&quot;) fmt.Println(s) // [a b c d e f] // copy 拷贝元素 c := make([]string, len(s)) copy(c, s) fmt.Println(c) // [a b c d e f] cs := []string&#123;&quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;, &quot;w&quot;&#125; copy(cs, s[:3]) fmt.Println(cs) // [a b c w w] // slice 切片取值操作也可以像 python 中的一样取出指定范围的元素, 只不过不可以是负数索引 fmt.Println(s[2:5]) // [c d e] fmt.Println(s[:5]) // [a b c d e] fmt.Println(s[2:]) // [c d e f] // 声明切片并初始化 good := []string&#123;&quot;g&quot;, &quot;o&quot;, &quot;o&quot;, &quot;d&quot;&#125; fmt.Println(good) // [g o o d] // 将切片 c 完全添加到切片 good 中! good = append(good, c...) fmt.Println(good) // [g o o d a b c d e f]&#125; 🤔切片元素的删除：Go 语言中并没有提供一个内置函数将切片中的元素进行删除，但我们可以使用 [x,y] 或者 append 来实现。 1234567// 切片元素的删除slice := []int&#123;1, 2, 3, 4, 5&#125; // 原始切片: [1 2 3 4 5]slice = slice[1:] // 删除索引为0的元素: [2 3 4 5]idx := 1 // 索引值 idx=1slice = append(slice[:idx], slice[idx+1:]...) // 删除索引为1的元素: [2 4 5]fmt.Println(slice) // [2 4 5] ⭐小结一下： 每一个切片都引用了一个底层数组。 切片创建时存储了一个长度和一个容量，还有一个指向数组的指针，当切片添加数据时，如果没有超过容量，直接添加，超出容量自动扩容成倍增长。 一旦切片扩容，指针会指向一个新的底层数组内存地址。 2.2.8 字典 mapmap 是 Go 语言中内置的字典类型，存储的是键值对 key:value 类型的数据，有以下特点： map 是完全无序的，遍历时不会按照字母顺序或插入顺序输出，而是随机的，且只能通过 key 访问对应的 value。 空的 slice 是可以直接使用的，因为它有底层数组；但空的 map 不能直接使用，需要先 make 或初始化后才能使用（map 是引用类型，如果声明没有初始化值，默认为 nil，是不能直接使用的）。 map 的 key 不能重复，否则新增加的值会覆盖原来 key 对应的 value。 创建 map： 123456// 声明空 map: 不可直接使用var map1 map[int]string// 创建 map (已初始化——零值填充): 可直接使用map2 := make(map[int]string)// 声明并初始化 map: 可直接使用map3 := map[string]int&#123;&quot;one&quot;: 1, &quot;two&quot;: 2&#125; 使用 map： 123456789101112131415161718192021222324252627282930313233343536373839package mainimport &quot;fmt&quot;func main() &#123; // make 创建 map m := make(map[string]int) m[&quot;one&quot;] = 1 m[&quot;two&quot;] = 2 fmt.Println(m) // map[one:1 two:2] fmt.Println(len(m)) // 2 fmt.Println(m[&quot;one&quot;]) // 1 fmt.Println(m[&quot;unknow&quot;]) // 0 // 如果 map 为空, 不能直接使用, 否则报错 panic: assignment to entry in nil map var nilMap map[int]float32 //nilMap[0] = 1.0 // panic: assignment to entry in nil map if nilMap == nil &#123; nilMap = make(map[int]float32) &#125; nilMap[0] = 1.0 fmt.Println(nilMap) // map[0:1] // 判断 key 是否存在, value,ok := map[key] r, ok := m[&quot;unknow&quot;] fmt.Println(r, ok) // 0 false t, ok := m[&quot;two&quot;] fmt.Println(t, ok) // 2 true // map 中使用 delete 删除 key 对应的键值对 delete(m, &quot;one&quot;) delete(m, &quot;two&quot;) fmt.Println(m) // map[] // 不使用 make 函数, 直接创建并初始化 map m2 := map[string]int&#123;&quot;one&quot;: 1, &quot;two&quot;: 2&#125; var m3 = map[string]int&#123;&quot;one&quot;: 1, &quot;two&quot;: 2&#125; fmt.Println(m2, m3) // map[one:1 two:2] map[one:1 two:2]&#125; 2.2.9 range 遍历介绍下 range 关键字：对于 slice 或者 map，我们可以使用 range 对其进行快速遍历。 slice：第一个是索引，第二个是值 map：第一个是键，第二个是值 如果不需要索引&#x2F;键，可以直接使用 _ 匿名变量代替。 1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport ( &quot;fmt&quot; &quot;strconv&quot;)func main() &#123; // slice —— range nums := []int&#123;2, 3, 4&#125; sum := 0 for i, num := range nums &#123; sum += num if num == 2 &#123; fmt.Println(&quot;index:&quot;, i, &quot;num:&quot;, num) // index: 0 num: 2 &#125; &#125; fmt.Println(sum) // 9 // 如若不需要索引, 可使用 _ 匿名变量 for _, num := range nums &#123; fmt.Println(num) &#125; // map —— range maps := make(map[int]string) maps[0] = &quot;hello&quot; maps[1] = &quot;world&quot; for key, value := range maps &#123; // int 转 string(1): fmt.Sprintf(&quot;%d&quot;, intVal) fmt.Println(fmt.Sprintf(&quot;%d&quot;, key) + &quot;:&quot; + value) // int 转 string(2): strconv.Itoa(intVal) fmt.Println(strconv.Itoa(key) + &quot;:&quot; + value) // int 转 string(3): , 分隔 fmt.Println(key, &quot;:&quot;, value) &#125; // 如若不需要键, 可使用 _ 匿名变量 for _, v := range maps &#123; fmt.Println(&quot;v&quot;, v) &#125; // 如若不需要值, 可使用 _ 匿名变量, 也可以直接省略 for k := range maps &#123; fmt.Println(&quot;key&quot;, k) &#125;&#125; 2.2.10 函数 func💖Go 语言中的函数比较特殊，参数类型、返回值类型都是后置的，而且函数首字母大写&#x2F;小写的作用不同： 如果函数名首字母大写则表示公共函数，其他包能够调用，前提得引入当前包。 如果函数名首字母小写则表示私有函数，仅能够在本包中调用。 Go 语言的函数 func 结构 💖Golang 中的函数原生支持返回多个值，且在实际业务场景中都返回两个值，第一个是真正的返回结果，第二个是错误信息。 多返回值 接下来看看函数的基本定义及其用法： 123456789101112131415161718192021222324package mainimport &quot;fmt&quot;func add(a int, b int) (int, string) &#123; return a + b, &quot;ok&quot;&#125;func add2(a, b int) int &#123; return a + b&#125;func exists(m map[string]string, k string) (v string, ok bool) &#123; v, ok = m[k] return v, ok&#125;func main() &#123; res, _ := add(1, 2) fmt.Println(res) // 3 v, ok := exists(map[string]string&#123;&quot;a&quot;: &quot;A&quot;&#125;, &quot;a&quot;) fmt.Println(v, ok) // A True&#125; 💖Go 语言中的函数也是一种数据结构，也可以被存储在一个变量中，调用变量的时候也就相当于调用函数——也就是可以将函数作为传递参数。 1234567891011121314151617181920package mainimport &quot;fmt&quot;func add(a int, b int) (int, string) &#123; return a + b, &quot;ok&quot;&#125;func main() &#123; // 函数作为传递参数 f := add ret, _ := f(2, 3) fmt.Println(ret) // 5 // 定义函数变量 var addingFunc func(int, int) (int, string) addingFunc = add result, str := addingFunc(1, 5) fmt.Println(result, str) // 6 ok&#125; 💖Go 中定义匿名函数加上 () 相当于直接调用；如果没有 () 则表示定义一个函数，可将其赋值给变量然后进行多次调用——匿名函数。 123456789101112131415161718192021222324252627package mainimport ( &quot;fmt&quot; &quot;strconv&quot;)func main() &#123; // 匿名函数的简单定义与调用 func() &#123; fmt.Println(&quot;匿名函数&quot;) &#125;() // 匿名函数 // 匿名函数的使用 sum := func(a int, b int) int &#123; return a + b &#125;(1, 2) fmt.Println(sum) // 3 // 定义匿名函数并赋值给其他变量, 此处并没有调用匿名函数, 因为没有() myFunc := func(a, b int) string &#123; return strconv.Itoa(a) + fmt.Sprintf(&quot;%d&quot;, b) &#125; // 调用定义的匿名函数 returnVal := myFunc(6, 66) fmt.Println(returnVal) // 666&#125; 💖甚至你可以将匿名函数作为另一个函数的参数&#x2F;返回值；其中作为参数的函数叫做回调函数，调用的函数叫做高阶函数。 1234567891011121314151617181920212223242526272829303132333435363738package mainimport &quot;fmt&quot;// 匿名函数作为返回值func returnFunc(a int, b int) func() int &#123; return func() int &#123; return a + b &#125;&#125;func increase(a int, b int) int &#123; return a + b&#125;func reduce(a int, b int) int &#123; return a - b&#125;// opera: 高阶函数// f: 回调函数func opera(a int, b int, f func(int, int) int) int &#123; res := f(a, b) return res&#125;func main() &#123; // 将匿名函数作为另一函数的参数 num1 := opera(1, 2, increase) // 3 num2 := opera(1, 2, reduce) // -1 fmt.Println(num1, num2) // 定义匿名函数作为函数参数 num3 := opera(3, 4, func(a int, b int) int &#123; return a * b &#125;) fmt.Println(num3) // 12&#125; 💖既然 Go 语言中的函数能作为返回值和参数，自然能打造闭包结构，与 JS 闭包含义相同。 所谓闭包，就是一个外层函数中有内层函数，这个内层函数会操作外层函数的局部变量，并且，外层函数把内层函数作为返回值，将内层函数与外层函数中的局部变量统称为闭包结构。 💖先捋清下为什么我们需要闭包结构，闭包有什么作用？ 首先看一个简单的计数器例子！ 1234567891011121314151617package mainimport &quot;fmt&quot;var counter = 0func add() int &#123; counter++ return counter&#125;func main() &#123; add() add() add() fmt.Println(counter) // 3&#125; 虽然我们已经达到了目的，但是任意一个函数中都可以随意改动 counter 的值，所以该计数器并不完美，那我们将 counter 放到函数中如何？ 12345678910111213141516package mainimport &quot;fmt&quot;func add() int &#123; counter := 0 counter++ return counter&#125;func main() &#123; add() add() ret := add() fmt.Println(ret) // 1&#125; 本意想输出 3，但由于局部变量在函数每次调用时都会被初始化为 0，所以达不到预期效果。所以我们此时就需要使用闭包来解决了。 1234567891011121314151617181920package mainimport &quot;fmt&quot;func add() func() int &#123; counter := 0 innerFunc := func() int &#123; counter++ return counter &#125; return innerFunc&#125;func main() &#123; inner := add() inner() inner() ret := inner() fmt.Println(ret) // 3&#125; 精简下闭包代码： 1234567891011121314151617181920package mainimport &quot;fmt&quot;func main() &#123; // 以上闭包的简写形式 add := func() func() int &#123; counter := 0 return func() int &#123; counter++ return counter &#125; &#125;() add() add() ret := add() fmt.Println(ret) // 3&#125; 💖现在估计你能很轻松的理解以下代码了。 注意：由于闭包会携带包含它的函数的作用域，因此会比其他函数占用更多的内存。因此可以手动解除对内层匿名函数的引用，以便释放内存。 1234567891011121314151617181920212223242526272829package mainimport &quot;fmt&quot;func main() &#123; res := closure() // 执行 closure 函数返回的内层函数 r1 := res() r2 := res() fmt.Println(res) // 返回内层函数函数体地址: 0x46c7e0 fmt.Println(r1) // 1 fmt.Println(r2) // 2 // 手动解除对内层函数的引用, 以便释放内存 res = nil&#125;// 定义一个闭包结构的函数, 返回一个匿名函数func closure() func() int &#123; //外层函数 // 定义外层函数的局部变量a a := 0 // 定义内层函数并返回 return func() int &#123; // 内层函数用到了外层函数的局部变量, 此变量不会随着外层函数的结束而销毁 a++ return a &#125;&#125; 💖defer 函数是 Go 语言中另一奇特的存在：当 defer 函数调用后，代码暂不执行，推迟到主函数 main 执行结束后才会执行；一般用于资源的关闭。 123456789101112131415package mainimport &quot;fmt&quot;func main() &#123; defer func() &#123; fmt.Println(&quot;Close Resource&quot;) &#125;() fmt.Println(&quot;defer...&quot;) // 输出结果: // defer... // Close Resource&#125; 2.2.11 指针Golang 也支持指针，用法同 C&#x2F;C++，只不过支持的操作比较有限。 Go 语言中通过 &amp; 获取变量的地址，通过 * 获取指针所对应的变量存储的数值。 12345678910111213141516171819package mainimport &quot;fmt&quot;func add2(n int) &#123; n += 2&#125;func add2ptr(n *int) &#123; *n += 2&#125;func main() &#123; n := 5 add2(n) fmt.Println(n) // 5 add2ptr(&amp;n) fmt.Println(n) // 7&#125; 🚀接着简单介绍下：「数组指针」、「指针数组」、「指针函数」、「指针参数」 区分数组指针和指针数组的定义，只需看清变量名更靠近 []（指针数组） 还是 *（数组指针）。 至于要区分这二者的使用方式只需要记得 [] 优先级高于 * 即可。 （1）数组指针：指向数组的指针 123456789101112131415package mainimport &quot;fmt&quot;func main() &#123; // 数组指针 arr := [3]int&#123;1, 2, 3&#125; var ars *[3]int ars = &amp;arr (*ars)[0] = 0 ars[1] = 1 fmt.Println(ars) // &amp;[0 1 3] fmt.Println(*ars) // [0 1 3] fmt.Println((*ars)[1]) // 1&#125; （2）指针数组：数组元素皆为指针 1234567891011121314// 指针数组a, b, c := 1, 2, 3nums := [3]int&#123;a, b, c&#125;numps := [3]*int&#123;&amp;a, &amp;b, &amp;c&#125;*numps[1] = 1*numps[2] = 6fmt.Println(nums) // [1 2 3]fmt.Println(numps) // [0xc000018128 0xc000018130 0xc000018138]fmt.Println(*numps[0]) // 1fmt.Println(*numps[2]) // 6for _, v := range numps &#123; fmt.Print(*v, &quot; &quot;) // 1 1 6&#125; （3）指针函数：如果一个函数返回结果是一个指针，那么这个函数就是一个指针函数 1234567891011121314package mainimport &quot;fmt&quot;func main() &#123; var p = pfunc() fmt.Println((*p)[1]) // 2&#125;// 指针函数: 此处返回切片指针(用法同数组指针)func pfunc() *[]int &#123; arr := []int&#123;1, 2, 3&#125; return &amp;arr&#125; （4）指针参数：指针作为函数的形参 1234567891011121314package mainimport &quot;fmt&quot;func main() &#123; s := 19 argpfunc(&amp;s) fmt.Println(s) // 6&#125;// 指针参数func argpfunc(p *int) &#123; *p = 6&#125; 2.2.12 结构体 &amp; 结构体方法Go 语言中不存在 Class 类的概念，但是可以通过结构体 struct 来实现。同时在结构体中也支持指针，避免对大结构体拷贝的开销。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport &quot;fmt&quot;type user struct &#123; name string password string&#125;func main() &#123; a := user&#123;name: &quot;wang&quot;, password: &quot;1024&quot;&#125; b := user&#123;&quot;wang&quot;, &quot;1024&quot;&#125; c := user&#123;name: &quot;wang&quot;&#125; c.password = &quot;1024&quot; var d user d.name = &quot;wang&quot; d.password = &quot;1024&quot; e := new(user) e.name = &quot;wang&quot; e.password = &quot;1024&quot; fmt.Println(a, b, c, d) // &#123;wang 1024&#125; &#123;wang 1024&#125; &#123;wang 1024&#125; &#123;wang 1024&#125; fmt.Println(e) // &amp;&#123;wang 1024&#125; fmt.Println(checkPassword(a, &quot;996&quot;)) // false changePassword(&amp;a, &quot;996&quot;) // 通过指针修改结构体中的数据 fmt.Println(a) // &#123;wang 996&#125; // 匿名结构体 &amp; 嵌套结构体 p := struct &#123; age int sex string u user &#125;&#123; age: 21, sex: &quot;Male&quot;, u: user&#123;&quot;w&quot;, &quot;1024&quot;&#125;, &#125; fmt.Println(p) // &#123;21 Male &#123;w 1024&#125;&#125;&#125;func checkPassword(u user, password string) bool &#123; return u.password == password&#125;func changePassword(u *user, password string) &#123; u.password = password&#125; 在 Golang 中还可以为结构体去定义方法，类似其他语言的类成员函数，这样就可以使用 对象.方法 去调用结构体方法了；结构体方法又分为带指针和不带指针两种，不带指针的是一种拷贝。 123456789101112131415161718192021222324252627282930313233package mainimport &quot;fmt&quot;// 结构体type user struct &#123; name string password string&#125;// 结构体方法func (u user) checkingPassword(password string) bool &#123; return u.password == password&#125;// u user: 拷贝传入的结构体, 不修改原有结构体// u *user: 可以修改传入的结构体func (u *user) changingPassword(password string) &#123; u.password = password&#125;func main() &#123; u := user&#123; name: &quot;w&quot;, password: &quot;1024&quot;, &#125; // 结构体方法的调用 isEqual := u.checkingPassword(&quot;1024&quot;) u.changingPassword(&quot;2022&quot;) fmt.Println(isEqual) // true fmt.Println(u) // &#123;w 2022&#125;&#125; 2.2.13 字符串操作Go 语言中的 strings 标准库含有很多操作字符串的工具函数，strings 主要针对 utf-8 编码。 123456789101112131415161718192021222324package mainimport ( &quot;fmt&quot; &quot;strings&quot;)func main() &#123; a := &quot;hello&quot; b := &quot;你好&quot; fmt.Println(strings.Contains(a, &quot;he&quot;)) // true fmt.Println(strings.Index(a, &quot;l&quot;)) // 2 fmt.Println(strings.Count(a, &quot;l&quot;)) // 2 fmt.Println(strings.HasPrefix(a, &quot;he&quot;)) // true fmt.Println(strings.HasSuffix(a, &quot;lo&quot;)) // true fmt.Println(strings.Join([]string&#123;a, b&#125;, &quot;-&quot;)) // hello-你好 fmt.Println(strings.Repeat(a, 2)) // hellohello fmt.Println(strings.Replace(a, &quot;l&quot;, &quot;i&quot;, 1)) // heilo fmt.Println(strings.Split(&quot;a-b-c&quot;, &quot;-&quot;)) // [a b c] fmt.Println(strings.ToUpper(a)) // HELLO fmt.Println(strings.ToLower(a)) // hello fmt.Println(len(a)) // 5 fmt.Println(len(b)) // 6&#125; 2.2.14 字符串格式化😎Go 可以使用 fmt.Printf() 或者 fmt.Sprintf() 格式化字符串（后者能将格式化后的字符串赋值给新字符串）！ 😎Go 语言中额外提供了占位符 %v 来打印任意类型的变量，你还可以用 %+v、%#v 打印更加详细的信息 … 🔎字符串格式化符号|一览表 占位符 说明 %d 十进制的数字 %T 取类型 %s 取字符串 %t 取 bool 类型的值 %p 取内存地址 %b 整数以二进制显示 %o 整数以八进制显示 %x 整数以十六进制显示 %v 任意类型变量 %+v 在 %v 基础上，对结构体字段名和值进行展开 %#v 输出 Go 语言语法格式的值 1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport ( &quot;fmt&quot; &quot;time&quot;)type point struct &#123; x, y int&#125;func main() &#123; s := &quot;hello&quot; n := 123 f := 3.141592653 b := true p := point&#123;1, 2&#125; // fmt.Printf() fmt.Printf(&quot;%s &quot;, s) // hello fmt.Printf(&quot;%d &quot;, n) // 123 fmt.Printf(&quot;%b &quot;, n) // 1111011 fmt.Printf(&quot;%f &quot;, f) // 3.141592653 fmt.Printf(&quot;%.3f &quot;, f) // 3.142 fmt.Printf(&quot;%t &quot;, b) // true fmt.Printf(&quot;%T &quot;, f) // float64 fmt.Printf(&quot;%T &quot;, p) // main.point fmt.Printf(&quot;s=%v &quot;, s) // s=hello fmt.Printf(&quot;n=%v &quot;, n) // n=123 fmt.Printf(&quot;p=%v &quot;, p) // p=&#123;1 2&#125; fmt.Printf(&quot;p=%+v &quot;, p) // p=&#123;x:1 y:2&#125; fmt.Printf(&quot;p=%#v &quot;, p) // p=main.point&#123;x:1, y:2&#125; // fmt.Sprintf() motto := fmt.Sprintf(&quot;Today is %s, and I&#x27;m working under the %d system... &quot;, time.Now(), 965) fmt.Printf(motto) // 利用 fmt.Sprintf() 方法返回 string 的特性, 可以将 int 转为 string intVal := 1024 var strVal string = fmt.Sprintf(&quot;%d&quot;, intVal) // int 转 string fmt.Printf(&quot;%T&quot;, strVal) // string&#125; 2.2.15 接口Golang 接口内可以定义多个方法，谁将这些方法实现，就可以认为是实现了该接口（这是一种约束，不像 Java 还需要 implements 来显式实现），这样规范了方法。在调用的时候使用不同的结构体对象，可以实现执行不同的方法。这样就实现了 Go 语言中的多态。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package mainimport &quot;fmt&quot;type action interface &#123; // run: run in speed run(int) // get: get name get() string&#125;type person struct &#123; name string speed int&#125;type animal struct &#123; types string velocity int&#125;func (per *person) run(speed int) &#123; fmt.Println(&quot;Run in&quot;, speed, &quot;m/s&quot;)&#125;func (per *person) get() string &#123; return per.name&#125;func (ani *animal) run(velocity int) &#123; fmt.Println(&quot;Run in&quot;, velocity, &quot;m/s&quot;)&#125;func (ani *animal) get() string &#123; return ani.types&#125;func main() &#123; per := person&#123;name: &quot;w&quot;, speed: 1&#125; ani := animal&#123;types: &quot;tiger&quot;, velocity: 6&#125; var act action act = &amp;per act.run(per.speed) // Run in 1 m/s name := act.get() // w act = &amp;ani act.run(ani.velocity) // Run in 6 m/s types := act.get() // tiger fmt.Println(name, types) // w tiger&#125; 🌓Golang 还存在空接口 interface&#123;&#125;，这种类型可以理解为任意类型，类似 Java 中的 Object 类。 12345678910111213141516package mainimport &quot;fmt&quot;// T 空接口的定义, 也可以直接使用 interface&#123;&#125;type T interface &#123;&#125;func test1(t T) &#123; fmt.Println(t)&#125;// 简化: T=interface&#123;&#125;func test2(t interface&#123;&#125;) &#123; fmt.Println(t)&#125; ⭐既然空接口可以传递任意类型，我们就可以利用这个特性把空接口 interface&#123;&#125; 当作容器使用。 12345678// interface&#123;&#125; 作为 map 的 valuemaps := make(map[int]interface&#123;&#125;)maps[1] = 1maps[3] = &quot;369&quot;maps[6] = truemaps[9] = 9.9fmt.Println(maps) // map[1:1 3:369 6:true 9:9.9] 123456789101112131415161718192021222324252627282930313233package mainimport &quot;fmt&quot;// Dictionary 封装maptype Dictionary struct &#123; data map[string]interface&#123;&#125;&#125;func NewDictionary() *Dictionary &#123; return &amp;Dictionary&#123; data: make(map[string]interface&#123;&#125;), &#125;&#125;func (dict *Dictionary) Set(key string, value interface&#123;&#125;) &#123; dict.data[key] = value&#125;func (dict *Dictionary) Get(key string) interface&#123;&#125; &#123; return dict.data[key]&#125;func main() &#123; // Dictionary dict := NewDictionary() dict.Set(&quot;a&quot;, &quot;abandon&quot;) dict.Set(&quot;b&quot;, 2) dict.Set(&quot;c&quot;, false) fmt.Println(dict.Get(&quot;a&quot;)) // abandon fmt.Println(dict.Get(&quot;d&quot;)) // &lt;nil&gt;&#125; 💖更多关于空接口的解释：The Go Empty Interface Explained 2.2.16 错误处理💧错误和异常不同： 错误是在程序中正常存在的，可以预知的失败在意料之中。 异常通常指在不应该出现问题的地方出现问题，比如空指针，这在人们的意料之外。 在 Golang 中，错误处理通常被单独作为一个返回值以传递错误信息。不同于 Java，Go 语言能很清晰的知道是哪个函数返回了错误，并且可以使用简单的 if-else 语句加以处理。 🔎error 的定义是一个接口，接口内部包含一个返回字符串类型的方法 Error()。 123type error interface &#123; Error() string&#125; 清楚 error 的定义是一个接口类型后，那么只要实现了这个接口都可以用来处理错误信息，来返回一个错误提示给用户。 Go 语言也提供了一个内置包 errors，使用 errors.New(&quot;&quot;) 来创建一个错误对象，以下为 errors 内置包中 errors.go 的定义： 12345678910111213141516package errors// New returns an error that formats as the given text.// Each call to New returns a distinct error value even if the text is identical.func New(text string) error &#123; return &amp;errorString&#123;text&#125;&#125;// errorString is a trivial implementation of error.type errorString struct &#123; s string&#125;func (e *errorString) Error() string &#123; return e.s&#125; ⭐通常的做法是：当出错时，返回一个 nil 和一个 error；否则直接返回原有值和 nil。 1234567891011121314151617181920212223242526272829303132333435363738package mainimport ( &quot;errors&quot; &quot;fmt&quot;)type user struct &#123; name string password string&#125;func findUser(users []user, name string) (v *user, err error) &#123; for _, u := range users &#123; if u.name == name &#123; return &amp;u, nil &#125; &#125; return nil, errors.New(&quot;not found&quot;)&#125;func main() &#123; users := []user&#123;&#123;&quot;w&quot;, &quot;1024&quot;&#125;, &#123;&quot;q&quot;, &quot;996&quot;&#125;&#125; u, e := findUser(users, &quot;w&quot;) if e != nil &#123; fmt.Println(e) return &#125; fmt.Println(*u) // &#123;w 1024&#125; if us, err := findUser(users, &quot;r&quot;); err != nil &#123; fmt.Println(err) // not found return &#125; else &#123; fmt.Println(*us) &#125;&#125; 2.2.17 时间处理关于时间处理，最常用的莫过于 time.now() 获取当前时间。以下还有一些 time 内置包的常见用法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main() &#123; nowTime := time.Now() fmt.Println(nowTime) // 2022-05-09 13:02:24.4523211 +0800 CST m=+0.007505401 // Date(): 获取年月日 year, month, day := time.Now().Date() fmt.Println(year, month, day) // 2022 May 09 // Clock(): 获取时分秒 hour, minute, second := time.Now().Clock() fmt.Println(hour, minute, second) // 13 1 1 // 格式化时间 formatTime1 := nowTime.Format(&quot;2006/01/02 15:04:05&quot;) fmt.Println(formatTime1) // 2022/05/09 11:40:29 formatTime2 := nowTime.Format(&quot;2006年01月02日 15时04分05秒&quot;) fmt.Println(formatTime2) // 2022年05月09日 11时41分25秒 // 构造带时区的时间 created := time.Date(2022, 5, 9, 11, 12, 13, 0, time.UTC) fmt.Println(created) // 2022-05-09 11:12:13 +0000 UTC fmt.Println(created.Year(), created.Month(), created.Day(), created.Hour(), created.Minute(), created.Second()) // 2022 May 9 11 12 13 // Add(): 对某个时间点进行增加时间间隔的操作 // Sub(): 可以对两个时间点进行减法然后获取时间段 another := created.Add(time.Hour + time.Minute*3) diff := another.Sub(created) fmt.Println(diff) // 1h3m0s fmt.Println(diff.Hours(), diff.Minutes()) // 1.05 63 // 时间戳 fmt.Println(nowTime.Unix()) // 1652417743 // 时间解析 t, err := time.Parse(&quot;2006-01-02 15:04:05&quot;, &quot;2022-05-09 11:12:13&quot;) if err != nil &#123; panic(err) &#125; fmt.Println(t == created) // true&#125; 😮更多： Go 的时间格式化为什么是 2006-01-02 15:04:05？ Golang 神奇的 2006-01-02 15:04:05 2.2.18 JSON 处理Go 中操作 JSON 非常简单，对于一个结构体我们只需要确保每个字段的首字母为大写（即公开字段），那么这个结构体就能够用 json.Marshal 去序列化成一个 JSON byte[]，如果要转化成字符串则通过 string() 即可；序列化后的字符串也可以用 json.Unmarshal 去反序列化到一个 struct 变量中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot;)type userInfo struct &#123; Name string Age int `json:&quot;age&quot;` // `json:&quot;age&quot;` 是 json tag, 可以按 tag 名进行输出 Hobby []string&#125;func main() &#123; // struct ==&gt; json(string) user := userInfo&#123;Name: &quot;w&quot;, Age: 21, Hobby: []string&#123;&quot;Java&quot;, &quot;Golang&quot;, &quot;Python&quot;, &quot;C++&quot;&#125;&#125; buf, err := json.Marshal(user) // struct ==&gt; byte[] if err != nil &#123; panic(err) &#125; fmt.Println(buf) // byte[]: [123 34 78 97...] fmt.Println(string(buf)) // string: &#123;&quot;Name&quot;:&quot;w&quot;,&quot;age&quot;:21,&quot;Hobby&quot;:[&quot;Java&quot;,&quot;Golang&quot;,&quot;Python&quot;,&quot;C++&quot;]&#125; // struct ==&gt; json(string): 带有缩进的标准 JSON 格式 buf, err = json.MarshalIndent(user, &quot;&quot;, &quot;\\t&quot;) if err != nil &#123; panic(err) &#125; fmt.Println(string(buf)) /* 输出结果: &#123; &quot;Name&quot;: &quot;w&quot;, &quot;age&quot;: 21, &quot;Hobby&quot;: [ &quot;Java&quot;, &quot;Golang&quot;, &quot;Python&quot;, &quot;C++&quot; ] &#125; */ // json(string) ==&gt; struct var u userInfo err = json.Unmarshal(buf, &amp;u) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;%#v&quot;, u) // main.userInfo&#123;Name:&quot;w&quot;, Age:21, Hobby:[]string&#123;&quot;Java&quot;, &quot;Golang&quot;, &quot;Python&quot;, &quot;C++&quot;&#125;&#125;&#125; 2.2.19 数字解析接下来学习下字符串与数字之间的转换，在 Go 语言中，关于字符串和数字类型的转换都在 strconv 内置包中，这个包名是 string &amp; convert 两个单词的缩写拼接而成。 12345678910111213141516171819202122232425262728package mainimport ( &quot;fmt&quot; &quot;strconv&quot;)func main() &#123; f, _ := strconv.ParseFloat(&quot;1.234&quot;, 64) fmt.Println(f) // 1.234 n, _ := strconv.ParseInt(&quot;111&quot;, 10, 64) fmt.Println(n) // 111 n, _ = strconv.ParseInt(&quot;0x1000&quot;, 0, 64) fmt.Println(n) // 4096 // string ==&gt; int n2, _ := strconv.Atoi(&quot;123&quot;) // Atoi is equivalent to `ParseInt()` fmt.Println(n2) // 123 // int ==&gt; string var str string = strconv.Itoa(123) fmt.Println(str) // 123 n2, err := strconv.Atoi(&quot;AAA&quot;) fmt.Println(n2, err) // 0 strconv.Atoi: parsing &quot;AAA&quot;: invalid syntax&#125; 2.2.20 进程信息在 Go 中，我们可以使用 os.Args 来获取程序执行时指定的命令行参数。 ⭐比如我们编译一个二进制文件，执行 go run example/20-env/main.go a b c d 命令，其中有 a b c d 四个命令行参数，但是 os.Args 会是长度为 5 的 slice，因为第一个成员代表二进制自身的名字。 12345678910111213141516171819202122package mainimport ( &quot;fmt&quot; &quot;os&quot; &quot;os/exec&quot;)func main() &#123; // go run example/20-env/main.go a b c d fmt.Println(os.Args) // [/var/folders/8p/n34xxfnx38dg8bv_x8l62t_m0000gn/T/go-build3406981276/b001/exe/main a b c d] slices := os.Args fmt.Println(len(slices)) // 5 fmt.Println(os.Getenv(&quot;PATH&quot;)) // /usr/local/go/bin... fmt.Println(os.Setenv(&quot;AA&quot;, &quot;BB&quot;)) buf, err := exec.Command(&quot;grep&quot;, &quot;127.0.0.1&quot;, &quot;/etc/hosts&quot;).CombinedOutput() if err != nil &#123; panic(err) &#125; fmt.Println(string(buf)) // 127.0.0.1 localhost&#125; 🔎「Go 入门」中的部分图片引用自：https://juejin.cn/book/6844733833401597966 3. Go 实战程序上文已经介绍了 Go 语言的基础语法和一些常用标准库的使用方法，接下来通过 3 个实例真正上手 Golang！ 3.1 猜谜游戏 唯一需要注意的是 Linux&#x2F;Unix、Windows、Mac OS 三个操作系统下换行符不一致问题！ Linux&#x2F;Unix：换行符为 Mac OS：换行符为 \\r Windows：换行符为\\r 附部分 ASCII 码对照表 OK，如下就可以实现一个简单的猜谜游戏程序了！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package mainimport ( &quot;bufio&quot; &quot;fmt&quot; &quot;math/rand&quot; &quot;os&quot; &quot;strconv&quot; &quot;strings&quot; &quot;time&quot;)func main() &#123; maxNum := 100 // 用时间戳初始化随机数种子 rand.Seed(time.Now().UnixNano()) // rand.Intn(100): 产生 0 到 100 之间的随机整数 secretNumber := rand.Intn(maxNum) fmt.Print(&quot;Please input your guess: &quot;) reader := bufio.NewReader(os.Stdin) for &#123; // 读取一行输入: 读到 xxxx ==&gt; 需要去掉 input, err := reader.ReadString(&#x27; &#x27;) // 输入结束符: if err != nil &#123; fmt.Println(&quot;An error occured while reading input. Please try again&quot;, err) continue &#125; // Windows —— CRLF(回车+换行): \\r // Linux/Unix —— LF(换行): // Mac OS —— CR(回车): \\r /* strings.TrimSuffix(): 去掉最后读入的回车换行 &quot;\\r &quot; */ input = strings.TrimSuffix(input, &quot;\\r &quot;) // Atoi: string ==&gt; int // Itoa: int ==&gt; string guess, err := strconv.Atoi(input) if err != nil &#123; fmt.Println(&quot;Invalid input. Please enter an integer value&quot;) continue &#125; fmt.Println(&quot;You guess is&quot;, guess) if guess &gt; secretNumber &#123; fmt.Println(&quot;Your guess is bigger than the secret number. Please try again&quot;) &#125; else if guess &lt; secretNumber &#123; fmt.Println(&quot;Your guess is smaller than the secret number. Please try again&quot;) &#125; else &#123; fmt.Println(&quot;Correct, you Legend!&quot;) break &#125; &#125;&#125; 3.2 在线词典 以彩云小译为例，来扒一下翻译接口： 我们需要在 Golang 中发送该请求，因为这个请求比较复杂，较难用代码构造，我们可以借助第三方工具 curlconverter 来生成代码。 首先 Copy as cURL (bash)，然后借助 curlconverter 工具生成 Golang 对应的请求代码： 将代码直接运行可得到请求成功后返回的 JSON 结果（v1）： 然后我们需要根据 Response Body 构造出对应的结构体，然后将响应回来的 json 字符串反序列化到结构体中，显然我们不可能自己构造（繁琐且易出错），此时需要再借助第三方工具 OKTools 生成对应的结构体。 具体做法是将彩云小译中响应的 json 字符串粘贴到 OKTools 生成对应的结构体： 构造「请求结构体」与「响应结构体」后，再次发送请求试试（v3）： 可以看出所有信息都已经打印出来，但这并不是我们想要的，我们只打印 explanations 和 prons 这两部分的信息即可。 这样在线词典就完成了，可以运行以下程序尝试一下。 3.3 SOCKS5 代理先浅浅演示下最终效果：启动 Golang 代理服务器程序，然后通过命令行 curl -socks5 代理服务器地址 目标URL 测试（或者通过 SwitchyOmega 插件配置，然后直接访问网站），如果代理服务器能正常工作，那么 curl 命令就会正常返回，代理服务器的日志也会打印出你所访问的网站域名或者 IP，这说明我们的网络流量是通过此代理服务器转发的。 这里我们将要编写一个较为复杂的 socks5 代理服务器，虽然 socks5 协议是代理协议，但是它并不能用于出去，它的协议使用明文传输。 该协议诞生于互联网早期，因为早些时候某些互联网的内网为了确保安全性，有很严格的防火墙策略，但是这会使其访问某些资源较为麻烦，所以 socks5 应运而生，它相当于在防火墙上开个口子，让授权用户可以通过单个端口访问内部资源。 实际上很多软件最终暴露的也是一个 socks5 协议的端口，其实爬虫中所使用的 IP 代理池中很多代理协议就是 socks5。 接着简单了解下 socks5 的工作原理（下附图解），大致流程是浏览器与 socks5 代理服务器建立 TCP 连接，然后 socks5 代理服务器再与目标服务器建立 TCP 连接，这里可分为四个阶段：握手阶段、认证阶段、请求阶段、relay 阶段。 第一阶段——握手：浏览器向 socks5 代理服务器发起请求，其中的数据包内容包括协议版本号 VER，还有支持的认证种类 NMETHODS，以及具体的认证方法 METHOD。如果类型为 00 则表示不需要认证，如果为其他类型则进入认证流程。 第二阶段——认证：不作详细介绍。 第三阶段——请求：认证通过后浏览器会向 socks5 代理服务器发起 Connection 请求，主要信息包括版本号 VER、请求类型 CMD、保留字段 RSV、目标地址类型 ATYP、目标 IP &amp; Port。代理服务器接收到请求后，会和目标服务器建立起连接，然后返回响应。 第四阶段——relay：此时浏览器与目标服务器就可以通过 socks5 代理进行数据的正常收发。 SOCKS5 协议工作原理 😮在正式实现 socks5 代理前，我们先用 Golang 实现一个简单的 TCP Echo Server 过渡一下： 💖「SOCKS5 代理服务器」完整代码（附超详细的代码注释） 🥰接着就是测试环节了，命令行测试和浏览器测试各演示一次。 命令行测试 浏览器测试：通过 SwitchyOmega 插件配置访问网站，代理服务器进行响应 4. 课后作业 4.1 简化猜谜游戏关键代码： 12var guess int_, err := fmt.Scanf(&quot;%d\\r &quot;, &amp;guess) // windows 最终代码： 4.2 新增翻译引擎所使用的翻译引擎：有道智云AI翻译 具体操作上文已经详细介绍过了，代码如下： 🚀这里补充推荐几个翻译接口： 必应翻译：Level 1 火山翻译：Level 1 有道翻译：Level 2（接口被加密，没法轻易破解） salt 随机数：时间 + rand 生成 sign：md5 加密认证 谷歌翻译：Level 3 百度翻译接口破解 百度翻译：Level 3 谷歌翻译接口破解 ⭐后三种翻译平台想要免费使用的话都需要破解，或者你可以氪金去申请对应翻译平台的 API 接口，比较稳定。 4.3 并行请求翻译关键代码： 1234567891011121314func main() &#123; // ... var wg sync.WaitGroup wg.Add(2) go func() &#123; queryYouDao(word) wg.Done() &#125;() go func() &#123; queryCaiYun(word) wg.Done() &#125;() wg.Wait()&#125; 最终代码： 5. 最后💖 如果本文对你有所帮助，点个「赞」支持一下吧！ 💖&#x2F; END &#x2F; 下期见！","tags":["Golang"],"categories":["Golang"]},{"title":"C++ 拷贝构造函数｜编译器优化","path":"/post/C++/cpp-copy-constructor/","content":"今天碰到一件令我百思不得其解的问题：为什么拷贝构造函数不按自己所预期的结果输出？ 按 C++ 的语法来说，本该如此，并非自己理解有误而导致的！ 功夫不负有心人，经过几天的搜索🔍、学习👨‍💻，我总算明白并解决了这个问题，特此输出该文记录一下。 📈 背景知识1. 构造函数💛创建并初始化类的数据成员时调用 2. 析构函数💚当对象生命周期终止时调用，用于释放对象占有的资源 3. 拷贝构造函数❤调用时机： 将某个对象用于初始化另一个新创建的对象时 当对象作为参数传递给函数，且函数形参为普通对象时（因为引用对象不会调用拷贝构造函数） 对象作为函数的返回值时 💙注意： 如果在类中没有定义拷贝构造函数，编译器会自行定义一个； 如果类带有指针变量，并有动态内存分配，则它必须有一个拷贝构造函数。 🌄 进入正题先来看一段包含构造函数、析构函数、拷贝构造函数的简单代码，代码中穿插着许多注释，这里就不再一一解释。 本文旨在探索拷贝构造函数，构造函数与析构函数仅为顺带学习而提及，可略过这二者。 顺带一提，注释中标注的各类函数调用顺序仅针对于预期结果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include &lt;iostream&gt;using namespace std;class Point &#123;public: int x; int y; int *p; Point(int xx, int yy, int *pp); ~Point(); Point(const Point &amp;point);&#125;;// 构造函数Point::Point(int xx, int yy, int *pp) : x(xx), y(yy) &#123; // 申请一块值为*pp的内存空间, 并让指针p指向它! p = new int(*pp); // p = new int; // *p = *pp; cout &lt;&lt; &quot;Point()&quot; &lt;&lt; endl;&#125;// 析构函数Point::~Point() &#123; delete p; cout &lt;&lt; this-&gt;x &lt;&lt; &quot;~Point()&quot; &lt;&lt; endl;&#125;// 拷贝构造函数Point::Point(const Point &amp;point) &#123; this-&gt;x = point.x; this-&gt;y = point.y; p = new int; *p = *point.p; cout &lt;&lt; &quot;Copy-Constructor()&quot; &lt;&lt; endl;&#125;// 参数为对象, 调用拷贝构造函数// 若定义为 const Point &amp;point 则不会调用拷贝构造函数: 因为 &amp; 是引用, 会指向同一个对象, 而不是拷贝!void display(Point point) &#123; point.x = 4;&#125;// 返回值为对象, 调用拷贝构造函数Point returnPoint() &#123; int c = 6; Point point(7, 5, &amp;c); return point;&#125;int main() &#123; int z = 3; // 调用构造函数 Point point1(1, 2, &amp;z); // 1.Point()、11.~Point() // 情况1: 调用拷贝构造函数 Point point2 = point1; // 2.Copy-Constructor()、10.~Point() point2.x = 2; // 情况2: 调用拷贝构造函数 display(point2); // 3.Copy-Constructor()、4.~Point() // 情况3: 调用拷贝构造函数??? Point point3 = returnPoint(); // 5.Point()、6.Copy-Constructor()、7.~Point()、8.Copy-Constructor()、9.~Point()、10.~Point() point3.x = 10; return 0;&#125; 运行结果12345678Point()Copy-Constructor()Copy-Constructor()4~Point()Point()10~Point()2~Point()1~Point() 预期结果🛕各类函数的调用顺序均已在注释中标明！ 123456789101112Point()Copy-Constructor()Copy-Constructor()4~Point()Point()Copy-Constructor()7~Point()Copy-Constructor()7~Point()10~Point()2~Point()1~Point() 🤨 分析原因浅浅分析下运行结果与预期结果之间拷贝构造函数调用的差异。 如果你感兴趣，可以自己去调试下，最后发现问题出在 情况 3: Point point3 = returnPoint(); 处，也就是函数的返回值为对象时。 为什么？！ 🚀原来是 GCC 做了优化，当返回值为对象时，不再产生临时对象，因此不再调用拷贝构造函数。 再来对比下两个结果，可见直接把 2 个拷贝构造函数都优化掉了， ⭐这时候又会有人问了：诶，为什么是 2 个，情况 3 不就是对象作为函数返回值吗？不就只会调用 1 次拷贝构造函数吗？ 1234567891011// ...Point returnPoint() &#123; int c = 6; Point point(7, 5, &amp;c); return point;&#125;int main() &#123; Point point3 = returnPoint(); // ...&#125; 就这部分代码而言，我的猜想是这样的： returnPoint() 函数返回对象时，将其拷贝到一个临时对象 temp 中（① 调用拷贝构造函数），然后释放函数中的局部对象； 当执行到 Point point3 = returnPoint(); 时，将对象赋值给 point3（② 再次调用拷贝构造函数），并释放临时对象 temp，最后释放 point3 对象。 差不多是这么回事 当然以上没有很严谨的科学依据，但是经过我几番调试，输出结果也吻合，估计是八九不离十！ 🌍 解决办法Q：如果一定想要让拷贝构造函数在这种情况下执行呢？ A：只需要让 GCC 不要优化：在编译命令中加入 -fno-elide-constructors 参数，例如 g++ -fno-elide-constructors CopyConstructor.cpp. 我个人是使用的 C++ IDE 是 CLion，如下也给出相应的解决办法。 因为使用 IDE 就是为了快速编译运行，不可能每次都执行相应代码来运行程序，所以需要配置。 只需在 CMakeLists.txt 中添加如下代码： 12# 添加编译选项! ==&gt; 防止g++优化导致&quot;返回对象不调用拷贝构造函数&quot;！add_definitions(-fno-elide-constructors) 🗺提醒一下：如果你的代码依赖于拷贝构造函数的副作用，那么你的代码就写得很烂。你编写的拷贝构造函数就应该保证这样的优化是安全的。 ⛵ 最后gcc 和 g++ 是什么，有什么区别？ 该段落出自：http://c.biancheng.net/view/7936.html 发展至今，GCC 编译器的功能也由最初仅能编译 C 语言，扩增至可以编译多种编程语言，其中就包括 C++ 。 除此之外，当下的 GCC 编译器还支持编译 Go、Objective-C，Objective-C ++，Fortran，Ada，D 和 BRIG（HSAIL）等程序，甚至于 GCC 6 以及之前的版本还支持编译 Java 程序。 那么，在已编辑好 C 语言或者 C++ 代码的前提下，如何才能调用 GCC 编译器为我们编译程序呢？很简单，GCC 编译器已经为我们提供了调用它的接口，对于 C 语言或者 C++ 程序，可以通过执行 gcc 或者 g++ 指令来调用 GCC 编译器。 值得一提的是：实际使用中我们更习惯使用 gcc 指令编译 C 语言程序，用 g++ 指令编译 C++ 代码。需要强调的一点是，gcc 指令也可以用来编译 C++ 程序，同样 g++ 指令也可以用于编译 C 语言程序。 ⭐总结： gcc 是 GCC 中的 GUN C Compiler（C 编译器） g++ 是 GCC 中的 GUN C++ Compiler（C++编译器） CMakeLists.txt 超傻瓜式教程CMake 命令官网：cmake.org 12345678910111213141516171819202122232425262728293031323334353637# 本CMakeLists.txt的project名称# 会自动创建两个变量，PROJECT_SOURCE_DIR和PROJECT_NAME# $&#123;PROJECT_SOURCE_DIR&#125;：本CMakeLists.txt所在的文件夹路径# $&#123;PROJECT_NAME&#125;：本CMakeLists.txt的project名称project(xxx)# 获取路径下所有的.cpp/.c/.cc文件，并赋值给变量中aux_source_directory(路径 变量)# 给文件名/路径名或其他字符串起别名，用$&#123;变量&#125;获取变量内容set(变量 文件名/路径/...)# 添加编译选项add_definitions(编译选项)# 打印消息message(消息)# 编译子文件夹的CMakeLists.txtadd_subdirectory(子文件夹名称)# 将.cpp/.c/.cc文件生成.a静态库# 注意，库文件名称通常为libxxx.so，在这里只要写xxx即可add_library(库文件名称 STATIC 文件)# 将.cpp/.c/.cc文件生成可执行文件add_executable(可执行文件名称 文件)# 规定.h头文件路径include_directories(路径)# 规定.so/.a库文件路径link_directories(路径)# 对add_library或add_executable生成的文件进行链接操作# 注意，库文件名称通常为libxxx.so，在这里只要写xxx即可target_link_libraries(库文件名称/可执行文件名称 链接的库文件名称)","tags":["C++","g++","gcc"],"categories":["C++"]},{"title":"张鑫旭 12 年技术写作经验分享","path":"/post/未来世界的幸存者/technical-writing-experience/","content":"写作像我这个掘金新人一样毫无头绪？那本文也许能帮助到你。 几日前有幸能参与【创作者训练营】第四期，在直播中也 Get 到不少有用的写作技巧，现在第二次直播回放，现帮大家归纳总结下张鑫旭前辈写作经验的几大要素。 ⭐不论是没时间或者错过直播，还是想要复习的掘友们，希望本文对你们有所帮助。 直播讲师：张鑫旭 直播主题：12 年技术写作经验分享 讲师介绍：阅文集团前端技术专家，同时也是鑫空间鑫生活博主，十几年来一直笔耕不缀，创作了接近 800 篇前端技术原创文章，并著有书籍《CSS世界》《CSS选择器世界》和《CSS新世界》，在与用户体验相关的前端领域有较多的研究心得。 直播回放：张鑫旭 12 年技术写作经验分享 1. 前言：为什么会想不到分享的东西？ 总想搞波大事件 要稀缺 要精致 要干货 害怕带来的不安全感 害怕内容不行 害怕版式糟糕 害怕暴露菜鸟水平 ⭐其实不能让这些因素造成我们写作困难，我们更应该考虑的是“我有什么”？！ 我是谁？ 我的精力怎样？ 我的水平如何？ 我的优势是什么？ 我的突破口又在哪里？ 2. 关于写作选题写作选题方向01 新特性、新方法介绍（适合新人）：推荐 Can I Use 网站 02 自认为厉害的小技巧、小创造 03 原理剖析、深入理解 04 技术方案汇总（适合新人） 05 棘手问题解决经验分享 06 优秀框架、项目、工具的体验指南（适合新人） 建议(1) 选题与自己学习相关 写作是学习的辅助手段 容易坚持，就算没人看，自己也收获了成长 (2) 不要写雷同内容 同一个知识点可以从不同点切入 (3) 迷茫时候写写个人故事、感悟与困惑 既能寻找答案，又能获得访问 3. 关于内容结构🙄你的写作目的决定了你的内容结构！ 功利写作🌈如果你是为了升职加薪，为了换工作，为了出名而写作。那么你的写作需要更加有套路一点，体现在两点：重点突出 &amp; 有闭环有递进。 重点突出 一眼扫过去知道你在讲什么 讲结论的：结论先行 讲交互的：效果先放 罗列知识的：需要清晰的目录 有闭环有递进 完整的故事化表达 背景，思考，尝试，困难，解决与结果 困难分1, 2, 3，解决后又出现了什么新问题 日常写作👨‍💻如果是为了学习与自我成长，个人展现。那么遵从自己的内心最重要，少一点套路，多一点真诚。因为真心想分享的心比什么乱七八糟的技巧都管用。 🚀记住：写文章不要指望着让所有人都满意，让所有人都满意的文章一定是中庸的文章，即枯燥与乏味。否则最后的文章一定是平平无奇，无法脱颖而出！ 看看张鑫旭大佬的文章结构（各式各样，随心而记） 4. 关于语言表达换位思考🤔先抛出一个问题：技术文章的语言表达，什么最重要？ 简洁的语句？❌ 华丽的辞藻？❌ 搞笑的段子？❌ 都不是！最重要的是换位思考的能力。 如果我是小白，这些术语懂吗？ 如果我是读者，好理解吗？ 是不是有个耳熟能详的东西类比下？ 是不是代码要简化下，加注释？ 是不是这里应该放个图？ 是不是这里应该加个演示？ 观点：除了是工作汇报、团队账号这样的严肃场景，否则一定是融入了个人感情的文章更有价值！ 展现真实的自己例如：我遇到了什么样的问题？我是怎么思考的？我又是怎么解决的？ 又例如：我觉得这个技术如何？我不太喜欢某某设计？我的建议是什么？ 你是什么样的人，就用什么样的风格 拒绝模板，展现出真实的自我！ 我话痨，喜欢扯东扯西，你就这么干，想到什么说什么！ 我御宅族，文章可以体现各种宅元素。 我喜欢晒自己，那文章配图就多多展示。 我是穷酸小透明，文章就不必强颜欢笑，透露出忧郁挺好！ 😶真实的自我更容易让人产生共鸣！并且保持一致的风格和特色有诸多好处： 糟糕的风格好过于毫无风格 让别人记住你，提高影响力 防盗版的手段之一 5. 关于文章质量🔮10 篇水文不如 1 篇高质量好文！ 配图和演示正所谓 “一例胜千图，一图胜千言” 对每一句话负责出现了不确信的结论，一定要自己验证一遍 例如：在桌面端 document.scrollingElement 就是 document.documentElement；在移动端 document.scrollingElement 就是 document.body。 🥴对还是不是？Android 和 iOS 都是吗？ 追求内心而不是热门文章质量和访问量并不正相关 例如：”面试技巧，N个特性汇总”这样的文章容易获得高赞，但它不一定能带给你影响力。 总结01 关于文章选题：与学习相关、不同切入点、感悟与困惑 02 关于内容结构：重点突出、闭环与递进、遵照内心 03 关于语言表达：换位思考、展示自我、保持风格 04 关于文章质量：配图与实例、对结论负责、追寻内心 💖大部分文字源于直播内容，直播回放地址已在文章开头贴出。","categories":["未来世界的幸存者"]},{"title":"你可以不使用排序库函数来解决这道题吗？","path":"/post/数据结构与算法/tackle-without-sort-library/","content":"你可以不使用代码库中的排序函数来解决这道题吗？🙄不是突发奇想，而是最近刷 LeetCode 曾被灵魂拷问过：“你可以不适用代码库中的排序函数来解决这道题吗？” 转念想想，好像让我随手写个快排都有点棘手，时间偷走了我的记忆，那就用文字记录下叭。 话不多说，本文归纳下各类经典的排序算法。 排序算法🎪👑因为代码中添加了一些有助于理解的注释，且很多算法都很常见，其排序思想就不再赘述了。 直接插入排序12345678910111213public static void insertSort(int[] data) &#123; int length = data.length; for (int i = 1; i &lt; length; i++) &#123; int temp = data[i]; if (data[i] - data[i - 1] &lt; 0) &#123; int j = i - 1; for (; j &gt;= 0 &amp;&amp; data[j] - temp &gt; 0; j--) &#123; data[j + 1] = data[j]; &#125; data[j + 1] = temp; &#125; &#125;&#125; 希尔排序1234567891011121314151617181920public static void ShellSort(int[] data) &#123; int arrayLength = data.length; int h = 1; while (h &lt;= arrayLength / 3) &#123; h = h * 3 + 1; &#125; while (h &gt; 0) &#123; for (int i = h; i &lt; arrayLength; i++) &#123; int temp = data[i]; if (data[i] - data[i - h] &lt; 0) &#123; int j = i - h; for (; j &gt;= 0 &amp;&amp; data[j] - temp &gt; 0; j -= h) &#123; data[j + h] = data[j]; &#125; data[j + h] = temp; &#125; &#125; h = (h - 1) / 3; &#125;&#125; 简单选择排序123456789101112public static void selectSort(int[] data) &#123; int arrayLength = data.length; for (int i = 0; i &lt; arrayLength - 1; i++) &#123; for (int j = i + 1; j &lt; arrayLength; j++) &#123; if (data[i] - data[j] &gt; 0) &#123; int temp = data[i]; data[i] = data[j]; data[j] = temp; &#125; &#125; &#125;&#125; 堆排序1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * 堆排序 */public static void heapSort(int[] data) &#123; int arrayLength = data.length; // 循环建堆 for (int i = 0; i &lt; arrayLength - 1; i++) &#123; // 建堆 buildMaxdHeap(data, arrayLength - 1 - i); // 交换堆顶和最后一个元素 swap(data, 0, arrayLength - 1 - i); &#125;&#125;// 对data数组从0到lastIndex建大顶堆private static void buildMaxdHeap(int[] data, int lastIndex) &#123; // 从lastIndex处节点（最后一个节点）的父节点开始 for (int i = (lastIndex - 1) / 2; i &gt;= 0; i--) &#123; // k保存当前正在判断的节点 int k = i; // 如果当前k节点的子节点存在 while (k * 2 + 1 &lt;= lastIndex) &#123; // k节点的左子节点的索引 int biggerIndex = 2 * k + 1; // 如果biggerIndex小于lastIndex，即biggerIndex +1 // 代表k节点的右子节点存在 if (biggerIndex &lt; lastIndex) &#123; // 如果右子节点的值较大 if (data[biggerIndex] - data[biggerIndex + 1] &lt; 0) &#123; // biggerIndex总是记录较大子节点的索引 biggerIndex++; &#125; &#125; // 如果k节点的值小于其较大子节点的值 if (data[k] - data[biggerIndex] &lt; 0) &#123; // 交换它们 swap(data, k, biggerIndex); // 将biggerIndex赋给k，开始while循环的下一次循环 // 重新保证k节点的值大于其左、右节点的值 k = biggerIndex; &#125; else &#123; break; &#125; &#125; &#125;&#125;// 交换data数组中i、j两个索引处的元素private static void swap(int[] data, int i, int j) &#123; int temp = data[i]; data[i] = data[j]; data[j] = temp;&#125; 冒泡排序1234567891011public static void bubbleSort(int[] arr) &#123; for (int i = 0; i &lt; arr.length - 1; i++) &#123; for (int j = 0; j &lt; arr.length - 1 - i; j++) &#123; if (arr[j] &gt; arr[j + 1]) &#123; int temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125; &#125; &#125;&#125; 归并排序123456789101112131415161718192021222324252627282930313233343536373839404142/** * 归并排序 */public static void mergeSort(int[] data) &#123; sort(data, 0, data.length - 1);&#125;// 将索引从left到right范围的数组元素进行归并排序private static void sort(int[] data, int left, int right) &#123; if (left &lt; right) &#123; //找出中间索引 int center = (left + right) / 2; sort(data, left, center); sort(data, center + 1, right); //合并 merge(data, left, center, right); &#125;&#125;// 将两个数组进行归并，归并前两个数组已经有序，归并后依然有序private static void merge(int[] data, int left, int center, int right) &#123; int[] tempArr = new int[data.length]; int mid = center + 1; int third = left; int temp = left; while (left &lt;= center &amp;&amp; mid &lt;= right) &#123; if (data[left] - data[mid] &lt;= 0) &#123; tempArr[third++] = data[left++]; &#125; else &#123; tempArr[third++] = data[mid++]; &#125; &#125; while (mid &lt;= right) &#123; tempArr[third++] = data[mid++]; &#125; while (left &lt;= center) &#123; tempArr[third++] = data[left++]; &#125; while (temp &lt;= right) &#123; data[temp] = tempArr[temp++]; &#125;&#125; 基数排序1234567891011121314151617181920212223public static void radixSort(int[] data, int radix, int d) &#123; int arrayLength = data.length; int[] temp = new int[arrayLength]; int[] buckets = new int[radix]; for (int i = 0, rate = 1; i &lt; d; i++) &#123; // 重置count数组，开始统计第二个关键字 Arrays.fill(buckets, 0); // 当data数组的元素复制到temp数组中进行缓存 System.arraycopy(data, 0, temp, 0, arrayLength); for (int j = 0; j &lt; arrayLength; j++) &#123; int subKey = (temp[j] / rate) % radix; buckets[subKey]++; &#125; for (int j = 1; j &lt; radix; j++) &#123; buckets[j] = buckets[j] + buckets[j - 1]; &#125; for (int m = arrayLength - 1; m &gt;= 0; m--) &#123; int subKey = (temp[m] / rate) % radix; data[--buckets[subKey]] = temp[m]; &#125; rate *= radix; &#125;&#125; 桶排序123456789101112131415161718public static void BucketSort(int[] data, int min, int max) &#123; int arrayLength = data.length; int[] temp = new int[arrayLength]; int[] buckets = new int[max - min]; for (int i = 0; i &lt; arrayLength; i++) &#123; buckets[data[i] - min]++; &#125; for (int i = 1; i &lt; max - min; i++) &#123; buckets[i] = buckets[i] + buckets[i - 1]; &#125; System.arraycopy(data, 0, temp, 0, arrayLength); for (int k = arrayLength - 1; k &gt;= 0; k--) &#123; data[--buckets[temp[k] - min]] = temp[k]; &#125;&#125; 快速排序1234567891011121314151617181920212223242526272829303132333435/** * 快速排序 */public static void quickSort(int[] data) &#123; subSort(data, 0, data.length - 1);&#125;private static void subSort(int[] data, int start, int end) &#123; if (start &lt; end) &#123; int base = data[start]; int low = start; int high = end + 1; while (true) &#123; while (low &lt; end &amp;&amp; data[++low] - base &lt;= 0) ; while (high &gt; start &amp;&amp; data[--high] - base &gt;= 0) ; if (low &lt; high) &#123; swap(data, low, high); &#125; else &#123; break; &#125; &#125; swap(data, start, high); subSort(data, start, high - 1); subSort(data, high + 1, end); &#125;&#125;private static void swap(int[] data, int i, int j) &#123; int temp = data[i]; data[i] = data[j]; data[j] = temp;&#125; 复杂度一览表🍦 图片源于菜鸟教程 😁对于算法的详细分析请参考：十大排序算法 何时调用库函数🔮不仅是本题的排序算法，LeetCode 中有许多可以调用库函数的地方，那么究竟何时该调用何时别调用呢？ 举个栗子：151.翻转字符串里的单词，这题本身是综合考察对字符串的处理能力，如果直接调用 split 和 reverse 库函数，那么这道题就失去了它存在的意义。 🚫所以如果题目关键代码可以直接调用库函数解决，建议不要使用库函数，毕竟面试官不是考察你对库函数的熟悉程度。 🔍如果库函数仅是解题过程中的一小部分，并且你已经很清楚这个库函数内部的实现原理的话，可以考虑调用库函数，节省时间。 本着提高代码水平的原则，我想你就会很清楚什么时候该调什么时候不该调了，只有才会有助于对算法的理解。 🌈注意：并非所有语言都像 Python 和 Java 有着丰富的库函数，C、C++ 等语言偏底层，这类所谓的库函数也许得自己手写。","tags":["LeetCode","算法"],"categories":["数据结构与算法"]},{"title":"2021 年终总结｜唯有热爱，可抵漫长岁月","path":"/post/年终总结/「2021」passion/","content":"自我介绍🙋‍♂️ Yikun Wu 🏫 IP：福建 😆 兴趣爱好 编程 阅读 写作 健身 听歌 吉他 乒乓球 游泳 中国&#x2F;国际象棋 魔方 遇见掘金的元年回顾写作历程2021 年 01 月 27 日，我正式加入掘金社区，直到现在，掘金仍是我写博客理想且唯一的社区。 2021 年 03 月 05 日，怀着忐忑的心情在掘金发表了第一篇文章，我永远也不会忘记那篇 Lambda 文章前前后后修改了一天。最初，总是害怕自己写的文章过于逊色，迟迟不肯动笔，转念一想，先开始再说，不能总在计划而提不上日程，提升自己，不必在意别人的目光。 2021 年 08 月 31 日，终于写下了心心念念的「LeetCode」相关文章，刷算法题的时间被我搁置太久了。 2021 年 09 月 09 日，创建了一个「深度思考」专栏，它为规划自己人生与理解生活提供了莫大的帮助。让这一年迷茫的我，短暂摆脱对未来的恐惧。 2021 年 10 月 20 日，第一次完成掘金活动：“程序员必懂小知识”创作挑战，专治写作困难症！ 2021 年 11 月 29 日，积极参与并达成11月活动打卡任务：2021最后一次更文挑战！ 🏆 流量不是写作的第一目标，却又是激励写作的一大乐趣。 🌹 我永远不会忘记第一次收到点赞|收藏|关注的喜悦，这是对自己写文的一种肯定。 💦 这一年在掘金的故事还未结束，2022 年在掘金的旅途也即将开始… 2021 掘金战利品 掘金徽章 2 枚（立志 2022 年集齐所有徽章） 掘金 Yoyo 抱枕 2 个（1 个是奖品，1 个是全部身家 8W 矿石兑换的） 蓝牙音箱 1 个（参与 “程序员必懂小知识” 获得） 掘金定制拖鞋 1 双 掘金贴纸（收藏） 掘金棒球帽（喜欢） 双肩袋黑-活动限定（4W 矿石兑换） 还有 11 月更文挑战 奖品 午睡毯（Like） 咖啡机（没咖啡豆就是了） 字节保温杯（极其喜欢） 随波逐流的一年大学生活与工作🤪不知不觉已是大三学子，大三这一年很荣幸能担任班长，即使辛苦，但能为集体发光发热的感觉真的挺不错，这也算是我人生道路上的一次小突破吧。 回顾即将结束的这学期，文件堆积成山，都是一点一滴堆积起来的，它们见证了我这半年工作，纪念一下。 当然，大学生活可不仅限于工作，生活也是大学的一大主旋律。可说起自己这一年的生活，却是不尽人意，上半年的我踌躇满志，下半年的我混吃等死放纵不羁。唯一让自己比较满意的是，爱干净的习惯没有丢失，同时做事多少还葆有条理性。哎！回想起大一意气风发、雄心壮志的自己，再看看现在镜中一蹶不振的样子，羞耻之心油然而生。当然，人的眼光还是要向前看的，汲取教训就是对过往最好的答复。 同时，今年（年初）首次尝试烫发，为什么烫发呢，不自信吗？可能多少有点吧，但更多的还是体验，人生有很多抉择，若只是推陈守旧，不敢尝试新事物，那么人生也太无趣了。 对于这次大胆的尝试，也有些许感受：Tony，烫得不错，下次不许烫了😅 今年 8 月份购入的 iPad 让我这个本就不富裕的家庭雪上加霜。但不得不说，iPad 手感不错，哈哈哈。今年没能让 iPad 的生产力最大化，明年是得挖掘下它本该有的价值了。 年末时【英语六级前一天 | 也是被接收为预备党员的前一天】遭遇一次小型车祸，给大家瞅瞅我去医院拍 X 光片 那些值得纪念的时刻💦 学习🌅🔥 GitHub 🔥 Gitee 🔥 书单 《操作系统导论》 《算法》 《计算机组成原理》 《现代操作系统》：基础知识又过了一遍，高深的知识还触碰不到 《$数据结构与算法分析_{Java语言描述}$》 《$计算机网络_{自顶向下方法}$》：每天早上 5:30 起床就为了读这本书，坚持了一个月；还剩下一些目前对我来说比较困难的知识，无伤大雅 《大话数据结构》：前后看了两遍，但遗忘速度也是够快 《鸟哥的 Linux 私房菜》：面向运维的书籍，用于查阅与学习指令足够了 《图解 TCP&#x2F;IP》：可作为参考手册 《图解 HTTP》：通俗易懂，绝了 《编码》：这本在学计算机组成原理一课给了我莫大的启事，书籍后半部分尚未有时间去咀嚼 《高性能 MySQL》：原以为这学期的高级数据库是讲 MySQL 呢，原来是 NoSQL 哇 《MySQL 必知必会》 《$JavaScript高级程序设计_{第三版}$》：确实不错 《数学建模》：虽然我很热爱数学，但抵不过时间受限 《批判性思维》：术语过于专业 《人性的弱点》：我最爱的书籍，它教会了我很多为人处世的道理 《圆圈正义》：罗翔老师受到那么多人追捧是不无道理的 《小懒财富自由之路 · 从基金开始》：有关基金的基本知识在这里都能以最通俗易懂的方式呈现 《小狗钱钱》：不错的理财入门书籍 《指数基金投资指南》：阅读该书的理由这还得从股神巴菲特的 20 年赌约说起 《穷爸爸·富爸爸》：典中典 《人性的优点》 $…$ 健身💪遥想 2019 那年开始健身，连续做 235 个俯卧撑，现在属于是廉颇老矣。 今年 11 月于我而言，是人生中的低谷。不仅健身，连生活与学习都处于一个恍惚的状态 凡是过往，皆为序章 感情🚫感情方面一直很稳定，确实，单身能不稳定吗 🥱 不一样的圣诞节🎄圣诞节这天班级里组织了志愿活动，前往养老院照顾老人们，意义非凡的一天 网易云年度歌单报告🎶 未来可期至今为止，我所写的大部分文章都是一些笔记类文章，无法深入某个知识点进行钻研与学习，这也是我写博客的一大痛点。 2022 年我会将写作的风格聚焦于具体的知识点，而非笔记博客类泛泛而谈，缺乏深度，聚焦后端。 大学是最佳的试错阶段，不要害怕；过分自信起码还有敢于尝试的勇气，而怯懦则会让一切的机会消失殆尽，自信点！别让他人口中的 “太难了、你不行” 成为自己的阻碍，生活是自己的，走出舒适圈，收获新天地。怎么知道自己的人生是在走上坡路还是下坡路呢，感觉累就是上坡，感觉轻松就是下坡。你现在感觉累吗？共勉～","categories":["年终总结"]},{"title":"内网穿透","path":"/post/开发工具/nat/","content":"内网穿透概念内网穿透，又称 NAT 穿透，进行 NAT 穿透是为了使数据包不被 NAT 设备屏蔽而正确路由到内网主机。 ⭐简单来说，内网穿透就是将私有（保留）地址转化为合法 IP 地址的转换技术。 巧妙地利用 NAT 原理实现 NAT 内网穿透技术，就可以使内网服务器接收到外网数据包。 内网穿透工具 在外网演示内网 Web 站点 常见的内网穿透工具数不胜数，这里枚举几个： NATAPP: 基于 ngrok 的国内收费内网穿透工具。 Frp: frp 是一个专注于内网穿透的高性能的反向代理应用，支持 TCP、UDP、HTTP、HTTPS 等多种协议。可以将内网服务以安全、便捷的方式通过具有公网 IP 节点的中转暴露到公网。 ngrok: 通过一条命令，即可通过任何 NAT 或者防火墙到达 LocalHost 服务器。 花生壳：内网穿透、远程访问、动态域名解析 Sunny-Ngrok: 提供免费内网穿透服务，免费服务器支持绑定自定义域名，管理内网服务器，内网 web 进行演示，快速开发微信程序和第三方支付平台调试，本地WEB外网访问、本地开发微信、TCP端口转发。 Sunny-Ngrok 演示首先需要开通隧道（官方教程，不再赘述）：Sunny-Ngrok 开通隧道 然后修改隧道要映射的本地端口号（即要让本地哪个服务穿透到公网）： ⭐记住该隧道对应的 id，待会启动 sunny-ngrok 需要用到： 下载 sunny-ngrok 客户端，有如下两种方式启动 Sunny-Ngrok 客户端： 方式一：sunny.exe 方式二：Sunny-Ngrok 启动工具.bat Invalid Host Header当使用 vue-cli 搭建 web 服务并进行内网穿透时，可能会出现 Invalid Host Header 问题： 这是因为新版的 webpack-dev-server 出于安全考虑，默认检查 hostname，如果 hostname 不是配置内的就不能访问，这里我们直接设置 vue.config.js 跳过 host 检查： 123456// 跳过 Host 检查: vue.config.js 文件若无则创建module.exports = &#123; devServer: &#123; disableHostCheck: true &#125;&#125;","tags":["内网穿透","NAT"],"categories":["开发工具"]},{"title":"什么是「正向代理」与「反向代理」？","path":"/post/计算机网络/reverse-proxy/","content":"代理服务器代理服务器 (proxy server) 又称 Web 缓存器 (Web cache)，它是能够代表初始 Web 服务器来满足 HTTP 请求的网络实体。代理服务器有自己的磁盘存储空间，并在存储空间中保存最近请求过的对象的副本。 为什么使用代理服务器？提高访问速度！由于目标主机返回的数据会存放到代理服务器的磁盘中，因此下一次客户再访问相同站点时，所获取到的数据直接从代理服务器磁盘读取，起到了缓存的作用，对于热门网站能明显提高访问速度。 作为防火墙！由于所有的客户机请求都必须通过代理服务器访问远程站点，因此可以在代理服务器上设限，过滤掉某些不安全信息。同时正向代理的冲浪者可以隐藏自己的 IP，免受攻击。 突破访问限制！ 懂的都懂🤪 互联网上有许多开发的代理服务器，客户机在访问受限时，可通过不受限的代理服务器访问目标站点。通俗点说，我们使用翻墙浏览器就是利用了代理服务器，可以直接访问外网。 正向代理正向代理一个位于客户端和原始服务器之间的服务器。为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标（原始服务器），然后代理向原始服务器转发请求并将获得的内容返回给客户端，同时缓存一份数据在本地（也就是代理服务器磁盘上），这样以后客户端才能使用正向代理。😁我们平时所说的代理就是指正向代理。 🤔有点抽象？没事，换个说法：A 向 C 借钱，由于一些缘由不能直接向 C 借钱，于是 A 让 B 以他自己 (B) 的名义去找 C 借钱，这样 A 也不仅得到了钱💴，还让 C 以为是 B 借的，并不知道 A 的存在，B 就充当了 A 的代理人。 反向代理反向代理则是以代理服务器来接收 internet 上的连接请求，然后将请求转发到内网上的服务器，并将其从服务器上得到的结果返回给 internet 上请求的客户端，此时代理服务器对外表现为一个反向代理服务器。 🤨还是有点抽象？那就再举个例子：A 向 B 借钱，B 没有拿自己的钱，而暗地里将这件事告诉给 C，借 C 的钱交给 A，然后 A 以为是 B 的钱💴，并没意识到 C 的存在，B 就是所谓的反向代理人。 「差异」正向代理 vs 反向代理架设位置不同正向代理：架设在客户端和目标主机之间。 反向代理：架设在服务器端。 代理对象不同🎯正向代理：代理客户端，服务器端不知道实际发起请求的客户端。 正向代理 — HTTP 代理为多个人提供翻墙服务。 🎯反向代理：代理服务端，客户端不知道实际提供服务的服务端。 反向代理 — 多个商家以美团外卖平台的名义向某个用户提供外卖服务。 用途不同正向代理：为防火墙内的局域网客户提供访问 Internet 的途径。 反向代理：将防火墙后面的服务器提供给 Internet 访问。 安全性不同正向代理：允许客户端通过它访问任意网站并且隐藏客户端自身，因此必须采取安全措施以确保仅为授权的客户端提供服务。 反向代理：对外透明，访问者并不知晓自己访问的是哪一个服务器。 正向代理的应用 访问原来无法访问的资源 用作缓存，加速访问速度 对客户端访问授权，上网进行认证 代理可以记录用户访问记录，并对外隐藏用户信息 反向代理的应用 保护内网安全 负载均衡 缓存，减少服务器的压力 nginx 作为最近较火的反向代理服务器，安装在目的主机端，主要用于转发客户机请求，后台有多个 Http 服务器提供服务，nginx 的作用就是把请求转发给后台的服务器集群，决定哪一台来处理当前请求。","tags":["网络","正向代理","反向代理"],"categories":["计算机网络"]},{"title":"搭建个人博客｜从服务器到域名","path":"/post/博客开发/building-a-personal-blog-from-scratch/","content":"🏆如果对搭建个人博客仍存在细节上的问题可参考该视频：如何用服务器优雅地搭建一个博客—Hello,Halo! 1. 购买云服务器1.1 前言买云服务器之前，千万不要只看价格，千万不要看哪个便宜，哪个优惠多，你就买哪个，你得结合你自己的需求。 如果你云买服务器的目的，只是为了学习 Linux，或者搭个博客网站，自己玩玩，不要求访问量，那你买个最低配的服务器完全够用了。 假如你买云服务器的目的，是为了开发网站赚钱，希望访问量越大越好，那还是建议你买配置稍高的云服务器。 因为假如你贪便宜，买了一台不能满足你需求的服务器，等到你想扩容的时候，会发现扩容的成本，远比你重新注册个新会员，享受优惠活动，再买一台高配的云服务器的成本，高得多得多。但如果你买了新的服务器，你之前买的低配的服务器，不就浪费了？ 所以，买之前，首先一定要搞清楚自己买服务器的用途！ 1.2 国外云服务器 vs 国内云服务器🎯国外服务器优势： 免备案 无监管 自由度高 性价比高 🎯国内服务器优势： 比较复合国人的使用习惯 稳定性更好 客服及工单系统响应迅速 优惠活动也不少 提供域名及备案服务（其实国内也有免备案服务器） 1.3 个人推荐国内有例如阿里云、腾讯云和华为云等，这里推荐阿里云服务器（我个人也在用）： ☁感兴趣的可以看一下这几者之间的测评对比：阿里云、腾讯云、百度云、华为云评测对比 但是我墙裂推荐 UCloud，如下我搭建个人网站所用的服务器就是 UCloud 上购买的： 1.4 云服务器购买步骤（优惠）阿里云服务器 和 UCloud 的云主机 UHost 我都有购买，这里详解下 UCloud 云服务器的购买过程！ 1.4.1 找到活动专区的 11.11 狂欢 1.4.2 选择 香港 地区的云服务器个人觉得 1核2G 配置的云服务器对于我而言完全足够了，毕竟只是搭建个人博客网站。 ⭐推荐中国香港地区的云服务器，免备案真的省去挺多时间的。 1.4.3 确认下购买的配置🔥镜像：CentOS 7.2 64位 🔥带宽：1M 之前选了 CentOS 8.3 64位 然后后面出现了 Docker 配置失败的问题，所以这里建议跟着我的配置走！ 对了，这里演示的是 1 年的云服务器价格，因为我 1 个月的买过了，已达购买数量上限。 若刚刚配置错镜像版本的可以参照如下操作方式进行恢复： 记住！系统盘大小调成 40 G，不然 UCloud 会让你补差价： 1.4.4 成了✔ 2. 购买域名上 NameSilo 购买域名即可： 2.1 搜索域名在搜索栏里检索你所要购买的域名，可能被人购买走了： 2.2 选择域名这里 wu-yikun.top 这个域名被我买走了，所以检索的时候会显示 Try To Buy，表示向这个域名持有者购买该域名！ 注意这里的单位是美元**$**，域名真的是一撮人的财富密码，甚至是小国的财富。 2.3 购买域名Add 后直接 Checkout，然后再 Checkout，别购买增值服务.. 付款后即可拥有该域名啦！ 2.4 配置域名映射，等待域名解析购买域名后并不代表着会自动映射到你所购买的云服务器主机 IP 上，还需要进行域名映射配置（即：域名解析）！ 选择 domain manager 域名管理： 管理这个域的 DNS（Manage DNS for this domain）： 然后如下图配置域名映射，配置成功后等待域名解析即可。 一般服务商都是给予 24 小时之内生效的承诺，但往往都是一两个小时内就可以生效。 该网站购买的域名解析起来大致要 30 分钟，算是比较快的了。 如果公司有内部 DNS 服务器的话，可能要等其缓存的更新，可能需要 48 小时。 一般通用顶级域名解析是 2 小时内生效，国家顶级域名解析 24 小时内生效。因为域名解析需要同步到 DNS 根服务器，而 DNS 根服务器会不定时刷新，只有 DNS 根服务器刷新后域名才能正常访问。 新增解析一般会在 10 分钟左右生效，最长不会超过 24 小时，修改解析时间会稍微延长。 🌹 域名解析生效的过程，就是域名与 IP 绑定的过程！ 🌹补充下该知识点 (资源记录)： 图片来源：《计算机网络—自顶向下方法》 2.5 域名解析生效ping 自己购买的域名地址，若出现下列结果即可说明域名解析成功！ 🌹 注：请求超时并不影响！只要出现域名后跟随 IP 地址即可！ 如下：正在 Ping www.wu-yikun.top [xx.xx.xx.xx] 具有 32 字节的数据 12345C:\\Users\\57715&gt;ping www.wu-yikun.top正在 Ping www.wu-yikun.top [xx.xx.xx.xx] 具有 32 字节的数据:请求超时。... 到这里域名相关配置的操作就结束啦！ 3. 宝塔 Linux 面板配置宝塔面板能做什么： 一键配置服务器环境（LAMP&#x2F;LNMP） LNMP: Linux + Nginx + MySQL + PHP LAMP: Linux + Apache + MySQL + PHP 一键安全重启 一键创建管理网站、ftp、数据库 一键部署 SSL 证书 一键部署源码（discuz、wordpress、dedecms、z-blog、微擎等等） 一键配置（定期备份、数据导入、伪静态、301、SSL、子目录、反向代理、切换 PHP 版本） 一键安装常用 PHP 扩展（fileinfo、intl、opcache、imap、memcache、apc、redis、ioncube、imagick） 数据库一键导入导出 系统监控（CPU、内存、磁盘 IO、网络 IO） 防火墙端口放行 SSH 开启与关闭及 SSH 端口更改 禁 PING 开启或关闭 方便高效的文件管理器（上传、下载、压缩、解压、查看、编辑等等） 计划任务（定期备份、日志切割、shell 脚本） 软件管理（一键安装、卸载、版本切换） 简单来说 ❗ ❗ ❗ 大型网站程序都安装在服务器上，服务器用的是 Linux 系统，进行服务器维护需要记住很多 Linux 的命令，这就很麻烦。面板的好处，就是通过一个交互界面就能完成服务器的维护工作，比如：更新系统，添加网站，修改设置等等。以前需要记住各种命令，现在通过面板点点按钮就可以了，省时省力。 3.1 Xshell 远程连接服务器首先登录 Xshell 远程连接刚刚购买的 UCloud 云服务器： 然后执行如下命令在云服务器上 (CentOS) 安装宝塔 Linux 面板： 💖其他 Linux 发行版的安装指令详见：宝塔 Linux 面板安装教程（官网教程） 1yum install -y wget &amp;&amp; wget -O install.sh http://download.bt.cn/install/install_6.0.sh &amp;&amp; sh install.sh 安装完之后会跳出宝塔面板的默认信息，然后访问外网面板地址即可跳转到 BT-Panel，输入刚刚提供的 username 和 password 即可登录。 ⭐若以后忘记 BT 宝塔面板的用户名、密码和入口等基本信息，则执行如下命令即可搞定： 12345678910111213[root@xxx ~]# /etc/init.d/bt default==================================================================BT-Panel default info!==================================================================外网面板地址: http://xxx/xxx内网面板地址: http://xxx/xxx*以下仅为初始默认账户密码，若无法登录请执行bt命令重置账户/密码登录username: xxxpassword: xxxIf you cannot access the panel,release the following panel port [8888] in the security group若无法访问面板，请检查防火墙/安全组是否有放行面板[8888]端口================================================================== 3.2 通过 BT 面板添加站点刚登陆宝塔面板时安装套件：选择 LNMP(推荐)，并勾选极速安装： 如下：宝塔面板主界面 接下来添加站点： 3.3 添加 SSL 证书 🍻注意：添加 SSL 证书的前提就是域名解析生效！所以在此之前请耐心等待吧。 添加成功后，点击开启强制HTTPS。 ⭐强制 HTTPS 之后访问 wu-yikun.top 的地址都会被默认转换为 https://wu-yikun.top！⭐当然也可以直接访问 https://wu-yikun.top！但是直接访问 http://wu-yikun.top 会无法访问！ 若不开启也可，不过访问 http://wu-yikun.top 会显示不安全！ 3.4 配置反向代理记得注释其余 location 的相关配置： ⭐⭐⭐反向代理配置将网站的默认访问端口 80 交由 8090 端口代理，所以之后访问 wu-yikun.top 地址就会被默认映射到 https://wu-yikun.top:8090 而不是 https://wu-yikun.top:80！ 1234567891011location / &#123; proxy_pass http://127.0.0.1:8090/; rewrite ^/(.*)$ /$1 break; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Upgrade-Insecure-Requests 1; proxy_set_header X-Forwarded-Proto https;&#125; 3.5 开启防火墙：放行指定端口安全组放行教程，如需完整使用宝塔的所有功能，还需要放行如下端口 443 端口：HTTPS 888 端口：phpMyAdmin 默认端口 ⭐39000-40000 端口：Linux 系统 20 端口：FTP 主动模式数据端口 22 端口：SSH 远程服务 21 端口：FTP 协议默认端口 ⭐8888 端口：宝塔 Linux 面板默认端口 80 端口：网站默认端口 ⭐8090 端口：反向代理指定的网站端口 💖此处解释下为什么要放行 8090 端口： 🧠除了 8090 端口，其余都是原本就一定要放行的一些端口，而放行 8090 端口仅仅是因为我们设置的反向代理用 8090 端口代理了 80 端口（默认网站端口），所以访问我域名 wu-yikun.top 会自动导向 wu-yikun.top:8090（但 URL 不会显示 8090 端口），所以需要放行该端口！ 4. 在 CentOS 上安装 Docker Engine ⭐官网教程：Install Docker Engine on CentOS⭐英文官网，若看不懂的小伙伴还是建议按顺序执行如下命令吧。 4.1 卸载 Docker 的旧版本（选）若严格按照本文的顺序进行搭建或从未下载过 Docker 的话则无需执行如下卸载命令，否则还是执行一下为好。 12345678sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 4.2 安装 yum-utils 包🍺依次执行如下两条命令： 12345sudo yum install -y yum-utilssudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 4.3 安装 Docker 引擎1sudo yum install docker-ce docker-ce-cli containerd.io 安装 Docker 就是为下文安装 Halo 做准备！ 5. 使用 Docker 部署 Halo 官网教程：Halo Documents ⭐在 Xshell 上依次执行如下命令： 5.1 创建工作目录1mkdir ~/.halo &amp;&amp; cd ~/.halo 5.2 下载示例配置文件到工作目录1wget https://dl.halo.run/config/application-template.yaml -O ./application.yaml 5.3 拉取最新的 Halo 镜像1docker pull halohub/halo:1.4.15 5.4 创建容器1docker run -it -d --name halo -p 8090:8090 -v ~/.halo:/root/.halo --restart=unless-stopped halohub/halo:1.4.15 -it： 开启输入功能并连接伪终端 -d： 后台运行容器 –name： 为容器指定一个名称 -p： 端口映射，格式为 主机(宿主)端口:容器端口 ，可在 application.yaml 配置。 -v： 工作目录映射。形式为：-v 宿主机路径:&#x2F;root&#x2F;.halo，后者不能修改。 –restart： 建议设置为 unless-stopped，在 Docker 启动的时候自动启动 Halo 容器。 5.5 访问个人网站（见证奇迹的时刻）🏆打开 https://ip:端口号 即可看到安装引导界面；我这里访问 https://wu-yikun.top 即可！ 💡Tip：如果需要配置域名访问，建议先配置好反向代理以及域名解析再进行初始化。如果通过 http://ip:端口号 的形式无法访问，请到服务器厂商后台将运行的端口号添加到安全组，如果服务器使用了 Linux 面板，请检查此 Linux 面板是否有还有安全组配置，需要同样将端口号添加到安全组（即放行端口）。 🌹 前台地址：https://wu-yikun.top 🌹后台地址：https://wu-yikun.top/admin ⭐有关 Halo 的更多主题：https://halo.run/themes.html","tags":["服务器","域名","Halo","UCloud","GitHub"],"categories":["博客开发"]},{"title":"不要以你现在的能力，束缚对未来的想象","path":"/post/未来世界的幸存者/don't-limit-your-future-imagination-with-your-current-abilities/","content":"分享一篇稻盛和夫的演讲。正如他所说：“实现目标犹如登山，而能力的提升是一个动态的过程，永远不要让现在的思维限制对未来的思考。”在成功之前，稻盛和夫也曾无数次怀疑自己，但他最终登上了自己人生的顶峰。 01 每天比昨天进步一点，哪怕只一厘米在我工作的第一家公司，我反复进行着各种实验，有失败也有成功。当时在无机化学的研究者中，同我年龄相仿的，有人拿到了奖学金赴美留学；有人在优秀的大企业里，使用最尖端的设备进行最先进的实验；而我在一个如此破旧、衰败的企业里，连最起码的设备都没有，日复一日地做着混合原料粉末这样简单的工作。 「一直从事如此单调的工作，究竟能搞出什么科研成果来？」我问自己。再进一步地：「自己的人生将会怎样呢？」想到这些，我不禁心灰意冷，一度过得很消极。 解除这样的迷惑，一般人的方法是和自己说：要预见到将来。就是说，不要将目光仅仅放在当下，而要从长远角度规划自己的人生蓝图；要把眼前的工作看作这长期规划中的一段过程。 这也许是合乎逻辑的方法。然而，我采用的方法与此相反——我采用短期的观点来摆正自己对工作的态度。 🏆「将来会搞出什么样的研究成果」、「自己的人生将会怎样」，我不再痴迷于这些不着边际的远景，而只是留神眼下的事情。就是说，我发誓，今天的目标今天一定要完成。工作的成绩和进度以今天一天为单位区分，然后切实完成。在今天这一天中，最低限度是必须向前跨进一步，今天比昨天，哪怕只是一厘米，也要向前推进。 我就是这样思考问题的。 同时，不单单是前进一步，而且要反省今天的工作，以便明天「要做一点改良」「要找一点窍门」。在前进一步时，一定同时是在改善、改进。 奔着每一天的目标去，让每一天都有所创新，就会天天前进，天天获得积累。为达到目标，不管外面刮风也好、下雨也好，不管碰到多大的困难，我都全神贯注，全力以赴。先是坚持 1 个月，再坚持 1 年，然后是 5 年、 10 年，锲而不舍。这样做下去，你就能踏入当初根本无法想象的境地。 将今天一天作为「生活的单位」，天天精神抖擞，日复一日，拼命工作，用这种踏实的步伐，就能走上人生的王道。 02 取胜之道：全力过好「今天」这一天每天，持续过好内容充实的「今天」这一天，我在经营公司的时候就一直坚持这一点。 公司创建至今，我们从来不建立长期的经营计划。新闻记者们采访我的时候，经常提出想听一听我们的中长期经营计划。当我回答 「我们从不设立长期的经营计划」 时，他们总觉得不可思议，露出疑惑的神情。 那么，我们为什么不建立长期计划呢？因为说自己能够预见到久远的将来，这种话基本上都会以「谎言」的结局而告终。 「多少年后销售额要达到多少，人员增加到多少，设备投资如何如何……」这一类蓝图，不管你怎样着力地描绘，但事实上，超出预想的环境变化、意料之外事态的发生都不可避免地会出现。这时就不得不改变计划，或将计划数字向下调整。有时甚至要无奈地放弃整个计划。 这样的计划变更如果频繁发生，不管你建立什么计划，员工们都会认为，「反正计划中途就得变更」，他们就会轻视计划，不把它当回事。结果就会降低员工的士气和工作热情。 同时，目标越是远大，为达此目的，就越需要持续付出不寻常的努力。但是，人们努力，再努力，如果仍然离终点很远很远，他们就难免泄气。「目标虽然没达成，能这样也就可以了，差不多就算了吧！」人们常常在中途泄气了。 从心理学的角度看，如果达到目标的过程太长，也就是说，设置的目标过于远大，往往在中途就会遭遇挫折。 与其中途就要作废，不如一开始就不要建立。这是我的观点。自京瓷创业以来，我只用心于建立一年的年度经营计划。3 年、5 年之后的事情，谁也无法准确预测，但是这一年的情况，应该大致能看清，不至于太离谱。 做年度计划，就要细化成每个月甚至每一天的具体目标，然后千方百计努力达成。 今天一天努力干吧，以今天一天的勤奋就一定能看清明天。这个月努力干吧，以这一个月的勤奋就一定能看清下个月。今年一年努力干吧，以今年一年的勤奋就一定能看清明年。 就这样，一瞬间、一瞬间都会过得非常充实，就像跨过一座一座小山。小小的成就连绵不断地积累、无限地持续，这样，乍看宏大高远的目标就一定能实现。这个方法就是最确实的取胜之道。 03 别以你现在的能力，限制你对未来的想象在建立目标时，要设定「超过自己能力之上的指标」 💦 要设定现在自己「不能胜任」的有难度的目标，「我要在未来某个时点实现这个目标」，要下这样的决心。然后，想方设法提高自己的能力，以便在「未来这个时点」实现既定的目标。 如果只用自己现有的能力来判断决定「能做」还是「不能做」，那么，就不可能挑战新事业，或者实现更高的目标。「现在做不到的事，今后无论如何也要达成」。如果缺乏这种强烈的愿望，就无法开拓新领域，无法达成高目标。 我用 「能力要用将来进行时」 这句话来表达这一观点。这句话意味着「人具备无限的可能性」。也就是说：人的能力有无限伸展的可能。坚信这一点，面向未来，描绘自己人生的理想。 这就是我想表达的意思。 但是，很多人在自己的工作和生活中，很轻率地下结论说:「我不行，做不到」。😔这是因为他们仅以自己现有的能力判断自己「行」还是「不行」。 这就错了。因为人的能力，在未来，一定会提高，一定会进步。 事实上，大家今天在做的工作，几年前来看，你也会想：「我不会做，我做不好，无法胜任」。可是到了今天，你不是也觉得这个工作挺简单的？因为你已经驾轻就熟了。 人这种动物，在各个方面都会进步。「神」就是这么造人的——我们应该这么思考。 因为我没有学过，没有知识，没有技术，所以我不行。说这话可不行，应该这样思考：因为我没有学过，所以我没有知识，没有技术。但是，我有干劲、有信心，所以明年一定能行。而且就从这一瞬间开始，努力学习，获取知识，掌握技术。将来秘藏在我身上的能力一定能开花结果。我的能力一定能增长。 对人生抱着消极态度，认为自己的人生就将以碌碌无为而告终，这么思考的年轻人并不多。但是，一旦面临困难的问题时，几乎所有的人都会脱口而出说自己「不行」。 绝对不要说「自己不行」这种话。面对难题，首先要做的就是相信自己。 现在也许不行，但只要努力一定能行。首先相信自己，然后必须对“自己解决问题的能力怎样才能提高”进行具体深入的思考。只有这样，通向光明未来的大门才会打开。 &#x2F; End &#x2F; 共勉 🌹","categories":["未来世界的幸存者"]},{"title":"重启就是关机再开机？","path":"/post/计算机网络/does-restarting-mean-shutting-down-and-power-on/","content":"前两天在刷 pyq 的时候，看到了一朋友发的一张与客服的对话截图： 说实话，这种情况我也遇到过，还不止一次.. 真是 Amazing！虽然先前就有听说重启和关机后再开机不一样，但当电脑跳出“需要重启”的弹窗时，我依旧会选择“稍后重启”，然后在使用完电脑后关机，下次使用时开机，当作重启… 当时还天真地以为，这样既没有打断正在进行的工作，还完成了重启，可谓是做到了效率的最大化… 今天亲眼见证了两种方式所带来的不同结果，我决心好好探索一下： “重启”和“关机后再开机”到底有哪些不同？ 01-定性来看从最表层看，当我们点击“重启”后，计算机会自动进行注销用户、关闭系统、重新打开并装载系统等操作，主机似乎停了一下，但并没有完全关闭； 而选择关机再开机，不仅中途主机会完全关闭，我们还要手动按一下主机上的电源键才能再次将系统开启。 所以从操作手段上，关机再开机相比重启要多按一次按钮；从主机经历的过程上看，关机再开机相比重启经历得更多。emmm，似乎说了一段废话… 不过通过主机呈现出的不同状态，我们应该能感觉到两者肯定是有不同的。 在主机没有完全关闭的背后，究竟还藏着什么不为人知的秘密？ 02-定量来看想要深挖计算机重启背后的秘密，就要知道计算机在重启过程中都发生了什么。 首先我们来看看，操作系统是通过什么来区分重启和关机再开机的，这里就要引入一个概念——高级配置电源管理接口（Advanced Configuration and Power Interface），简称 ACPI。 ACPI 是1997年由多家公司共同提出、制定的操作系统电源管理、硬件配置接口，是一种开放标准。 ACPI 整体框架图 相信大家看到上图的感觉一定是非常头大，不过我们今天不是去深挖 ACPI 的，而是看 ACPI 是如何决定计算机的重启的。 ACPI 规范定义了一台兼容 ACPI 的计算机系统可以有以下七个状态（所谓的全局状态）： G0(S0)：正常工作状态。计算机的正常工作状态-操作系统和应用程序都在运行。 G1：睡眠。这个状态还可以再细分为以下几种： S0ix：Modern Standby。在这种睡眠状态下，计算机还能联网，音乐还可以播放，其余大部分应用处于暂停的状态，轻按任意键即可登录账户并进入工作状态。 S1：比较耗电的睡眠模式。CPU 的所有寄存器被刷新，并且停止执行指令，但 CPU 和内存的电源会被维持。 S2：一种比S1更深的睡眠状态，会停止CPU的电源供应，这种模式通常不被采用。 S3：称为 Suspend to RAM，简称 STR。这个模式就是我们计算机上常见的“睡眠” S4：称为Suspend to Disk，也是我们常说的“休眠”，其和 S3 的差别在于，S4 消耗的时间更长，而且如果此时系统断电，S3状态下没有保存的数据会丢失，而 S4 状态下不会影响。 G2(S5)：称为 Soft Off。此状态和下面所所述的 G3(S6) 类似，不过在这个状态下，系统仍可以被部分设备（如键盘等）唤醒。 G3(S6)：称为 Mechanical Off。此状态下所有部件断电，需要再次按下电源键才能唤醒。 虽然看起来我们一直没有提到重启，但从 ACPI 规范下计算机的几种状态，我们却可以看出其不同的运行模式和唤醒模式，这和我们马上要讲到的重启都是有关联的。 ⭐其实你可能想不到，重启也分很多个种类，而我们平时最常接触到的重启，叫 hard reset，其通过信号通知所有芯片、外围网卡等等一起进行 reset 操作，使系统大多数寄存器重置到缺省值（默认值），而后 CPU 从 reset vector 开始执行程序。 ⭐在这个过程中系统不会完全断电，不会进入 G3(S6) 的状态，CPU 在其它组件的协助下执行 reset 的相关程序。 ⭐而关机再开机的过程中，系统会完全切断电源，即进入 G3(S6) 的状态，让所有寄存器均恢复到初始状态，整个过程需要执行的程序会更多，速度上也会更慢一些。 03-重启和关机再开机该怎么选择？⭐我们选择重启计算机，可能是计算机进行了软件更新或者系统更新，亦或是系统的某个部件出了问题（就好比开头处那张截图里遇到的问题：微软和 Intel 芯片兼容问题） 一般情况下，如果是系统希望我们进行重启，那就按照要求进行重启就行。因为在软件或系统进行更新，计算机需要重新加载配置文件，这时候重启会显得更加得有针对性并且效率较高。 ⭐而当计算机的部分功能出现障碍时，由于重启无法保证所有寄存器都恢复到默认状态，所以就会导致重启也可能解决不了问题，所以这时候就需要通过关机的方式来尝试解决。 写到这里，不禁感叹计算机这个系统真的太过庞大，一个小小的操作背后都隐藏有如此丰富的知识点，真心佩服研究计算机这个领域的大佬们，向你们学习！","tags":["网络","计算机系统","ACPI"],"categories":["计算机网络"]},{"title":"学好算法，有三重境界","path":"/post/数据结构与算法/advanced-algorithms/","content":"王国维先生在《人间词话》中写道：“古今之成大事业、大学问者，必经过三种境界： ‘昨夜西风凋碧树。独上高楼，望尽天涯路。’ 此第一境也。‘衣带渐宽终不悔，为伊消得人憔悴。’ 此第二境也。‘众里寻他千百度，蓦然回首，那人却在，灯火阑珊处。‘ 此第三境也。” 算法的学习之道也是如此。 夯实根基在最初的阶段，算法世界的大门刚刚打开，这个时候迷茫是正常的，解决迷茫的要诀在于少想多做，勇往直前。怀着一颗 “千磨万击还坚韧，任尔东西南北风” 的恒心，爬上算法的高楼，做到 “望尽天涯路”。 从一个算法萌新入门，第一步便在于打牢根基。推荐阅读书籍： 《算法第 4 版》- Robert Sedgewick 《大话数据结构》- 程杰 《算法图解》- Aditya Bhargava 《算法导论》- Cormen,T.H. ⭐**《算法第 4 版》适合初学者入门。⭐《大话数据结构》和《算法图解》这两本书的特点是有趣、易理解，也非常适合初学者。⭐《算法导论》**的特点是全面，它是一本算法的百科全书，着重在于开阔算法视野，适合有一定算法基础后再去学习。 入门阶段是看一些天赋的，花费时间因人而异，大约在 3～6 月之间，将上述提到的书籍选择其中一本看完基本就能入门了。在这个阶段中，需要了解几类常用的算法： 其中，暴力枚举、贪心算法容易理解，可以很快上手。数论相关的算法需要用到一些数学技巧，包括位运算、幂函数、求模等等性质。二分算法和深度优先搜索算法相对有些技巧性，好在他们都有固定的模板。另外，不得不提的是，深度优先搜索算法的思想非常重要，而且深度优先搜索是动态规划、分治和回溯的基础，需要重点掌握。 🌹在此过程中，可以辅以力扣（LeetCode）中的简单题目，它们往往都代表了一类经典算法，如： 70. 爬楼梯 假设你正在爬楼梯。需要 n 阶你才能到达楼顶。每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？ 🏆动态规划 算法的经典题目，通过此题目可以了解状态、边界条件、状态转移方程等基本概念。 112. 路径总和 给定一个二叉树和一个目标和，判断该树中是否存在根节点到叶子节点的路径，这条路径上所有节点值相加等于目标和。 🏆深度优先算法 的入门题目，递归实现和迭代实现都不难，可以学习到深度优先算法的层层嵌套搜索、找到答案或到达边界停止的基本解题思路。 35. 搜索插入位置 给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。 🏆二分算法 的典型题目，使用二分算法的解题模板可以轻松解决，二分算法的算法思想清晰明确，一通百通。 169. 求众数 给定一个大小为 n 的数组，找到其中的众数。众数是指在数组中出现次数大于 ⌊ n/2 ⌋ 的元素。你可以假设数组是非空的，并且给定的数组总是存在众数。 🏆分治算法 的简单题目，如果我们知道数组左边一半和右边一半的众数，我们就可以用线性时间知道全局的众数是哪个。这道题妙就妙在可以有多种解题方式，让初学者至少可以写出暴力枚举算法 AC 题目，然后再逐步深入，优化算法。 944. 删列造序 给定由 N 个小写字母字符串组成的数组 A，其中每个字符串长度相等。选取一个删除索引序列，对于 A 中的每个字符串，删除对应每个索引处的字符。 所余下的字符串行从上往下读形成列。假设，我们选择了一组删除索引 D，那么在执行删除操作之后，A 中所剩余的每一列都必须是 非降序 排列的，然后请你返回 D.length 的最小可能值。 🏆这是一道 贪心算法 的简单题目，贪心算法理解简单，上手容易，适合作为初学者掌握的第一个算法。 融会贯通学习算法理论如同阅读了一本武功秘籍，然而仅仅掌握理论是不够的，接下来就要进入到实际练习阶段。 实战练习非常重要，不经过实战练习，理论仅仅是纸上谈兵。比如，不经过大量练习，永远不会知道二分算法是多么容易出现死循环。一个边界条件控制不好，程序就会显示无情的”Time Limit Exceeded”。在 20 分钟的调试后，或许仅仅是将 while (left &lt;= right) 改为了 while (left &lt; right) 。程序员说到底也是手艺人，这一个字符的改动，正是”台上一分钟，台下十年功”的体现，需要在大量的练习中才能理解两者之间的不同作用。 再比如，动态规划算法中，递归的函数就像是《盗梦空间》中的”梦中梦”，一层套一层，又渐次展开，很难整体把控。在不断的练习后，才会知道，动态规划算法的重点是抓住动态转移方程，只处理两个状态之间的过渡和边界条件，慢慢”大事化小，小事化了”。 这一阶段花费的时间将会很长很长，伴随着不断地摔倒、爬起，你会对每类算法逐渐融会贯通。好在这一阶段是不看天赋只看勤奋的，每次从坑里爬起，都是献给成长的一份力量。推荐的进阶书籍有**《编程珠玑》**，本书探讨了程序设计人员面对一系列的实际问题以及解决问题的措施（解决方案的代码以 C&#x2F;C++ 语言编写）。书中选取了许多具有典型意义的复杂编程和算法问题，并阐述和总结了许多独特精妙的设计原则、思考和解决问题的方法以及实用的程序设计技巧。 🌹在这个阶段，可以尝试练习力扣上的中等题目，中等题目基本上也只会使用一种算法，加上一些特殊的限制，好比让你在学习了直拳的理论后衍生出左勾拳和右勾拳。推荐练习题目有： 1048. 最长字符串链 给出一个单词列表，其中每个单词都由小写英文字母组成。如果我们可以在 word1 的任何地方添加一个字母使其变成 word2，那么我们认为 word1 是 word2 的前身。例如，”abc” 是 “abac” 的前身。词链是单词 [word_1, word_2, …, word_k] 组成的序列，k &gt;&#x3D; 1，其中 word_1 是 word_2 的前身，word_2 是 word_3 的前身，依此类推。从给定单词列表 words 中选择单词组成词链，返回词链的最长可能长度。 🏆分析题目可知，要求出答案必须遍历所有可能的词链，动态规划算法在其中起备忘录的作用，用于记录已经算过的答案，减少计算次数。 47. 全排列 II 给定一个可包含重复数字的序列，返回所有不重复的全排列。 🏆这道题是 46. 全排列 的加强版，全排列 I 的题目是：给定一个 没有重复 数字的序列，返回其所有可能的全排列。使用深度优先搜索算法即可解决。本题在其基础上加强了难度，有两种方法可解。第一种方法最简单，直接用全排列 I 的答案去重即可，第二种方法是先将数组排序，全排列时遇到重复数字则跳过，这样的剪枝优化可以减少遍历次数，提高算法效率。 40. 组合总和 II 给定一个数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。candidates 中的每个数字在每个组合中只能使用一次。 🏆深度优先搜索算法衍生出来的回溯算法，同样用到 47 题的剪枝优化思想：相同数字只允许递归第一个。 89. 格雷编码 格雷编码是一个二进制数字系统，在该系统中，两个连续的数值仅有一个位数的差异。给定一个代表编码总位数的非负整数 n，打印其格雷编码序列。格雷编码序列必须以 0 开头。 🏆动态规划 算法的实际应用之一。 79. 单词搜索 给定一个二维网格和一个单词，找出该单词是否存在于网格中。单词必须按照字母顺序，通过相邻的单元格内的字母构成，其中“相邻”单元格是那些水平相邻或垂直相邻的单元格。同一个单元格内的字母不允许被重复使用。 🏆深度优先搜索的中级应用，使用单独数组标记已使用过的元素，这也是 DFS 中较为常见的做法，难点在于将标记数组复原的时机，需要反复练习，熟练掌握。 🌹当你把每一类算法的中等题目刷起来得心应手时，不妨开始尝试困难题目的练习。困难题目总是融合两种或两种以上算法，或是加深难度的经典算法，如二维甚至三维动态规划。练习困难题目好比同时用上左勾拳和扫堂腿，不仅让思维酣畅淋漓，在每次 AC 之后还会带来无与伦比的成就感。推荐练习题目有： 679. 24 点游戏 你有 4 张写有 1 到 9 数字的牌。你需要判断是否能通过 *，/，+，-，(，) 的运算得到 24。 🧠只有 4 张牌，且只能执行 4 种操作。即使所有运算符都不进行交换，最多也只有 12 * 6 * 2 * 4 * 4 * 4 &#x3D; 9216 种可能性，这使得我们可以尝试所有这些可能，如果用深度优先搜索算法则需要费一番功夫。 124. 二叉树中的最大路径和 给定一个非空二叉树，返回其最大路径和。本题中，路径被定义为一条从树中任意节点出发，达到任意节点的序列。该路径至少包含一个节点，且不一定经过根节点。 🧠首先，考虑实现一个简化的函数：计算每个节点及其子树对路径和的最大贡献。再考虑第二点：最大路径不一定包括根节点。这意味着我们在每一步都检查哪种选择更好：是继续当前路径或者以当前节点作为最高节点计算新的路径。 410. 分割数组的最大值 给定一个非负整数数组和一个整数 m，你需要将这个数组分成 m 个非空的连续子数组。设计一个算法使得这 m 个子数组各自和的最大值最小。 🧠二分算法和贪心算法的综合练习，仔细分析可知其单调关系：数组和的最大值越小，分组数越大。并且数组和的范围是可以确定的。根据此特性，可以将题目转换为：当子数组的和最大为 maxSum 时，至少需要分多少组，能否在最多 m 组的限制范围内完成分割。在每次分割时，采用贪心策略，尽可能多的放置元素，直到一组放不下，再另起一组。如果满足分割条件，记录当前值，利用二分法，缩小子数组总和。否则扩大子数组总和，直到找到最佳答案。 推陈出新事实上，大量程序员停留在第二重境界就无法再进一步。当提到某一类算法时，你可以说：”我知道”、”我会用”、”踩过坑”，但能说出”我完全理解其思想“、甚至”我能想办法改进“的人却很少很少。这一步仿佛武学中的攻守之道，当你掌握到这一层，便可不再拘泥于一刀一剑、一招一式，如金书中所说：飞花摘叶皆可伤人、草木竹石均可为剑。 开创算法的过程是艰难又孤独的。每一个经典算法的诞生都伴随着”一将功成万骨枯”。比如现在我们在很多语言中都可以直接调用Collection.sort()实现快速排序，而在快速排序算法出现之前，曾有一段时间仅有冒泡、选择、插入三种排序算法。直到1959年，希尔提出”希尔排序”算法，或许现在知道此算法的人已经很少了。但它是首个突破了复杂度的排序算法，它的基本算法思想如下： 选择一个增量序列t1，t2，…，tk，其中 ti &gt; tj， tk &#x3D; 1； 按增量序列个数k，对序列进行k 趟排序； 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为 m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 希尔排序算法较为晦涩难懂，而且并不是最优的排序算法，现在已经被后来的快速排序算法给淘汰了。然而不可否认希尔对排序算法的演进具有开创性贡献，在攀越算法高峰的路上，每一步都走得战战兢兢，我们只有铭记这些伟大的引路人，以此激励自己不断前行。 💖算法世界不尽完美。不仅有经典算法在前奠基，后起之秀遗传算法、深度学习算法也熠熠生辉。算法世界还有许多”所罗门王的宝藏”，一直静静地守候在”灯火阑珊处”，等待着人们去发掘。 学习方法 现在网上有很多资源、博客、论坛可供我们更方便地学习知识片段。然而这种类似兵来将挡、水来土掩般的学习方法虽然有用，却并不特别的好。这里推荐大家在网上寻找一些系统的学习教程，以帮助自己由浅入深，一路成长。 算法学习之道非一日之功，在技术提升的路上，力扣会一直助你前行。","tags":["LeetCode","算法"],"categories":["数据结构与算法"]},{"title":"让你选一句话裱起来，你会选什么？","path":"/post/未来世界的幸存者/choose-one-sentence/","content":"摩尔定律对软件开发也是间接奏效的，每过 18 个月，就会有一半的知识会过期。我之前写的有些文章就已经过期了，今天我们来聊一个不会那么容易过时的话题 —— 那些业界‘大佬’是怎么思考的？一个结构化的知识体系是怎样的？ 不过要提前说明，本文没那么严肃，仅作抛砖引玉。如果你想要多了解这方面的知识，应该多读几本经典的书籍。 从思考框架到基本原则，再到具体最佳实践前些日子学习了 《10x程序员工作法》、《研发效率破局之道》，内容本身质量很高自不必说，给我启发较大的是他们的内容组织方式。以 《10x程序员工作法》为例，它的内容是这样组织的： 这种设计可以让我们直观地把握课程的主要脉络。 思考框架是事物的出发点，用于审视目标、把握方向；基本原则是在思考框架下的核心指导思想；最后在基本原则指导下进行具体实践。后面会详细说明这三者的关系。 在我看来，这才是一种结构化的知识体系。这种方法可以帮助你建立一套自己的知识体系、认知模型，还可以用来指导你的行动实践。希望本文也可以给你一些启发。 🤔思考框架最上层的思考框架往往是一些哲学问题，无非就是保安经常问你的那三个问题： 你是谁？ 从哪来？ 到哪去？ 还有类似的 WWH： Why？ → 目的、理念 What？→ 定义、概念、现象或成果 How？ → 具体操作方法、措施 ⭐而《10x 程序员工作法》的思考框架是： 估计这个思考框架你从小学、幼儿园老师就会教你，不用多解释。那么问题来了，大家有没有形成这样的思考习惯呢❓❓❓ 这个思考框架，虽然简单，却可以受益终生💭。 它可以是任何行动的基础。比如在上一篇文章中“如何看待新技术章节” 也套用了这个模式： 这是啥玩意？ 解决什么问题？ 怎么解决的？ 思想 → 流程 → 实现 再比如下次产品经理给你一个需求，套用这个框架，你可以问他： WHY ？为什么要这个做这个功能？ 它可以给用户带来什么价值？ 或者说能给公司带来什么收益？→ 没价值，就没有做的意义。 WHAT &amp; HOW ？ 什么样的用户会用到这个功能，他们在什么场景下使用，他们又会怎样使用它？实现这个功能就只有这种方式吗？还有没有其他方案？→ 可以衡量这个功能是否有经过认真思考的，是不是自己 YY，是不是合理。 如果产品回答不上来，那不好意思，回去等通知吧。 面试也很可能按照上面的套路考察你的 ‘要性’ (阿里土话，道听途说)： 你觉得你现在处于什么水平？有哪些不足 你的目标是什么？想加入什么样的团队？ 你有什么计划？ OK，这里留一个思考题，如果你的老板在画大饼，你会怎么怼他呢？ 🧠原则接下来是在思考框架指导下的 ‘原则’。这些原则相比思考框架要具体一些，是针对特定领域的思想指导，在处理某个特定领域的问题时会更有用一些。 比如《10x 程序员工作法》归纳了四个原则： 因为是付费专栏，所以我也不多剧透，可以看它的导读。 可以举其他我们比较熟悉的例子，比如面向对象设计的 SOLID 原则： S 单一功能原则: 认为 “对象应该仅具有一种单一功能” 的概念 O 开闭原则: 认为 “软件体应该是对于扩展开放的，但是对于修改封闭的” 的概念。 L 里氏替换原则: 认为 “程序中的对象应该是可以在不改变程序正确性的前提下被它的子类所替换的” 的概念。 I 接口隔离原则: 认为 “多个特定客户端接口要好于一个宽泛用途的接口” 的概念 D 依赖反转原则：认为一个方法应该遵从 “依赖于抽象而不是一个实例” 的概念。依赖注入是该原则的一种实现方式。 搞对象的人，看到这些原则就会如数家珍，刚入门的小白可能比较难以理解。他们是历代火影燃烧火的意志沉淀下来的宝贝，没有经过战场的洗礼理解可能不会那么深刻。 ❤说一个我编程生涯比较受用的原则，那就是 DRY (Don’t repeat yourself)，因为它相比 SOLID 原则、KISS 原则，更好理解、或者说更有实践性。 DRY 原则简单说就是识别你的重复代码，思考，然后重构它。 如果你在编程时养成了这种习惯，你会发现你的代码自然而言会有比较良好的结构，同时也可能符合上述各种原则一些特征（实际上它们本来就是交叉和相通的）。 或者说，经过 DRY 原则下的刻意训练，你会形成一种编程品味（敲黑板，这也是大厂考点）。 ⭐类似思想&#x2F;原则还有很多，比如 Unix 哲学 、Windows 哲学，还有一些算法思想： 算法思想：源于 https://zhuanlan.zhihu.com/p/73144439 Unix 哲学： 下图有两个彩蛋： 一个是 Ken Thompson (Unix、Go 作者之一，真大神级人物) 非常实用的 “建议”： “拿不准就穷举”, 干就是了，干了再说。Unix 哲学用一个词概括就是 KISS (Keep It Simple, Stupid)，在这个 ‘面试造火箭，上班拧螺丝钉’ 内卷年代, 很多人容易走偏，把事情复杂化，写一些花里胡哨代码，做一些花里胡哨的功能。Unix 的远古哲学告诫我们：简洁就是好，好就是简洁。 第二个是我自己写的，尽管大学时就看过这本书，当时只有盲目崇拜，时隔多年再看，这些原则个个是说到心尖上了，顿时感叹应该把这些 ‘哲学’ 裱起来，日看夜看。这也是本文的灵感来源。 Windows 哲学：小事重启、大事重装。 这些原则你说难吗？其实不难，几句话就可以说清楚。 如果你是多年的老鸟，可以让你返璞归真。如果你是菜鸟，那你应该背诵下来 (开玩笑)，或者裱起来挂客厅、搞成壁纸、做成鼠标垫、印在保温瓶上… 💪具体的最佳实践再往下更具体，这是在原则指导下、经过实践总结出来的最佳实践&#x2F;设计模式。可以用于指导解决具体的领域问题。 还是以 《10x 程序员工作法》为例，它最终的知识结构如下： 举大家比较熟悉的例子，最典型的莫属于面向对象的《设计模式》，它就是属于这个层次的知识： 设计模式就是在 SOLID 原则指导下的具体实践。 并不是说我们只要学习思考框架和指导原则就行了，最佳实践也是要刻意学习的。三个层次相得益彰，这样形成的知识体系才是比较稳固的： 最佳实践是在思考框架和指导原则下形成的产物。 如果只是掌握最佳实践，停留在皮毛，不去挖掘它的内在思想，则不能做到内化和升华。 如果有幸，来到了一个新大陆，这里没有任何最佳实践和设计模式，要怎么办呢？ 思想和原则不能脱离实践。 最佳实践通常是别人实践总结出来的， 能复用的就复用是吧？最佳实践、准则、对我们来说是站在巨人的肩膀上，是捷径，让我们可以少走点弯路。 由于每个人的场景千差万别，别人的实践并不一定适合你， 或者你走在世界前头，上层的思想则是创造最佳实践的有用指导。 另外实践也在深化我们对上层思想的理解。 实践和思想是相互验证的关系。 后面大家看书、学习某些课程时，可以留意一下它们的组织结构，某种程度上可以折射出作者的水平。 一切都是套路，套了又套。 那么，让你选一句话裱起来，你会选什么？来点真实的，软件开发领域选一句让你受益匪浅的话，裱起来告诫自己&#x2F;后人，你会选什么? 我举一些例子吧： KISS DRY SOLID SPOT Unix 哲学 17 大原则 程序员的三大美德：懒惰、急躁、傲慢。—— Larry Wall 懒惰，是一种品质，它会使你花很大力气去规避过度的精力消耗，敦促你写出节省体力的程序，别人也能很好地利用，你还会为此写出完善的文档，以免别人来问问题。 急躁，是计算机偷懒时，你会感到的一种愤怒。它会促使你写出超越预期的程序，而不只是响应需求。 傲慢，极度自信，写出（或维护）别人挑不出毛病的程序。不是开玩笑，这真是美德。如果身边多几个这样的程序员，就不用 996 了。 Stay hungry, Stay foolish —— Steve Jobs Talk is cheap. Show me the code —— Linus Torvalds …","categories":["未来世界的幸存者"]},{"title":"Git 中的撤销操作","path":"/post/开发工具/git-undo/","content":"Git 版本管理时，往往需要撤销某些操作。 本文介绍几种最主要的情况，给出详细的解释。更多的命令可以参考《常用 Git 命令清单》一文。 1. 撤销提交一种常见的场景是，提交代码以后，你突然意识到这个提交有问题，应该撤销掉，这时执行下面的命令就可以了。 1$ git revert HEAD 上面命令的原理是，在当前提交后面，新增一次提交(commit+1)，抵消掉上一次提交导致的所有变化(workspace&amp;stage change)。它不会改变过去的历史，所以是首选方式，没有任何丢失代码的风险。 git revert 命令只能抵消上一个提交，如果想抵消多个提交，必须在命令行依次指定这些提交。比如，抵消前两个提交，要像下面这样写。 1$ git revert [倒数第一个提交] [倒数第二个提交] git revert 命令还有两个参数。 --no-edit：执行时不打开默认编辑器，直接使用 Git 自动生成的提交信息。 --no-commit：只抵消暂存区(stage)和工作区的文件变化，不产生新的提交。 2. 丢弃提交如果希望以前的提交在历史中彻底消失，而不是被抵消掉，可以使用git reset命令，丢弃掉某个提交之后的所有提交。 1$ git reset [last good SHA] git reset的原理是，让最新提交的指针回到以前某个时点，该时点之后的提交都从历史中消失。 默认情况下，git reset不改变工作区的文件（但会改变暂存区），--hard 参数可以让工作区里面的文件也回到以前的状态。 123$ git reset --hard [last good SHA]# 或者$ git reset --hard HEAD^1 执行 git reset 命令之后，如果想找回那些丢弃掉的提交，可以使用 git reflog 命令，具体做法参考这里。不过，这种做法有时效性，时间长了可能找不回来。 3. 替换上一次提交提交以后，发现提交信息写错了，这时可以使用 git commit 命令的 --amend 参数，可以修改上一次的提交信息。 1$ git commit --amend -m &quot;Fixes bug #42&quot; ⭐它的原理是产生一个新的提交对象，替换掉上一次提交产生的提交对象。这时如果暂存区有发生变化的文件，会一起提交到仓库。 所以，--amend 不仅可以修改提交信息，还可以整个把上一次提交替换掉。 4. 撤销工作区的文件修改如果工作区的某个文件被改乱了，但还没有 执行git add，可以用 git checkout 命令找回本次修改之前的文件。 1$ git checkout -- [filename] ⭐它的原理是先找暂存区，如果该文件有暂存的版本，则恢复该版本，否则恢复上一次提交的版本。 注意：工作区的文件变化一旦被撤销，就无法找回了。 5. 从暂存区撤销文件如果不小心把一个文件添加到暂存区，可以用下面的命令撤销。 1$ git rm --cached [filename] 上面的命令不影响已经提交的内容。 6. 撤销当前分支的变化你在当前分支上做了几次提交，突然发现放错了分支，这几个提交本应该放到另一个分支。 123456789# 新建一个 feature 分支，指向当前最新的提交# 注意，这时依然停留在当前分支$ git branch feature# 切换到这几次提交之前的状态$ git reset --hard [当前分支此前的最后一次提交]# 切换到 feature 分支$ git checkout feature 上面的操作等于是撤销当前分支的变化，将这些变化放到一个新建的分支。 ⭐也就是在当前 commit 位置（的另一个分支 feature 上）建立一个锚点保存最近几次 commits，并且在本分支 master 回溯到前几次 commit 记录的位置！这样可以有效撤销当前分支的提交，还能将 commits 转移到另一分支。 其实也可以用 git cherry-pick 实现！ 见博客：https://ruanyifeng.com/blog/2020/04/git-cherry-pick.html （完）","tags":["git"],"categories":["开发工具"]},{"title":"探秘 .git 文件夹，理解 git 运作机制","path":"/post/开发工具/understanding-.git-folder/","content":"前言： 近期需要给 git 仓库制作一个 commit-msg 钩子，进入 .git/hooks 文件夹正准备干活，突然想知道其它 git hooks 都是干啥的？.git 文件夹里面那么多文件，又都是干什么的呢？于是写了这篇文章。 另外，想要 git 进阶，了解 .git 文件夹也是最佳切入点，关于 git 运作机制的线索都可以在这里找到。 1. .git 文件夹创建任意文件夹中，用 git init 命令初始化仓库，即可在此文件夹下创建 .git 文件夹（.打头为隐藏文件夹，所以平时可能看不到）。这个文件夹之外的部分叫做工作区（Working Directory），.git 文件夹我们称做 Git 仓库 (Git Repository)。 如果出于某种原因，想要重新来过，rm -rf .git &amp;&amp; git init，此仓库的 git 记录会归零！（提醒：慎用！！！） 2. .git 结构随便初始化一个仓库，git init temp，运行 cd temp &amp;&amp; ls -F1 .git，可以看到基本的 .git 目录结构： 1234567HEADconfigdescriptionhooks/info/objects/refs/ 但这里面没有实质性内容，研究意义不大。我们找一个有过几次提交的仓库，运行 ls -F1 .git 可以看到更丰富的 .git 目录结构（通常会有 7 个文件 5 个目录）： 123456789101112COMMIT_EDITMSGHEADORIG_HEADFETCH_HEADconfigdescriptionindexhooks/info/logs/objects/refs/ 重要：动手之前，请做好整个仓库的备份！！！ 重要：动手之前，请做好整个仓库的备份！！！ 重要：动手之前，请做好整个仓库的备份！！！ 2.1. 文件 COMMIT_EDITMSG此文件是一个临时文件，存储最后一次提交的信息内容，git commit 命令之后打开的编辑器就是在编辑此文件，而你退出编辑器后，git 会把此文件内容写入 commit 记录。 ⭐实际应用： git pull 远程仓库后，新增了很多提交，淹没了本地提交记录，直接 cat .git/COMMIT_EDITMSG 就可以弄清楚最后工作的位置了，是不是很实用？ 2.2 文件 HEAD此文件永远存储当前位置指针，就像 linux 中的 $PWD 变量和命令提示符的箭头一样，永远指向当前位置，表明当前的工作位置。在 git 中 HEAD 永远指向当前正在工作的那个 commit。 分支 HEADHEAD 存储一个分支的 ref，运行：cat .git/HEAD 通常会显示： 1ref: refs/heads/master 这说明你目前正在 master 分支工作。此时你的任何 commit，默认自动附加到 master 分支之上。 执行 git cat-file -p HEAD, 显示详细的提交信息： 1234567$ git cat-file -p HEADtree 95a4c1cd778ad62586c47afc06d2a1b5dff1bdecparent bfdec30d39951b49fa8964863bd801058878f3b2author Wu-Yikun &lt;577159462@qq.com&gt; 1634876894 +0800committer Wu-Yikun &lt;577159462@qq.com&gt; 1634876894 +0800? 孤立 HEADHEAD 不关联任何分支，只指向某个 commit，运行 git checkout bfdec30d，你会看到如下信息： You are in ‘detached HEAD’ state. You can look around, make experimentalchanges and commit them, and you can discard any commits you make in thisstate without impacting any branches by performing another checkout. 相信很多人一开始使用 git 都会对这段信息头大，其实它只是告诉你 HEAD 这个文件中存储的信息已不再是一个分支信息，运行：cat .git/HEAD，看到： 12$ cat .git/HEADbfdec30d39951b49fa8964863bd801058878f3b2 看到区别了吗？HEAD 指向一个40字符的 SHA-1 提交记录，git 已经不知道你在哪个分支工作了，所以你如果生成新的 commit，git 不知道往哪里 push，你只能做些实验性代码自嗨一把，无法影响到任何分支，也无法与人协同。这就是所谓的 &#39;detached HEAD&#39; state。 (由分支HEAD 变为 孤立HEAD) 关于 HEAD 的用法示例： 12$ git push origin HEAD$ git checkout HEAD~1 2.3 文件 ORIG_HEAD正因为 HEAD 比较重要，此文件会在你进行危险操作时备份 HEAD，如以下操作时会触发备份： 1234$ git reset$ git merge$ git rebase$ git pull 此文件的应用示例： 12# 回滚到上一次的状态(慎用!!!)$ git reset --hard ORIG_HEAD 2.4 文件 FETCH_HEAD这个文件作用在于追踪远程分支的拉取与合并，与其相关的命令有 git pull/fetch/merge， 而 git pull 命令相当于执行以下两条命令 (pull &#x3D; fetch &amp; merge)： 1234567$ git fetch$ git merge FETCH_HEAD# 显示如下&gt;&gt;&gt;From https://github.com/xxx/xxxx* branch master -&gt; FETCH_HEADUpdating f785638..59db1b2 并且，此时会默默备份 HEAD 到 ORIG_HEAD。 看看 FETCH_HEAD 里面有什么内容： 12$ cat .git/FETCH_HEAD848d7701250d5fee1449c5355158f629f6564484 branch &#x27;master&#x27; of https://github.com/xxxx/xxx 最前面是 hash 值，最后面是需要 fetch 的分支信息。 此文件可能不止一行，比如： 12345$ cat .git/FETCH_HEAD848d7701250d5fee1449c5355158f629f6564484 branch &#x27;master&#x27; of https://github.com/xxxx/xxx81d84ed74fc2b29c73d6ac82d681e5819b4d35d3 branch &#x27;next&#x27; of https://github.com/xxxx/xxxa25f5f1615a479e717a82bc4a10d816a44de6cd1 not-for-merge branch &#x27;add-i18n&#x27; of https://github.com/xxxx/xxx065c1b268386d533be65f4ae34742b2f1780d589 not-for-merge branch &#x27;add-sche-catch&#x27; of https://github.com/xxxx/xxx ⭐其中会有关键字 not-for-merge，由于 git pull 其实就是 fetch + merge，有这个标志就表明 git pull 时只 fetch，不 merge。 此特性在 2015 年 git 2.5 之后被加入，可以看看 源码，当 git pull 时，not-for-merge 会做为 magic string 来判定是否要从远程合并到本地分支。上面这段源码的注释写得恰到好处： “Appends merge candidates from FETCH_HEAD that are not marked not-for-merge into merge_heads.” 2.5 文件 config此文件存储项目本地的 git 设置，典型内容如下： 123456789101112131415161718[core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true ignorecase = true[remote &quot;origin&quot;] url = git@gitlab.xxxx.com/xxx.git fetch = +refs/heads/*:refs/remotes/origin/*[branch &quot;master&quot;] remote = origin merge = refs/heads/master[branch &quot;v2.6.0&quot;] remote = origin merge = refs/heads/v2.6.0[branch &quot;v2.8.0&quot;] remote = origin merge = refs/heads/v2.8.0 这是典型的 INI 配置文件，每个 section 可包含多个 variable = value，其中 [core] 字段包含各种 git 的参数设置，如 ignorecase = true 表示忽略文件名大小写。 ⭐git config --global 影响的则是全局配置文件 ~/.gitconfig；可执行以下命令对该文件进行修改： 1$ git config --global -e [core] 段的内容跟 git config 命令对应 执行以下命令： 12$ git config user.name abc$ git config user.email abc@abc.com 会在 config 文件中追加以下内容： 1234... ...[user] name = abc email = abc@abc.com [remote] 段表示远程仓库配置 详见 Git Internals - The Refspec，注意这里的 + 与 * 的含义。 [branch] 段表示分支同步设置 假设当前在 master 分支，执行 git pull 若出现以下提示： 12345There is no tracking information for the current branch.Please specify which branch you want to merge with.See git-pull(1) for details. git pull &lt;remote&gt; &lt;branch&gt; 就说明 .git/config 文件缺少对应的 [branch &quot;master&quot;] 字段。 解决方案为： 1234567$ git branch -u origin/master master# 或者执行一次 push$ git push -u origin master# 或者根据如下命令设置远程分支与本地分支的关联(如下命令表示本地分支的master与远程分支的master分支关联)$ git push --set-upstream origin master:master 会出现提示： Branch ‘master’ set up to track remote branch ‘master’ from ‘origin’. 其实就是生成以下内容在 .git/config中： 123[branch &quot;master&quot;] remote = origin merge = refs/heads/master 你去手动编辑 .git/config，效果一样。这就是 upstream 的真正含义，即生成 config 中的这段配置。 2.6 文件 description看到文档中有如下一段描述： The description file is used only by the GitWeb program, so don’t worry about it. 说明这个文件主要用于 GitWeb 的描述，如果我们要启动 GitWeb 可用如下命令： 12# 确保lighttpd已安装: brew install lighttpd$ git instaweb --start 默认会启动 lighttpd 服务并打开浏览器 http://127.0.0.1:1234 (试着改成对外IP并分享给别人？) 以下显示当前的 git 仓库名称以及描述，默认的描述如下： Unnamed repository; edit this file ‘description’ to name the repository. 上面这段话就是默认的 description 文件的内容，编辑这个文件来让你 GitWeb 描述更友好。除此之外没发现其它用处。 2.7 文件夹 hooks&#x2F;存放 git hooks，用于在 git 命令前后做检查或做些自定义动作。运行 ls -F1 .git/hooks 12345678910111213prepare-commit-msg.sample # git commit 之前，编辑器启动之前触发，传入 COMMIT_FILE，COMMIT_SOURCE，SHA1commit-msg.sample # git commit 之前，编辑器退出后触发，传入 COMMIT_EDITMSG 文件名pre-commit.sample # git commit 之前，commit-msg 通过后触发，譬如校验文件名是否含中文pre-push.sample # git push 之前触发pre-receive.sample # git push 之后，服务端更新 ref 前触发update.sample # git push 之后，服务端更新每一个 ref 时触发，用于针对每个 ref 作校验等post-update.sample # git push 之后，服务端更新 ref 后触发pre-rebase.sample # git rebase 之前触发，传入 rebase 分支作参数applypatch-msg.sample # 用于 git am 命令提交信息校验pre-applypatch.sample # 用于 git am 命令执行前动作fsmonitor-watchman.sample # 配合 core.fsmonitor 设置来更好监测文件变化 参考：https://git-scm.com/docs/githooks 如果要启用某个 hook，只需把 .sample 删除即可，然后编辑其内容来实现相应的逻辑。 比如我们要校验每个 commit message 至少要包含两个单词，否则就提示并拒绝提交，将 commit-msg.sample 改为 commit-msg 后，编辑如下： 12#!/bin/shgrep -q &#x27;\\S\\s\\+\\S&#x27; $1 || &#123; echo &#x27;提交信息至少为两个单词&#x27; &amp;&amp; exit 1; &#125; 这样当提交一个 commit 时，会执行 bash 命令： .git/hooks/commit-msg .git/COMMIT_EDITMSG，退出值不为 0，就拒绝提交。 2.8 文件夹 info&#x2F;此文件夹基本就有两个文件： 文件 info/exclude 用于排除规则，与 .gitignore 功能类似。 可能会包含文件 info/refs ，用于跟踪各分支的信息。此文件一般通过命令 git update-server-info 生成，里面的内容： 1294e1a0d952f577fe1348d828d145507d3709e11e refs/heads/master# object hash # branch reference 这表示 master 分支所指向的文件对象 hash 值为：94e1a0d952f577fe1348d828d145507d3709e11e， 运行 git cat-file -p 94e1a0d952f577fe1348d828d145507d3709e11e，可以看到 master 分支最后提交的记录信息。 同时：cat .git/objects/94/e1a0d952f577fe1348d828d145507d3709e11e 可以看到最后提交文件的二进制内容表示。 文件 info/refs 对于 搭建 git 服务器 来说至关重要。 2.9 文件夹 logs&#x2F;记录了操作信息，git reflog 命令以及像 HEAD@&#123;1&#125; 形式的路径会用到。如果删除此文件夹（危险！），那么依赖于 reflog 的命令就会报错。 12$ mv .git/logs .git/logs_bak$ git checkout HEAD@&#123;1&#125; 报错信息如下： error: pathspec ‘HEAD@{1}’ did not match any file(s) known to git 2.10 文件夹 objects&#x2F;此文件夹简单说，就是 git的数据库，运行 tree .git/objects，可以看到目录结构： 123456789101112131415.git/objects/|-- 0c| `-- d370696b581c38ee01e62b148a759f80facc2d|-- 59| `-- 3d5b490556791212acd5a516a37bbfa05d44dd|-- 61| `-- be44eedde61d723e5761577a2b420ba0fc2794|-- 64| `-- c0aed8ddcbb546bdcec2848938fc82348db227|-- d4| `-- 9904676ce8ddde276bdbfa9bbec313e90e0f50|-- info`-- pack |-- pack-75e3f2aa378752ec93a8e9f375f01204d498605b.idx `-- pack-75e3f2aa378752ec93a8e9f375f01204d498605b.pack 这些文件分两种形式：pack压缩包 形式放在 pack/ 目录下，除此之外都是 hash文件 形式，被叫做 loost objects。 这个文件夹以及相应的算法，我没找到独立的名称，就叫它 hash-object 体系吧。因为确实有个 git hash-object 命令存在，是一个底层的负责生成这些 loost objects 文件，如果要看到这些文件各自的含义，执行以下命令： 1$ git cat-file --batch-check --batch-all-objects 可以看到 1234567804c87c65f142f33945f2f5951cf7801a32dfa240 commit 194098217953a6ca169bed33d2be8a07d584fcdaf30 tree 310cd370696b581c38ee01e62b148a759f80facc2d commit 2452a810017bfc85d7db2627f4aabdaa1583212bda3 blob 193920a07c1d5694df6b8658592b0939241d70e9e5 tree 93593d5b490556791212acd5a516a37bbfa05d44dd tag 14861be44eedde61d723e5761577a2b420ba0fc2794 tree 154... ... 但你会发现这个列表里有些值在文件夹中并不存在，因为除了 loost objects 它还汇总了 pack 文件中的内容。 hash 文件又称为 loose object，文件名称共由 40 字符的 SHA-1 hash 值组成，其中前两个字符为文件夹分桶，后 38 个字符为文件名称。 按文件内容可分为四种类型：commit, tree, blob, tag，若执行以下命令会生成所有四种类型： 1234$ echo -en &#x27;xx &#x27; &gt; xx # 共 3 个字符$ git add .$ git commit -m &#x27;update xx&#x27;$ git tag -a &#x27;v1.0&#x27; -m &#x27;release: 1.0.0&#x27; 经过以上操作后，对比一下文件树，发现多了四个 hash文件： 12345678910111213141516171819202122|-- 0c| `-- d370696b581c38ee01e62b148a759f80facc2d|-- 18| `-- 143661f96845f11e0b4ab7312bdc0f356834ce|-- 30| `-- 20feea86d222d83218eb3eb5aa9f58f73df04d|-- 59| `-- 3d5b490556791212acd5a516a37bbfa05d44dd|-- 61| `-- be44eedde61d723e5761577a2b420ba0fc2794|-- 64| `-- c0aed8ddcbb546bdcec2848938fc82348db227|-- ad| `-- f4c9afac7afae3ff3e95e6c4eefe009d547f00|-- cc| `-- c9bd67dc5c467859102d53d54c5ce851273bdd|-- d4| `-- 9904676ce8ddde276bdbfa9bbec313e90e0f50|-- info`-- pack |-- pack-75e3f2aa378752ec93a8e9f375f01204d498605b.idx `-- pack-75e3f2aa378752ec93a8e9f375f01204d498605b.pack 这四个 hash文件 分别是： 1234cc/c9bd67dc5c467859102d53d54c5ce851273bdd # blob30/20feea86d222d83218eb3eb5aa9f58f73df04d # commitad/f4c9afac7afae3ff3e95e6c4eefe009d547f00 # tree18/143661f96845f11e0b4ab7312bdc0f356834ce # tag 我们想看下里面到底存的什么？其实这些文件都经过了压缩，压缩形式为 zlib。先安装一下解压工具 macOS 版 brew install pigz 或 windows 版 pigz，后执行： 1234567891011121314151617181920212223242526$ pigz -d &lt; .git/objects/cc/c9bd67dc5c467859102d53d54c5ce851273bdd# BLOB类型，显示结果为&gt;&gt;&gt;&gt;(注意xx后有个 )blob 3xx$ pigz -d &lt; .git/objects/30/20feea86d222d83218eb3eb5aa9f58f73df04d# COMMIT类型，显示结果为&gt;&gt;&gt;&gt;commit 248tree adf4c9afac7afae3ff3e95e6c4eefe009d547f00parent 0cd370696b581c38ee01e62b148a759f80facc2dauthor jamesyang.yjm &lt;jamesyang.yjm@alibaba-inc.com&gt; 1562044880 +0800committer jamesyang.yjm &lt;jamesyang.yjm@alibaba-inc.com&gt; 1562044880 +0800update xx$ pigz -d &lt; .git/objects/ad/f4c9afac7afae3ff3e95e6c4eefe009d547f00# TREE类型，显示结果为&gt;&gt;&gt;&gt;tree 154100644 abc*???]&#125;?bJ?ڡX2??100644 asdf???CK?)?wZ???S?100644 iou???CK?)?wZ???S?100644 xx?ɽg?\\FxY-S?L\\?Q&#x27;;?100644 yy???CK?)?wZ???S?$ pigz -d &lt; .git/objects/18/143661f96845f11e0b4ab7312bdc0f356834ce# TAG类型，显示结果为&gt;&gt;&gt;&gt;tag 155object 3020feea86d222d83218eb3eb5aa9f58f73df04dtype committag v1.0tagger jamesyang.yjm &lt;jamesyang.yjm@alibaba-inc.com&gt; 1562045942 +0800release: 1.0.0 会发现，显示结果都是 type size+内容 形式，这就是 object 文件的存储格式： 1[type] [size][NULL][content] type 可选值：commit, tree, blob, tag，NULL 就是C语言里的字符结束符：\\0，size 就是 NULL后内容的字节长度。 type 的几种类型可以使用 git cat-file -t hash 看到，内容可以用 git cat-file -p hash 看到。 12345678$ git cat-file -t ccc9bd67dc5c467859102d53d54c5ce851273bdd# 显示结果为&gt;&gt;&gt;&gt;blob$ git cat-file -p ccc9bd67dc5c467859102d53d54c5ce851273bdd# 显示结果为&gt;&gt;&gt;&gt;xx 所以 blob 文件就是对原文件内容的全量拷贝，同时前面加了 blob size\\0，而文件名称的 hash 值计算是计算整体字符的 SHA-1 值： 123$ echo -en &#x27;blob 3\\0xx &#x27; | shasum# 显示结果为&gt;&gt;&gt;&gt;ccc9bd67dc5c467859102d53d54c5ce851273bdd - 知道原理后，其它类型格式请自行参考 斯坦福 Ben Lynn 所著的 GitMagic。 所以，当我们 git show 3020feea86d222d83218eb3eb5aa9f58f73df04d 时，会发生些什么？ 找到 3020feea86d222d83218eb3eb5aa9f58f73df04d 这个 commit，显示出来 找到此 commit 关联的 tree object: adf4c9afac7afae3ff3e95e6c4eefe009d547f00，拉取相应的 blob 文件，并与当前工作区内的文件做 diff，然后显示出来 这就是 objects/ 文件夹作为 git数据库 被使用的真实例子。 pack 文件为什么会有 .pack 文件？ 由于每次 commit 都会生成许多 hash文件，并且由于 blob 文件都是全量存储的，导致 git 效率下降，于是有了 pack-format，优势： 对于大仓库存储效率高 利于网络传输，便于备份 增量存储，优化磁盘空间 将 .git/objects 下的部分文件打包成 pack格式 12345678910111213$ tree .git/objects/ | wc -l311$ git gcEnumerating objects: 288, done.Counting objects: 100% (288/288), done.Delta compression using up to 4 threadsCompressing objects: 100% (287/287), done.Writing objects: 100% (288/288), done.Total 288 (delta 131), reused 90 (delta 0)$ tree .git/objects/ | wc -l12 可以看到文件数量减小了不少，其中大部分文件被打到一个 .pack 包中，并且是增量存储，有部分变更的文件只存储 基础hash ＋ 变更内容，磁盘空间优化很明显。 ⭐git gc 其实运行了两条命令：git repack 用来打包 和 git prune-packed 用来移除已打包的 hash文件 如果你想打包所有文件，并不推荐，但可以用以下命令： 1$ git repack -a -d -f --depth=250 --window=250 具体可见：此问题 如果想看一下包里有啥，运行： 1$ git verify-pack -v .git/objects/pack/pack-5963b552193021791c1a0ab9136c272f07124c98.pack 显示如下： 123456789101112131415161718192021222324252627285978c2c79cd3a4711fb8edd3166c9f9f5c8c97f5 commit 245 153 122305588a632214f266462260428c4395f936b5b0 commit 252 156 1651fa9735670eb952b6468d17b418525717c8e3527 commit 248 156 3213ffb7fb9830e232669c95b3b65f0f8f3fc7a6027 commit 248 155 47786a5912f97d7dd8f90a28cab6bffc8ee78997e2c commit 244 151 63294e1a0d952f577fe1348d828d145507d3709e11e commit 249 156 78386903f8f5024485afa8480020a04cc00f228d23c commit 243 150 9396efdffad4fb725aa8d0f4d7d29feb5aee7ea5dff commit 242 151 108904c87c65f142f33945f2f5951cf7801a32dfa240 commit 73 85 1240 1 6efdffad4fb725aa8d0f4d7d29feb5aee7ea5dff2a810017bfc85d7db2627f4aabdaa1583212bda3 blob 19 27 1325e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 blob 0 9 1352b5e810691433cf8a2960c27c1b33546fa96e2bef blob 16 26 13612f36e957afc2b3bcda988cb29a86e3a1490e8cc2 tree 153 106 13872ed6130bd33afa26817418308e29c4081ea056ec tree 5 15 1493 1 2f36e957afc2b3bcda988cb29a86e3a1490e8cc29df301ad27294a62ba1ae65aaed489072d778c79 tree 123 103 15087d48a14b9ca1dca2f6a593eef19633ce45f81bee blob 12 21 1611a448b4d6450de854dcc6fe658bdb72e22c726cbb tree 123 102 16329e56fd51f52d8b9d242c50c24a4cae586d76ec7e blob 7 16 1734bde15b851f135327ada02c9deac0fb1ee01cf343 tree 123 102 175058c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c blob 4 13 18523920a07c1d5694df6b8658592b0939241d70e9e5 tree 7 17 1865 1 bde15b851f135327ada02c9deac0fb1ee01cf34316729e3b94f19bc95cb6f563f776bfb4694a6e5b tree 4 14 1882 2 3920a07c1d5694df6b8658592b0939241d70e9e5b72c74792528892694c395b2c9a3d6af740f3fb2 tree 63 50 1896098217953a6ca169bed33d2be8a07d584fcdaf30 tree 31 42 1946non delta: 20 objectschain length = 1: 3 objectschain length = 2: 1 object.git/objects/pack/pack-5963b552193021791c1a0ab9136c272f07124c98.pack: ok 后面那串数字说明文档里很详细： 123456789When specifying the -v option the format used is: SHA-1 type size size-in-packfile offset-in-packfilefor objects that are not deltified in the pack, and SHA-1 type size size-in-packfile offset-in-packfile depth base-SHA-1for objects that are deltified. 以上最后有 hash 的条目，说明是增量存储的 基础hash，其前是增量深度。 2.11 文件夹 refs&#x2F;refs 可以理解成文件系统中的 symbol link，看下结构： 12345678910111213141516$ tree .git/refs/.git/refs|-- heads| `-- master`-- tags `-- v1.0$ cat .git/refs/heads/master 5978c2c79cd3a4711fb8edd3166c9f9f5c8c97f5$ cat .git/refs/tags/v1.0 5978c2c79cd3a4711fb8edd3166c9f9f5c8c97f5$ git cat-file -t 5978c2c79cd3a4711fb8edd3166c9f9f5c8c97f5commit 可以看到 master 和 v1.0 都指向 5978c2c79cd3a4711fb8edd3166c9f9f5c8c97f5 这个 commit。 refs/heads/ 文件夹内的 ref 一般通过 git branch 生成。git show-ref --heads 可以查看。 refs/tags/ 文件夹内的 ref 一般通过 git tag 生成。git show-ref --tags 可以查看。 如下： 12345678910111213$ git branch abc$ tree .git/refs/.git/refs/|-- heads| |-- abc| `-- master`-- tags `-- v1.0$ cat .git/refs/heads/abc 5978c2c79cd3a4711fb8edd3166c9f9f5c8c97f5 说明新建分支其实就是生成了一个指向某个 commit 的 symbol link，当然在这里叫做 ref。 而 git tag 命令本质与 git branch 相同，只生成一个 ref 放在 tags 目录下，所以被称为 lightweight tag。 而 git tag -a xx 命令会首先生成一个类型为 tag 的 hash文件 放到 objects/ 目录，然后生成 ref 放到 tags 目录下指向那个文件。这就叫做 annotated tag，好处是可包含一些元信息如 tagger 和 message，被 git 的 hash-object 算法管理，可被 GPG 签名等，所以更稳定，更安全。 使用以下命令来拿到 refs 文件夹存储的信息： 1234567$ git show-ref --head --dereference5978c2c79cd3a4711fb8edd3166c9f9f5c8c97f5 HEAD5978c2c79cd3a4711fb8edd3166c9f9f5c8c97f5 refs/heads/abc5978c2c79cd3a4711fb8edd3166c9f9f5c8c97f5 refs/heads/master5978c2c79cd3a4711fb8edd3166c9f9f5c8c97f5 refs/tags/v1.05e84371048faa20412f5492e6af264a7e1edfec1 refs/tags/xx5978c2c79cd3a4711fb8edd3166c9f9f5c8c97f5 refs/tags/xx^&#123;&#125; 我们来看这些信息如何变化的： 123456789101112$ touch new_file &amp;&amp; git add . &amp;&amp; git commit -m &#x27;add new_file&#x27;[master 44b0d05] add new_file 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 new_file$ git show-ref --head --dereference44b0d05ddadaaa8d2cc40d6647cc474b26f5d8d3 HEAD5978c2c79cd3a4711fb8edd3166c9f9f5c8c97f5 refs/heads/abc44b0d05ddadaaa8d2cc40d6647cc474b26f5d8d3 refs/heads/master5978c2c79cd3a4711fb8edd3166c9f9f5c8c97f5 refs/tags/v1.05e84371048faa20412f5492e6af264a7e1edfec1 refs/tags/xx5978c2c79cd3a4711fb8edd3166c9f9f5c8c97f5 refs/tags/xx^&#123;&#125; diff 一下可以看到： 125978c2c79cd3a4711fb8edd3166c9f9f5c8c97f5 HEAD5978c2c79cd3a4711fb8edd3166c9f9f5c8c97f5 refs/heads/master 这两行发生了变化。也就是每次 commit 时，HEAD 与 heads 都会自动更新。 2.12 文件 index细心的读者发现，没有讲 index 文件？原因在于： ⭐index 文件是整个 git 除 hash-object 体系最核心的部分，值得用单独一篇来讲。 可以先参考以下文章： 阮一峰老师写的 Git 原理入门 中 暂存区 的部分 Git index format Use of index and Racy Git problem 简要说一下，index 是一个微型的 linux 文件系统，用最经济的方式实现了 inode，这并不是偶然，因为创造这个想法的人同时也是 linux 的创造者 Linus Torvalds。 这个文件也叫做 git 的暂存区(Staging Area)，git add 就是把工作区内的某些文件取部分 stat 抓取的内容并写入 .git/index 文件并存为相应的一条 index entry，多条 index entry 形成一个 tree。 git commit 是把上一步形成的 tree 结构及相应的 blob 存储到 objects/ 文件夹下并同时生成一条 commit 记录。 git reset 是将刚写入 index 文件的 tree 丢弃，并从 HEAD 中恢复一个 tree。 git status 是拿 index 文件中存储的 tree 与工作区内的文件在 stat 层面做对比，并输出变更。 以上，这几个文件夹咱们用一张图做总结：","tags":["git"],"categories":["开发工具"]},{"title":"一文带你认识 Docker 与 k8s","path":"/post/开发工具/docker-and-k8s/","content":"随着 k8s 作为容器编排解决方案变得越来越流行，有些人开始拿 Docker 和 k8s 进行对比，不禁问道：Docker 不香吗？ k8s 是 kubernetes 的缩写，’8’ 代表中间的八个字符。 其实 Docker 和 k8s 并非直接的竞争对手，它俩相互依存。 Docker 是一个容器化平台，而 k8s 是 Docker 等容器平台的协调器。 1. 容器化时代来了虚拟化技术已经走过了三个时代，没有容器化技术的演进就不会有 Docker 技术的诞生。 （1）物理机时代：多个应用程序可能会跑在一台机器上。 （2）虚拟机时代：一台物理机器安装多个虚拟机（VM），一个虚拟机跑多个程序。 （3）容器化时代：一台物理机安装多个容器实例（container），一个容器跑多个程序。 容器化解决了软件开发过程中一个令人非常头疼的问题，用一段对话描述： 测试人员：你这个功能有问题。 开发人员：我本地是好的呀！ 开发人员编写代码，在自己本地环境测试完成后，将代码部署到测试或生产环境中，经常会遇到各种各样的问题。明明本地完美运行的代码为什么部署后出现很多 bug，原因有很多：不同的操作系统、不同的依赖库等，总结一句话就是因为本地环境和远程环境不一致。 容器化技术正好解决了这一关键问题，它将软件程序和运行的基础环境分开。开发人员编码完成后将程序打包到一个容器镜像中，镜像中详细列出了所依赖的环境，在不同的容器中运行标准化的镜像，从根本上解决了环境不一致的问题。 ⭐虽然容器概念已经出现不短的时间，但 2013 年推出的开源项目 Docker 在很大程度上帮助推广了容器这项技术，并推动了软件开发中容器化和微服务的趋势，这种趋势后来被称为云原生开发。 2. 容器化技术的尖刀武器 可移植性：不依赖具体的操作系统或云平台，比如在阿里云或腾讯云直接随意迁移。 占地小：容器只需要其应用程序以及它需要运行的所有容器和库的依赖清单，不需要将所有的依赖库都打包在一起。 共享 bin 和 lib：不同的容器可以共享 bin 和 lib，进一步节省了空间。 3. Docker 横空出世2010 年一位年轻小伙子在美国旧金山成立了一家名叫【dotCloud】的公司， 开发了 Docker 的核心技术，从此开启了容器技术的时代。 后面 dotCloud 公司将自己的容器技术进行了简化和标准化，取名为 Docker，就是大家熟悉的鲸鱼 logo。 2013 年 dotCloud 公司宣布将 Docker 开源，随着越来越多的工程师发现了它的优点， Docker 的人气迅速攀升，成为当时最火爆的开源技术之一。 当前有 30％ 以上的企业在其 AWS 环境中使用 Docker，并且这个数字还在继续增长。 此时的 Docker，已经成为行业里人气最火爆的开源技术，没有之一。甚至像 Google、微软、Amazon、VMware 这样的巨头，都对它青睐有加，表示将全力支持。 Docker 火了之后，dotCloud 公司干脆把公司名字也改成了 Docker Inc. 。 Docker 和容器技术为什么会这么火爆？说白了，就是因为它 “轻”。 在容器技术之前，业界的网红是虚拟机。虚拟机技术的代表，是 VMWare 和 OpenStack 。 相信很多人都用过虚拟机。虚拟机，就是在你的操作系统里面，装一个软件，然后通过这个软件，再模拟一台甚至多台“子电脑”出来。 在 “子电脑” 里，你可以和正常电脑一样运行程序，例如登录 QQ。如果你愿意，你可以变出好几个 “子电脑”，里面都登录上 QQ。“子电脑” 和 “子电脑” 之间，是相互隔离的，互不影响。 虚拟机属于虚拟化技术。而 Docker 这样的容器技术，也是虚拟化技术，属于轻量级的虚拟化。 虚拟机虽然可以隔离出很多 “子电脑”，但占用空间更大，启动更慢，虚拟机软件可能还要花钱（例如：VMWare）。 而容器技术恰好没有这些缺点。它不需要虚拟出整个操作系统，只需要虚拟一个小规模的环境（类似 “沙箱”）。Docker 可以轻松创建容器和基于容器的应用程序，最初是为 Linux 构建的，现在也可以在 Windows 和 MacOS 上运行。 它启动时间很快，几秒钟就能完成。而且，它对资源的利用率很高（一台主机可以同时运行几千个 Docker 容器）。此外，它占的空间很小，虚拟机一般要几 GB 到几十 GB 的空间，而容器只需要 MB 级甚至 KB 级。 正因为如此，容器技术受到了热烈的欢迎和追捧，发展迅速。大家需要注意，Docker 本身并不是容器，它是创建容器的工具，是应用容器引擎。想要搞懂 Docker，其实看它的两句口号就行。 第一句，是 “Build, Ship and Run”。 第二句口号则是：“Build once，Run anywhere（搭建一次，到处能用）”。 Build（构建镜像）： 镜像就像是集装箱，包含文件以及运行环境等等资源； Ship（运输镜像）：在宿主机和仓库间进行运输，这里仓库就像是超级码头； Run（运行镜像）：运行的镜像就是一个容器，容器就是运行程序的地方。 ⭐说白了，这个 Docker 镜像，是一个特殊的文件系统。它除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（例如：环境变量）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。 ⭐综上所述，Docker 的运行过程，也就是去仓库把镜像拉到本地，然后用执行命令把镜像运行起来变成容器，这也就是为什么人们常常将 Docker 称为码头工人或码头装卸工。 ⭐负责对 Docker 镜像进行管理的，是 Docker Registry 服务（类似仓库管理员）。当然，不是任何人建的任何镜像都是合法的。万一有人构建的镜像存在问题呢？所以，Docker Registry 服务对镜像的管理是非常严格的。最常使用的 Registry 公开服务，是官方的 Docker Hub，这也是默认的 Registry，并拥有大量的高质量的官方镜像。 4. Docker 如何使用其实大多数人谈论 Docker 时说的是 Docker Engine，这只是一个构建和运行的容器。 在运行容器前需要编写 Docker File，通过 dockerFile 生成镜像，然后才能运行 Docker 容器。 Docker File 定义了运行镜像（image）所需的所有内容，包括操作系统和软件安装位置。一般情况下都不需要从头开始编写 Docker File，在 Docker Hub 中有来自世界各地的工程师编写好的镜像，你可以基于此修改。 📚此外，Docker 容器提供了一种构建企业应用程序和业务流程应用程序的方法，这些应用程序比传统应用程序更容易安装、维护和移动。 ⭐Docker 容器支持隔离：Docker 容器使应用程序不仅彼此隔离，而且与底层系统隔离。这不仅使软件栈更干净，而且更容易使容器化应用程序使用系统资源，例如 CPU、GPU、内存、I&#x2F;O、网络等，它还可以确保数据和代码保持独立。 ⭐Docker 容器支持可移植性：Docker 容器在支持容器运行环境的任何机器上运行。应用程序不必绑定到主机操作系统，因此可以保持应用程序环境和底层操作环境的整洁和最小化。例如，采用容器的 MySQL 将在大多数支持容器的 Linux 系统上运行，应用程序的所有依赖项通常都在同一个容器中提供。基于容器的应用程序可以轻易从 on-prem 系统迁移到云环境中，或从开发人员的笔记本电脑移到服务器上，只要目标系统支持 Docker 以及可能与之一起使用的任何第三方工具，比如 Kubernetes。 ⭐通常，Docker 容器镜像必须为特定的平台构建。例如 Windows 容器不能在 Linux 上运行，反之亦然；以前，绕过此限制的一种方法是启动运行所需操作系统实例的虚拟机，并在虚拟机中运行容器。然而 Docker 团队后来设计了一个更优雅的解决方案，称为 manifest，它允许多个操作系统的镜像并行打包。尽管 manifest 还处于试验阶段，但这暗示了容器可能成为跨平台应用程序解决方案和跨环境应用程序解决方案。 ⭐Docker 容器支持可组合性：大多数业务应用程序由几个独立的组件组成，web 服务器、数据库和 cache 缓存。Docker 容器可以将这些部件组合成一个容易更换的功能单元。每个部分由不同的容器提供，可以独立于其他容器进行维护、更新、交换和修改。 🔥 这本质上是应用程序设计的微服务模型。通过将应用程序功能划分为独立的、自包含的服务，微服务模型为过程缓慢的传统开发和单一僵化的应用程序提供了一种解决方案，轻量级和便携式容器使构建和维护基于微服务的应用程序变得更加容易。 5. 编排系统的需求催生 k8s尽管 Docker 为容器化的应用程序提供了开放标准，但随着容器越来越多出现了一系列新问题： 如何协调、调度和管理这些容器？ 如何在升级应用程序时不中断服务？ 如何监视应用程序的运行状况？ 如何批量重新启动容器里的程序？ 解决这些问题需要容器编排技术，可以将众多机器抽象，对外呈现出一台超大机器。现在业界比较流行的有：k8s、Mesos、Docker Swarm。 在业务发展初期只有几个微服务，这时用 Docker 就足够了，但随着业务规模逐渐扩大，容器越来越多，运维人员的工作越来越复杂，这个时候就需要编排系统解救 opers。 一个成熟的容器编排系统需要具备以下能力： 处理大量的容器和用户 负载均衡 鉴权和安全性 管理服务通信 多平台部署 🌊 其中，K8S，就是基于容器的集群管理平台，它的全称，是 kubernetes。 和 Docker 不同，K8S 的创造者，是众人皆知的行业巨头——Google。 然而，K8S 并不是一件全新的发明。它的前身，是 Google 自己捣鼓了十多年的 Borg 系统。K8S 是 Google 研发的容器协调器，已捐赠给 CNCF，现已开源。 Google 利用在容器管理多年的经验和专业知识推出了 k8s，主要用于自动化部署应用程序容器，可以支持众多容器化工具包括现在非常流行的 Docker。 目前 k8s 是容器编排市场的领导者，开源并公布了一系列标准化方法，主流的公有云平台都宣布支持。 一流的厂商都在抢占标准的制高点，一堆小厂商跟着一起玩，这就叫生态了。国内的大厂商都在干嘛呢？抢社区团购市场，玩资本游戏，哎？！ 6. k8s 架构和组件k8s 由众多组件组成，组件间通过 API 互相通信，归纳起来主要分为三个部分： controller manager nodes pods k8s 集群架构图： Controller Manager，即控制平面，用于调度程序以及节点状态检测。 Nodes，构成了 Kubernetes 集群的集体计算能力，实际部署容器运行的地方。 Pods，Kubernetes 集群中资源的最小单位。 下图是 Kubernetes 集成 Jenkins 实现 CICD（一图胜千言，需要对其有一个大致的认识）： 而下图则是 GitLab + Jenkins Pipeline + Doker + k8s + Helm 自动化部署： 7. k8s 与 Docker Swarm 江湖恩怨Docker Swarm 与 k8s 同为容器编排技术。 如果你非要拿 Docker 和 k8s 进行比较，其实你更应该拿 Docker Swarm 和 k8s 比较。 Docker Swarm 是 Docker 自家针对集群化部署管理的解决方案，优点很明显，可以更紧密集成到 Docker 生态系统中。 虽说 Swarm 是 Docker 亲儿子，但依旧没有 k8s 流行，不流行很大程度是因为商业、生态的原因，不多解释。 8. Docker 与 k8s 难舍难分Docker 和 k8s 在业界非常流行，都已经是事实上的标准。 Docker 是用于构建、分发、运行（Build, Ship and Run）容器的平台和工具。 而 k8s 实际上是一个使用 Docker 容器进行编排的系统，主要围绕 pods 进行工作。Pods 是 k8s 生态中最小的调度单位，可以包含一个或多个容器。 Docker 和 k8s 是根本上不同的技术，两者可以很好的协同工作。 9. 开发实践，灵魂追问（1）为什么还要用 k8s？没有 k8s 可以使用 docker 吗？ 可以。实际上一些小型公司，在业务不太复杂的情况下都是直接使用 Docker。尽管 k8s 有很多好处，但是众所周知它非常复杂，业务比较简单可以放弃使用 k8s。但 k8s 在业务达到一定规模后也得启用！ （2）没有 Docker 可以使用 k8s 吗？ k8s 只是一个容器编排器，没有容器拿什么编排？！ k8s 经常与 Docker 进行搭配使用，但是也可以使用其他容器，如 RunC、Containerted 等。 （3）Docker Swarm 和 k8s 怎么选？ 选 k8s。2019 年底 Docker Enterprise 已经出售给 Mirantis，Mirantis 声明要逐步淘汰 Docker Swarm，后续会将 k8s 作为默认编排工具。","tags":["Kubernetes","Docker"],"categories":["开发工具"]},{"title":"Tips for precise search on GitHub","path":"/post/开发工具/tips-for-precise-search-on-github/","content":"GitHub 上有很多优秀的开源项目与学习资料，如何通过这些资源来抹平你的信息不对称呢？ 那么你就应该明白我们要如何搜索 GitHub，以下为大家带来精准搜索 GitHub 的神仙技巧！ 1. 普通的搜索📚相信一般人搜索项目时，都是直接搜索技术栈相关的项目。 高级一点的搜索，会根据 Best match、Most starts … 来进行排序、选择相应的语言、选择仓库或者代码来进行筛选。 但是 GitHub 的搜索功能只支持以上这些而已吗 ？ No！ 如果你只会用以上的功能，那你知道的仅仅是 GitHub 搜索的冰山一角！ GitHub 的搜索是非常强大的！下面介绍更高级的搜索技巧！ 2. 搜索语法📚搜索 GitHub 时，你可以构建匹配特定数字和单词的查询。 2.1 查询大于或小于另一个值的值你可以使用 &gt;、&gt;=、&lt; 和 &lt;= 搜索大于、大于等于、小于以及小于等于另一个值的值。 查询 示例 &gt;n cats vue:&gt;1000 匹配含有 “vue” 字样、星标超过 1000 个的仓库。 &gt;=n vue topics:&gt;&#x3D;5 匹配含有 “vue” 字样、有 5 个或更多主题的仓库。 &lt;n vue size:&lt;10000 匹配小于 10 KB 的文件中含有 “vue” 字样的代码。 &lt;=n vue stars:&lt;&#x3D;50 匹配含有 “vue” 字样、星标不超过 50 个的仓库。 你还可以使用范围查询：搜索大于等于或小于等于另一个值的值。 查询 示例 n..* vue stars:10..* 等同于 stars:&gt;=10 并匹配含有 “vue” 字样、有 10 个或更多星号的仓库。 *..n vue stars:*..10 等同于 stars:&lt;=10 并匹配含有 “vue” 字样、有不超过 10 个星号的仓库。 2.2 查询范围之间的值你可以使用范围语法 n..n 搜索范围内的值，其中第一个数字 n 是最小值，而第二个 n 是最大值。 查询 示例 n..n vue stars:10..50 匹配含有 “vue” 字样、有 10 到 50 个星号的仓库。 2.3 查询日期你可以通过使用 &gt;、&gt;=、&lt;、&lt;= 和 范围查询 搜索早于或晚于另一个日期，或者位于日期范围内的日期。 日期格式必须遵循 ISO8601 标准，即 YYYY-MM-DD（年-月-日）。 查询 示例 &gt;YYYY-MM-DD vue created:&gt;2016-04-29 匹配含有 “vue” 字样、在 2016 年 4 月 29 日之后创建的议题。 &gt;=YYYY-MM-DD vue created:&gt;&#x3D;2017-04-01 匹配含有 “vue” 字样、在 2017 年 4 月 1 日或之后创建的议题。 &lt;YYYY-MM-DD vue pushed:&lt;2012-07-05 匹配在 2012 年 7 月 5 日之前推送的仓库中含有 “vue” 字样的代码。 &lt;=YYYY-MM-DD vue created:&lt;&#x3D;2012-07-04 匹配含有 “vue” 字样、在 2012 年 7 月 4 日或之前创建的议题。 YYYY-MM-DD..YYYY-MM-DD vue pushed:2016-04-30..2016-07-04 匹配含有 “vue” 字样、在 2016 年 4 月末到 7 月之间推送的仓库。 YYYY-MM-DD..* vue created:2012-04-30..* 匹配在 2012 年 4 月 30 日之后创建、含有 “vue” 字样的议题。 *..YYYY-MM-DD vue created:*..2012-04-30 匹配在 2012 年 7 月 4 日之前创建、含有 “vue” 字样的议题。 你也可以在日期后添加可选的时间信息 THH:MM:SS+00:00，以便按小时、分钟和秒进行搜索。 这是 T，随后是 HH:MM:SS（时-分-秒）和 UTC 偏移 (+00:00)。 查询 示例 YYYY-MM-DDTHH:MM:SS+00:00 vue created:2017-01-01T01:00:00+07:00..2017-03-01T15:30:15+07:00 匹配在 2017 年 1 月 1 日凌晨 1 点（UTC 偏移为 07:00）与 2017 年 3 月 1 日下午 3 点（UTC 偏移为 07:00）之间创建的议题。 UTC 偏移量 07:00，2017 年 3 月 1 日下午 3 点。 UTC 偏移量 07:00。 YYYY-MM-DDTHH:MM:SSZ vue created:2016-03-21T14:11:00Z..2016-04-07T20:45:00Z 匹配在 2016 年 3 月 21 日下午 2:11 与 2016 年 4 月 7 日晚上 8:45 之间创建的议题。 2.4 排除特定结果你可以使用 NOT 语法排除包含特定字词的结果。 NOT 运算符只能用于字符串关键词， 不适用于数字或日期。 查询 示例 NOT hello NOT world 匹配含有 “hello” 字样但不含有 “world” 字样的仓库。 缩小搜索结果范围的另一种途径是排除特定的子集。 你可以为任何搜索限定符添加 - 前缀，以排除该限定符匹配的所有结果。 查询 示例 -QUALIFIER vue stars:&gt;10 -language:javascript 匹配含有 “vue” 字样、有超过 10 个星号但并非以 JavaScript 编写的仓库。 mentions:Wu-Yikun -org:github 匹配提及 @Wu-Yikun 且不在 GitHub 组织仓库中的议题 2.5 对带有空格的查询使用引号如果搜索含有空格的查询，你需要用引号将其括起来。 例如： vue cats NOT “hello world” 匹配含有 “vue” 字样但不含有 “hello world” 字样的仓库。 build label:”bug fix” 匹配具有标签 “bug fix”、含有 “build” 字样的议题。 某些非字母数字符号（例如空格）会从引号内的代码搜索查询中删除，因此结果可能出乎意料。 2.6 使用用户名的查询如果搜索查询包含需要用户名的限定符，例如 user、actor 或 assignee，你可以使用任何 GitHub 用户名指定特定人员，或使用 @me 指定当前用户。 查询 示例 QUALIFIER:USERNAME author:biaochenxuying 匹配 @biaochenxuying 创作的提交。 QUALIFIER:@me is:issue assignee:@me 匹配已分配给结果查看者的议题 @me 只能与限定符一起使用，而不能用作搜索词，例如 @me main.workflow。 3. 高级的搜索📚3.1 按仓库名称、说明或自述文件内容搜索通过 in 限定符，你可以将搜索限制为仓库名称、仓库说明、自述文件内容或这些的任意组合。 如果省略此限定符，则只搜索仓库名称和说明。 限定符 示例 in:name jquery in:name 匹配其名称中含有 “jquery” 的仓库。 in:description vue in:name,description 匹配其名称或说明中含有 “vue” 的仓库。 in:readme vue in:readme 匹配其自述文件中提及 “vue” 的仓库。 repo:owner/name repo:biaochenxuying&#x2F;blog 匹配特定仓库名称，比如：用户为 biaochenxuying 的 blog 项目。 3.2 在用户或组织的仓库内搜索要在 特定用户或组织 拥有的所有仓库中搜索，你可以使用 user 或 org 限定符。 限定符 示例 user:USERNAME user:biaochenxuying forks:&gt;&#x3D;100 匹配来自 @biaochenxuying、拥有超过 100 fork 的仓库。 org:ORGNAME org:github 匹配来自 GitHub 的仓库。 3.3 按仓库大小搜索size 限定符使用 大于、小于和范围限定符 查找匹配特定大小（以千字节为单位）的仓库。 限定符 示例 size:n size:1000 匹配恰好为 1 MB 的仓库。 size:&gt;&#x3D;30000 匹配至少为 30 MB 的仓库。 size:&lt;50 匹配小于 50 KB 的仓库。 size:50..120 匹配介于 50 KB 与 120 KB 之间的仓库。 3.4 按 followers 搜索你可以使用 followers 限定符以及大于、小于和范围限定符基于仓库拥有的关注者数量过滤仓库。 限定符 示例 followers:n node followers:&gt;&#x3D;10000 匹配有 10,000 或更多关注者提及文字 “node” 的仓库。 styleguide linter followers:1..10 匹配拥有 1 到 10 个关注者并且提及 “styleguide linter” 一词的的仓库。 3.5 按 forks 搜索forks 限定符使用大于、小于和范围限定符指定仓库应具有的复刻数量。 限定符 示例 forks:n forks:5 匹配只有 5 个复刻的仓库。 forks:&gt;&#x3D;205 匹配具有至少 205 个复刻的仓库。 forks:&lt;90 匹配具有少于 90 个复刻的仓库。 forks:10..20 匹配具有 10 到 20 个复刻的仓库。 3.6 按 stars 数量搜索你可以使用 大于、小于和范围限定符 基于仓库具有的 星标 数量搜索仓库 限定符 示例 stars:n stars:500 匹配恰好具有 500 个星号的仓库。 stars:10..20 匹配具有 10 到 20 个星号、小于 1000 KB 的仓库。 stars:&gt;&#x3D;500 fork:true language:vue 匹配具有至少 500 个星号，包括复刻的星号（以 vue 编写）的仓库。 3.7 按仓库创建或上次更新时间搜索你可以基于创建时间或上次更新时间过滤仓库。 对于仓库创建的时间，你可以使用 created 限定符； 要了解仓库上次更新的时间，你要使用 pushed 限定符。 pushed 限定符将返回仓库列表，按仓库中任意分支上最近进行的提交排序。 两者均采用日期作为参数。 日期格式必须遵循 ISO8601 标准，即 YYYY-MM-DD（年-月-日）。 也可以在日期后添加可选的时间信息 THH:MM:SS+00:00，以便按小时、分钟和秒进行搜索。 这是 T，随后是 HH:MM:SS（时-分-秒）和 UTC 偏移 (+00:00)。 日期支持 大于、小于和范围限定符。 限定符 示例 created:YYYY-MM-DD vue created:&lt;2020-01-01 匹配具有 “vue” 字样、在 2020 年之前创建的仓库。 pushed:YYYY-MM-DD css pushed:&gt;2020-02-01 匹配具有 “css” 字样、在 2020 年 1 月之后收到推送的仓库。 vue pushed:&gt;&#x3D;2020-03-06 fork:only 匹配具有 “vue” 字样、在 2020 年 3 月 6 日或之后收到推送并且作为复刻的仓库。 3.8 按语言搜索你可以基于其编写采用的主要语言搜索仓库。 限定符 示例 language:LANGUAGE vue language:javascript 匹配具有 “vue” 字样、以 JavaScript 编写的仓库。 3.9 按主题搜索你可以查找归类为特定 主题 的所有仓库。 限定符 示例 topic:TOPIC topic:algorithm 匹配已归类为 “algorithm” 主题的仓库。 估计又有很多人不知道 GitHub 上有话题一说的吧。 3.10 按主题数量搜索你可以使用 topics 限定符以及 大于、小于和范围限定符 按应用于仓库的 主题 数量搜索仓库。 限定符 示例 topics:n topics:5 匹配具有五个主题的仓库。 topics:&gt;3 匹配超过三个主题的仓库。 3.11 使用可视界面搜索还可以使用 search page 或 advanced search page 搜索 GitHub 哦。 这种搜索方式，估计就更少人知道了吧。 advanced search page 提供用于构建搜索查询的可视界面。 你可以按各种因素过滤搜索，例如仓库具有的星标数或复刻数。 在填写高级搜索字段时，你的查询将在顶部搜索栏中自动构建。 3.12 按许可搜索你可以按其许可搜索仓库。 你必须使用许可关键词按特定许可或许可系列过滤仓库。 限定符 示例 license:LICENSE_KEYWORD license:apache-2.0 匹配根据 Apache License 2.0 授权的仓库。 3.13 按公共或私有仓库搜索你可以基于仓库是公共还是私有，以此过滤搜索。 限定符 示例 is:public is:public org:github 匹配 GitHub 拥有的公共仓库。 is:private is:private pages 匹配你有访问权限且包含 “pages” 字样的私有仓库。 3.14 按仓库是否为镜像你可以根据仓库是否为镜像以及托管于其他位置托管来搜索它们。 限定符 示例 mirror:true mirror:true GNOME 匹配是镜像且包含 “GNOME” 字样的仓库。 mirror:false mirror:false GNOME 匹配并非镜像且包含 “GNOME” 字样的仓库。 3.15 基于仓库是否已存档搜索你可以基于仓库是否已存档来搜索仓库。 限定符 示例 archived:true archived:true GNOME 匹配已存档且包含 “GNOME” 字样的仓库。 archived:false archived:false GNOME 匹配未存档且包含 “GNOME” 字样的仓库。 3.16 基于具有 good first issue 或 help wanted 标签的议题数量搜索你可以使用限定符 help-wanted-issues:&gt;n 和 good-first-issues:&gt;n 搜索具有最少数量标签为 help-wanted 或 good-first-issue 议题的仓库。 限定符 示例 good-first-issues:&gt;n good-first-issues:&gt;2 javascript 匹配具有超过两个标签为 good-first-issue 的议题且包含 “javascript” 字样的仓库。 help-wanted-issues:&gt;n help-wanted-issues:&gt;4 react 匹配具有超过四个标签为 help-wanted 的议题且包含 “React” 字样的仓库。 4. 更多技巧其实，以上很多内容的都是来自于 GitHub 的官方文档，如果你还想学习更多技巧，请看 GitHub 官方文档 GitHub Docs： 如果你还不了解或者还不会使用 GitHub ，可以看看这一章节：Git 和 GitHub 学习资源","tags":["GitHub","Search"],"categories":["开发工具"]},{"title":"计算机网络中的各类 IP","path":"/post/计算机网络/network-ip/","content":"相信不少电脑用户都曾遇到过使用 localhost 或 127.0.0.1 或直接输入本机 IP 的场景，看上去这三者都可以访问到本机，那为什么会存在这三种形式呢？它们之间又有什么区别呢？看似简单，其实区别还是较大的。 此外，你可能也对 VPN、公网与私网、网卡与 IP 之间的关系感到困惑，以下为你一一解答。 本机 IP我们电脑主板上都内置了多种网卡，一般主要有以下几类： 虚拟网卡（Loopback） 注意：它是虚拟的，并不是物理网卡，也被称为是本地环回地址（或接口），一般将 127.0.0.1 作为本地环回地址。 有线网卡&#x2F;以太网卡（Ethernet） 这是以太网（局域网）使用的，我们日常说的网卡指的就是这个，插入的就是网线。 无线网卡（WLAN） 这是无线局域网所使用的网卡，笔记本上常内置此网卡，它用的是无线电技术，不需要像以太网卡那样插网线。 以上这些网卡都会绑定一个本机 IP… localhost 是一种特殊的域名首先 localhost 它并不是 IP，而是一种特殊的域名（没有后缀），默认的情况下它解析到的是本地 IP（即 127.0.0.1），主要通过本机的 hosts 文件进行管理，如果你愿意，也可以把 localhost 域名解析到某个公网 IP 上去，也可以被配置为任意的 IP 地址（也就是说，可以通过 hosts 这个文件进行更改），不过通常情况下都（如下）指向： IPv4：表示 127.0.0.1 IPv6：表示 [::1] hosts 文件位置：C:\\Windows\\System32\\drivers\\etc 127.0.0.1 是一种本机保留的私有 IP127.0.0.1 它是一个私有 IP，代表（或者说真正的名称）的就是本机环回地址，其实本质上是绑定在虚拟网卡（loopback）上的 IP。 那什么是环回地址呢？它有什么作用呢？ 环回地址：环回地址是主机用于向自身发送通信的一个特殊地址（也就是一个特殊的目的地址）。 可以这么说：同一台主机上的两项服务若使用环回地址而非分配的主机地址，就可以绕开 TCP&#x2F;IP 协议栈的下层（也就是说：不用再通过什么链路层、物理层、以太网传出去了，而是可以直接在自己的网络层，运输层进行处理了） 网络号为 127 的地址根本就不是一个网络地址，因为产生的 IP 数据报就不会到达外部网络接口中，是不离开主机的包。 所以说：127.0.0.1 是保留地址之一，只是被经常的使用，来检验本机 TCP&#x2F;IP 协议栈而已，如果我们可以 ping 通的话，就说明本机的网卡和 IP 协议安装都没有问题（跟我们当前主机有没有联网没有一点关系）。 事实上 IPv4 保留 127.0.0.0 整个网段的地址用于环回测试（只是有两个特殊的保留），127.0.0.1 只是其中一个，你可以 ping 通这个网段里的所有地址，也可以在浏览器中输入任意一个地址访问本机的 Web 服务。另外一个经常被混淆的 IP 地址是 0.0.0.0，它才是真正意义上的本机地址，它的用法跟 127.0.0.1 完全不同。 举例说明：比如电脑有两块网卡，其中一块使用公网 IP 用于连接互联网，另外一块使用私有 IP 连接局域网，如果本机搭建了 Web 服务，并且希望外网和内网都能正常访问，可以在服务器的配置中将服务器地址改为 0.0.0.0. localhost、本机 IP、127.0.0.1 的区别 网络需求不同 localhost 和 127.0.0.1 并不需要联网访问，即使在无网络环境下访问这两者都能找到本机。 本机 IP 中的有线网 IP 和无线网 IP 都是需要联网后才能正常分配和访问的，它们是本机对外开放的 IP 地址。 localhost 是本机访问；127.0.0.1 是本机访问；本机 IP 是本机或外部访问。 localhost 是域名，默认是指向 127.0.0.1；而本机 IP 就是本机对外放开访问的 IP 地址，这个网址就是与物理网卡绑定的 IP 地址。 在一个局域网里，同一网段（即同一局域网下的同一网段）的其他电脑就可以用上面的 IP 地址来访问你的电脑（私有地址下文介绍）。 网卡地址 &amp; IP地址网卡地址网卡地址即 MAC 地址，意译为媒体访问控制，或称为物理地址、硬件地址，用来定义网络设备的位置。 在 OSI 模型中，第三层网络层负责 IP 地址，第二层数据链路层则负责 MAC 地址。因此一个主机会有一个 MAC 地址，而每个网络位置会有一个专属于它的 IP 地址。 MAC 地址是网卡决定的，是固定的，也是唯一的。形象的说，MAC 地址就如同我们身份证上的身份证号码，具有全球唯一性。 IP 地址IP 地址是指互联网协议地址。IP 地址是 IP 协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。 小结 通俗来讲就是物理地址是指网卡的硬件地址，一般是固化在网卡上的，全球没有任何两块网卡的物理地址是一样的，它具有唯一性！ IP 地址是网络分配给网卡使用的软地址，是可以改变的！ 注：我们可以使用 ipconfig /all 查看 IP 地址和物理地址。 公网 IP 与私网 IP我们可以通过127.0.0.1访问本机，通过私有IP访问局域网内部的其它设备，通过公网IP访问互联网上的其它设备。 公有 IP 地址（公网 IP）组建一个企业级网络，需要去向 “电信运营商 ISP” 申请一个接入 Internet (我们常说的接入网) 的宽带，同时 ISP 还会给我们分配一个或多个 IP 地址，这些 IP 地址可以供我们企业内部上网，这些 ISP 分配给我们的 IP，就是公有 IP。 公有地址（Public address，也可称为公网地址）由 Internet NIC（Internet Network Information Center 因特网信息中心）负责。这些 IP 地址分配给注册并向 Internet NIC 提出申请的组织机构。通过它直接访问因特网，它是广域网范畴内的。 私有 IP 地址（私网 IP）我们企业或家庭内部组建局域网用的 IP，一般都会用私有 IP。 私有地址（Private address，也可称为专网地址）属于非注册地址，专门为组织机构内部使用，它是局域网范畴内的，私有 IP 禁止出现在 Internet 中，在 ISP 连接用户的地方，将来自于私有 IP 的流量全部都会阻止并丢掉。 如果在企业内部的电脑要访问 Internet，则需要在企业边界上用 “NAT 技术” 将私网 IP 转成公网 IP 才能正常的上网！ 公网与私网的访问如果私网 IP 要访问公网网站的话，需要在私网和公网接口处，做 SNAT。 一般我们称运营商搭建的网络为公网，主要负责连接各个公司或者家庭的网络，里面的 IP 都是公网 IP，里面也只会出现公网 IP 组成的路由，因此私网 IP 进到公网后，是没有路由的，会被丢弃，所以上面提到私网访问公网的话，需要 SNAT，把私网 IP 换成公网 IP。 聪明的你肯定会想到，公网要访问私网咋办？这其实涉及到 DNAT、VPN 等技术。 还有就是两个私网要跨公网通信咋办？这可以通过 VPN 解决。 补充：内网的话，可以简单理解为私网，不过其实这个概念的出发点是对于企业而言，在企业内部叫私网，企业外部就叫外网。 从概念上讲一个企业以外的网络，可以包括运营商的网络（即公网），也可以包括其他企业或者家庭的网络（即私网）。 所以说，外网与公网不能化等号的。 但其实也没有那么特意去区分，公网&#x3D;外网，私网&#x3D;内网，可以简单这么理解，没必要去咬文嚼字（但至少还是要懂得我上面说的外网与公网的区别）。 全部 IP 地址的范围IP 地址，一共分成了 5 类，范围分别如下： A类 IP：1.0.0.1 – 127.255.255.254 B类 IP：128.0.0.1 – 191.255.255.254 C类 IP：192.0.0.1 – 223.255.255.254 D类 IP：224.0.0.0 – 239.255.255.255 E类 IP：240.0.0.0 – 255.255.255.255 而其中，能在 Internet 或被用户使用的有 A、B、C 三类，而D类地址称为广播地址，供特殊协议向选定的节点发送信息时用，E类地址保留给将来使用。 特殊的网址： 每一个字节都为 0 的地址（“0.0.0.0”）对应于当前主机； IP 地址中的每一个字节都为 1 的 IP 地址（“255.255.255.255”）是当前子网的广播地址； IP 地址中凡是以 “11110” 开头的 E 类 IP 地址都保留用于将来和实验使用。 IP 地址中不能以十进制 “127” 作为开头，该类地址中数字 127.0.0.1 到 127.255.255.255 用于回路测试，如：127.0.0.1 可以代表本机IP地址，用 “http://127.0.0.1” 就可以测试本机中配置的 Web 服务器。 网络 ID 的第一个 6 位组也不能全置为 “0”，全 “0” 表示本地网络。 公有 IP 地址的范围在 IP 地址 3 种主要类型里，各保留了 3 个区域作为私有地址，也就是比较常用的 IP 地址。其地址范围如下： A 类的公有 IP： 1.0.0.0 ~ 9.255.255.255 11.0.0.0 ~ 126.255.255.255 B 类的公有 IP： 128.0.0.0 ~ 172.15.255.255 172.32.0.0 ~ 191.255.255.255 C 类的公有 IP： 192.0.0.0 ~ 192.168.255.255 192.169.0.0 ~ 223.255.255.255 私有 IP 地址的范围 A 类私有 IP 地址： 10.0.0.0 ～ 10.255.255.255 即 10.0.0.0/8 B 类私有 IP 地址： 172.16.0.0 ～ 172.31.255.255 即 172.16.0.0/12 C 类私有 IP 地址： 192.168.0.0 ～ 192.168.255.255 即 192.168.0.0/16 这些地址是不会被 Internet 分配的，它们在 Internet 上也不会被路由，虽然它们不能直接和 Internet 连接，但通过技术手段仍旧可以和 Internet 通讯（NAT 技术）。我们可以根据需要来选择适当的地址类，在内部局域网中将这些地址像公用 IP 地址一样地使用。在 Internet 上，有些不需要与 Internet 通讯的设备，如打印机、可管理集线器等也可以使用这些地址，以节省 IP 地址资源。 网段 &amp; 局域网网段是指一个计算机网络使用同一层物理层设备（如集线器，交换机）能够直接通信的那一部分，即每台电脑只能和自己同一网段的电脑直接进行通信。 局域网是指由交换机构成的一整个网络系统，局域网内的所有设备一般都处于同一网段，因此可以直接进行通信，但是局域网也可以划分成多个网段，如使用 VLAN。 关于 VLAN 的介绍，可以看这篇博客（强推）：https://info.support.huawei.com/info-finder/encyclopedia/zh/VLAN.html 只有同一局域网内的相同网段的设备才可直接进行通信。所以我的理解，当局域网内只有一个网段时，该局域网就可以等价于网段。 如何区分是否同一网段理解了网段后，我们接下来来讲解下如何判别两网段是否为同一网段。 根据掩码确定 IP 地址网段只需要使用 IP 地址 &amp; 子网掩码即可！ 例 1比如以下两个 IP 地址 IP 地址1：192.168.1.1\t子网掩码：255.255.255.0 IP 地址2：192.168.1.2\t子网掩码：255.255.255.0 我们可以直接的判断，它们是属于同一个 (192.168.1.0) 网段的 IP 地址。 例 2那么对于下面这样的呢？ IP 地址1：192.168.1.1\t子网掩码：255.255.255.0 IP 地址2：192.168.1.2\t子网掩码：255.255.0.0 这两个 IP 地址虽然在不看掩码的情况下，比较像，但他们并不是同一个网段内的。 这可以从子网掩码来判断： IP 192.168.1.1 &amp; 掩码 255.255.255.0 属于 192.168.1.0 网段； 而 IP 192.168.1.2 &amp; 掩码 255.255.0.0 则属于 192.168.0.0 网段。 例 3 IP 地址1：192.168.1.1\t子网掩码：255.255.252.0 IP 地址2：192.168.2.1\t子网掩码：255.255.252.0 很明显，我们这个和上面例1 的 IP 地址是一样的，只是子网掩码不一样，如果不看子网掩码，首先可能就误判它们不是同一个网段。 经过判别，两个 IP 地址都是属于 192.168.0.0 网段，所以它们是同属于一个网段的。 VPN⚠️ 私自架设 VPN 是违法行为！ 这里我们就简单看下维基百科对于 VPN 的介绍： 虚拟专用网（英语：virtual private network，缩写：VPN）是常用于连接中、大型企业或团体间私人网络的通讯方法。它利用隧道协议（Tunneling Protocol）来达到发送端认证、消息保密与准确性等功能。 历史20 世纪 90 年代，计算机网络上的计算机通过非常昂贵的专线和&#x2F;或拨号连线互连。视站点间的距离，花费可达数千美元（56 kbps连线）或上万美元。 为了避免租用多条各自连接互联网的专线，因为虚拟专用网可减少网络开支，用户可以安全地交换私密数据，虚拟专用网变得普及，使昂贵的专线变得多余。 安全性安全的虚拟专用网使用加密穿隧协议，通过阻止截听与嗅探来提供机密性，还允许发送者身份验证，以阻止身份伪造，同时通过防止信息被修改提供消息完整性。 某些虚拟专用网不使用加密保护数据。虽然虚拟专用网通常都会提供安全性，但未加密的虚拟专用网严格来说是不“安全”或不“可信”的。例如，一条通过 GRE 协议在两台主机间创建的隧道属于虚拟专用网，但既不安全也不可信。 除以上的 GRE 协议例子外，本地的明文穿隧协议包括 L2TP（不带 IPsec 时）和PPTP（不使用微软点对点加密（MPPE）时）。 协议常用的虚拟专用网协议有： PPTP L2TP IPsec SSL VPN WireGuard OpenVPN IKEv2 使用许多公司企业的员工等使用虚拟专用网（VPN）来访问其内部的网络，以达到远程办公的作用。 在中国，由于中国大陆境内对海外网络的限制及屏蔽，中国大陆兴起以采用虚拟专用网连接外国网络的突破网络审查方法，俗称翻墙。许多外资公司、学术单位因欲连回海外网站，也多自行架设 VPN 或采用付费的 VPN 服务。 📚补充根据《国务院关于修改〈中华人民共和国计算机信息网络国际联网管理暂行规定〉的决定》第六条规定： 计算机信息网络直接进行国际联网，必须使用邮电部国家公用电信网提供的国际出入口信道。 任何单位和个人不得自行建立或者使用其他信道进行国际联网。 万万不可跨越法律底线自行架设 VPN！！！ 更多关于 VPN 的内容：https://zhuanlan.zhihu.com/p/402715597","tags":["网络","IP"],"categories":["计算机网络"]},{"title":"本科生如何才能进入 BAT 等一流互联网大厂","path":"/post/未来世界的幸存者/how-can-undergraduates-enter-bat/","content":"分几点讲讲，校招最重要的素质都有哪些。 01首先是项目经历。在国内找工作，尤其是非微软、谷歌等外企的情况下，这往往是重中之重。 当然，作为本科生，尤其是处于正在找实习阶段的本科生，这点要求可以相对放缓。 在最理想的状态下，你应该讲出能够让面试官听懂的、让面试官觉得你牛逼且方向对口的项目。这三点按重要程度从高到低排序。 ⭐你做的事情应该能够让面试官听明白，这是最低也是最重要的一个要求。 项目 low 不要紧，哪怕是讲课程设计，也聊胜于无。把话说清楚就行。毕竟哪怕项目不合心意，面试官还是可以转而从你扎实的专业基础或是灵活的解题思路上寻找亮点。 面试终究是发生在人与人之间的一种羁绊。问答与交流只是一种手段，对于求职者而言，终极目的还是为了调动面试官的情绪，建立对自己的正面印象。 能让面试官对自己产生钦慕之心，自然是最高的追求。反过来讲，面试很忌讳在两人之间形成一种微妙的龃龉。 一个没给人家讲明白的项目，就像聊天群里除了你以外没人 get 到点的冷笑话般尴尬。不但没有意义，兴许还会产生负面作用。 作为未来同事的候选人，面试官难免要因此质疑一下你的交流沟通能力能否 Hold 住可能的项目合作与交接。 说到这里突然想起一个很多搞竞赛的同学会遇到的尴尬面试题：总会有一些不知道 ACM 竞赛有几个人组队的 b 面试官，在你做完自我介绍以后，冷不丁上来就让你直接给讲一个在 ACM 里做过的最难的算法题。 毕竟术业有专攻，面试官不懂不能强求，这不是他的过错。 可有些比较实在的同学，这时候就会真的给上一个爆难的算法题来维护竞赛选手的尊严。大致讲一遍解题流程，他不懂。 接着细讲… 结果四十分钟过去了，你会发现你们还在绕预处理数据时用到的一个小结论是怎么来的。面试官看时间到了，就客客气气请你回去等消息，换下一位进门~ 这样的故事我听多了，反正至今还不知道有谁在这种情况下最后面试通过的 XD。 毕竟生活在这世界上，谁都不是一座孤岛；没有理解也就没有爱。面试也是同理。 02然后是，你需要面试官觉得你牛x 如前面所说的，这种牛逼构筑于被理解的基础之上，是项目经历的核心所在。 牛逼这个词其实微秒，说复杂也复杂。 但说到底仍然是一种情绪、一种主观的印象。举个不恰当的、极端的例子：一个好项目，如果是放在一本学生身上，面试官自然会认为你优秀。但如果是个三本出身的倒霉孩子做的，也许面试官可以留下更为深刻的印象。 你的项目最好在被面试官充分地展开、理解之后仍然被认为是复杂的。 这种复杂性可能涉及艰辛的公式推导、精巧的代码结构或是用上了炫酷而繁琐的技术特性。这些都是相对客观的指标。 然而互联网嘛，技术栈划分细、变化快。 老道的面试官并不特别关心你做过什么，他会转而透过你的这段项目经历，去观察、揣摩你的智力、好奇心以及执行力分别到达了怎样的程度。 ⭐这里我的建议是：分配好精力。花大量时间，精心准备一个 “牛逼” 的项目。 毕竟，在这个复杂的世界里，一个就够了。 事实上你那几十分钟面试时间里也就够你们详谈一个项目。 人的错觉有很多种，第一印象的效应尤为明显。 又或是八二原理、马太效应、路径依赖…… 作为一个有志于盅惑人心的面试者，你得把自己想象成是一个剑客，十步杀一人、光速出剑、一击毙命。 只要心够决，去把一个项目做好、做深、做到极致。做完以后再深入了解项目细节，包括上游客户需求、下游开源工具特性和原理、可行优化方案以及后续可能的开发方向。 这是你的使命，只能一次成功，不容许失败。 举个例子，记得 15 年的 7 月份那会有一篇爆款论文，关于如何利用神经网络训练一个转换艺术风格的迁移学习模型。 如果你作为一个两个月后找算法工作的大三本科生，那么把论文细细读了，公式全部会推，写靠谱代码把项目做好。 在面试前再把相关算法原理跟实践中遇到的困难以及你攻坚克难的过程耐下性子理清楚、面试的时候讲明白。 是不是显得很有含金量、很能体现个人动手能力与技术好奇心、在一群连基本的 k-means 都写不好的校招生中，陡然间鹤立鸡群了？ ⭐除了让面试官理解你牛以外，方向对口也重要。 毕竟校招统一面试，如果没有恰到好处的内推，往往是需要部门主动捞你简历约面试的。 又比如过了谷歌的面试，后续也还是需要做 team match。 很多时候去哪不是你说了算，而是你的简历起决定性作用。另外方向对口对于面试本身的重要性更不必多说。就算是校招，相同水平下谁都更想找熟练工吧。 所以你得提前很久想清楚自己想干什么，提前做准备。 找工作这件事很多时候是蝴蝶效应。也许偶然帮老师做了个项目，然后主要靠这个项目找了个实习接着做相关方向，最后的正式校招就很可能这么一直续下去。 最好从一开始就要不将就。 有道是：Fuck everything, but growth. 想清楚做什么才是有用、有效率的。 比如本科毕业就打算工作的，如果真的想做机器学习算法，那么我认为极端情况下，宁愿去有活力的小公司做算法岗，也别去谷歌做前端实习。 其实一次实习的机会成本还是挺高昂的，而实习的 title 在最后的校招中也未必如你想象得那么有用。 我个人曾因为在微软实习的项目相对零散而兴趣不相关，在去年校招的过程中甚至直接将这一段实习经历删掉，以避免与面试官在这一点上陷入尬聊的窘境。 然后是专业基础知识。 正常情况下外企在这里不会做太多要求。 而 BAT 三家都会考察基础知识，且各有侧重面，这个你们具体还是要看面经。 不同考察方向都有哪些常见知识点，你们随便一搜都有。 最好能结合之前的专业课所学，在具体的面试知识点上深入下去，了解细节。 当然大学前几年能把计算机组成原理、计算机网络以及操作系统等几门专业课基础先打牢了，会好很多。 我承认，本科的 CS 教育往往扯淡，但是我建议该上的课还是应该上一下的，哪怕自己跟着书本自学。不去上课，你的自制力恐怕没有想象中那么强。 这些基础课程对以后的职业生涯会有潜移默化的影响。 毕竟，计算机上的设计思想，很多地方都是可以互相借鉴的，这些知识会成为你以后解决工作中遇到的棘手问题的灵感来源。 而且这部分知识都是成体系的，等工作了以后就没有整块时间去啃了。 劝君惜取少年时！ ⭐面试中所涉及的另一个重要部分是算法题、代码题，以及一些智力题。 面试时间有限，问到的题目都不会太难的。当然也看候选人背景，经历以竞赛为主的就会给难一些的 —— 不会涉及太繁琐的分析，往往只需要你灵机一动。 这里还是有一些技巧的。 不太好用语言表述出来，就像乒乓球一样，要在实践中练习击球的感觉。 所以多争取面试机会很重要，尽量适应面试氛围，从而避免紧张而产生智商滑坡的情况。 面试算法题、思维题，也是一种测试团队协作能力的方式。 面对算法题，有经验的人往往会建议你，不要急着给出最优解，先讲基本方法，可以暴力一点，然后慢慢优化。这很有道理。 其实最好能按一定的节奏来一步步地展现你的思考过程，甚至遇到不太会聊的面试官你得自己学会去引导，掌控面试的节奏。 甚至有的时候，你给讲一些你觉得很靠谱的思考路线，面试官也会主动提醒你，想歪了。 或是另一种情况，饶有兴致地陪着你按照新思路想下去，最后不论是否能解决问题，往往都会觉得你想法不错，是个面试加分项。 实在没有好思路的情况下，试探性地讲些模糊的大体思路也比过久的沉默要好。 哪怕随便瞎讲点什么，面试官兴许会提点你一下，继续观察你接下来的表现。 用考场上的话来讲，面试中要学会尽量拿到步骤分。 如果你以一个人冥思苦想的方式玩命怼一道难题而不得，中间过程一言不发，那么好比是考试交白卷。 03最后，在校招前，争取做一份实习。 如果你在武大国软这种自由放浪的环境下，从大一开始出去实习，到校招前实习个四五次完全存在理论上的可能性。 实习次数多了，你也就可以循序渐进地换更好的公司，跟更牛逼的同事做更牛逼的项目。至于结识朋友、邂逅妹子、开阔视野什么的更不在话下。 而对于大部分中规中矩度过前三年本科生涯，基本功还算扎实的同学来说，大三暑假的实习期将会是一个补充项目经历的大好机会。 最好能争取一个稍有难度的、相对独立的项目好好做。这是你将来的几个月冲刺校招的主要资本之一。 04这些话很想讲给多年前的我自己听，但是不现实了。沉舟侧畔千帆过，现在我把积淀后的思想赠予你们。 首先，快速迭代自己的方法论。 很多孩子在刚上大学的时候，因为太习惯于被父母老师安排的人生，往往只重视战术，不懂得经营发展战略眼光。 大局观很重要。有的时候只是只言片语，一点小小的信息素，就有四两拨千斤的效果。 人与人之间在判断力上的差距其实很重要。在一些关键的决策点上，如果能稍微提高百分之一的准确率，乘上可能的潜在收益或是损失，都会是很大的数学期望值。 记得学长的一次讲座，提问环节的时候我问他，在曾有 FB 面试机会的情况下，直接去 CMU 读书，是否考虑过不妥。 他说，这是他人生最后悔的决定之一，如果早入职几年，存在获得数百万美刀期权的可能性。 如果让现在的我回到大学报到的时候，大概会出去做很多次实习、多认识很多朋友、去折腾很多奇怪的项目，甚至刷语言绩点准备出国。 可是那时的我什么也不懂，这种状态持续了好几年。现在回想起来，本科时代的大部分事情我都做错了，做对的判断只是少数。 从个人角度出发，如何高效率地获取信息以及反刍，也是一个很有意思的课题。 举个例子，你可以考虑挑选一定数量的靠谱微信公众号来了解互联网信息，不要多，控制在每个公众号的推送都能定期读完的关注规模。 当然，其实互联网圈的媒体人写东西都有点虚浮，对不同的观点你要有自己审慎的判断。 上述的例子只是抛砖引玉。其实解决信息不对称，甚至是构筑自己相对于常人的信息壁垒，仍然有很多可行的方法有待探索。 年轻人可以多尝试、多试错。毕竟年轻没有失败，等级低就是复活快！ 其次就是：不要怂。 这一点我深有感触。尤其是针对学 CS 的孩子来说，很重要。 这个专业出身的同学，往往家里不是很富裕，见识不够广，不够自信。 甚至有些还会因为过于敏感多思，反而过于独善其身，存在与人交流的障碍，又或是做事情瞻前顾后、缺乏决断，聪明反被聪明误。 我也见过很多人，当本可进取时，却故作谦卑，因为不愿承担过大的心里压力，错过了唾手可得的面试、出国、比赛机会。 我在读大学以前，一度非常自闭，不爱与人说话。 这几年下来改变了很多，虽然仍有轻微的社交恐惧症，但只是面对陌生人会有点难受，正常交谈是没有问题了。 事实上我心里清楚，我是花了大力气来打磨自己在这方面的性格缺陷的。 我常常分析，为什么会对他人感到恐惧呢。 后来发现，因为我总是习惯性地在潜意识里预设，他人、或是某个外部事物是完美的。 但经历了很多之后又发现，没有什么是完美的，均值回归是普遍存在的现象。 事物的诸多美好品质之间并不存在绝对的因果关系，往往只是弱相关。 高大上的互联网公司、遗世独立的牛人、狂拽酷炫的技术，只是世人所见的一个片面。哪怕是那天上的月亮，也有圆缺，存在暗面。 本该是不卑不亢的平等交流，却因为过分谨慎而表现得小心翼翼、唯唯诺诺；我也曾因此错过了爱情。 ⭐最后，一定要有自己的追求。 这点见仁见智，不强求。像大多数人一样，我也总是在思考，人生的意义是什么。 成长的过程中，我发现身边的大环境是，总是会预设一个最优路径。 比如，中学时代大家的注意力都在高考上，觉得上了好大学就可以万事大吉。 搞竞赛的同学容易认为打好 ACM 就可以获得一切。 CS 专业的同学整日想法设法地想要进 BAT、谷歌。投资人对共享单车、共享充电宝这些项目趋之若鹜、蜂拥而上。 然而，名校是终点吗？ACM World Final 是终点吗？Google 优雅舒适的工作环境里和身为谷歌员工的逼格是终点吗？ 无论是成绩突出的高中学霸，还是表现优异的大学生，在获得了满意的结果，进入人生的下一个阶段以后，还是会有很多感到迷茫。 像艘驶入无人深空的太空飞船那样迷失了方向。 或许从一开始我们就错了，不该过分执迷于一个成就、一个被预设为完美，得到之后却终究归于平淡的的 title。 叔本华说，人生就是在痛苦和无聊这二者之间像钟摆一样摆来摆去：当你需要为生存而劳作时，你是痛苦的；当你的基本需求满足之后，你会感到无聊。 我想，人生本来没有意义，痛苦欢快不过是虚幻。 而创造，是生而为人的唯一救赎。 Stay hungry, stay foolish. 共勉！","tags":["大厂"],"categories":["未来世界的幸存者"]},{"title":"About","path":"/about/index.html","content":"About MeI am an M.S. student in the Department of Software Engineering at the School of Informatics, Xiamen University. My research interests include data deduplication and storage system. Here is the CV. Education M.S. in Software Engineering, Xiamen University (2023-Present) B.S. in Software Engineering, Fujian Normal University (2019-2023) Experience Platform Software Development Center, OPPO (Xi’an, 2024) Intelligent Software Research Center, ISCAS (Beijing, 2024) Zhejiang-Suiyuan Joint Innovation Research Center, Zhejiang Lab (Hangzhou, 2023) Awards 2024年英雄联盟全球总决赛冠军 2022年奥林匹克杯得主 2008年感动中国特别奖获得者 2006年时代周刊年度风云人物 Yikun Wu我终于活到了小时候最羡慕的年纪，却没有成为小时候最想成为的人。毕业之后的我一直在害怕自己没出息，害怕自己买不起房子车子，遇不到喜欢自己的人，每次过年回家面对什么时候结婚，什么时候要孩子这种话题，其实更害怕的是面对许久不见的父母。我只是普通家庭的孩子，我只想让自己的爸爸妈妈更自豪一些，更幸福一些。可我自己的幸福都还像个石子，在生活的湖面上打着水漂。这么多年上学上过来，努力地学习，考试，可到最后才发现，普通的孩子只是聚光灯下的基石。想想这些年，我有很多以为近在咫尺的时候，我努力地抓啊抓，可就是什么都抓不到。再多的书也比不上让导师满意的汇报和恰到好处的谄媚。我一边和自己的妈妈保证说，以后我一定会有出息的，一边成晚成晚的睡不着觉。这样的场景太多了，多到我觉得每一场跌宕起伏的人生经历总是会有个这样毫不意外的结局。 爬到山顶的时候，跑向海边的时候，以为我不再是我的时候。 我总以为山顶的石头不一样，升起的太阳不一样。 我总以为海边吹的风不一样，尽头的那边不一样。 我以为我不再是我，我爱她，她也爱我。 可惜，山还是山，海还是海。 我拥有很多人情绪崩溃的瞬间，他们有的在我身边，有的靠互联网奇缘。我没有和其中的任何一个人有过合照，有一起吃过一顿饭，没有听到过他们的声音，也没有听太多他们的故事。我只是短暂地让他们靠了一下岸。 而当生活的节奏反复无常，日历上的时间不断反转，我总是会在人生的重要时刻丧失无穷无尽的仪式感。我常觉得所有人都是被上了锁的自由花，偶尔被阳光照耀的时候会觉得自己配的上很多东西。像是野马找到了河边的水，牵牛爬上了缺角的屋檐。我很难分辨压在自己身上的到底是挡住眼睛的石头，还是粘住了后背的五指山。任何一种喘不过来气的定义都被他人掌控，我带着面罩，别人掐着氧气管。等到自己坚持不住的那一刻，很难说是呼吸的缺失，还是自己早就病入膏肓。 好多事情想不明白，只能先活着，看以后能不能想明白了。 人人都得活着，所以人人都得藏着。我偶尔就在这样沉默的冰河之下，悄悄探出头来，感受下有温度的太阳。然后再沉下去，告诉别人海面之上的故事。 Life 音乐书籍好物电影游戏她公益编程运动旅游朋友我热爱音乐，喜欢华语、粤语、民谣，尤其是 Jay Chou、Eason 与 Taylor Swift 歌手 Jay Chou Jay Chou - Album NetEaseMusic·2024 NetEaseMusic·2023 《Linux 系统编程手册》《操作系统 原理与实现》《操作系统导论》《还原操作系统真象》《穿越操作系统迷雾》《计算机体系结构量化研究方法》《C++ Primer》《C++20 高级编程》《STL 源码剖析》《图解 TCP/IP》《图解机器学习》《图解深度学习》《深度学习》《机器学习》《机器学习数学原理》《Effective C++》《设计数据密集型应用》《高性能 MySQL》《编码 隐匿在计算机软硬件背后的语言》 《红书》《罪与罚》《文城》《兄弟》《许三观卖血记》《焦虑的人》《我的阿勒泰》《阿勒泰的角落》《乌合之众》《瓦尔登湖》《城南旧事》《福尔摩斯探案·全集》《东野圭吾·全集》《埃隆马斯克传》《挪威的森林》《撒哈拉的故事》《中国通史》《中国近代史》《置身事内》《务虚笔记》《病隙碎笔》《我与地坛》《黄金时代》《理想国》《沉思录》《生死疲劳》《人生的枷锁》《我们仨》《面纱》《人生》《月亮与六便士》《活着》《刀锋》《百年孤独》《直视骄阳 · 征服死亡恐惧》《中华人民共和国民法典》《人性的弱点》《沉默的大多数》 《悉达多》《被讨厌的勇气》《恋爱必修课》《分布式系统概念与设计》《深入浅出SSD》《穷爸爸与富爸爸》《小懒财富自由之路》《小狗钱钱》《MySQL 必知必会》《现代操作系统》《计算机网络自顶向下方法》《LINUX 私房菜》 松下 Lumix S5M2 + 50mm 定焦镜头 iPhone 16 Pro 128G 佳沃 JAVA 公路自行车鱼雷 SILURO6-TOP-7120 AirPods 4 DJI Mavic 4 Pro DJI RS 4 Mini Osmo Action 5 Pro DJI Mini 3 妙控鼠标 Apple Watch Series 10 iPhone 13 256G AirPods Pro 2 MacBook Air 13.6英寸 M2 8核 16G+512G iPad Air 10.9英寸 64G Jay Chou 15 张实体专辑 + CD 机 狂飙 301_横版 FL（主板） + DHS 39 度 2.15（正） + MOON 月球（反） RAIN75 客制化机械键盘 + 碧纹水行键帽 小米体脂秤 民谣吉他 悬疑片爱好者 让子弹飞海边的曼彻斯特白日梦想家当幸福来敲门爱乐之城美国往事死亡诗社我的阿勒泰海上钢琴师囚徒新世界釜山行坏家伙们冠军与神同行恶人传犯罪都市 1~4罪恶的编年史邻里的人们愤怒的黄牛邻居信条大卫·戈尔的一生恐怖游轮一级恐惧玩命记忆洛城机密控方证人 人生大事触不可及绿皮书遗愿清单楚门的世界调音师飞驰人生 1~2西虹市首富抓娃娃羞羞的铁拳这个杀手不太冷静独行月球头文字 D不能说的秘密唐探 1900哪吒 1~2功夫熊猫 1~3名侦探柯南剧场版全系列天空之眼动物世界十二怒汉悬崖之上惊天魔盗团 1~2通勤营救秘密访客寻梦环游记王牌特工搏击俱乐部 爆裂鼓手源代码无双士兵突击周处除三害阿甘正传三傻大闹宝莱坞利刃出鞘狙击电话亭催眠·裁决网络谜踪嫌疑人 X 的献身猫鼠游戏泰坦尼克号华尔街之狼盗梦空间禁闭岛机械师 1~2人之怒蜂鸟特工养蜂人家园防线帕克无限杀机神秘巨星摔跤吧爸爸未知死亡无人生还匆匆那年十二生肖新警察故事 尼罗河上的惨案误杀 1~2反贪风暴 1~5肖申克的救赎唐人街探案 1~3扫毒魔警追龙 1~2人潮汹涌使徒行者 1~3看不见的客人七宗罪明日边缘东方快车谋杀案我是谁: 没有绝对安全的系统听说乘风破浪破风激战翻滚吧阿信邪不压正热带往事湄公河行动危城中国机长你的名字天气之子你好世界大鱼海棠铃芽之旅 钻石 超凡大师 我一直以为，我已经放下过去了，直到最近有一天我梦见她 我忘了她长什么样子，但我知道是她，我和她在高中的桌子上背靠着背坐着 我忘了是为什么，忘了和她说了什么，也忘了结局是什么，在醒来后，我只记得这个场景 但有种说不出的感受，没有多么伤感，也没有多欣喜，像记忆里被砍去了一块，好比放满书的书架，突然有一天你发现有个地方少了一本书，你忘记了少的是什么书，也或许这本书早就丢了，或许你早就不看这本书了，书里的内容早就没用了，但那个缺口却永远留在了哪里，你永远能发现这里确实少了一本书 回忆会陪你一生，即使再模糊，你还是忘不掉 有些事并不是一件需要被解决的事情，而是一件需要被接受的事情，或者说，绝大多数的事情，都只是需要接受的事情，你解决不了 比如在地球 online 度过的这二十来年来看，目前我就这样一人，改变的话起码要拿年来衡量，或者十年来衡量人情冷暖，生离死别，固然让人痛苦与无奈，而贫穷则可能让人失去希望。我的理想不伟大，只愿年过半百，归来仍是少年，希望还有机会重新认识这个世界，不辜负这一生吃过的苦。最后如果还能做出点让别人生活更美好的事，那这辈子就赚了。 2025 年 5 月 27 日公益一周年纪念公益一周年纪念2024 年 12 月 30 日四季壁纸2024 年 8 月 27 日三个月达成2024 年 5 月 27 日梦开始的地方GitHub LeetCode2025 2024 2023中学的时候喜欢看意林之类的杂志，里面的作者用乱七八糟的理由跑去旅游，然后说 “阻碍你脚步的永远只有逃离的勇气和对生活的热爱”。 我觉得太对了，可惜 12306 付款方式里没有勇气和热爱，不知道是不是下了盗版。 足迹 2025 年 6 月 14 日福建·福州https://wu-yikun.github.io/post/%E6%91%84%E5%BD%B1%E6%97%A5%E5%BF%97/fuzhou_2025-06-14/2024 年 11 月 29 日广东·广州https://wu-yikun.github.io/post/%E6%91%84%E5%BD%B1%E6%97%A5%E5%BF%97/guangzhou_2024-11-29/2024 年 10 月 30 日漳州·东山岛https://wu-yikun.github.io/post/%E6%91%84%E5%BD%B1%E6%97%A5%E5%BF%97/dongshandao_2024-10-30/2024 年 10 月 1 日福建·福州https://wu-yikun.github.io/post/%E6%91%84%E5%BD%B1%E6%97%A5%E5%BF%97/fuzhou_2024-10-01/2024 年 7 月 27 日宁夏·银川https://wu-yikun.github.io/post/%E6%91%84%E5%BD%B1%E6%97%A5%E5%BF%97/yinchuan_2024-07-27/2024 年 7 月 14 日四川·成都https://wu-yikun.github.io/post/%E6%91%84%E5%BD%B1%E6%97%A5%E5%BF%97/chengdu_2024-07-14/2024 年 6 月 24 日陕西·西安https://wu-yikun.github.io/post/%E6%91%84%E5%BD%B1%E6%97%A5%E5%BF%97/xi'an_2024-06-24/2024 年 6 月 15 日浙江·杭州https://wu-yikun.github.io/post/%E6%91%84%E5%BD%B1%E6%97%A5%E5%BF%97/hangzhou_2024-06-15/2024 年 5 月 1 日漳州·南靖土楼https://wu-yikun.github.io/post/%E6%91%84%E5%BD%B1%E6%97%A5%E5%BF%97/zhangzhou_2024-05-01/2024 年 1 月 28 日福建·泉州https://wu-yikun.github.io/post/%E6%91%84%E5%BD%B1%E6%97%A5%E5%BF%97/quanzhou_2024-01-28/2023 年 12 月 24 日福建·厦门https://wu-yikun.github.io/post/%E6%91%84%E5%BD%B1%E6%97%A5%E5%BF%97/xiamen_2023-12-24/2023 年 10 月 27 日广东·深圳https://wu-yikun.github.io/post/%E6%91%84%E5%BD%B1%E6%97%A5%E5%BF%97/shenzhen_2023-10-27/2023 年 6 月 14 日福州·毕业季https://wu-yikun.github.io/post/%E6%91%84%E5%BD%B1%E6%97%A5%E5%BF%97/fjnu_2023-06-14/2023 年 4 月 28 日浙江·杭州https://wu-yikun.github.io/post/%E6%91%84%E5%BD%B1%E6%97%A5%E5%BF%97/hangzhou_2023-04-28/2023 年 4 月 4 日湖北·武汉https://wu-yikun.github.io/post/%E6%91%84%E5%BD%B1%E6%97%A5%E5%BF%97/wuhan_2023-04-04/我一直是个很悲观的人，也没什么安全感，我走在一直变强的路上，我现在有能力屏蔽掉许多坎坷，但终有一天，我会遇到迈不过去的门槛，压抑不了的负面情绪。我始终会想，这时候，谁还会在我身边，我希望大家都在，但这个显然太过天真了，我现在给不出答案，但其实与人的每一次相遇我都在想，TA 会怎么做。 我这人从很小的时候就争强好胜，我一直以为是我自己赢了，直到有一天看着镜子，才知道自己输了。在我最美好的时候，我最在意的人都不在我身边。我的很多值得交心的朋友，在我决定敞开心扉的时候，早就不在我身边了。从认识我到对我失望，到底需要多长时间，我每认识一个朋友，就会在心里想一遍这个问题。如果几年前你问我会不会害怕失去而逃避未来的相遇，我会回答是的，但现在不会是。因为我已经失去过很多了，不再差这点了。 我很重感情，这是优点也是弱点。 反正这个世界挺没意思的，要是没了我那几个朋友，就更没意思了。 我由衷感谢那些还陪在我身边的好朋友们。 We 节选 Mutual Encouragement 送东阳马生序余幼时即嗜学。家贫，无从致书以观，每假借于藏书之家，手自笔录，计日以还。天大寒，砚冰坚，手指不可屈伸，弗之怠。录毕，走送之，不敢稍逾约。以是人多以书假余，余因得遍观群书。既加冠，益慕圣贤之道。又患无硕师名人与游，尝趋百里外，从乡之先达执经叩问。先达德隆望尊，门人弟子填其室，未尝稍降辞色。余立侍左右，援疑质理，俯身倾耳以请；或遇其叱咄，色愈恭，礼愈至，不敢出一言以复；俟其欣悦，则又请焉。故余虽愚，卒获有所闻。当余之从师也，负箧曳屣行深山巨谷中。穷冬烈风，大雪深数尺，足肤皲裂而不知。至舍，四支僵劲不能动，媵人持汤沃灌，以衾拥覆，久而乃和。寓逆旅，主人日再食，无鲜肥滋味之享。同舍生皆被绮绣，戴朱缨宝饰之帽，腰白玉之环，左佩刀，右备容臭，烨然若神人；余则缊袍敝衣处其间，略无慕艳意，以中有足乐者，不知口体之奉不若人也。盖余之勤且艰若此。今虽耄老，未有所成，犹幸预君子之列，而承天子之宠光，缀公卿之后，日侍坐备顾问，四海亦谬称其氏名，况才之过于余者乎？今诸生学于太学，县官日有廪稍之供，父母岁有裘葛之遗，无冻馁之患矣；坐大厦之下而诵诗书，无奔走之劳矣；有司业、博士为之师，未有问而不告、求而不得者也；凡所宜有之书，皆集于此，不必若余之手录，假诸人而后见也。其业有不精、德有不成者，非天质之卑，则心不若余之专耳，岂他人之过哉！东阳马生君则，在太学已二年，流辈甚称其贤。余朝京师，生以乡人子谒余，撰长书以为贽，辞甚畅达。与之论辨，言和而色夷。自谓少时用心于学甚劳，是可谓善学者矣。其将归见其亲也，余故道为学之难以告之。谓余勉乡人以学者，余之志也；诋我夸际遇之盛而骄乡人者，岂知予者哉！宋濂[明] Latest News"},{"title":"現在可公開な情報","path":"/documents/index.html","content":"C++ C++ 并发编程实战.pdf Is Parallel Programming Hard.pdf Linux&#x2F;UNIX 系统编程手册（上、下册）.pdf Optimizing Software in C++ When Nanoseconds Matter: Ultrafast Trading Systems in C++ C++ 八股文｜GitHub C++ 八股文｜牛客版 C++ 八股文｜代码随想录版 Distributed System Distributed Systems.pptx Golang Go 入门指南.pdf Go 语言圣经.pdf Go 专家编程.pdf Go 语法树入门.pdf Go 语言 101.pdf Go 语言学习笔记.pdf Go 语言编程.pdf Go 语言高级编程.pdf Go Web 编程.pdf LeetCode LeetCode 101 - A LeetCode Grinding Guide (C++ Version).pdf LeetCode-CookBook (Golang).pdf Academic Research FAST 2022—25 Years of Storage Research.pdf Systems and Papers.pdf The Most Common Habits from more than 200 English Papers written.pdf 上海交通大学学生生存手册.pdf 中国计算机学会推荐国际学术会议和期刊目录-2019.pdf 中国计算机学会推荐国际学术会议和期刊目录-2022.pdf 向量数据库·科普.pptx 存储系统研究的一些体会与经验-清华大学汪庆.pdf 科学研究与学术论文写作基础-于静.pdf 科技论文写作 LaTeX.pptx 问题驱动研究 By Yuanyuan Zhou.ppt GeekTime 极客时间上几乎所有的课程 链接: https://pan.baidu.com/s/120Xc94ZvaikXjpHDSgT68g?pwd=kxbd 提取码: kxbd Civil Servant 26 考公资料：包含粉笔 980 以及其他公考名师课程与事业单位备考资料 链接: https://pan.baidu.com/s/1jfb_IkLjDK4wC5Rc2lgQnQ?pwd=1pac 提取码: 1pac 2026 福建选调备考一本通.pdf 26 版本国考讲义.pdf 2025 公务员考试｜厦大专场.pptx 厦门大学信息学院福建选调交流分享会__叶苏航.pdf Jay Chou Jay Chou 所有专辑的 .mp3 音乐包 链接: https://pan.baidu.com/s/1U53SlT2-IYwIeRDFKvRwjA?pwd=ss8d 提取码: ss8d 未完待续…","tags":[null,null,null]},{"path":"/documents/civil-servant/README.html","content":"26 考公资料：包含粉笔 980 以及其他公考名师课程与事业单位备考资料 链接: https://pan.baidu.com/s/1jfb_IkLjDK4wC5Rc2lgQnQ?pwd=1pac 提取码: 1pac"}]